2022-09-11 12:10:11 [INFO ]  ======================================== 2022-09-11 12:10:11 ========================================
2022-09-11 12:10:11 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-09-11 12:10:11 [INFO ]  Options: 
2022-09-11 12:10:11 [INFO ]  	base_dir: null
2022-09-11 12:10:11 [INFO ]  	batch_size: 1024
2022-09-11 12:10:11 [INFO ]  	checkpoint_interval: 10
2022-09-11 12:10:11 [INFO ]  	dataset: SVHN
2022-09-11 12:10:11 [INFO ]  	dataset_labels:
2022-09-11 12:10:11 [INFO ]  	- 0
2022-09-11 12:10:11 [INFO ]  	- 1
2022-09-11 12:10:11 [INFO ]  	- 2
2022-09-11 12:10:11 [INFO ]  	- 3
2022-09-11 12:10:11 [INFO ]  	- 4
2022-09-11 12:10:11 [INFO ]  	- 5
2022-09-11 12:10:11 [INFO ]  	- 6
2022-09-11 12:10:11 [INFO ]  	- 7
2022-09-11 12:10:11 [INFO ]  	- 8
2022-09-11 12:10:11 [INFO ]  	- 9
2022-09-11 12:10:11 [INFO ]  	dataset_normalization: !!python/tuple
2022-09-11 12:10:11 [INFO ]  	- !!python/tuple
2022-09-11 12:10:11 [INFO ]  	    - 0.4379104971885681
2022-09-11 12:10:11 [INFO ]  	    - 0.44398033618927
2022-09-11 12:10:11 [INFO ]  	    - 0.4729299545288086
2022-09-11 12:10:11 [INFO ]  	- !!python/tuple
2022-09-11 12:10:11 [INFO ]  	    - 0.19803012907505035
2022-09-11 12:10:11 [INFO ]  	    - 0.2010156363248825
2022-09-11 12:10:11 [INFO ]  	    - 0.19703614711761475
2022-09-11 12:10:11 [INFO ]  	dataset_root: ./data/svhn
2022-09-11 12:10:11 [INFO ]  	decay_epochs: 50
2022-09-11 12:10:11 [INFO ]  	decay_factor: 0.1
2022-09-11 12:10:11 [INFO ]  	device_id: 0
2022-09-11 12:10:11 [INFO ]  	distill_epochs: 1
2022-09-11 12:10:11 [INFO ]  	distill_lr: 0.02
2022-09-11 12:10:11 [INFO ]  	distill_steps: 1
2022-09-11 12:10:11 [INFO ]  	epochs: 200
2022-09-11 12:10:11 [INFO ]  	expand_cls: false
2022-09-11 12:10:11 [INFO ]  	forgetting_dataset: null
2022-09-11 12:10:11 [INFO ]  	init: xavier
2022-09-11 12:10:11 [INFO ]  	init_param: 1.0
2022-09-11 12:10:11 [INFO ]  	input_size: 32
2022-09-11 12:10:11 [INFO ]  	ipc: 1
2022-09-11 12:10:11 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-09-11 12:10:11 [INFO ]  	log_interval: 100
2022-09-11 12:10:11 [INFO ]  	log_level: INFO
2022-09-11 12:10:11 [INFO ]  	lr: 0.01
2022-09-11 12:10:11 [INFO ]  	mode: distill_adapt
2022-09-11 12:10:11 [INFO ]  	nc: 3
2022-09-11 12:10:11 [INFO ]  	num_classes: 10
2022-09-11 12:10:11 [INFO ]  	num_workers: 8
2022-09-11 12:10:11 [INFO ]  	phase: train
2022-09-11 12:10:11 [INFO ]  	source_dataset: FASHION_MNIST
2022-09-11 12:10:11 [INFO ]  	start_time: '2022-09-11 12:10:11'
2022-09-11 12:10:11 [INFO ]  	test_batch_size: 1024
2022-09-11 12:10:11 [INFO ]  	
2022-09-11 12:10:13 [INFO ]  train dataset size:	73257
2022-09-11 12:10:13 [INFO ]  test dataset size: 	26032
2022-09-11 12:10:13 [INFO ]  datasets built!
2022-09-11 12:10:13 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-09-11 12:10:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-09-11 12:10:16 [INFO ]  
2022-09-11 12:10:16 [INFO ]  Begin of epoch 0 :
2022-09-11 12:10:20 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:10:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:10:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:10:20 [INFO ]  	   step  1 (lr=0.020000)                    7.91%                   9.6166
2022-09-11 12:10:20 [INFO ]  
2022-09-11 12:10:20 [INFO ]  Epoch:    0	Loss: 9.5018	Data Time: 0.53s	Train Time: 0.03s
2022-09-11 12:10:22 [INFO ]  Epoch:    1	Loss: 3.7145	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:10:24 [INFO ]  Epoch:    2	Loss: 3.0332	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:10:26 [INFO ]  Epoch:    3	Loss: 2.6210	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:10:28 [INFO ]  Epoch:    4	Loss: 2.3743	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:10:30 [INFO ]  Epoch:    5	Loss: 2.2713	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:10:31 [INFO ]  Epoch:    6	Loss: 2.2442	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:10:33 [INFO ]  Epoch:    7	Loss: 2.1919	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:10:35 [INFO ]  Epoch:    8	Loss: 2.1621	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:10:37 [INFO ]  Epoch:    9	Loss: 2.1938	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:10:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-09-11 12:10:41 [INFO ]  
2022-09-11 12:10:41 [INFO ]  Begin of epoch 10 :
2022-09-11 12:10:44 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:10:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:10:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:10:44 [INFO ]  	   step  1 (lr=0.047376)                   26.01%                   2.1642
2022-09-11 12:10:44 [INFO ]  
2022-09-11 12:10:44 [INFO ]  Epoch:   10	Loss: 2.2051	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:10:46 [INFO ]  Epoch:   11	Loss: 2.1415	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:10:48 [INFO ]  Epoch:   12	Loss: 2.1167	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:10:50 [INFO ]  Epoch:   13	Loss: 2.0582	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:10:52 [INFO ]  Epoch:   14	Loss: 2.0407	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:10:54 [INFO ]  Epoch:   15	Loss: 2.0641	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:10:55 [INFO ]  Epoch:   16	Loss: 1.9303	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:10:57 [INFO ]  Epoch:   17	Loss: 1.9379	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:10:59 [INFO ]  Epoch:   18	Loss: 1.9092	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:01 [INFO ]  Epoch:   19	Loss: 1.8352	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:11:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-09-11 12:11:04 [INFO ]  
2022-09-11 12:11:04 [INFO ]  Begin of epoch 20 :
2022-09-11 12:11:08 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:11:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:11:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:11:08 [INFO ]  	   step  1 (lr=0.096072)                   28.33%                   2.1874
2022-09-11 12:11:08 [INFO ]  
2022-09-11 12:11:08 [INFO ]  Epoch:   20	Loss: 1.9740	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:11:09 [INFO ]  Epoch:   21	Loss: 1.7487	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:11:11 [INFO ]  Epoch:   22	Loss: 1.6506	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:11:13 [INFO ]  Epoch:   23	Loss: 1.6386	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:11:15 [INFO ]  Epoch:   24	Loss: 1.5633	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:17 [INFO ]  Epoch:   25	Loss: 1.6005	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:19 [INFO ]  Epoch:   26	Loss: 1.4398	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:21 [INFO ]  Epoch:   27	Loss: 1.5925	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:23 [INFO ]  Epoch:   28	Loss: 1.4556	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:11:25 [INFO ]  Epoch:   29	Loss: 1.4877	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:11:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-09-11 12:11:28 [INFO ]  
2022-09-11 12:11:28 [INFO ]  Begin of epoch 30 :
2022-09-11 12:11:32 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:11:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:11:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:11:32 [INFO ]  	   step  1 (lr=0.138681)                   43.63%                   1.7720
2022-09-11 12:11:32 [INFO ]  
2022-09-11 12:11:32 [INFO ]  Epoch:   30	Loss: 1.6634	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:11:34 [INFO ]  Epoch:   31	Loss: 1.5907	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:11:36 [INFO ]  Epoch:   32	Loss: 1.4869	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:11:38 [INFO ]  Epoch:   33	Loss: 1.4893	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:11:39 [INFO ]  Epoch:   34	Loss: 1.5214	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:41 [INFO ]  Epoch:   35	Loss: 2.1943	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:11:43 [INFO ]  Epoch:   36	Loss: 1.5369	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:11:45 [INFO ]  Epoch:   37	Loss: 1.3666	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:11:47 [INFO ]  Epoch:   38	Loss: 1.6947	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:11:49 [INFO ]  Epoch:   39	Loss: 1.4474	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:11:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-09-11 12:11:52 [INFO ]  
2022-09-11 12:11:52 [INFO ]  Begin of epoch 40 :
2022-09-11 12:11:56 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:11:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:11:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:11:56 [INFO ]  	   step  1 (lr=0.170339)                   54.67%                   1.4329
2022-09-11 12:11:56 [INFO ]  
2022-09-11 12:11:56 [INFO ]  Epoch:   40	Loss: 1.4329	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:11:58 [INFO ]  Epoch:   41	Loss: 1.3055	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:00 [INFO ]  Epoch:   42	Loss: 1.4326	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:02 [INFO ]  Epoch:   43	Loss: 1.3729	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:12:04 [INFO ]  Epoch:   44	Loss: 1.3798	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:12:05 [INFO ]  Epoch:   45	Loss: 1.4590	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:12:07 [INFO ]  Epoch:   46	Loss: 1.4792	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:12:09 [INFO ]  Epoch:   47	Loss: 1.2914	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:11 [INFO ]  Epoch:   48	Loss: 1.4150	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:12:13 [INFO ]  Epoch:   49	Loss: 1.3782	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:12:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-09-11 12:12:17 [INFO ]  
2022-09-11 12:12:17 [INFO ]  Begin of epoch 50 :
2022-09-11 12:12:20 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:12:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:12:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:12:20 [INFO ]  	   step  1 (lr=0.187045)                   61.36%                   1.2904
2022-09-11 12:12:20 [INFO ]  
2022-09-11 12:12:20 [INFO ]  Epoch:   50	Loss: 1.2642	Data Time: 0.26s	Train Time: 0.00s
2022-09-11 12:12:22 [INFO ]  Epoch:   51	Loss: 1.2371	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:12:24 [INFO ]  Epoch:   52	Loss: 1.2054	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:12:26 [INFO ]  Epoch:   53	Loss: 1.2499	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:12:28 [INFO ]  Epoch:   54	Loss: 1.2143	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:12:30 [INFO ]  Epoch:   55	Loss: 1.2230	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:32 [INFO ]  Epoch:   56	Loss: 1.1977	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:12:34 [INFO ]  Epoch:   57	Loss: 1.2020	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:12:36 [INFO ]  Epoch:   58	Loss: 1.2139	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:38 [INFO ]  Epoch:   59	Loss: 1.2371	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:12:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-09-11 12:12:41 [INFO ]  
2022-09-11 12:12:41 [INFO ]  Begin of epoch 60 :
2022-09-11 12:12:45 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:12:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:12:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:12:45 [INFO ]  	   step  1 (lr=0.209125)                   64.03%                   1.2231
2022-09-11 12:12:45 [INFO ]  
2022-09-11 12:12:45 [INFO ]  Epoch:   60	Loss: 1.1717	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:12:47 [INFO ]  Epoch:   61	Loss: 1.2807	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:12:49 [INFO ]  Epoch:   62	Loss: 1.2623	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:12:51 [INFO ]  Epoch:   63	Loss: 1.1754	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:12:52 [INFO ]  Epoch:   64	Loss: 1.2712	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:12:54 [INFO ]  Epoch:   65	Loss: 1.1802	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:12:56 [INFO ]  Epoch:   66	Loss: 1.2323	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:12:58 [INFO ]  Epoch:   67	Loss: 1.2120	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:13:00 [INFO ]  Epoch:   68	Loss: 1.2134	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:13:02 [INFO ]  Epoch:   69	Loss: 1.2185	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:13:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-09-11 12:13:06 [INFO ]  
2022-09-11 12:13:06 [INFO ]  Begin of epoch 70 :
2022-09-11 12:13:09 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:13:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:13:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:13:09 [INFO ]  	   step  1 (lr=0.214436)                   64.17%                   1.2200
2022-09-11 12:13:09 [INFO ]  
2022-09-11 12:13:09 [INFO ]  Epoch:   70	Loss: 1.2140	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:13:11 [INFO ]  Epoch:   71	Loss: 1.1769	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:13:13 [INFO ]  Epoch:   72	Loss: 1.2128	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:13:15 [INFO ]  Epoch:   73	Loss: 1.2041	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:13:17 [INFO ]  Epoch:   74	Loss: 1.1692	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:19 [INFO ]  Epoch:   75	Loss: 1.1680	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:13:21 [INFO ]  Epoch:   76	Loss: 1.2700	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:13:23 [INFO ]  Epoch:   77	Loss: 1.1530	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:25 [INFO ]  Epoch:   78	Loss: 1.2199	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:27 [INFO ]  Epoch:   79	Loss: 1.1625	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-09-11 12:13:30 [INFO ]  
2022-09-11 12:13:30 [INFO ]  Begin of epoch 80 :
2022-09-11 12:13:34 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:13:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:13:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:13:34 [INFO ]  	   step  1 (lr=0.223416)                   63.13%                   1.2295
2022-09-11 12:13:34 [INFO ]  
2022-09-11 12:13:34 [INFO ]  Epoch:   80	Loss: 1.1900	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:13:36 [INFO ]  Epoch:   81	Loss: 1.1132	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:38 [INFO ]  Epoch:   82	Loss: 1.1177	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:13:40 [INFO ]  Epoch:   83	Loss: 1.0729	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:13:42 [INFO ]  Epoch:   84	Loss: 1.1677	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:13:44 [INFO ]  Epoch:   85	Loss: 1.1622	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:13:46 [INFO ]  Epoch:   86	Loss: 1.2378	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:48 [INFO ]  Epoch:   87	Loss: 1.1638	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:49 [INFO ]  Epoch:   88	Loss: 1.0765	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:13:51 [INFO ]  Epoch:   89	Loss: 1.1545	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:13:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-09-11 12:13:54 [INFO ]  
2022-09-11 12:13:54 [INFO ]  Begin of epoch 90 :
2022-09-11 12:13:58 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:13:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:13:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:13:58 [INFO ]  	   step  1 (lr=0.230670)                   65.90%                   1.1700
2022-09-11 12:13:58 [INFO ]  
2022-09-11 12:13:58 [INFO ]  Epoch:   90	Loss: 1.1514	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:14:00 [INFO ]  Epoch:   91	Loss: 1.1104	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:14:02 [INFO ]  Epoch:   92	Loss: 1.0817	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:14:04 [INFO ]  Epoch:   93	Loss: 1.1674	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:14:06 [INFO ]  Epoch:   94	Loss: 1.1024	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:14:08 [INFO ]  Epoch:   95	Loss: 1.1853	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:14:10 [INFO ]  Epoch:   96	Loss: 1.0970	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:14:12 [INFO ]  Epoch:   97	Loss: 1.0924	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:14:13 [INFO ]  Epoch:   98	Loss: 1.2250	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:14:15 [INFO ]  Epoch:   99	Loss: 1.1226	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:14:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-09-11 12:14:18 [INFO ]  
2022-09-11 12:14:18 [INFO ]  Begin of epoch 100 :
2022-09-11 12:14:22 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:14:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:14:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:14:22 [INFO ]  	   step  1 (lr=0.235186)                   65.12%                   1.1752
2022-09-11 12:14:22 [INFO ]  
2022-09-11 12:14:22 [INFO ]  Epoch:  100	Loss: 1.0423	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:14:24 [INFO ]  Epoch:  101	Loss: 1.0876	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:14:26 [INFO ]  Epoch:  102	Loss: 1.1282	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:14:28 [INFO ]  Epoch:  103	Loss: 1.1011	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:14:30 [INFO ]  Epoch:  104	Loss: 1.1482	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:14:32 [INFO ]  Epoch:  105	Loss: 1.1475	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:14:34 [INFO ]  Epoch:  106	Loss: 1.2665	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:14:36 [INFO ]  Epoch:  107	Loss: 1.1223	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:14:38 [INFO ]  Epoch:  108	Loss: 1.1110	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:14:40 [INFO ]  Epoch:  109	Loss: 1.2423	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:14:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-09-11 12:14:43 [INFO ]  
2022-09-11 12:14:43 [INFO ]  Begin of epoch 110 :
2022-09-11 12:14:47 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:14:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:14:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:14:47 [INFO ]  	   step  1 (lr=0.232828)                   65.56%                   1.1558
2022-09-11 12:14:47 [INFO ]  
2022-09-11 12:14:47 [INFO ]  Epoch:  110	Loss: 1.1304	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:14:49 [INFO ]  Epoch:  111	Loss: 1.1300	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:14:51 [INFO ]  Epoch:  112	Loss: 1.0962	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:14:53 [INFO ]  Epoch:  113	Loss: 1.0492	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:14:55 [INFO ]  Epoch:  114	Loss: 1.1647	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:14:57 [INFO ]  Epoch:  115	Loss: 1.2642	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:14:59 [INFO ]  Epoch:  116	Loss: 1.1482	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:15:01 [INFO ]  Epoch:  117	Loss: 1.1210	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:15:03 [INFO ]  Epoch:  118	Loss: 1.0683	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:15:05 [INFO ]  Epoch:  119	Loss: 1.1720	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:15:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-09-11 12:15:08 [INFO ]  
2022-09-11 12:15:08 [INFO ]  Begin of epoch 120 :
2022-09-11 12:15:11 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:15:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:15:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:15:11 [INFO ]  	   step  1 (lr=0.234245)                   65.47%                   1.1530
2022-09-11 12:15:11 [INFO ]  
2022-09-11 12:15:11 [INFO ]  Epoch:  120	Loss: 1.1583	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:15:13 [INFO ]  Epoch:  121	Loss: 1.0672	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:15:15 [INFO ]  Epoch:  122	Loss: 1.1468	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:15:17 [INFO ]  Epoch:  123	Loss: 1.1074	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:15:19 [INFO ]  Epoch:  124	Loss: 1.1694	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:15:21 [INFO ]  Epoch:  125	Loss: 1.0692	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:15:23 [INFO ]  Epoch:  126	Loss: 1.0858	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:15:25 [INFO ]  Epoch:  127	Loss: 1.0826	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:15:27 [INFO ]  Epoch:  128	Loss: 1.0790	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:15:29 [INFO ]  Epoch:  129	Loss: 1.1257	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:15:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-09-11 12:15:32 [INFO ]  
2022-09-11 12:15:32 [INFO ]  Begin of epoch 130 :
2022-09-11 12:15:35 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:15:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:15:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:15:35 [INFO ]  	   step  1 (lr=0.237559)                   66.24%                   1.1388
2022-09-11 12:15:35 [INFO ]  
2022-09-11 12:15:35 [INFO ]  Epoch:  130	Loss: 1.0770	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:15:37 [INFO ]  Epoch:  131	Loss: 1.1371	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:15:39 [INFO ]  Epoch:  132	Loss: 1.0933	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:15:41 [INFO ]  Epoch:  133	Loss: 1.0902	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:15:43 [INFO ]  Epoch:  134	Loss: 1.0620	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:15:45 [INFO ]  Epoch:  135	Loss: 1.2064	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:15:47 [INFO ]  Epoch:  136	Loss: 1.0868	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:15:49 [INFO ]  Epoch:  137	Loss: 1.0762	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:15:51 [INFO ]  Epoch:  138	Loss: 1.4245	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:15:53 [INFO ]  Epoch:  139	Loss: 1.1388	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:15:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-09-11 12:15:56 [INFO ]  
2022-09-11 12:15:56 [INFO ]  Begin of epoch 140 :
2022-09-11 12:16:00 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:16:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:16:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:16:00 [INFO ]  	   step  1 (lr=0.239211)                   66.58%                   1.1333
2022-09-11 12:16:00 [INFO ]  
2022-09-11 12:16:00 [INFO ]  Epoch:  140	Loss: 1.0948	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:16:01 [INFO ]  Epoch:  141	Loss: 1.0948	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:16:03 [INFO ]  Epoch:  142	Loss: 1.0908	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:16:05 [INFO ]  Epoch:  143	Loss: 1.0967	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:16:07 [INFO ]  Epoch:  144	Loss: 1.1510	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:16:09 [INFO ]  Epoch:  145	Loss: 1.1808	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:16:11 [INFO ]  Epoch:  146	Loss: 1.1514	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:16:13 [INFO ]  Epoch:  147	Loss: 1.0149	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:15 [INFO ]  Epoch:  148	Loss: 1.1773	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:17 [INFO ]  Epoch:  149	Loss: 1.1435	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:16:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-09-11 12:16:20 [INFO ]  
2022-09-11 12:16:20 [INFO ]  Begin of epoch 150 :
2022-09-11 12:16:24 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:16:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:16:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:16:24 [INFO ]  	   step  1 (lr=0.239553)                   65.56%                   1.1628
2022-09-11 12:16:24 [INFO ]  
2022-09-11 12:16:24 [INFO ]  Epoch:  150	Loss: 1.2102	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:16:26 [INFO ]  Epoch:  151	Loss: 1.1122	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:28 [INFO ]  Epoch:  152	Loss: 1.1572	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:30 [INFO ]  Epoch:  153	Loss: 1.1455	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:32 [INFO ]  Epoch:  154	Loss: 1.1605	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:16:34 [INFO ]  Epoch:  155	Loss: 1.1304	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:36 [INFO ]  Epoch:  156	Loss: 1.0644	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:16:37 [INFO ]  Epoch:  157	Loss: 1.2236	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:39 [INFO ]  Epoch:  158	Loss: 1.0730	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:16:41 [INFO ]  Epoch:  159	Loss: 1.1200	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:16:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-09-11 12:16:44 [INFO ]  
2022-09-11 12:16:44 [INFO ]  Begin of epoch 160 :
2022-09-11 12:16:48 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:16:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:16:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:16:48 [INFO ]  	   step  1 (lr=0.240011)                   65.79%                   1.1508
2022-09-11 12:16:48 [INFO ]  
2022-09-11 12:16:48 [INFO ]  Epoch:  160	Loss: 1.1175	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:16:50 [INFO ]  Epoch:  161	Loss: 1.0507	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:16:52 [INFO ]  Epoch:  162	Loss: 1.1422	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:53 [INFO ]  Epoch:  163	Loss: 1.1293	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:16:55 [INFO ]  Epoch:  164	Loss: 1.0828	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:16:57 [INFO ]  Epoch:  165	Loss: 1.1204	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:16:59 [INFO ]  Epoch:  166	Loss: 1.1377	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:17:01 [INFO ]  Epoch:  167	Loss: 1.2838	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:17:03 [INFO ]  Epoch:  168	Loss: 1.1429	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:17:05 [INFO ]  Epoch:  169	Loss: 1.1718	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-09-11 12:17:08 [INFO ]  
2022-09-11 12:17:08 [INFO ]  Begin of epoch 170 :
2022-09-11 12:17:12 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:17:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:17:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:17:12 [INFO ]  	   step  1 (lr=0.239766)                   65.32%                   1.1675
2022-09-11 12:17:12 [INFO ]  
2022-09-11 12:17:12 [INFO ]  Epoch:  170	Loss: 1.1662	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:14 [INFO ]  Epoch:  171	Loss: 1.1821	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:17:15 [INFO ]  Epoch:  172	Loss: 1.1324	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:17:17 [INFO ]  Epoch:  173	Loss: 1.0792	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:19 [INFO ]  Epoch:  174	Loss: 1.1548	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:17:21 [INFO ]  Epoch:  175	Loss: 1.3874	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:17:23 [INFO ]  Epoch:  176	Loss: 1.1927	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:17:25 [INFO ]  Epoch:  177	Loss: 1.1093	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:27 [INFO ]  Epoch:  178	Loss: 1.0961	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:29 [INFO ]  Epoch:  179	Loss: 1.1263	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:17:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-09-11 12:17:32 [INFO ]  
2022-09-11 12:17:32 [INFO ]  Begin of epoch 180 :
2022-09-11 12:17:35 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:17:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:17:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:17:35 [INFO ]  	   step  1 (lr=0.239390)                   65.36%                   1.1768
2022-09-11 12:17:35 [INFO ]  
2022-09-11 12:17:35 [INFO ]  Epoch:  180	Loss: 1.0629	Data Time: 0.23s	Train Time: 0.00s
2022-09-11 12:17:37 [INFO ]  Epoch:  181	Loss: 1.2038	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:17:39 [INFO ]  Epoch:  182	Loss: 1.0913	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:17:41 [INFO ]  Epoch:  183	Loss: 1.1820	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:17:43 [INFO ]  Epoch:  184	Loss: 1.2608	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:17:45 [INFO ]  Epoch:  185	Loss: 1.2345	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:17:47 [INFO ]  Epoch:  186	Loss: 1.1379	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:17:49 [INFO ]  Epoch:  187	Loss: 1.2842	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:17:51 [INFO ]  Epoch:  188	Loss: 1.2120	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:17:53 [INFO ]  Epoch:  189	Loss: 1.2886	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:17:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-09-11 12:17:57 [INFO ]  
2022-09-11 12:17:57 [INFO ]  Begin of epoch 190 :
2022-09-11 12:18:00 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:18:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:18:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:18:00 [INFO ]  	   step  1 (lr=0.238712)                   57.86%                   1.4262
2022-09-11 12:18:00 [INFO ]  
2022-09-11 12:18:00 [INFO ]  Epoch:  190	Loss: 1.2940	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:18:02 [INFO ]  Epoch:  191	Loss: 1.1259	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:18:04 [INFO ]  Epoch:  192	Loss: 1.2940	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:18:06 [INFO ]  Epoch:  193	Loss: 1.1805	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:18:08 [INFO ]  Epoch:  194	Loss: 1.1104	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:18:10 [INFO ]  Epoch:  195	Loss: 1.2707	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:18:12 [INFO ]  Epoch:  196	Loss: 1.4098	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:18:14 [INFO ]  Epoch:  197	Loss: 1.2193	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:18:16 [INFO ]  Epoch:  198	Loss: 1.3277	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:18:18 [INFO ]  Epoch:  199	Loss: 1.3856	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:18:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-09-11 12:18:21 [INFO ]  
2022-09-11 12:18:21 [INFO ]  Final evaluation for SVHN :
2022-09-11 12:18:24 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:18:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:18:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:18:24 [INFO ]  	   step  1 (lr=0.237961)                   58.32%                   1.3981
2022-09-11 12:18:24 [INFO ]  
2022-09-11 12:18:24 [INFO ]  
2022-09-11 12:18:24 [INFO ]  Final evaluation for FASHION_MNIST :
2022-09-11 12:18:27 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:18:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:18:27 [INFO ]  	            before steps                   87.27%                   0.3620
2022-09-11 12:18:27 [INFO ]  	   step  1 (lr=0.237961)                   22.27%                   4.3908
2022-09-11 12:18:27 [INFO ]  
2022-09-11 12:27:43 [INFO ]  ======================================== 2022-09-11 12:27:43 ========================================
2022-09-11 12:27:43 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-09-11 12:27:43 [INFO ]  Options: 
2022-09-11 12:27:43 [INFO ]  	base_dir: null
2022-09-11 12:27:43 [INFO ]  	batch_size: 1024
2022-09-11 12:27:43 [INFO ]  	checkpoint_interval: 10
2022-09-11 12:27:43 [INFO ]  	dataset: SVHN
2022-09-11 12:27:43 [INFO ]  	dataset_labels:
2022-09-11 12:27:43 [INFO ]  	- 0
2022-09-11 12:27:43 [INFO ]  	- 1
2022-09-11 12:27:43 [INFO ]  	- 2
2022-09-11 12:27:43 [INFO ]  	- 3
2022-09-11 12:27:43 [INFO ]  	- 4
2022-09-11 12:27:43 [INFO ]  	- 5
2022-09-11 12:27:43 [INFO ]  	- 6
2022-09-11 12:27:43 [INFO ]  	- 7
2022-09-11 12:27:43 [INFO ]  	- 8
2022-09-11 12:27:43 [INFO ]  	- 9
2022-09-11 12:27:43 [INFO ]  	dataset_normalization: !!python/tuple
2022-09-11 12:27:43 [INFO ]  	- !!python/tuple
2022-09-11 12:27:43 [INFO ]  	    - 0.4379104971885681
2022-09-11 12:27:43 [INFO ]  	    - 0.44398033618927
2022-09-11 12:27:43 [INFO ]  	    - 0.4729299545288086
2022-09-11 12:27:43 [INFO ]  	- !!python/tuple
2022-09-11 12:27:43 [INFO ]  	    - 0.19803012907505035
2022-09-11 12:27:43 [INFO ]  	    - 0.2010156363248825
2022-09-11 12:27:43 [INFO ]  	    - 0.19703614711761475
2022-09-11 12:27:43 [INFO ]  	dataset_root: ./data/svhn
2022-09-11 12:27:43 [INFO ]  	decay_epochs: 50
2022-09-11 12:27:43 [INFO ]  	decay_factor: 0.1
2022-09-11 12:27:43 [INFO ]  	device_id: 0
2022-09-11 12:27:43 [INFO ]  	distill_epochs: 1
2022-09-11 12:27:43 [INFO ]  	distill_lr: 0.02
2022-09-11 12:27:43 [INFO ]  	distill_steps: 1
2022-09-11 12:27:43 [INFO ]  	epochs: 200
2022-09-11 12:27:43 [INFO ]  	expand_cls: false
2022-09-11 12:27:43 [INFO ]  	forgetting_dataset: null
2022-09-11 12:27:43 [INFO ]  	init: xavier
2022-09-11 12:27:43 [INFO ]  	init_param: 1.0
2022-09-11 12:27:43 [INFO ]  	input_size: 32
2022-09-11 12:27:43 [INFO ]  	ipc: 1
2022-09-11 12:27:43 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-09-11 12:27:43 [INFO ]  	log_interval: 100
2022-09-11 12:27:43 [INFO ]  	log_level: INFO
2022-09-11 12:27:43 [INFO ]  	lr: 0.01
2022-09-11 12:27:43 [INFO ]  	mode: distill_adapt
2022-09-11 12:27:43 [INFO ]  	nc: 3
2022-09-11 12:27:43 [INFO ]  	num_classes: 10
2022-09-11 12:27:43 [INFO ]  	num_workers: 8
2022-09-11 12:27:43 [INFO ]  	phase: train
2022-09-11 12:27:43 [INFO ]  	source_dataset: FASHION_MNIST
2022-09-11 12:27:43 [INFO ]  	start_time: '2022-09-11 12:27:43'
2022-09-11 12:27:43 [INFO ]  	test_batch_size: 1024
2022-09-11 12:27:43 [INFO ]  	
2022-09-11 12:27:45 [INFO ]  train dataset size:	73257
2022-09-11 12:27:45 [INFO ]  test dataset size: 	26032
2022-09-11 12:27:45 [INFO ]  datasets built!
2022-09-11 12:27:45 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-09-11 12:27:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-09-11 12:27:48 [INFO ]  
2022-09-11 12:27:48 [INFO ]  Begin of epoch 0 :
2022-09-11 12:27:52 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:27:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:27:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:27:52 [INFO ]  	   step  1 (lr=0.020000)                    6.89%                  10.2533
2022-09-11 12:27:52 [INFO ]  
2022-09-11 12:27:52 [INFO ]  Epoch:    0	Loss: 9.9734	Data Time: 0.55s	Train Time: 0.03s
2022-09-11 12:27:54 [INFO ]  Epoch:    1	Loss: 3.4051	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:27:56 [INFO ]  Epoch:    2	Loss: 2.9747	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:27:58 [INFO ]  Epoch:    3	Loss: 2.5630	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:28:00 [INFO ]  Epoch:    4	Loss: 2.4003	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:28:02 [INFO ]  Epoch:    5	Loss: 2.2882	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:28:04 [INFO ]  Epoch:    6	Loss: 2.2188	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:28:06 [INFO ]  Epoch:    7	Loss: 2.2120	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:28:08 [INFO ]  Epoch:    8	Loss: 2.1745	Data Time: 0.19s	Train Time: 0.00s
2022-09-11 12:28:10 [INFO ]  Epoch:    9	Loss: 2.1688	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:28:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-09-11 12:28:13 [INFO ]  
2022-09-11 12:28:13 [INFO ]  Begin of epoch 10 :
2022-09-11 12:28:16 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:28:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:28:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:28:16 [INFO ]  	   step  1 (lr=0.056775)                   25.67%                   2.1755
2022-09-11 12:28:16 [INFO ]  
2022-09-11 12:28:16 [INFO ]  Epoch:   10	Loss: 2.2017	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:28:18 [INFO ]  Epoch:   11	Loss: 2.1508	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:28:20 [INFO ]  Epoch:   12	Loss: 2.1097	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:28:22 [INFO ]  Epoch:   13	Loss: 2.0788	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:28:24 [INFO ]  Epoch:   14	Loss: 2.1024	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:28:26 [INFO ]  Epoch:   15	Loss: 1.9496	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:28:28 [INFO ]  Epoch:   16	Loss: 1.9584	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:28:30 [INFO ]  Epoch:   17	Loss: 1.8365	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:28:32 [INFO ]  Epoch:   18	Loss: 1.8252	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:28:34 [INFO ]  Epoch:   19	Loss: 1.7718	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:28:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-09-11 12:28:37 [INFO ]  
2022-09-11 12:28:37 [INFO ]  Begin of epoch 20 :
2022-09-11 12:28:40 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:28:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:28:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:28:40 [INFO ]  	   step  1 (lr=0.132206)                   47.68%                   1.6318
2022-09-11 12:28:40 [INFO ]  
2022-09-11 12:28:40 [INFO ]  Epoch:   20	Loss: 1.6015	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:28:42 [INFO ]  Epoch:   21	Loss: 1.6468	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:28:44 [INFO ]  Epoch:   22	Loss: 1.8629	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:28:46 [INFO ]  Epoch:   23	Loss: 1.6945	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:28:48 [INFO ]  Epoch:   24	Loss: 1.6949	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:28:50 [INFO ]  Epoch:   25	Loss: 1.6449	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:28:52 [INFO ]  Epoch:   26	Loss: 1.5272	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:28:53 [INFO ]  Epoch:   27	Loss: 1.5215	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:28:55 [INFO ]  Epoch:   28	Loss: 1.9422	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:28:57 [INFO ]  Epoch:   29	Loss: 1.6478	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:29:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-09-11 12:29:01 [INFO ]  
2022-09-11 12:29:01 [INFO ]  Begin of epoch 30 :
2022-09-11 12:29:04 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:29:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:29:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:29:04 [INFO ]  	   step  1 (lr=0.150902)                   49.68%                   1.5758
2022-09-11 12:29:04 [INFO ]  
2022-09-11 12:29:04 [INFO ]  Epoch:   30	Loss: 1.5398	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:06 [INFO ]  Epoch:   31	Loss: 1.5267	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:08 [INFO ]  Epoch:   32	Loss: 1.5013	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:29:10 [INFO ]  Epoch:   33	Loss: 1.4020	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:12 [INFO ]  Epoch:   34	Loss: 1.3601	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:29:14 [INFO ]  Epoch:   35	Loss: 1.3983	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:16 [INFO ]  Epoch:   36	Loss: 1.4063	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:29:18 [INFO ]  Epoch:   37	Loss: 1.4063	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:20 [INFO ]  Epoch:   38	Loss: 1.3039	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:29:22 [INFO ]  Epoch:   39	Loss: 1.4581	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:29:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-09-11 12:29:25 [INFO ]  
2022-09-11 12:29:25 [INFO ]  Begin of epoch 40 :
2022-09-11 12:29:29 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:29:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:29:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:29:29 [INFO ]  	   step  1 (lr=0.212779)                   59.22%                   1.3445
2022-09-11 12:29:29 [INFO ]  
2022-09-11 12:29:29 [INFO ]  Epoch:   40	Loss: 1.2637	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:31 [INFO ]  Epoch:   41	Loss: 1.4127	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:32 [INFO ]  Epoch:   42	Loss: 1.3785	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:29:34 [INFO ]  Epoch:   43	Loss: 1.2952	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:29:36 [INFO ]  Epoch:   44	Loss: 1.2761	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:38 [INFO ]  Epoch:   45	Loss: 1.3389	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:29:40 [INFO ]  Epoch:   46	Loss: 1.2685	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:29:42 [INFO ]  Epoch:   47	Loss: 1.3329	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:29:45 [INFO ]  Epoch:   48	Loss: 1.3839	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:29:46 [INFO ]  Epoch:   49	Loss: 1.2102	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:29:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-09-11 12:29:50 [INFO ]  
2022-09-11 12:29:50 [INFO ]  Begin of epoch 50 :
2022-09-11 12:29:53 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:29:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:29:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:29:53 [INFO ]  	   step  1 (lr=0.243509)                   63.03%                   1.2313
2022-09-11 12:29:53 [INFO ]  
2022-09-11 12:29:53 [INFO ]  Epoch:   50	Loss: 1.1593	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:55 [INFO ]  Epoch:   51	Loss: 1.1335	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:29:57 [INFO ]  Epoch:   52	Loss: 1.3326	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:29:59 [INFO ]  Epoch:   53	Loss: 1.2025	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:01 [INFO ]  Epoch:   54	Loss: 1.1829	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:03 [INFO ]  Epoch:   55	Loss: 1.2330	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:05 [INFO ]  Epoch:   56	Loss: 1.1900	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:30:07 [INFO ]  Epoch:   57	Loss: 1.2780	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:30:09 [INFO ]  Epoch:   58	Loss: 1.2064	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:30:11 [INFO ]  Epoch:   59	Loss: 1.3674	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:30:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-09-11 12:30:14 [INFO ]  
2022-09-11 12:30:14 [INFO ]  Begin of epoch 60 :
2022-09-11 12:30:17 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:30:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:30:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:30:17 [INFO ]  	   step  1 (lr=0.244025)                   58.11%                   1.3770
2022-09-11 12:30:17 [INFO ]  
2022-09-11 12:30:17 [INFO ]  Epoch:   60	Loss: 1.2758	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:19 [INFO ]  Epoch:   61	Loss: 1.2297	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:21 [INFO ]  Epoch:   62	Loss: 1.2381	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:23 [INFO ]  Epoch:   63	Loss: 1.2661	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:25 [INFO ]  Epoch:   64	Loss: 1.2644	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:27 [INFO ]  Epoch:   65	Loss: 1.2807	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:29 [INFO ]  Epoch:   66	Loss: 1.1283	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:31 [INFO ]  Epoch:   67	Loss: 1.2005	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:33 [INFO ]  Epoch:   68	Loss: 1.1998	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:30:35 [INFO ]  Epoch:   69	Loss: 1.3222	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-09-11 12:30:38 [INFO ]  
2022-09-11 12:30:38 [INFO ]  Begin of epoch 70 :
2022-09-11 12:30:41 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:30:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:30:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:30:41 [INFO ]  	   step  1 (lr=0.249569)                   65.05%                   1.1848
2022-09-11 12:30:41 [INFO ]  
2022-09-11 12:30:41 [INFO ]  Epoch:   70	Loss: 1.1156	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:43 [INFO ]  Epoch:   71	Loss: 1.1697	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:45 [INFO ]  Epoch:   72	Loss: 1.2137	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:30:47 [INFO ]  Epoch:   73	Loss: 1.1678	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:49 [INFO ]  Epoch:   74	Loss: 1.1781	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:30:51 [INFO ]  Epoch:   75	Loss: 1.2384	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:30:54 [INFO ]  Epoch:   76	Loss: 1.0699	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:30:56 [INFO ]  Epoch:   77	Loss: 1.3409	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:30:58 [INFO ]  Epoch:   78	Loss: 1.2364	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:31:00 [INFO ]  Epoch:   79	Loss: 1.2167	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:31:03 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-09-11 12:31:03 [INFO ]  
2022-09-11 12:31:03 [INFO ]  Begin of epoch 80 :
2022-09-11 12:31:07 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:31:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:31:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:31:07 [INFO ]  	   step  1 (lr=0.246474)                   64.00%                   1.1976
2022-09-11 12:31:07 [INFO ]  
2022-09-11 12:31:07 [INFO ]  Epoch:   80	Loss: 1.1495	Data Time: 0.24s	Train Time: 0.00s
2022-09-11 12:31:09 [INFO ]  Epoch:   81	Loss: 1.1196	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:31:10 [INFO ]  Epoch:   82	Loss: 1.1575	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:12 [INFO ]  Epoch:   83	Loss: 1.1757	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:31:14 [INFO ]  Epoch:   84	Loss: 1.3385	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:31:16 [INFO ]  Epoch:   85	Loss: 1.1444	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:31:18 [INFO ]  Epoch:   86	Loss: 1.1028	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:20 [INFO ]  Epoch:   87	Loss: 1.3436	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:22 [INFO ]  Epoch:   88	Loss: 1.1490	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:31:24 [INFO ]  Epoch:   89	Loss: 1.1911	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:31:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-09-11 12:31:28 [INFO ]  
2022-09-11 12:31:28 [INFO ]  Begin of epoch 90 :
2022-09-11 12:31:31 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:31:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:31:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:31:31 [INFO ]  	   step  1 (lr=0.248820)                   61.92%                   1.2858
2022-09-11 12:31:31 [INFO ]  
2022-09-11 12:31:31 [INFO ]  Epoch:   90	Loss: 1.2117	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:31:33 [INFO ]  Epoch:   91	Loss: 1.1465	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:31:35 [INFO ]  Epoch:   92	Loss: 1.1530	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:31:37 [INFO ]  Epoch:   93	Loss: 1.2664	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:39 [INFO ]  Epoch:   94	Loss: 1.3373	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:41 [INFO ]  Epoch:   95	Loss: 1.1188	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:31:43 [INFO ]  Epoch:   96	Loss: 1.1259	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:31:45 [INFO ]  Epoch:   97	Loss: 1.1877	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:31:47 [INFO ]  Epoch:   98	Loss: 1.1384	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:31:49 [INFO ]  Epoch:   99	Loss: 1.1646	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:31:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-09-11 12:31:52 [INFO ]  
2022-09-11 12:31:52 [INFO ]  Begin of epoch 100 :
2022-09-11 12:31:56 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:31:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:31:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:31:56 [INFO ]  	   step  1 (lr=0.263610)                   65.69%                   1.1805
2022-09-11 12:31:56 [INFO ]  
2022-09-11 12:31:56 [INFO ]  Epoch:  100	Loss: 1.0575	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:31:57 [INFO ]  Epoch:  101	Loss: 1.0951	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:31:59 [INFO ]  Epoch:  102	Loss: 1.2370	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:32:01 [INFO ]  Epoch:  103	Loss: 1.1939	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:03 [INFO ]  Epoch:  104	Loss: 1.3213	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:32:05 [INFO ]  Epoch:  105	Loss: 1.3698	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:32:07 [INFO ]  Epoch:  106	Loss: 1.2281	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:32:09 [INFO ]  Epoch:  107	Loss: 1.1832	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:32:11 [INFO ]  Epoch:  108	Loss: 1.1862	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:32:13 [INFO ]  Epoch:  109	Loss: 1.2807	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:32:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-09-11 12:32:16 [INFO ]  
2022-09-11 12:32:16 [INFO ]  Begin of epoch 110 :
2022-09-11 12:32:20 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:32:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:32:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:32:20 [INFO ]  	   step  1 (lr=0.262144)                   62.15%                   1.2737
2022-09-11 12:32:20 [INFO ]  
2022-09-11 12:32:20 [INFO ]  Epoch:  110	Loss: 1.2930	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:32:22 [INFO ]  Epoch:  111	Loss: 1.2018	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:32:24 [INFO ]  Epoch:  112	Loss: 1.1675	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:26 [INFO ]  Epoch:  113	Loss: 1.1541	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:28 [INFO ]  Epoch:  114	Loss: 1.1511	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:30 [INFO ]  Epoch:  115	Loss: 1.1617	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:32:32 [INFO ]  Epoch:  116	Loss: 1.1874	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:32:35 [INFO ]  Epoch:  117	Loss: 1.1486	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:32:37 [INFO ]  Epoch:  118	Loss: 1.2317	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:32:39 [INFO ]  Epoch:  119	Loss: 1.2834	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-09-11 12:32:42 [INFO ]  
2022-09-11 12:32:42 [INFO ]  Begin of epoch 120 :
2022-09-11 12:32:46 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:32:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:32:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:32:46 [INFO ]  	   step  1 (lr=0.260672)                   64.72%                   1.1990
2022-09-11 12:32:46 [INFO ]  
2022-09-11 12:32:46 [INFO ]  Epoch:  120	Loss: 1.1767	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:32:48 [INFO ]  Epoch:  121	Loss: 1.0837	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:32:50 [INFO ]  Epoch:  122	Loss: 1.1509	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:32:52 [INFO ]  Epoch:  123	Loss: 1.1564	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:32:54 [INFO ]  Epoch:  124	Loss: 1.0925	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:32:55 [INFO ]  Epoch:  125	Loss: 1.1366	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:32:57 [INFO ]  Epoch:  126	Loss: 1.1747	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:32:59 [INFO ]  Epoch:  127	Loss: 1.1831	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:33:01 [INFO ]  Epoch:  128	Loss: 1.0724	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:33:03 [INFO ]  Epoch:  129	Loss: 1.1121	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:33:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-09-11 12:33:07 [INFO ]  
2022-09-11 12:33:07 [INFO ]  Begin of epoch 130 :
2022-09-11 12:33:10 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:33:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:33:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:33:10 [INFO ]  	   step  1 (lr=0.259831)                   65.24%                   1.1776
2022-09-11 12:33:10 [INFO ]  
2022-09-11 12:33:10 [INFO ]  Epoch:  130	Loss: 1.1464	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:12 [INFO ]  Epoch:  131	Loss: 1.2336	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:33:14 [INFO ]  Epoch:  132	Loss: 1.2777	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:33:16 [INFO ]  Epoch:  133	Loss: 1.2540	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:33:18 [INFO ]  Epoch:  134	Loss: 1.2061	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:20 [INFO ]  Epoch:  135	Loss: 1.2401	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:33:22 [INFO ]  Epoch:  136	Loss: 1.7566	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:33:24 [INFO ]  Epoch:  137	Loss: 1.1809	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:26 [INFO ]  Epoch:  138	Loss: 1.2528	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:33:28 [INFO ]  Epoch:  139	Loss: 1.2054	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-09-11 12:33:31 [INFO ]  
2022-09-11 12:33:31 [INFO ]  Begin of epoch 140 :
2022-09-11 12:33:35 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:33:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:33:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:33:35 [INFO ]  	   step  1 (lr=0.260804)                   57.68%                   1.4030
2022-09-11 12:33:35 [INFO ]  
2022-09-11 12:33:35 [INFO ]  Epoch:  140	Loss: 1.4048	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:33:37 [INFO ]  Epoch:  141	Loss: 1.2686	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:39 [INFO ]  Epoch:  142	Loss: 1.3514	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:33:41 [INFO ]  Epoch:  143	Loss: 1.1536	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:33:43 [INFO ]  Epoch:  144	Loss: 1.2016	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:33:45 [INFO ]  Epoch:  145	Loss: 1.2204	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:33:47 [INFO ]  Epoch:  146	Loss: 1.1296	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:48 [INFO ]  Epoch:  147	Loss: 1.1488	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:33:51 [INFO ]  Epoch:  148	Loss: 1.2247	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:33:53 [INFO ]  Epoch:  149	Loss: 1.3192	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:33:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-09-11 12:33:56 [INFO ]  
2022-09-11 12:33:56 [INFO ]  Begin of epoch 150 :
2022-09-11 12:33:59 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:33:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:33:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:33:59 [INFO ]  	   step  1 (lr=0.259401)                   63.96%                   1.2240
2022-09-11 12:33:59 [INFO ]  
2022-09-11 12:33:59 [INFO ]  Epoch:  150	Loss: 1.2148	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:34:02 [INFO ]  Epoch:  151	Loss: 1.2195	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:34:04 [INFO ]  Epoch:  152	Loss: 1.1297	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:34:05 [INFO ]  Epoch:  153	Loss: 1.1860	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:34:07 [INFO ]  Epoch:  154	Loss: 1.1962	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:34:09 [INFO ]  Epoch:  155	Loss: 1.2374	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:34:11 [INFO ]  Epoch:  156	Loss: 1.1794	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:34:13 [INFO ]  Epoch:  157	Loss: 1.1944	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:34:15 [INFO ]  Epoch:  158	Loss: 1.1961	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:34:17 [INFO ]  Epoch:  159	Loss: 1.1616	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:34:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-09-11 12:34:20 [INFO ]  
2022-09-11 12:34:20 [INFO ]  Begin of epoch 160 :
2022-09-11 12:34:24 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:34:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:34:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:34:24 [INFO ]  	   step  1 (lr=0.259802)                   64.57%                   1.1985
2022-09-11 12:34:24 [INFO ]  
2022-09-11 12:34:24 [INFO ]  Epoch:  160	Loss: 1.1384	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:34:25 [INFO ]  Epoch:  161	Loss: 1.1431	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:34:27 [INFO ]  Epoch:  162	Loss: 1.0502	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:34:29 [INFO ]  Epoch:  163	Loss: 1.1486	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:34:31 [INFO ]  Epoch:  164	Loss: 1.2508	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:34:33 [INFO ]  Epoch:  165	Loss: 1.1395	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:34:36 [INFO ]  Epoch:  166	Loss: 1.1705	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:34:38 [INFO ]  Epoch:  167	Loss: 1.2233	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:34:40 [INFO ]  Epoch:  168	Loss: 1.2046	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:34:42 [INFO ]  Epoch:  169	Loss: 1.1517	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:34:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-09-11 12:34:45 [INFO ]  
2022-09-11 12:34:45 [INFO ]  Begin of epoch 170 :
2022-09-11 12:34:48 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:34:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:34:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:34:48 [INFO ]  	   step  1 (lr=0.260284)                   64.39%                   1.2066
2022-09-11 12:34:48 [INFO ]  
2022-09-11 12:34:48 [INFO ]  Epoch:  170	Loss: 1.1776	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:34:50 [INFO ]  Epoch:  171	Loss: 1.1920	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:34:52 [INFO ]  Epoch:  172	Loss: 1.1867	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:34:54 [INFO ]  Epoch:  173	Loss: 1.1933	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:34:56 [INFO ]  Epoch:  174	Loss: 1.1350	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:34:58 [INFO ]  Epoch:  175	Loss: 1.1904	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:35:00 [INFO ]  Epoch:  176	Loss: 1.0894	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:35:02 [INFO ]  Epoch:  177	Loss: 1.2167	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:35:04 [INFO ]  Epoch:  178	Loss: 1.1666	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:35:06 [INFO ]  Epoch:  179	Loss: 1.2089	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:35:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-09-11 12:35:09 [INFO ]  
2022-09-11 12:35:09 [INFO ]  Begin of epoch 180 :
2022-09-11 12:35:13 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:35:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:35:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:35:13 [INFO ]  	   step  1 (lr=0.259969)                   64.02%                   1.2307
2022-09-11 12:35:13 [INFO ]  
2022-09-11 12:35:13 [INFO ]  Epoch:  180	Loss: 1.2485	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:35:14 [INFO ]  Epoch:  181	Loss: 1.1619	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:35:16 [INFO ]  Epoch:  182	Loss: 1.1420	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:35:18 [INFO ]  Epoch:  183	Loss: 1.2177	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:35:20 [INFO ]  Epoch:  184	Loss: 1.1900	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:35:23 [INFO ]  Epoch:  185	Loss: 1.1634	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:35:25 [INFO ]  Epoch:  186	Loss: 1.1832	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:35:27 [INFO ]  Epoch:  187	Loss: 1.1359	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:35:29 [INFO ]  Epoch:  188	Loss: 1.1339	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:35:31 [INFO ]  Epoch:  189	Loss: 1.1655	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:35:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-09-11 12:35:35 [INFO ]  
2022-09-11 12:35:35 [INFO ]  Begin of epoch 190 :
2022-09-11 12:35:38 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:35:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:35:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:35:38 [INFO ]  	   step  1 (lr=0.260108)                   64.87%                   1.1997
2022-09-11 12:35:38 [INFO ]  
2022-09-11 12:35:38 [INFO ]  Epoch:  190	Loss: 1.1149	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:35:40 [INFO ]  Epoch:  191	Loss: 1.1966	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:35:42 [INFO ]  Epoch:  192	Loss: 1.1151	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:35:44 [INFO ]  Epoch:  193	Loss: 1.2125	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:35:46 [INFO ]  Epoch:  194	Loss: 1.1270	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:35:48 [INFO ]  Epoch:  195	Loss: 1.1299	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:35:50 [INFO ]  Epoch:  196	Loss: 1.1656	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:35:52 [INFO ]  Epoch:  197	Loss: 1.0918	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:35:54 [INFO ]  Epoch:  198	Loss: 1.2052	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:35:56 [INFO ]  Epoch:  199	Loss: 1.1241	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:35:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-09-11 12:35:58 [INFO ]  
2022-09-11 12:35:58 [INFO ]  Final evaluation for SVHN :
2022-09-11 12:36:02 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:36:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:36:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:36:02 [INFO ]  	   step  1 (lr=0.260150)                   65.09%                   1.1873
2022-09-11 12:36:02 [INFO ]  
2022-09-11 12:36:02 [INFO ]  
2022-09-11 12:36:02 [INFO ]  Final evaluation for FASHION_MNIST :
2022-09-11 12:36:05 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:36:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:36:05 [INFO ]  	            before steps                   87.27%                   0.3620
2022-09-11 12:36:05 [INFO ]  	   step  1 (lr=0.260150)                   22.27%                   5.0073
2022-09-11 12:36:05 [INFO ]  
2022-09-11 12:36:55 [INFO ]  ======================================== 2022-09-11 12:36:55 ========================================
2022-09-11 12:36:55 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-09-11 12:36:55 [INFO ]  Options: 
2022-09-11 12:36:55 [INFO ]  	base_dir: null
2022-09-11 12:36:55 [INFO ]  	batch_size: 1024
2022-09-11 12:36:55 [INFO ]  	checkpoint_interval: 10
2022-09-11 12:36:55 [INFO ]  	dataset: SVHN
2022-09-11 12:36:55 [INFO ]  	dataset_labels:
2022-09-11 12:36:55 [INFO ]  	- 0
2022-09-11 12:36:55 [INFO ]  	- 1
2022-09-11 12:36:55 [INFO ]  	- 2
2022-09-11 12:36:55 [INFO ]  	- 3
2022-09-11 12:36:55 [INFO ]  	- 4
2022-09-11 12:36:55 [INFO ]  	- 5
2022-09-11 12:36:55 [INFO ]  	- 6
2022-09-11 12:36:55 [INFO ]  	- 7
2022-09-11 12:36:55 [INFO ]  	- 8
2022-09-11 12:36:55 [INFO ]  	- 9
2022-09-11 12:36:55 [INFO ]  	dataset_normalization: !!python/tuple
2022-09-11 12:36:55 [INFO ]  	- !!python/tuple
2022-09-11 12:36:55 [INFO ]  	    - 0.4379104971885681
2022-09-11 12:36:55 [INFO ]  	    - 0.44398033618927
2022-09-11 12:36:55 [INFO ]  	    - 0.4729299545288086
2022-09-11 12:36:55 [INFO ]  	- !!python/tuple
2022-09-11 12:36:55 [INFO ]  	    - 0.19803012907505035
2022-09-11 12:36:55 [INFO ]  	    - 0.2010156363248825
2022-09-11 12:36:55 [INFO ]  	    - 0.19703614711761475
2022-09-11 12:36:55 [INFO ]  	dataset_root: ./data/svhn
2022-09-11 12:36:55 [INFO ]  	decay_epochs: 50
2022-09-11 12:36:55 [INFO ]  	decay_factor: 0.1
2022-09-11 12:36:55 [INFO ]  	device_id: 0
2022-09-11 12:36:55 [INFO ]  	distill_epochs: 1
2022-09-11 12:36:55 [INFO ]  	distill_lr: 0.02
2022-09-11 12:36:55 [INFO ]  	distill_steps: 1
2022-09-11 12:36:55 [INFO ]  	epochs: 200
2022-09-11 12:36:55 [INFO ]  	expand_cls: false
2022-09-11 12:36:55 [INFO ]  	forgetting_dataset: null
2022-09-11 12:36:55 [INFO ]  	init: xavier
2022-09-11 12:36:55 [INFO ]  	init_param: 1.0
2022-09-11 12:36:55 [INFO ]  	input_size: 32
2022-09-11 12:36:55 [INFO ]  	ipc: 1
2022-09-11 12:36:55 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-09-11 12:36:55 [INFO ]  	log_interval: 100
2022-09-11 12:36:55 [INFO ]  	log_level: INFO
2022-09-11 12:36:55 [INFO ]  	lr: 0.01
2022-09-11 12:36:55 [INFO ]  	mode: distill_adapt
2022-09-11 12:36:55 [INFO ]  	nc: 3
2022-09-11 12:36:55 [INFO ]  	num_classes: 10
2022-09-11 12:36:55 [INFO ]  	num_workers: 8
2022-09-11 12:36:55 [INFO ]  	phase: train
2022-09-11 12:36:55 [INFO ]  	source_dataset: FASHION_MNIST
2022-09-11 12:36:55 [INFO ]  	start_time: '2022-09-11 12:36:55'
2022-09-11 12:36:55 [INFO ]  	test_batch_size: 1024
2022-09-11 12:36:55 [INFO ]  	
2022-09-11 12:36:57 [INFO ]  train dataset size:	73257
2022-09-11 12:36:57 [INFO ]  test dataset size: 	26032
2022-09-11 12:36:57 [INFO ]  datasets built!
2022-09-11 12:36:57 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-09-11 12:37:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-09-11 12:37:01 [INFO ]  
2022-09-11 12:37:01 [INFO ]  Begin of epoch 0 :
2022-09-11 12:37:04 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:37:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:37:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:37:04 [INFO ]  	   step  1 (lr=0.020000)                    6.70%                  12.3290
2022-09-11 12:37:04 [INFO ]  
2022-09-11 12:37:04 [INFO ]  Epoch:    0	Loss: 11.3914	Data Time: 0.47s	Train Time: 0.03s
2022-09-11 12:37:06 [INFO ]  Epoch:    1	Loss: 3.7989	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:37:08 [INFO ]  Epoch:    2	Loss: 3.0109	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:37:10 [INFO ]  Epoch:    3	Loss: 2.5972	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:37:12 [INFO ]  Epoch:    4	Loss: 2.4559	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:37:14 [INFO ]  Epoch:    5	Loss: 2.3203	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:37:16 [INFO ]  Epoch:    6	Loss: 2.2287	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:37:18 [INFO ]  Epoch:    7	Loss: 2.2369	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:37:20 [INFO ]  Epoch:    8	Loss: 2.2327	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:37:22 [INFO ]  Epoch:    9	Loss: 2.2112	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:37:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-09-11 12:37:26 [INFO ]  
2022-09-11 12:37:26 [INFO ]  Begin of epoch 10 :
2022-09-11 12:37:29 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:37:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:37:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:37:29 [INFO ]  	   step  1 (lr=0.042777)                   26.18%                   2.1905
2022-09-11 12:37:29 [INFO ]  
2022-09-11 12:37:29 [INFO ]  Epoch:   10	Loss: 2.1984	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:37:31 [INFO ]  Epoch:   11	Loss: 2.2070	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:37:33 [INFO ]  Epoch:   12	Loss: 2.1837	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:37:35 [INFO ]  Epoch:   13	Loss: 2.1506	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:37:37 [INFO ]  Epoch:   14	Loss: 2.1262	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:37:39 [INFO ]  Epoch:   15	Loss: 2.1557	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:37:41 [INFO ]  Epoch:   16	Loss: 2.0985	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:37:43 [INFO ]  Epoch:   17	Loss: 2.0868	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:37:45 [INFO ]  Epoch:   18	Loss: 2.0473	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:37:47 [INFO ]  Epoch:   19	Loss: 2.0438	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:37:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-09-11 12:37:51 [INFO ]  
2022-09-11 12:37:51 [INFO ]  Begin of epoch 20 :
2022-09-11 12:37:54 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:37:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:37:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:37:54 [INFO ]  	   step  1 (lr=0.078483)                   34.53%                   1.9268
2022-09-11 12:37:54 [INFO ]  
2022-09-11 12:37:54 [INFO ]  Epoch:   20	Loss: 1.9290	Data Time: 0.21s	Train Time: 0.00s
2022-09-11 12:37:56 [INFO ]  Epoch:   21	Loss: 1.9103	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:37:58 [INFO ]  Epoch:   22	Loss: 1.8523	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:38:00 [INFO ]  Epoch:   23	Loss: 1.9535	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:02 [INFO ]  Epoch:   24	Loss: 1.8717	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:38:04 [INFO ]  Epoch:   25	Loss: 1.7666	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:38:06 [INFO ]  Epoch:   26	Loss: 1.6732	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:08 [INFO ]  Epoch:   27	Loss: 1.5300	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:38:10 [INFO ]  Epoch:   28	Loss: 1.7054	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:38:12 [INFO ]  Epoch:   29	Loss: 1.5929	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:38:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-09-11 12:38:15 [INFO ]  
2022-09-11 12:38:15 [INFO ]  Begin of epoch 30 :
2022-09-11 12:38:19 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:38:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:38:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:38:19 [INFO ]  	   step  1 (lr=0.134290)                   52.29%                   1.5118
2022-09-11 12:38:19 [INFO ]  
2022-09-11 12:38:19 [INFO ]  Epoch:   30	Loss: 1.4701	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:20 [INFO ]  Epoch:   31	Loss: 1.5189	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:38:22 [INFO ]  Epoch:   32	Loss: 1.4992	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:24 [INFO ]  Epoch:   33	Loss: 1.4670	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:26 [INFO ]  Epoch:   34	Loss: 1.7790	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:38:28 [INFO ]  Epoch:   35	Loss: 1.5276	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:30 [INFO ]  Epoch:   36	Loss: 1.5171	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:38:32 [INFO ]  Epoch:   37	Loss: 1.3963	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:34 [INFO ]  Epoch:   38	Loss: 1.4715	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:38:36 [INFO ]  Epoch:   39	Loss: 1.3624	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-09-11 12:38:39 [INFO ]  
2022-09-11 12:38:39 [INFO ]  Begin of epoch 40 :
2022-09-11 12:38:43 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:38:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:38:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:38:43 [INFO ]  	   step  1 (lr=0.162019)                   54.91%                   1.4404
2022-09-11 12:38:43 [INFO ]  
2022-09-11 12:38:43 [INFO ]  Epoch:   40	Loss: 1.3582	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:38:45 [INFO ]  Epoch:   41	Loss: 1.3341	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:38:47 [INFO ]  Epoch:   42	Loss: 1.4377	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:38:49 [INFO ]  Epoch:   43	Loss: 1.3383	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:38:51 [INFO ]  Epoch:   44	Loss: 1.3652	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:38:53 [INFO ]  Epoch:   45	Loss: 1.3135	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:55 [INFO ]  Epoch:   46	Loss: 1.2347	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:38:56 [INFO ]  Epoch:   47	Loss: 1.1631	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:38:58 [INFO ]  Epoch:   48	Loss: 1.4578	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:39:01 [INFO ]  Epoch:   49	Loss: 1.2732	Data Time: 0.28s	Train Time: 0.01s
2022-09-11 12:39:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-09-11 12:39:04 [INFO ]  
2022-09-11 12:39:04 [INFO ]  Begin of epoch 50 :
2022-09-11 12:39:07 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:39:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:39:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:39:07 [INFO ]  	   step  1 (lr=0.179145)                   57.11%                   1.4783
2022-09-11 12:39:07 [INFO ]  
2022-09-11 12:39:07 [INFO ]  Epoch:   50	Loss: 1.3602	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:39:09 [INFO ]  Epoch:   51	Loss: 1.2360	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:39:11 [INFO ]  Epoch:   52	Loss: 1.1943	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:39:13 [INFO ]  Epoch:   53	Loss: 1.1394	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:39:15 [INFO ]  Epoch:   54	Loss: 1.2018	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:39:17 [INFO ]  Epoch:   55	Loss: 1.2193	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:39:19 [INFO ]  Epoch:   56	Loss: 1.2310	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:39:21 [INFO ]  Epoch:   57	Loss: 1.3487	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:39:23 [INFO ]  Epoch:   58	Loss: 1.3684	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:39:25 [INFO ]  Epoch:   59	Loss: 1.2957	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:39:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-09-11 12:39:28 [INFO ]  
2022-09-11 12:39:28 [INFO ]  Begin of epoch 60 :
2022-09-11 12:39:32 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:39:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:39:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:39:32 [INFO ]  	   step  1 (lr=0.180509)                   59.10%                   1.3584
2022-09-11 12:39:32 [INFO ]  
2022-09-11 12:39:32 [INFO ]  Epoch:   60	Loss: 1.2639	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:39:33 [INFO ]  Epoch:   61	Loss: 1.2085	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:39:35 [INFO ]  Epoch:   62	Loss: 1.2964	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:39:37 [INFO ]  Epoch:   63	Loss: 1.1633	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:39:39 [INFO ]  Epoch:   64	Loss: 1.1647	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:39:41 [INFO ]  Epoch:   65	Loss: 1.2468	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:39:43 [INFO ]  Epoch:   66	Loss: 1.2191	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:39:45 [INFO ]  Epoch:   67	Loss: 1.2077	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:39:47 [INFO ]  Epoch:   68	Loss: 1.3491	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:39:49 [INFO ]  Epoch:   69	Loss: 1.2877	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:39:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-09-11 12:39:52 [INFO ]  
2022-09-11 12:39:52 [INFO ]  Begin of epoch 70 :
2022-09-11 12:39:56 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:39:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:39:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:39:56 [INFO ]  	   step  1 (lr=0.190357)                   60.18%                   1.3259
2022-09-11 12:39:56 [INFO ]  
2022-09-11 12:39:56 [INFO ]  Epoch:   70	Loss: 1.2475	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:39:58 [INFO ]  Epoch:   71	Loss: 1.2224	Data Time: 0.20s	Train Time: 0.00s
2022-09-11 12:40:00 [INFO ]  Epoch:   72	Loss: 1.2515	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:02 [INFO ]  Epoch:   73	Loss: 1.2123	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:40:04 [INFO ]  Epoch:   74	Loss: 1.1418	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:40:06 [INFO ]  Epoch:   75	Loss: 1.2938	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:08 [INFO ]  Epoch:   76	Loss: 1.2054	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:40:09 [INFO ]  Epoch:   77	Loss: 1.2159	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:40:12 [INFO ]  Epoch:   78	Loss: 1.2046	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:14 [INFO ]  Epoch:   79	Loss: 1.2397	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:40:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-09-11 12:40:17 [INFO ]  
2022-09-11 12:40:17 [INFO ]  Begin of epoch 80 :
2022-09-11 12:40:21 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:40:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:40:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:40:21 [INFO ]  	   step  1 (lr=0.192932)                   62.91%                   1.2500
2022-09-11 12:40:21 [INFO ]  
2022-09-11 12:40:21 [INFO ]  Epoch:   80	Loss: 1.1586	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:40:22 [INFO ]  Epoch:   81	Loss: 1.1291	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:40:24 [INFO ]  Epoch:   82	Loss: 1.2496	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:26 [INFO ]  Epoch:   83	Loss: 1.2776	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:40:28 [INFO ]  Epoch:   84	Loss: 1.1509	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:40:30 [INFO ]  Epoch:   85	Loss: 1.1289	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:40:32 [INFO ]  Epoch:   86	Loss: 1.1366	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:34 [INFO ]  Epoch:   87	Loss: 1.1669	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:36 [INFO ]  Epoch:   88	Loss: 1.2250	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:40:38 [INFO ]  Epoch:   89	Loss: 1.1372	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:40:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-09-11 12:40:42 [INFO ]  
2022-09-11 12:40:42 [INFO ]  Begin of epoch 90 :
2022-09-11 12:40:45 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:40:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:40:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:40:45 [INFO ]  	   step  1 (lr=0.191373)                   63.66%                   1.2375
2022-09-11 12:40:45 [INFO ]  
2022-09-11 12:40:45 [INFO ]  Epoch:   90	Loss: 1.1654	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:47 [INFO ]  Epoch:   91	Loss: 1.1335	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:49 [INFO ]  Epoch:   92	Loss: 1.1248	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:51 [INFO ]  Epoch:   93	Loss: 1.2043	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:40:53 [INFO ]  Epoch:   94	Loss: 1.1089	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:40:55 [INFO ]  Epoch:   95	Loss: 1.0750	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:40:57 [INFO ]  Epoch:   96	Loss: 1.1808	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:40:59 [INFO ]  Epoch:   97	Loss: 1.1565	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:01 [INFO ]  Epoch:   98	Loss: 1.1266	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:41:03 [INFO ]  Epoch:   99	Loss: 1.1703	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-09-11 12:41:06 [INFO ]  
2022-09-11 12:41:06 [INFO ]  Begin of epoch 100 :
2022-09-11 12:41:10 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:41:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:41:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:41:10 [INFO ]  	   step  1 (lr=0.193087)                   61.32%                   1.2819
2022-09-11 12:41:10 [INFO ]  
2022-09-11 12:41:10 [INFO ]  Epoch:  100	Loss: 1.2309	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:41:12 [INFO ]  Epoch:  101	Loss: 1.3042	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:41:13 [INFO ]  Epoch:  102	Loss: 1.1221	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:41:16 [INFO ]  Epoch:  103	Loss: 1.2056	Data Time: 0.14s	Train Time: 0.01s
2022-09-11 12:41:17 [INFO ]  Epoch:  104	Loss: 1.2110	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:41:19 [INFO ]  Epoch:  105	Loss: 1.1508	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:41:21 [INFO ]  Epoch:  106	Loss: 1.1333	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:23 [INFO ]  Epoch:  107	Loss: 1.1666	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:41:25 [INFO ]  Epoch:  108	Loss: 1.1166	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:41:27 [INFO ]  Epoch:  109	Loss: 1.1191	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:41:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-09-11 12:41:30 [INFO ]  
2022-09-11 12:41:30 [INFO ]  Begin of epoch 110 :
2022-09-11 12:41:34 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:41:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:41:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:41:34 [INFO ]  	   step  1 (lr=0.192614)                   59.41%                   1.3213
2022-09-11 12:41:34 [INFO ]  
2022-09-11 12:41:34 [INFO ]  Epoch:  110	Loss: 1.2037	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:36 [INFO ]  Epoch:  111	Loss: 1.2031	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:41:38 [INFO ]  Epoch:  112	Loss: 1.2913	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:41:40 [INFO ]  Epoch:  113	Loss: 1.2611	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:41:42 [INFO ]  Epoch:  114	Loss: 1.2726	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:41:45 [INFO ]  Epoch:  115	Loss: 1.1108	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:41:47 [INFO ]  Epoch:  116	Loss: 1.0606	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:49 [INFO ]  Epoch:  117	Loss: 1.1454	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:41:51 [INFO ]  Epoch:  118	Loss: 1.0826	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:53 [INFO ]  Epoch:  119	Loss: 1.0721	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:41:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-09-11 12:41:56 [INFO ]  
2022-09-11 12:41:56 [INFO ]  Begin of epoch 120 :
2022-09-11 12:41:59 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:41:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:41:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:41:59 [INFO ]  	   step  1 (lr=0.193959)                   61.61%                   1.3227
2022-09-11 12:41:59 [INFO ]  
2022-09-11 12:41:59 [INFO ]  Epoch:  120	Loss: 1.2096	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:01 [INFO ]  Epoch:  121	Loss: 1.1769	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:42:03 [INFO ]  Epoch:  122	Loss: 1.0834	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:42:05 [INFO ]  Epoch:  123	Loss: 1.0261	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:42:07 [INFO ]  Epoch:  124	Loss: 1.1587	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:09 [INFO ]  Epoch:  125	Loss: 1.1070	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:42:11 [INFO ]  Epoch:  126	Loss: 1.1389	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:42:13 [INFO ]  Epoch:  127	Loss: 1.0769	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:42:15 [INFO ]  Epoch:  128	Loss: 1.1031	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:42:17 [INFO ]  Epoch:  129	Loss: 1.0736	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:42:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-09-11 12:42:20 [INFO ]  
2022-09-11 12:42:20 [INFO ]  Begin of epoch 130 :
2022-09-11 12:42:24 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:42:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:42:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:42:24 [INFO ]  	   step  1 (lr=0.196611)                   64.72%                   1.2044
2022-09-11 12:42:24 [INFO ]  
2022-09-11 12:42:24 [INFO ]  Epoch:  130	Loss: 1.1728	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:42:26 [INFO ]  Epoch:  131	Loss: 1.0891	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:42:28 [INFO ]  Epoch:  132	Loss: 1.1324	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:42:30 [INFO ]  Epoch:  133	Loss: 1.1668	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:42:32 [INFO ]  Epoch:  134	Loss: 1.2838	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:42:34 [INFO ]  Epoch:  135	Loss: 1.1728	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:36 [INFO ]  Epoch:  136	Loss: 1.1081	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:42:38 [INFO ]  Epoch:  137	Loss: 1.2406	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:40 [INFO ]  Epoch:  138	Loss: 1.2864	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:42:42 [INFO ]  Epoch:  139	Loss: 1.1843	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-09-11 12:42:45 [INFO ]  
2022-09-11 12:42:45 [INFO ]  Begin of epoch 140 :
2022-09-11 12:42:49 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:42:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:42:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:42:49 [INFO ]  	   step  1 (lr=0.197877)                   65.43%                   1.1787
2022-09-11 12:42:49 [INFO ]  
2022-09-11 12:42:49 [INFO ]  Epoch:  140	Loss: 1.1093	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:42:50 [INFO ]  Epoch:  141	Loss: 1.0478	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:42:52 [INFO ]  Epoch:  142	Loss: 1.1060	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:54 [INFO ]  Epoch:  143	Loss: 1.1151	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:42:56 [INFO ]  Epoch:  144	Loss: 1.0786	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:42:58 [INFO ]  Epoch:  145	Loss: 1.1469	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:00 [INFO ]  Epoch:  146	Loss: 1.1715	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:02 [INFO ]  Epoch:  147	Loss: 1.0824	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:43:04 [INFO ]  Epoch:  148	Loss: 1.0609	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:43:06 [INFO ]  Epoch:  149	Loss: 1.0784	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-09-11 12:43:09 [INFO ]  
2022-09-11 12:43:09 [INFO ]  Begin of epoch 150 :
2022-09-11 12:43:13 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:43:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:43:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:43:13 [INFO ]  	   step  1 (lr=0.198705)                   65.66%                   1.1772
2022-09-11 12:43:13 [INFO ]  
2022-09-11 12:43:13 [INFO ]  Epoch:  150	Loss: 1.0893	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:15 [INFO ]  Epoch:  151	Loss: 1.1089	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:17 [INFO ]  Epoch:  152	Loss: 1.0968	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:43:19 [INFO ]  Epoch:  153	Loss: 1.1134	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:21 [INFO ]  Epoch:  154	Loss: 1.0594	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:43:23 [INFO ]  Epoch:  155	Loss: 1.1025	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:25 [INFO ]  Epoch:  156	Loss: 1.1827	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:27 [INFO ]  Epoch:  157	Loss: 1.1496	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:43:29 [INFO ]  Epoch:  158	Loss: 1.1569	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:43:31 [INFO ]  Epoch:  159	Loss: 1.0814	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-09-11 12:43:34 [INFO ]  
2022-09-11 12:43:34 [INFO ]  Begin of epoch 160 :
2022-09-11 12:43:38 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:43:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:43:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:43:38 [INFO ]  	   step  1 (lr=0.199357)                   65.88%                   1.1700
2022-09-11 12:43:38 [INFO ]  
2022-09-11 12:43:38 [INFO ]  Epoch:  160	Loss: 1.1319	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:43:40 [INFO ]  Epoch:  161	Loss: 1.1670	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:43:42 [INFO ]  Epoch:  162	Loss: 1.0941	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:44 [INFO ]  Epoch:  163	Loss: 1.0937	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:46 [INFO ]  Epoch:  164	Loss: 1.1304	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:48 [INFO ]  Epoch:  165	Loss: 1.0899	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:43:50 [INFO ]  Epoch:  166	Loss: 1.1031	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:43:52 [INFO ]  Epoch:  167	Loss: 1.0625	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:43:54 [INFO ]  Epoch:  168	Loss: 1.0976	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:43:56 [INFO ]  Epoch:  169	Loss: 1.2472	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:43:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-09-11 12:43:59 [INFO ]  
2022-09-11 12:43:59 [INFO ]  Begin of epoch 170 :
2022-09-11 12:44:03 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:44:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:44:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:44:03 [INFO ]  	   step  1 (lr=0.199396)                   64.85%                   1.2006
2022-09-11 12:44:03 [INFO ]  
2022-09-11 12:44:03 [INFO ]  Epoch:  170	Loss: 1.1492	Data Time: 0.24s	Train Time: 0.00s
2022-09-11 12:44:05 [INFO ]  Epoch:  171	Loss: 1.0622	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:44:07 [INFO ]  Epoch:  172	Loss: 1.2531	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:44:09 [INFO ]  Epoch:  173	Loss: 1.1124	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:44:11 [INFO ]  Epoch:  174	Loss: 1.3221	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:44:13 [INFO ]  Epoch:  175	Loss: 1.1397	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:44:15 [INFO ]  Epoch:  176	Loss: 1.2148	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:17 [INFO ]  Epoch:  177	Loss: 1.1341	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:44:19 [INFO ]  Epoch:  178	Loss: 1.1499	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:20 [INFO ]  Epoch:  179	Loss: 1.0893	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:44:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-09-11 12:44:23 [INFO ]  
2022-09-11 12:44:23 [INFO ]  Begin of epoch 180 :
2022-09-11 12:44:27 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:44:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:44:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:44:27 [INFO ]  	   step  1 (lr=0.199222)                   65.30%                   1.1968
2022-09-11 12:44:27 [INFO ]  
2022-09-11 12:44:27 [INFO ]  Epoch:  180	Loss: 1.1311	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:29 [INFO ]  Epoch:  181	Loss: 1.1706	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:44:31 [INFO ]  Epoch:  182	Loss: 1.1736	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:44:33 [INFO ]  Epoch:  183	Loss: 1.3806	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:44:35 [INFO ]  Epoch:  184	Loss: 1.1847	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:44:37 [INFO ]  Epoch:  185	Loss: 1.0677	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:44:40 [INFO ]  Epoch:  186	Loss: 1.1471	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:44:41 [INFO ]  Epoch:  187	Loss: 1.0377	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:44:43 [INFO ]  Epoch:  188	Loss: 1.1927	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:45 [INFO ]  Epoch:  189	Loss: 1.1730	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:44:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-09-11 12:44:49 [INFO ]  
2022-09-11 12:44:49 [INFO ]  Begin of epoch 190 :
2022-09-11 12:44:53 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:44:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:44:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:44:53 [INFO ]  	   step  1 (lr=0.199176)                   65.89%                   1.1725
2022-09-11 12:44:53 [INFO ]  
2022-09-11 12:44:53 [INFO ]  Epoch:  190	Loss: 1.0917	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:54 [INFO ]  Epoch:  191	Loss: 1.1526	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:44:56 [INFO ]  Epoch:  192	Loss: 1.1375	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:44:58 [INFO ]  Epoch:  193	Loss: 1.1880	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:45:00 [INFO ]  Epoch:  194	Loss: 1.0986	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:45:02 [INFO ]  Epoch:  195	Loss: 1.1623	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:45:04 [INFO ]  Epoch:  196	Loss: 1.0948	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:45:06 [INFO ]  Epoch:  197	Loss: 1.3040	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:45:08 [INFO ]  Epoch:  198	Loss: 1.1103	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:45:10 [INFO ]  Epoch:  199	Loss: 1.1573	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:45:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-09-11 12:45:13 [INFO ]  
2022-09-11 12:45:13 [INFO ]  Final evaluation for SVHN :
2022-09-11 12:45:16 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:45:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:45:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:45:16 [INFO ]  	   step  1 (lr=0.198889)                   65.80%                   1.1787
2022-09-11 12:45:16 [INFO ]  
2022-09-11 12:45:16 [INFO ]  
2022-09-11 12:45:16 [INFO ]  Final evaluation for FASHION_MNIST :
2022-09-11 12:45:20 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:45:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:45:20 [INFO ]  	            before steps                   87.27%                   0.3620
2022-09-11 12:45:20 [INFO ]  	   step  1 (lr=0.198889)                   21.75%                   4.2715
2022-09-11 12:45:20 [INFO ]  
2022-09-11 12:45:47 [INFO ]  ======================================== 2022-09-11 12:45:47 ========================================
2022-09-11 12:45:47 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-09-11 12:45:47 [INFO ]  Options: 
2022-09-11 12:45:47 [INFO ]  	base_dir: null
2022-09-11 12:45:47 [INFO ]  	batch_size: 1024
2022-09-11 12:45:47 [INFO ]  	checkpoint_interval: 10
2022-09-11 12:45:47 [INFO ]  	dataset: SVHN
2022-09-11 12:45:47 [INFO ]  	dataset_labels:
2022-09-11 12:45:47 [INFO ]  	- 0
2022-09-11 12:45:47 [INFO ]  	- 1
2022-09-11 12:45:47 [INFO ]  	- 2
2022-09-11 12:45:47 [INFO ]  	- 3
2022-09-11 12:45:47 [INFO ]  	- 4
2022-09-11 12:45:47 [INFO ]  	- 5
2022-09-11 12:45:47 [INFO ]  	- 6
2022-09-11 12:45:47 [INFO ]  	- 7
2022-09-11 12:45:47 [INFO ]  	- 8
2022-09-11 12:45:47 [INFO ]  	- 9
2022-09-11 12:45:47 [INFO ]  	dataset_normalization: !!python/tuple
2022-09-11 12:45:47 [INFO ]  	- !!python/tuple
2022-09-11 12:45:47 [INFO ]  	    - 0.4379104971885681
2022-09-11 12:45:47 [INFO ]  	    - 0.44398033618927
2022-09-11 12:45:47 [INFO ]  	    - 0.4729299545288086
2022-09-11 12:45:47 [INFO ]  	- !!python/tuple
2022-09-11 12:45:47 [INFO ]  	    - 0.19803012907505035
2022-09-11 12:45:47 [INFO ]  	    - 0.2010156363248825
2022-09-11 12:45:47 [INFO ]  	    - 0.19703614711761475
2022-09-11 12:45:47 [INFO ]  	dataset_root: ./data/svhn
2022-09-11 12:45:47 [INFO ]  	decay_epochs: 50
2022-09-11 12:45:47 [INFO ]  	decay_factor: 0.1
2022-09-11 12:45:47 [INFO ]  	device_id: 0
2022-09-11 12:45:47 [INFO ]  	distill_epochs: 1
2022-09-11 12:45:47 [INFO ]  	distill_lr: 0.02
2022-09-11 12:45:47 [INFO ]  	distill_steps: 1
2022-09-11 12:45:47 [INFO ]  	epochs: 200
2022-09-11 12:45:47 [INFO ]  	expand_cls: false
2022-09-11 12:45:47 [INFO ]  	forgetting_dataset: null
2022-09-11 12:45:47 [INFO ]  	init: xavier
2022-09-11 12:45:47 [INFO ]  	init_param: 1.0
2022-09-11 12:45:47 [INFO ]  	input_size: 32
2022-09-11 12:45:47 [INFO ]  	ipc: 1
2022-09-11 12:45:47 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-09-11 12:45:47 [INFO ]  	log_interval: 100
2022-09-11 12:45:47 [INFO ]  	log_level: INFO
2022-09-11 12:45:47 [INFO ]  	lr: 0.01
2022-09-11 12:45:47 [INFO ]  	mode: distill_adapt
2022-09-11 12:45:47 [INFO ]  	nc: 3
2022-09-11 12:45:47 [INFO ]  	num_classes: 10
2022-09-11 12:45:47 [INFO ]  	num_workers: 8
2022-09-11 12:45:47 [INFO ]  	phase: train
2022-09-11 12:45:47 [INFO ]  	source_dataset: FASHION_MNIST
2022-09-11 12:45:47 [INFO ]  	start_time: '2022-09-11 12:45:47'
2022-09-11 12:45:47 [INFO ]  	test_batch_size: 1024
2022-09-11 12:45:47 [INFO ]  	
2022-09-11 12:45:49 [INFO ]  train dataset size:	73257
2022-09-11 12:45:49 [INFO ]  test dataset size: 	26032
2022-09-11 12:45:49 [INFO ]  datasets built!
2022-09-11 12:45:49 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-09-11 12:45:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-09-11 12:45:52 [INFO ]  
2022-09-11 12:45:52 [INFO ]  Begin of epoch 0 :
2022-09-11 12:45:56 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:45:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:45:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:45:56 [INFO ]  	   step  1 (lr=0.020000)                    6.58%                  10.7880
2022-09-11 12:45:56 [INFO ]  
2022-09-11 12:45:56 [INFO ]  Epoch:    0	Loss: 10.2647	Data Time: 0.47s	Train Time: 0.03s
2022-09-11 12:45:58 [INFO ]  Epoch:    1	Loss: 3.7888	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:46:00 [INFO ]  Epoch:    2	Loss: 2.8679	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:02 [INFO ]  Epoch:    3	Loss: 2.6945	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:04 [INFO ]  Epoch:    4	Loss: 2.4606	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:06 [INFO ]  Epoch:    5	Loss: 2.2530	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:46:08 [INFO ]  Epoch:    6	Loss: 2.2621	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:46:10 [INFO ]  Epoch:    7	Loss: 2.2354	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:46:12 [INFO ]  Epoch:    8	Loss: 2.1950	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:46:14 [INFO ]  Epoch:    9	Loss: 2.2069	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:46:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-09-11 12:46:17 [INFO ]  
2022-09-11 12:46:17 [INFO ]  Begin of epoch 10 :
2022-09-11 12:46:21 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:46:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:46:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:46:21 [INFO ]  	   step  1 (lr=0.043852)                   27.09%                   2.1986
2022-09-11 12:46:21 [INFO ]  
2022-09-11 12:46:21 [INFO ]  Epoch:   10	Loss: 2.2169	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:22 [INFO ]  Epoch:   11	Loss: 2.2195	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:46:25 [INFO ]  Epoch:   12	Loss: 2.1665	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:26 [INFO ]  Epoch:   13	Loss: 2.1413	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:28 [INFO ]  Epoch:   14	Loss: 2.1275	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:46:30 [INFO ]  Epoch:   15	Loss: 2.1286	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:46:32 [INFO ]  Epoch:   16	Loss: 2.1048	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:35 [INFO ]  Epoch:   17	Loss: 2.1986	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:46:37 [INFO ]  Epoch:   18	Loss: 2.0874	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:46:39 [INFO ]  Epoch:   19	Loss: 2.0856	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:46:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-09-11 12:46:42 [INFO ]  
2022-09-11 12:46:42 [INFO ]  Begin of epoch 20 :
2022-09-11 12:46:46 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:46:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:46:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:46:46 [INFO ]  	   step  1 (lr=0.064821)                   24.11%                   2.1458
2022-09-11 12:46:46 [INFO ]  
2022-09-11 12:46:46 [INFO ]  Epoch:   20	Loss: 2.1722	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:46:47 [INFO ]  Epoch:   21	Loss: 1.9875	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:46:49 [INFO ]  Epoch:   22	Loss: 1.9419	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:46:52 [INFO ]  Epoch:   23	Loss: 1.9276	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:46:53 [INFO ]  Epoch:   24	Loss: 1.8524	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:46:55 [INFO ]  Epoch:   25	Loss: 2.0308	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:46:57 [INFO ]  Epoch:   26	Loss: 1.8232	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:46:59 [INFO ]  Epoch:   27	Loss: 1.9469	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:47:01 [INFO ]  Epoch:   28	Loss: 1.8649	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:47:03 [INFO ]  Epoch:   29	Loss: 1.8706	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:47:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-09-11 12:47:06 [INFO ]  
2022-09-11 12:47:06 [INFO ]  Begin of epoch 30 :
2022-09-11 12:47:10 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:47:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:47:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:47:10 [INFO ]  	   step  1 (lr=0.119751)                   15.02%                   2.5057
2022-09-11 12:47:10 [INFO ]  
2022-09-11 12:47:10 [INFO ]  Epoch:   30	Loss: 2.3135	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:47:12 [INFO ]  Epoch:   31	Loss: 1.7016	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:47:14 [INFO ]  Epoch:   32	Loss: 1.7231	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:47:16 [INFO ]  Epoch:   33	Loss: 2.4789	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:47:18 [INFO ]  Epoch:   34	Loss: 1.8055	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:47:20 [INFO ]  Epoch:   35	Loss: 1.7241	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:47:22 [INFO ]  Epoch:   36	Loss: 2.0452	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:47:24 [INFO ]  Epoch:   37	Loss: 1.6619	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:47:25 [INFO ]  Epoch:   38	Loss: 1.7855	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:47:27 [INFO ]  Epoch:   39	Loss: 1.6719	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:47:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-09-11 12:47:31 [INFO ]  
2022-09-11 12:47:31 [INFO ]  Begin of epoch 40 :
2022-09-11 12:47:34 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:47:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:47:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:47:34 [INFO ]  	   step  1 (lr=0.143871)                   46.75%                   1.6501
2022-09-11 12:47:34 [INFO ]  
2022-09-11 12:47:34 [INFO ]  Epoch:   40	Loss: 1.6339	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:47:36 [INFO ]  Epoch:   41	Loss: 2.0708	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:47:38 [INFO ]  Epoch:   42	Loss: 2.3138	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:47:40 [INFO ]  Epoch:   43	Loss: 2.2704	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:47:42 [INFO ]  Epoch:   44	Loss: 2.2195	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:47:44 [INFO ]  Epoch:   45	Loss: 2.1983	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:47:46 [INFO ]  Epoch:   46	Loss: 2.1538	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:47:48 [INFO ]  Epoch:   47	Loss: 2.1111	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:47:50 [INFO ]  Epoch:   48	Loss: 2.0621	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:47:52 [INFO ]  Epoch:   49	Loss: 2.0713	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:47:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-09-11 12:47:55 [INFO ]  
2022-09-11 12:47:55 [INFO ]  Begin of epoch 50 :
2022-09-11 12:47:59 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:47:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:47:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:47:59 [INFO ]  	   step  1 (lr=0.097051)                   36.17%                   2.0120
2022-09-11 12:47:59 [INFO ]  
2022-09-11 12:47:59 [INFO ]  Epoch:   50	Loss: 2.0389	Data Time: 0.22s	Train Time: 0.00s
2022-09-11 12:48:00 [INFO ]  Epoch:   51	Loss: 2.0022	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:03 [INFO ]  Epoch:   52	Loss: 2.0152	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:48:05 [INFO ]  Epoch:   53	Loss: 1.9885	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:48:07 [INFO ]  Epoch:   54	Loss: 2.0114	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:48:09 [INFO ]  Epoch:   55	Loss: 1.9905	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:48:10 [INFO ]  Epoch:   56	Loss: 2.0004	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:48:12 [INFO ]  Epoch:   57	Loss: 2.0083	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:48:14 [INFO ]  Epoch:   58	Loss: 1.9478	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:48:16 [INFO ]  Epoch:   59	Loss: 1.9687	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:48:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-09-11 12:48:19 [INFO ]  
2022-09-11 12:48:19 [INFO ]  Begin of epoch 60 :
2022-09-11 12:48:23 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:48:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:48:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:48:23 [INFO ]  	   step  1 (lr=0.101828)                   35.38%                   1.9714
2022-09-11 12:48:23 [INFO ]  
2022-09-11 12:48:23 [INFO ]  Epoch:   60	Loss: 1.9131	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:48:25 [INFO ]  Epoch:   61	Loss: 1.9170	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:48:27 [INFO ]  Epoch:   62	Loss: 1.9128	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:48:29 [INFO ]  Epoch:   63	Loss: 1.8458	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:48:31 [INFO ]  Epoch:   64	Loss: 1.8382	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:33 [INFO ]  Epoch:   65	Loss: 1.8974	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:48:35 [INFO ]  Epoch:   66	Loss: 1.8588	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:37 [INFO ]  Epoch:   67	Loss: 1.8660	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:48:38 [INFO ]  Epoch:   68	Loss: 1.8082	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:48:40 [INFO ]  Epoch:   69	Loss: 1.7770	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:48:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-09-11 12:48:43 [INFO ]  
2022-09-11 12:48:43 [INFO ]  Begin of epoch 70 :
2022-09-11 12:48:47 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:48:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:48:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:48:47 [INFO ]  	   step  1 (lr=0.115432)                   41.29%                   1.7711
2022-09-11 12:48:47 [INFO ]  
2022-09-11 12:48:47 [INFO ]  Epoch:   70	Loss: 1.7887	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:48:49 [INFO ]  Epoch:   71	Loss: 1.7345	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:48:51 [INFO ]  Epoch:   72	Loss: 1.7333	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:53 [INFO ]  Epoch:   73	Loss: 1.7039	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:48:55 [INFO ]  Epoch:   74	Loss: 1.7033	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:57 [INFO ]  Epoch:   75	Loss: 1.6561	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:48:59 [INFO ]  Epoch:   76	Loss: 1.6924	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:01 [INFO ]  Epoch:   77	Loss: 1.6228	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:03 [INFO ]  Epoch:   78	Loss: 1.5766	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:49:05 [INFO ]  Epoch:   79	Loss: 1.5861	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-09-11 12:49:09 [INFO ]  
2022-09-11 12:49:09 [INFO ]  Begin of epoch 80 :
2022-09-11 12:49:12 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:49:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:49:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:49:12 [INFO ]  	   step  1 (lr=0.140782)                   45.29%                   1.6869
2022-09-11 12:49:12 [INFO ]  
2022-09-11 12:49:12 [INFO ]  Epoch:   80	Loss: 1.6165	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:14 [INFO ]  Epoch:   81	Loss: 1.5790	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:49:16 [INFO ]  Epoch:   82	Loss: 1.6276	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:49:18 [INFO ]  Epoch:   83	Loss: 1.5773	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:20 [INFO ]  Epoch:   84	Loss: 1.5953	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:49:22 [INFO ]  Epoch:   85	Loss: 1.6004	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:49:24 [INFO ]  Epoch:   86	Loss: 1.5150	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:26 [INFO ]  Epoch:   87	Loss: 1.5659	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:49:28 [INFO ]  Epoch:   88	Loss: 1.5193	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:30 [INFO ]  Epoch:   89	Loss: 1.5936	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-09-11 12:49:33 [INFO ]  
2022-09-11 12:49:33 [INFO ]  Begin of epoch 90 :
2022-09-11 12:49:37 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:49:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:49:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:49:37 [INFO ]  	   step  1 (lr=0.159243)                   43.46%                   1.7005
2022-09-11 12:49:37 [INFO ]  
2022-09-11 12:49:37 [INFO ]  Epoch:   90	Loss: 1.5959	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:49:38 [INFO ]  Epoch:   91	Loss: 1.4791	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:49:40 [INFO ]  Epoch:   92	Loss: 1.5297	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:42 [INFO ]  Epoch:   93	Loss: 1.5019	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:49:44 [INFO ]  Epoch:   94	Loss: 1.5444	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:49:46 [INFO ]  Epoch:   95	Loss: 1.6320	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:49:48 [INFO ]  Epoch:   96	Loss: 1.5626	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:50 [INFO ]  Epoch:   97	Loss: 1.4654	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:49:52 [INFO ]  Epoch:   98	Loss: 1.5123	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:49:54 [INFO ]  Epoch:   99	Loss: 1.5588	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:49:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-09-11 12:49:57 [INFO ]  
2022-09-11 12:49:57 [INFO ]  Begin of epoch 100 :
2022-09-11 12:50:01 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:50:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:50:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:50:01 [INFO ]  	   step  1 (lr=0.165749)                   50.12%                   1.5595
2022-09-11 12:50:01 [INFO ]  
2022-09-11 12:50:01 [INFO ]  Epoch:  100	Loss: 1.4892	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:03 [INFO ]  Epoch:  101	Loss: 1.4337	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:05 [INFO ]  Epoch:  102	Loss: 1.5599	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:50:07 [INFO ]  Epoch:  103	Loss: 1.5302	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:50:09 [INFO ]  Epoch:  104	Loss: 1.5220	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:50:11 [INFO ]  Epoch:  105	Loss: 1.4874	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:50:13 [INFO ]  Epoch:  106	Loss: 1.4887	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:50:15 [INFO ]  Epoch:  107	Loss: 1.5465	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:50:17 [INFO ]  Epoch:  108	Loss: 1.4622	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:50:19 [INFO ]  Epoch:  109	Loss: 1.5113	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:50:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-09-11 12:50:22 [INFO ]  
2022-09-11 12:50:22 [INFO ]  Begin of epoch 110 :
2022-09-11 12:50:26 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:50:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:50:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:50:26 [INFO ]  	   step  1 (lr=0.166695)                   50.00%                   1.5649
2022-09-11 12:50:26 [INFO ]  
2022-09-11 12:50:26 [INFO ]  Epoch:  110	Loss: 1.5146	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:50:28 [INFO ]  Epoch:  111	Loss: 1.5092	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:50:30 [INFO ]  Epoch:  112	Loss: 1.5143	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:50:32 [INFO ]  Epoch:  113	Loss: 1.6143	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:50:34 [INFO ]  Epoch:  114	Loss: 1.5088	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:36 [INFO ]  Epoch:  115	Loss: 1.4749	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:38 [INFO ]  Epoch:  116	Loss: 1.5126	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:50:40 [INFO ]  Epoch:  117	Loss: 1.5298	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:50:42 [INFO ]  Epoch:  118	Loss: 1.4663	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:44 [INFO ]  Epoch:  119	Loss: 1.5403	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-09-11 12:50:47 [INFO ]  
2022-09-11 12:50:47 [INFO ]  Begin of epoch 120 :
2022-09-11 12:50:51 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:50:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:50:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:50:51 [INFO ]  	   step  1 (lr=0.165322)                   49.30%                   1.5788
2022-09-11 12:50:51 [INFO ]  
2022-09-11 12:50:51 [INFO ]  Epoch:  120	Loss: 1.5848	Data Time: 0.18s	Train Time: 0.00s
2022-09-11 12:50:53 [INFO ]  Epoch:  121	Loss: 1.4764	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:55 [INFO ]  Epoch:  122	Loss: 1.5197	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:50:56 [INFO ]  Epoch:  123	Loss: 1.4803	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:50:58 [INFO ]  Epoch:  124	Loss: 1.4719	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:51:01 [INFO ]  Epoch:  125	Loss: 1.5265	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:51:02 [INFO ]  Epoch:  126	Loss: 1.4835	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:51:04 [INFO ]  Epoch:  127	Loss: 1.4933	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:51:06 [INFO ]  Epoch:  128	Loss: 1.4418	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:08 [INFO ]  Epoch:  129	Loss: 1.4908	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:51:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-09-11 12:51:11 [INFO ]  
2022-09-11 12:51:11 [INFO ]  Begin of epoch 130 :
2022-09-11 12:51:15 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:51:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:51:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:51:15 [INFO ]  	   step  1 (lr=0.170248)                   50.07%                   1.5635
2022-09-11 12:51:15 [INFO ]  
2022-09-11 12:51:15 [INFO ]  Epoch:  130	Loss: 1.5453	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:51:17 [INFO ]  Epoch:  131	Loss: 1.4042	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:51:19 [INFO ]  Epoch:  132	Loss: 1.5042	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:51:21 [INFO ]  Epoch:  133	Loss: 1.5124	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:51:23 [INFO ]  Epoch:  134	Loss: 1.4811	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:25 [INFO ]  Epoch:  135	Loss: 1.4945	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:27 [INFO ]  Epoch:  136	Loss: 1.4656	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:51:29 [INFO ]  Epoch:  137	Loss: 1.5015	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:51:31 [INFO ]  Epoch:  138	Loss: 1.5389	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:51:33 [INFO ]  Epoch:  139	Loss: 1.4704	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:51:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-09-11 12:51:36 [INFO ]  
2022-09-11 12:51:36 [INFO ]  Begin of epoch 140 :
2022-09-11 12:51:40 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:51:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:51:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:51:40 [INFO ]  	   step  1 (lr=0.175146)                   50.45%                   1.5538
2022-09-11 12:51:40 [INFO ]  
2022-09-11 12:51:40 [INFO ]  Epoch:  140	Loss: 1.4903	Data Time: 0.23s	Train Time: 0.00s
2022-09-11 12:51:42 [INFO ]  Epoch:  141	Loss: 1.6055	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:44 [INFO ]  Epoch:  142	Loss: 1.7686	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:51:46 [INFO ]  Epoch:  143	Loss: 1.6737	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:51:48 [INFO ]  Epoch:  144	Loss: 1.8038	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:50 [INFO ]  Epoch:  145	Loss: 1.5262	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:52 [INFO ]  Epoch:  146	Loss: 1.6342	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:51:54 [INFO ]  Epoch:  147	Loss: 1.6929	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:56 [INFO ]  Epoch:  148	Loss: 1.7107	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:51:58 [INFO ]  Epoch:  149	Loss: 1.4809	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:52:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-09-11 12:52:01 [INFO ]  
2022-09-11 12:52:01 [INFO ]  Begin of epoch 150 :
2022-09-11 12:52:05 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:52:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:52:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:52:05 [INFO ]  	   step  1 (lr=0.169940)                   42.56%                   1.7377
2022-09-11 12:52:05 [INFO ]  
2022-09-11 12:52:05 [INFO ]  Epoch:  150	Loss: 1.6508	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:52:07 [INFO ]  Epoch:  151	Loss: 1.5382	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:52:09 [INFO ]  Epoch:  152	Loss: 1.4803	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:52:10 [INFO ]  Epoch:  153	Loss: 1.6645	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:52:12 [INFO ]  Epoch:  154	Loss: 1.5148	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:52:14 [INFO ]  Epoch:  155	Loss: 1.7121	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:52:16 [INFO ]  Epoch:  156	Loss: 1.5101	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:52:18 [INFO ]  Epoch:  157	Loss: 1.5131	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:52:20 [INFO ]  Epoch:  158	Loss: 1.4571	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:52:22 [INFO ]  Epoch:  159	Loss: 1.6850	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:52:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-09-11 12:52:25 [INFO ]  
2022-09-11 12:52:25 [INFO ]  Begin of epoch 160 :
2022-09-11 12:52:29 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:52:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:52:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:52:29 [INFO ]  	   step  1 (lr=0.169624)                   49.99%                   1.5885
2022-09-11 12:52:29 [INFO ]  
2022-09-11 12:52:29 [INFO ]  Epoch:  160	Loss: 1.5594	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 12:52:31 [INFO ]  Epoch:  161	Loss: 1.4805	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:52:33 [INFO ]  Epoch:  162	Loss: 1.5439	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:52:35 [INFO ]  Epoch:  163	Loss: 1.4807	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:52:37 [INFO ]  Epoch:  164	Loss: 1.4775	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:52:39 [INFO ]  Epoch:  165	Loss: 1.6611	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:52:41 [INFO ]  Epoch:  166	Loss: 1.4793	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:52:43 [INFO ]  Epoch:  167	Loss: 1.6532	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:52:45 [INFO ]  Epoch:  168	Loss: 1.5582	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:52:47 [INFO ]  Epoch:  169	Loss: 1.5458	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:52:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-09-11 12:52:50 [INFO ]  
2022-09-11 12:52:50 [INFO ]  Begin of epoch 170 :
2022-09-11 12:52:53 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:52:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:52:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:52:53 [INFO ]  	   step  1 (lr=0.169344)                   50.06%                   1.5794
2022-09-11 12:52:53 [INFO ]  
2022-09-11 12:52:53 [INFO ]  Epoch:  170	Loss: 1.5321	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:52:55 [INFO ]  Epoch:  171	Loss: 1.5395	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:52:57 [INFO ]  Epoch:  172	Loss: 1.6611	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:52:59 [INFO ]  Epoch:  173	Loss: 1.5018	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:53:01 [INFO ]  Epoch:  174	Loss: 1.4944	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:03 [INFO ]  Epoch:  175	Loss: 1.4701	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:53:05 [INFO ]  Epoch:  176	Loss: 1.4862	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:53:07 [INFO ]  Epoch:  177	Loss: 1.5427	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:53:09 [INFO ]  Epoch:  178	Loss: 1.5256	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:53:11 [INFO ]  Epoch:  179	Loss: 1.5345	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-09-11 12:53:14 [INFO ]  
2022-09-11 12:53:14 [INFO ]  Begin of epoch 180 :
2022-09-11 12:53:17 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:53:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:53:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:53:17 [INFO ]  	   step  1 (lr=0.169163)                   43.10%                   1.7521
2022-09-11 12:53:17 [INFO ]  
2022-09-11 12:53:17 [INFO ]  Epoch:  180	Loss: 1.6868	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:19 [INFO ]  Epoch:  181	Loss: 1.7115	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:53:21 [INFO ]  Epoch:  182	Loss: 1.7598	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:53:23 [INFO ]  Epoch:  183	Loss: 1.7353	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:53:25 [INFO ]  Epoch:  184	Loss: 1.4995	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:27 [INFO ]  Epoch:  185	Loss: 1.5536	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:53:29 [INFO ]  Epoch:  186	Loss: 1.4794	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:53:31 [INFO ]  Epoch:  187	Loss: 1.5274	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:33 [INFO ]  Epoch:  188	Loss: 1.5275	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:53:35 [INFO ]  Epoch:  189	Loss: 1.5565	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-09-11 12:53:39 [INFO ]  
2022-09-11 12:53:39 [INFO ]  Begin of epoch 190 :
2022-09-11 12:53:42 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:53:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:53:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:53:42 [INFO ]  	   step  1 (lr=0.168696)                   50.50%                   1.5633
2022-09-11 12:53:42 [INFO ]  
2022-09-11 12:53:42 [INFO ]  Epoch:  190	Loss: 1.4438	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:53:44 [INFO ]  Epoch:  191	Loss: 1.5650	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:53:46 [INFO ]  Epoch:  192	Loss: 1.4875	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:48 [INFO ]  Epoch:  193	Loss: 1.5033	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:53:50 [INFO ]  Epoch:  194	Loss: 1.7479	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:53:52 [INFO ]  Epoch:  195	Loss: 1.5677	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:53:54 [INFO ]  Epoch:  196	Loss: 1.6688	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:53:56 [INFO ]  Epoch:  197	Loss: 1.4961	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:53:58 [INFO ]  Epoch:  198	Loss: 1.6866	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:54:00 [INFO ]  Epoch:  199	Loss: 1.5073	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:54:03 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-09-11 12:54:03 [INFO ]  
2022-09-11 12:54:03 [INFO ]  Final evaluation for SVHN :
2022-09-11 12:54:06 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:54:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:54:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:54:06 [INFO ]  	   step  1 (lr=0.168555)                   49.87%                   1.5771
2022-09-11 12:54:06 [INFO ]  
2022-09-11 12:54:06 [INFO ]  
2022-09-11 12:54:06 [INFO ]  Final evaluation for FASHION_MNIST :
2022-09-11 12:54:10 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:54:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:54:10 [INFO ]  	            before steps                   87.27%                   0.3620
2022-09-11 12:54:10 [INFO ]  	   step  1 (lr=0.168555)                   24.81%                   3.5950
2022-09-11 12:54:10 [INFO ]  
2022-09-11 12:54:39 [INFO ]  ======================================== 2022-09-11 12:54:39 ========================================
2022-09-11 12:54:39 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-09-11 12:54:39 [INFO ]  Options: 
2022-09-11 12:54:39 [INFO ]  	base_dir: null
2022-09-11 12:54:39 [INFO ]  	batch_size: 1024
2022-09-11 12:54:39 [INFO ]  	checkpoint_interval: 10
2022-09-11 12:54:39 [INFO ]  	dataset: SVHN
2022-09-11 12:54:39 [INFO ]  	dataset_labels:
2022-09-11 12:54:39 [INFO ]  	- 0
2022-09-11 12:54:39 [INFO ]  	- 1
2022-09-11 12:54:39 [INFO ]  	- 2
2022-09-11 12:54:39 [INFO ]  	- 3
2022-09-11 12:54:39 [INFO ]  	- 4
2022-09-11 12:54:39 [INFO ]  	- 5
2022-09-11 12:54:39 [INFO ]  	- 6
2022-09-11 12:54:39 [INFO ]  	- 7
2022-09-11 12:54:39 [INFO ]  	- 8
2022-09-11 12:54:39 [INFO ]  	- 9
2022-09-11 12:54:39 [INFO ]  	dataset_normalization: !!python/tuple
2022-09-11 12:54:39 [INFO ]  	- !!python/tuple
2022-09-11 12:54:39 [INFO ]  	    - 0.4379104971885681
2022-09-11 12:54:39 [INFO ]  	    - 0.44398033618927
2022-09-11 12:54:39 [INFO ]  	    - 0.4729299545288086
2022-09-11 12:54:39 [INFO ]  	- !!python/tuple
2022-09-11 12:54:39 [INFO ]  	    - 0.19803012907505035
2022-09-11 12:54:39 [INFO ]  	    - 0.2010156363248825
2022-09-11 12:54:39 [INFO ]  	    - 0.19703614711761475
2022-09-11 12:54:39 [INFO ]  	dataset_root: ./data/svhn
2022-09-11 12:54:39 [INFO ]  	decay_epochs: 50
2022-09-11 12:54:39 [INFO ]  	decay_factor: 0.1
2022-09-11 12:54:39 [INFO ]  	device_id: 0
2022-09-11 12:54:39 [INFO ]  	distill_epochs: 1
2022-09-11 12:54:39 [INFO ]  	distill_lr: 0.02
2022-09-11 12:54:39 [INFO ]  	distill_steps: 1
2022-09-11 12:54:39 [INFO ]  	epochs: 200
2022-09-11 12:54:39 [INFO ]  	expand_cls: false
2022-09-11 12:54:39 [INFO ]  	forgetting_dataset: null
2022-09-11 12:54:39 [INFO ]  	init: xavier
2022-09-11 12:54:39 [INFO ]  	init_param: 1.0
2022-09-11 12:54:39 [INFO ]  	input_size: 32
2022-09-11 12:54:39 [INFO ]  	ipc: 1
2022-09-11 12:54:39 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-09-11 12:54:39 [INFO ]  	log_interval: 100
2022-09-11 12:54:39 [INFO ]  	log_level: INFO
2022-09-11 12:54:39 [INFO ]  	lr: 0.01
2022-09-11 12:54:39 [INFO ]  	mode: distill_adapt
2022-09-11 12:54:39 [INFO ]  	nc: 3
2022-09-11 12:54:39 [INFO ]  	num_classes: 10
2022-09-11 12:54:39 [INFO ]  	num_workers: 8
2022-09-11 12:54:39 [INFO ]  	phase: train
2022-09-11 12:54:39 [INFO ]  	source_dataset: FASHION_MNIST
2022-09-11 12:54:39 [INFO ]  	start_time: '2022-09-11 12:54:39'
2022-09-11 12:54:39 [INFO ]  	test_batch_size: 1024
2022-09-11 12:54:39 [INFO ]  	
2022-09-11 12:54:41 [INFO ]  train dataset size:	73257
2022-09-11 12:54:41 [INFO ]  test dataset size: 	26032
2022-09-11 12:54:41 [INFO ]  datasets built!
2022-09-11 12:54:41 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-09-11 12:54:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-09-11 12:54:44 [INFO ]  
2022-09-11 12:54:44 [INFO ]  Begin of epoch 0 :
2022-09-11 12:54:48 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:54:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:54:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:54:48 [INFO ]  	   step  1 (lr=0.020000)                    6.83%                   8.9823
2022-09-11 12:54:48 [INFO ]  
2022-09-11 12:54:48 [INFO ]  Epoch:    0	Loss: 9.4268	Data Time: 0.48s	Train Time: 0.03s
2022-09-11 12:54:49 [INFO ]  Epoch:    1	Loss: 3.5376	Data Time: 0.14s	Train Time: 0.01s
2022-09-11 12:54:51 [INFO ]  Epoch:    2	Loss: 2.9537	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:54:53 [INFO ]  Epoch:    3	Loss: 2.7617	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:54:55 [INFO ]  Epoch:    4	Loss: 2.4529	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:54:57 [INFO ]  Epoch:    5	Loss: 2.2849	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:54:59 [INFO ]  Epoch:    6	Loss: 2.2580	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:55:02 [INFO ]  Epoch:    7	Loss: 2.2278	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:55:04 [INFO ]  Epoch:    8	Loss: 2.2623	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:55:06 [INFO ]  Epoch:    9	Loss: 2.2001	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:55:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-09-11 12:55:09 [INFO ]  
2022-09-11 12:55:09 [INFO ]  Begin of epoch 10 :
2022-09-11 12:55:13 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:55:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:55:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:55:13 [INFO ]  	   step  1 (lr=0.047350)                   26.72%                   2.1741
2022-09-11 12:55:13 [INFO ]  
2022-09-11 12:55:13 [INFO ]  Epoch:   10	Loss: 2.2095	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:55:15 [INFO ]  Epoch:   11	Loss: 2.1645	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:55:17 [INFO ]  Epoch:   12	Loss: 2.1338	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:55:18 [INFO ]  Epoch:   13	Loss: 2.1123	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:55:20 [INFO ]  Epoch:   14	Loss: 2.0728	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:55:22 [INFO ]  Epoch:   15	Loss: 2.0006	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:25 [INFO ]  Epoch:   16	Loss: 1.9450	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:55:27 [INFO ]  Epoch:   17	Loss: 1.8841	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:55:28 [INFO ]  Epoch:   18	Loss: 1.9315	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:55:30 [INFO ]  Epoch:   19	Loss: 2.0923	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-09-11 12:55:34 [INFO ]  
2022-09-11 12:55:34 [INFO ]  Begin of epoch 20 :
2022-09-11 12:55:37 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:55:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:55:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:55:37 [INFO ]  	   step  1 (lr=0.095808)                   37.95%                   1.8910
2022-09-11 12:55:37 [INFO ]  
2022-09-11 12:55:37 [INFO ]  Epoch:   20	Loss: 1.8731	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:55:39 [INFO ]  Epoch:   21	Loss: 1.8497	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:41 [INFO ]  Epoch:   22	Loss: 1.9308	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:55:43 [INFO ]  Epoch:   23	Loss: 1.8125	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:45 [INFO ]  Epoch:   24	Loss: 1.8776	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:55:47 [INFO ]  Epoch:   25	Loss: 1.7335	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:49 [INFO ]  Epoch:   26	Loss: 1.5472	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:55:51 [INFO ]  Epoch:   27	Loss: 2.2523	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:55:53 [INFO ]  Epoch:   28	Loss: 1.5879	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:55:55 [INFO ]  Epoch:   29	Loss: 1.5930	Data Time: 0.28s	Train Time: 0.01s
2022-09-11 12:55:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-09-11 12:55:58 [INFO ]  
2022-09-11 12:55:58 [INFO ]  Begin of epoch 30 :
2022-09-11 12:56:01 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:56:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:56:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:56:01 [INFO ]  	   step  1 (lr=0.158543)                   49.10%                   1.5678
2022-09-11 12:56:01 [INFO ]  
2022-09-11 12:56:01 [INFO ]  Epoch:   30	Loss: 1.4529	Data Time: 0.17s	Train Time: 0.00s
2022-09-11 12:56:03 [INFO ]  Epoch:   31	Loss: 1.5392	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:05 [INFO ]  Epoch:   32	Loss: 2.4570	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:56:07 [INFO ]  Epoch:   33	Loss: 1.4589	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:56:09 [INFO ]  Epoch:   34	Loss: 1.5141	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:56:11 [INFO ]  Epoch:   35	Loss: 1.3869	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:14 [INFO ]  Epoch:   36	Loss: 1.4290	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:56:15 [INFO ]  Epoch:   37	Loss: 1.4970	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:18 [INFO ]  Epoch:   38	Loss: 1.3885	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:56:20 [INFO ]  Epoch:   39	Loss: 1.4879	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:56:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-09-11 12:56:23 [INFO ]  
2022-09-11 12:56:23 [INFO ]  Begin of epoch 40 :
2022-09-11 12:56:27 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:56:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:56:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:56:27 [INFO ]  	   step  1 (lr=0.177638)                   53.72%                   1.4916
2022-09-11 12:56:27 [INFO ]  
2022-09-11 12:56:27 [INFO ]  Epoch:   40	Loss: 1.4816	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:56:28 [INFO ]  Epoch:   41	Loss: 1.6049	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:30 [INFO ]  Epoch:   42	Loss: 1.3576	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:56:32 [INFO ]  Epoch:   43	Loss: 1.4294	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:56:34 [INFO ]  Epoch:   44	Loss: 1.2478	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:56:37 [INFO ]  Epoch:   45	Loss: 1.2779	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:56:39 [INFO ]  Epoch:   46	Loss: 1.4563	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:56:41 [INFO ]  Epoch:   47	Loss: 1.4807	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:43 [INFO ]  Epoch:   48	Loss: 1.5103	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:45 [INFO ]  Epoch:   49	Loss: 1.2455	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:56:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-09-11 12:56:48 [INFO ]  
2022-09-11 12:56:48 [INFO ]  Begin of epoch 50 :
2022-09-11 12:56:51 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:56:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:56:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:56:51 [INFO ]  	   step  1 (lr=0.201400)                   61.18%                   1.3010
2022-09-11 12:56:51 [INFO ]  
2022-09-11 12:56:51 [INFO ]  Epoch:   50	Loss: 1.2176	Data Time: 0.25s	Train Time: 0.00s
2022-09-11 12:56:53 [INFO ]  Epoch:   51	Loss: 1.2879	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:55 [INFO ]  Epoch:   52	Loss: 1.1813	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:56:57 [INFO ]  Epoch:   53	Loss: 1.3364	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:56:59 [INFO ]  Epoch:   54	Loss: 1.2569	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:57:01 [INFO ]  Epoch:   55	Loss: 1.3749	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:57:03 [INFO ]  Epoch:   56	Loss: 1.3022	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:05 [INFO ]  Epoch:   57	Loss: 1.2218	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:57:07 [INFO ]  Epoch:   58	Loss: 1.1887	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:09 [INFO ]  Epoch:   59	Loss: 1.1487	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-09-11 12:57:12 [INFO ]  
2022-09-11 12:57:12 [INFO ]  Begin of epoch 60 :
2022-09-11 12:57:16 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:57:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:57:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:57:16 [INFO ]  	   step  1 (lr=0.205237)                   57.48%                   1.3987
2022-09-11 12:57:16 [INFO ]  
2022-09-11 12:57:16 [INFO ]  Epoch:   60	Loss: 1.2941	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:18 [INFO ]  Epoch:   61	Loss: 1.2099	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:20 [INFO ]  Epoch:   62	Loss: 1.1675	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:22 [INFO ]  Epoch:   63	Loss: 1.2729	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:24 [INFO ]  Epoch:   64	Loss: 1.1901	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:57:26 [INFO ]  Epoch:   65	Loss: 1.2151	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 12:57:28 [INFO ]  Epoch:   66	Loss: 1.4008	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:57:30 [INFO ]  Epoch:   67	Loss: 1.1547	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:32 [INFO ]  Epoch:   68	Loss: 1.1055	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:34 [INFO ]  Epoch:   69	Loss: 1.1869	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:57:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-09-11 12:57:37 [INFO ]  
2022-09-11 12:57:37 [INFO ]  Begin of epoch 70 :
2022-09-11 12:57:41 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:57:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:57:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:57:41 [INFO ]  	   step  1 (lr=0.209640)                   62.90%                   1.2409
2022-09-11 12:57:41 [INFO ]  
2022-09-11 12:57:41 [INFO ]  Epoch:   70	Loss: 1.1248	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:57:42 [INFO ]  Epoch:   71	Loss: 1.1124	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:57:44 [INFO ]  Epoch:   72	Loss: 1.1534	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:46 [INFO ]  Epoch:   73	Loss: 1.0767	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:57:49 [INFO ]  Epoch:   74	Loss: 1.1023	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:57:51 [INFO ]  Epoch:   75	Loss: 1.2180	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:53 [INFO ]  Epoch:   76	Loss: 1.0812	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:57:55 [INFO ]  Epoch:   77	Loss: 1.2044	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:57:57 [INFO ]  Epoch:   78	Loss: 1.1366	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:57:59 [INFO ]  Epoch:   79	Loss: 1.1390	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:58:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-09-11 12:58:02 [INFO ]  
2022-09-11 12:58:02 [INFO ]  Begin of epoch 80 :
2022-09-11 12:58:06 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:58:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:58:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:58:06 [INFO ]  	   step  1 (lr=0.221402)                   64.82%                   1.2068
2022-09-11 12:58:06 [INFO ]  
2022-09-11 12:58:06 [INFO ]  Epoch:   80	Loss: 1.0452	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:58:08 [INFO ]  Epoch:   81	Loss: 1.2139	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:58:10 [INFO ]  Epoch:   82	Loss: 1.2983	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:58:12 [INFO ]  Epoch:   83	Loss: 1.3494	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:58:14 [INFO ]  Epoch:   84	Loss: 1.1135	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:58:16 [INFO ]  Epoch:   85	Loss: 1.6923	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:58:18 [INFO ]  Epoch:   86	Loss: 1.1730	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:58:20 [INFO ]  Epoch:   87	Loss: 1.1910	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:58:22 [INFO ]  Epoch:   88	Loss: 1.2232	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:58:24 [INFO ]  Epoch:   89	Loss: 1.1724	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 12:58:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-09-11 12:58:27 [INFO ]  
2022-09-11 12:58:27 [INFO ]  Begin of epoch 90 :
2022-09-11 12:58:30 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:58:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:58:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:58:30 [INFO ]  	   step  1 (lr=0.221522)                   65.24%                   1.1845
2022-09-11 12:58:30 [INFO ]  
2022-09-11 12:58:30 [INFO ]  Epoch:   90	Loss: 1.1075	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:58:32 [INFO ]  Epoch:   91	Loss: 1.1860	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:58:34 [INFO ]  Epoch:   92	Loss: 1.1164	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:58:36 [INFO ]  Epoch:   93	Loss: 1.1296	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:58:38 [INFO ]  Epoch:   94	Loss: 1.0411	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 12:58:40 [INFO ]  Epoch:   95	Loss: 1.0562	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:58:42 [INFO ]  Epoch:   96	Loss: 1.0718	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:58:45 [INFO ]  Epoch:   97	Loss: 1.1468	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:58:46 [INFO ]  Epoch:   98	Loss: 1.1185	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:58:49 [INFO ]  Epoch:   99	Loss: 1.1815	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 12:58:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-09-11 12:58:52 [INFO ]  
2022-09-11 12:58:52 [INFO ]  Begin of epoch 100 :
2022-09-11 12:58:55 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:58:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:58:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:58:55 [INFO ]  	   step  1 (lr=0.221810)                   65.17%                   1.1738
2022-09-11 12:58:55 [INFO ]  
2022-09-11 12:58:55 [INFO ]  Epoch:  100	Loss: 1.0860	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:58:57 [INFO ]  Epoch:  101	Loss: 1.0402	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:58:59 [INFO ]  Epoch:  102	Loss: 1.1451	Data Time: 0.18s	Train Time: 0.00s
2022-09-11 12:59:01 [INFO ]  Epoch:  103	Loss: 1.2826	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:59:03 [INFO ]  Epoch:  104	Loss: 1.0253	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:59:05 [INFO ]  Epoch:  105	Loss: 1.2674	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:59:06 [INFO ]  Epoch:  106	Loss: 1.1374	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:59:08 [INFO ]  Epoch:  107	Loss: 1.0827	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 12:59:10 [INFO ]  Epoch:  108	Loss: 1.1213	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 12:59:12 [INFO ]  Epoch:  109	Loss: 1.1524	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:59:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-09-11 12:59:15 [INFO ]  
2022-09-11 12:59:15 [INFO ]  Begin of epoch 110 :
2022-09-11 12:59:20 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:59:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:59:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:59:20 [INFO ]  	   step  1 (lr=0.222385)                   64.88%                   1.2001
2022-09-11 12:59:20 [INFO ]  
2022-09-11 12:59:20 [INFO ]  Epoch:  110	Loss: 1.0586	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 12:59:21 [INFO ]  Epoch:  111	Loss: 1.1275	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:59:24 [INFO ]  Epoch:  112	Loss: 1.1239	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:59:26 [INFO ]  Epoch:  113	Loss: 1.1892	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:59:28 [INFO ]  Epoch:  114	Loss: 1.1171	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:59:30 [INFO ]  Epoch:  115	Loss: 1.0668	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:59:32 [INFO ]  Epoch:  116	Loss: 1.1090	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 12:59:34 [INFO ]  Epoch:  117	Loss: 1.1756	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:59:36 [INFO ]  Epoch:  118	Loss: 1.0470	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 12:59:38 [INFO ]  Epoch:  119	Loss: 1.1078	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:59:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-09-11 12:59:42 [INFO ]  
2022-09-11 12:59:42 [INFO ]  Begin of epoch 120 :
2022-09-11 12:59:45 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 12:59:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 12:59:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 12:59:45 [INFO ]  	   step  1 (lr=0.223277)                   64.30%                   1.2008
2022-09-11 12:59:45 [INFO ]  
2022-09-11 12:59:45 [INFO ]  Epoch:  120	Loss: 1.0957	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 12:59:47 [INFO ]  Epoch:  121	Loss: 1.2181	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:59:49 [INFO ]  Epoch:  122	Loss: 1.1581	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:59:51 [INFO ]  Epoch:  123	Loss: 1.2981	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 12:59:53 [INFO ]  Epoch:  124	Loss: 1.0828	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:59:55 [INFO ]  Epoch:  125	Loss: 1.2047	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 12:59:57 [INFO ]  Epoch:  126	Loss: 1.0449	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 12:59:59 [INFO ]  Epoch:  127	Loss: 1.1079	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:00:01 [INFO ]  Epoch:  128	Loss: 1.0614	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:00:03 [INFO ]  Epoch:  129	Loss: 1.0812	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:00:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-09-11 13:00:07 [INFO ]  
2022-09-11 13:00:07 [INFO ]  Begin of epoch 130 :
2022-09-11 13:00:10 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:00:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:00:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:00:10 [INFO ]  	   step  1 (lr=0.219967)                   62.32%                   1.2731
2022-09-11 13:00:10 [INFO ]  
2022-09-11 13:00:10 [INFO ]  Epoch:  130	Loss: 1.1594	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 13:00:12 [INFO ]  Epoch:  131	Loss: 1.1169	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 13:00:14 [INFO ]  Epoch:  132	Loss: 1.0873	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 13:00:16 [INFO ]  Epoch:  133	Loss: 1.2739	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:18 [INFO ]  Epoch:  134	Loss: 1.0969	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:20 [INFO ]  Epoch:  135	Loss: 1.1109	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:22 [INFO ]  Epoch:  136	Loss: 1.0806	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:24 [INFO ]  Epoch:  137	Loss: 1.1523	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:26 [INFO ]  Epoch:  138	Loss: 1.1294	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 13:00:28 [INFO ]  Epoch:  139	Loss: 1.1769	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-09-11 13:00:31 [INFO ]  
2022-09-11 13:00:31 [INFO ]  Begin of epoch 140 :
2022-09-11 13:00:35 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:00:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:00:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:00:35 [INFO ]  	   step  1 (lr=0.222176)                   65.69%                   1.1454
2022-09-11 13:00:35 [INFO ]  
2022-09-11 13:00:35 [INFO ]  Epoch:  140	Loss: 1.1536	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:00:37 [INFO ]  Epoch:  141	Loss: 1.1441	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:39 [INFO ]  Epoch:  142	Loss: 1.0611	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:41 [INFO ]  Epoch:  143	Loss: 1.0653	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 13:00:43 [INFO ]  Epoch:  144	Loss: 1.0660	Data Time: 0.26s	Train Time: 0.01s
2022-09-11 13:00:45 [INFO ]  Epoch:  145	Loss: 1.1630	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:47 [INFO ]  Epoch:  146	Loss: 1.1528	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:49 [INFO ]  Epoch:  147	Loss: 1.0798	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:51 [INFO ]  Epoch:  148	Loss: 1.1091	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:00:53 [INFO ]  Epoch:  149	Loss: 1.0551	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:00:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-09-11 13:00:56 [INFO ]  
2022-09-11 13:00:56 [INFO ]  Begin of epoch 150 :
2022-09-11 13:01:00 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:01:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:01:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:01:00 [INFO ]  	   step  1 (lr=0.224715)                   66.76%                   1.1275
2022-09-11 13:01:00 [INFO ]  
2022-09-11 13:01:00 [INFO ]  Epoch:  150	Loss: 1.0916	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:01 [INFO ]  Epoch:  151	Loss: 1.0848	Data Time: 0.27s	Train Time: 0.01s
2022-09-11 13:01:03 [INFO ]  Epoch:  152	Loss: 1.2270	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:05 [INFO ]  Epoch:  153	Loss: 1.0175	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:07 [INFO ]  Epoch:  154	Loss: 1.1468	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 13:01:09 [INFO ]  Epoch:  155	Loss: 1.1009	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:01:12 [INFO ]  Epoch:  156	Loss: 1.0732	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 13:01:14 [INFO ]  Epoch:  157	Loss: 1.1937	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:16 [INFO ]  Epoch:  158	Loss: 1.1039	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:17 [INFO ]  Epoch:  159	Loss: 1.0246	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-09-11 13:01:21 [INFO ]  
2022-09-11 13:01:21 [INFO ]  Begin of epoch 160 :
2022-09-11 13:01:25 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:01:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:01:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:01:25 [INFO ]  	   step  1 (lr=0.225087)                   66.44%                   1.1330
2022-09-11 13:01:25 [INFO ]  
2022-09-11 13:01:25 [INFO ]  Epoch:  160	Loss: 1.0570	Data Time: 0.16s	Train Time: 0.00s
2022-09-11 13:01:26 [INFO ]  Epoch:  161	Loss: 1.1103	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 13:01:28 [INFO ]  Epoch:  162	Loss: 1.0913	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:30 [INFO ]  Epoch:  163	Loss: 0.9988	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:32 [INFO ]  Epoch:  164	Loss: 1.0226	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:34 [INFO ]  Epoch:  165	Loss: 1.0317	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 13:01:36 [INFO ]  Epoch:  166	Loss: 1.0777	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:38 [INFO ]  Epoch:  167	Loss: 1.0100	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 13:01:40 [INFO ]  Epoch:  168	Loss: 1.1574	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:42 [INFO ]  Epoch:  169	Loss: 1.1229	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-09-11 13:01:45 [INFO ]  
2022-09-11 13:01:45 [INFO ]  Begin of epoch 170 :
2022-09-11 13:01:49 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:01:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:01:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:01:49 [INFO ]  	   step  1 (lr=0.225620)                   66.45%                   1.1257
2022-09-11 13:01:49 [INFO ]  
2022-09-11 13:01:49 [INFO ]  Epoch:  170	Loss: 1.0847	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:01:51 [INFO ]  Epoch:  171	Loss: 1.1080	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:53 [INFO ]  Epoch:  172	Loss: 1.1086	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:01:55 [INFO ]  Epoch:  173	Loss: 1.1822	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:01:57 [INFO ]  Epoch:  174	Loss: 1.0606	Data Time: 0.19s	Train Time: 0.01s
2022-09-11 13:01:59 [INFO ]  Epoch:  175	Loss: 1.0589	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:02:01 [INFO ]  Epoch:  176	Loss: 1.0188	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:02:03 [INFO ]  Epoch:  177	Loss: 1.0053	Data Time: 0.24s	Train Time: 0.01s
2022-09-11 13:02:05 [INFO ]  Epoch:  178	Loss: 1.1643	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:02:07 [INFO ]  Epoch:  179	Loss: 1.0675	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:02:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-09-11 13:02:10 [INFO ]  
2022-09-11 13:02:10 [INFO ]  Begin of epoch 180 :
2022-09-11 13:02:13 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:02:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:02:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:02:13 [INFO ]  	   step  1 (lr=0.225943)                   66.72%                   1.1256
2022-09-11 13:02:13 [INFO ]  
2022-09-11 13:02:13 [INFO ]  Epoch:  180	Loss: 1.1583	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:02:15 [INFO ]  Epoch:  181	Loss: 1.1041	Data Time: 0.15s	Train Time: 0.01s
2022-09-11 13:02:18 [INFO ]  Epoch:  182	Loss: 1.1766	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 13:02:20 [INFO ]  Epoch:  183	Loss: 1.2760	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 13:02:22 [INFO ]  Epoch:  184	Loss: 1.0315	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:02:24 [INFO ]  Epoch:  185	Loss: 1.1255	Data Time: 0.22s	Train Time: 0.01s
2022-09-11 13:02:26 [INFO ]  Epoch:  186	Loss: 1.0185	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:02:28 [INFO ]  Epoch:  187	Loss: 1.0867	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 13:02:30 [INFO ]  Epoch:  188	Loss: 1.1177	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:02:32 [INFO ]  Epoch:  189	Loss: 1.2565	Data Time: 0.16s	Train Time: 0.01s
2022-09-11 13:02:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-09-11 13:02:35 [INFO ]  
2022-09-11 13:02:35 [INFO ]  Begin of epoch 190 :
2022-09-11 13:02:39 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:02:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:02:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:02:39 [INFO ]  	   step  1 (lr=0.226511)                   66.26%                   1.1429
2022-09-11 13:02:39 [INFO ]  
2022-09-11 13:02:39 [INFO ]  Epoch:  190	Loss: 1.1091	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:02:41 [INFO ]  Epoch:  191	Loss: 1.0381	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 13:02:43 [INFO ]  Epoch:  192	Loss: 1.3049	Data Time: 0.23s	Train Time: 0.01s
2022-09-11 13:02:45 [INFO ]  Epoch:  193	Loss: 1.0255	Data Time: 0.21s	Train Time: 0.01s
2022-09-11 13:02:47 [INFO ]  Epoch:  194	Loss: 1.0787	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:02:48 [INFO ]  Epoch:  195	Loss: 1.0458	Data Time: 0.18s	Train Time: 0.01s
2022-09-11 13:02:50 [INFO ]  Epoch:  196	Loss: 1.0508	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 13:02:53 [INFO ]  Epoch:  197	Loss: 1.0270	Data Time: 0.25s	Train Time: 0.01s
2022-09-11 13:02:55 [INFO ]  Epoch:  198	Loss: 1.0407	Data Time: 0.17s	Train Time: 0.01s
2022-09-11 13:02:57 [INFO ]  Epoch:  199	Loss: 1.1059	Data Time: 0.20s	Train Time: 0.01s
2022-09-11 13:02:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-09-11 13:02:59 [INFO ]  
2022-09-11 13:02:59 [INFO ]  Final evaluation for SVHN :
2022-09-11 13:03:03 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:03:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:03:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-09-11 13:03:03 [INFO ]  	   step  1 (lr=0.226827)                   66.63%                   1.1265
2022-09-11 13:03:03 [INFO ]  
2022-09-11 13:03:03 [INFO ]  
2022-09-11 13:03:03 [INFO ]  Final evaluation for FASHION_MNIST :
2022-09-11 13:03:06 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-09-11 13:03:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-09-11 13:03:06 [INFO ]  	            before steps                   87.27%                   0.3620
2022-09-11 13:03:06 [INFO ]  	   step  1 (lr=0.226827)                   17.55%                   5.7247
2022-09-11 13:03:06 [INFO ]  
2022-10-03 06:37:08 [INFO ]  ======================================== 2022-10-03 06:37:08 ========================================
2022-10-03 06:37:08 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 06:37:08 [INFO ]  Options: 
2022-10-03 06:37:08 [INFO ]  	base_dir: null
2022-10-03 06:37:08 [INFO ]  	batch_size: 1024
2022-10-03 06:37:08 [INFO ]  	checkpoint_interval: 10
2022-10-03 06:37:08 [INFO ]  	dataset: SVHN
2022-10-03 06:37:08 [INFO ]  	dataset_labels:
2022-10-03 06:37:08 [INFO ]  	- 0
2022-10-03 06:37:08 [INFO ]  	- 1
2022-10-03 06:37:08 [INFO ]  	- 2
2022-10-03 06:37:08 [INFO ]  	- 3
2022-10-03 06:37:08 [INFO ]  	- 4
2022-10-03 06:37:08 [INFO ]  	- 5
2022-10-03 06:37:08 [INFO ]  	- 6
2022-10-03 06:37:08 [INFO ]  	- 7
2022-10-03 06:37:08 [INFO ]  	- 8
2022-10-03 06:37:08 [INFO ]  	- 9
2022-10-03 06:37:08 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 06:37:08 [INFO ]  	- !!python/tuple
2022-10-03 06:37:08 [INFO ]  	    - 0.4379104971885681
2022-10-03 06:37:08 [INFO ]  	    - 0.44398033618927
2022-10-03 06:37:08 [INFO ]  	    - 0.4729299545288086
2022-10-03 06:37:08 [INFO ]  	- !!python/tuple
2022-10-03 06:37:08 [INFO ]  	    - 0.19803012907505035
2022-10-03 06:37:08 [INFO ]  	    - 0.2010156363248825
2022-10-03 06:37:08 [INFO ]  	    - 0.19703614711761475
2022-10-03 06:37:08 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 06:37:08 [INFO ]  	decay_epochs: 50
2022-10-03 06:37:08 [INFO ]  	decay_factor: 0.1
2022-10-03 06:37:08 [INFO ]  	device_id: 0
2022-10-03 06:37:08 [INFO ]  	distill_epochs: 1
2022-10-03 06:37:08 [INFO ]  	distill_lr: 0.02
2022-10-03 06:37:08 [INFO ]  	distill_steps: 1
2022-10-03 06:37:08 [INFO ]  	epochs: 200
2022-10-03 06:37:08 [INFO ]  	expand_cls: false
2022-10-03 06:37:08 [INFO ]  	forgetting_dataset: null
2022-10-03 06:37:08 [INFO ]  	init: xavier
2022-10-03 06:37:08 [INFO ]  	init_param: 1.0
2022-10-03 06:37:08 [INFO ]  	input_size: 32
2022-10-03 06:37:08 [INFO ]  	ipc: 1
2022-10-03 06:37:08 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 06:37:08 [INFO ]  	log_interval: 100
2022-10-03 06:37:08 [INFO ]  	log_level: INFO
2022-10-03 06:37:08 [INFO ]  	lr: 0.01
2022-10-03 06:37:08 [INFO ]  	mode: distill_adapt
2022-10-03 06:37:08 [INFO ]  	nc: 3
2022-10-03 06:37:08 [INFO ]  	num_classes: 10
2022-10-03 06:37:08 [INFO ]  	num_workers: 8
2022-10-03 06:37:08 [INFO ]  	phase: train
2022-10-03 06:37:08 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 06:37:08 [INFO ]  	start_time: '2022-10-03 06:37:08'
2022-10-03 06:37:08 [INFO ]  	test_batch_size: 1024
2022-10-03 06:37:08 [INFO ]  	
2022-10-03 06:37:10 [INFO ]  train dataset size:	73257
2022-10-03 06:37:10 [INFO ]  test dataset size: 	26032
2022-10-03 06:37:10 [INFO ]  datasets built!
2022-10-03 06:37:10 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 06:37:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 06:37:13 [INFO ]  
2022-10-03 06:37:13 [INFO ]  Begin of epoch 0 :
2022-10-03 06:37:16 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:37:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:37:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:37:16 [INFO ]  	   step  1 (lr=0.020000)                    6.76%                  10.4843
2022-10-03 06:37:16 [INFO ]  
2022-10-03 06:37:16 [INFO ]  Epoch:    0	Loss: 9.9959	Data Time: 0.31s	Train Time: 0.03s
2022-10-03 06:37:18 [INFO ]  Epoch:    1	Loss: 3.6075	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:37:20 [INFO ]  Epoch:    2	Loss: 3.0412	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:37:21 [INFO ]  Epoch:    3	Loss: 2.7804	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:37:23 [INFO ]  Epoch:    4	Loss: 2.4639	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:37:25 [INFO ]  Epoch:    5	Loss: 2.4068	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:27 [INFO ]  Epoch:    6	Loss: 2.3268	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:37:29 [INFO ]  Epoch:    7	Loss: 2.2286	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:30 [INFO ]  Epoch:    8	Loss: 2.2949	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:32 [INFO ]  Epoch:    9	Loss: 2.2365	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:37:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 06:37:35 [INFO ]  
2022-10-03 06:37:35 [INFO ]  Begin of epoch 10 :
2022-10-03 06:37:38 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:37:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:37:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:37:38 [INFO ]  	   step  1 (lr=0.040333)                   24.00%                   2.2256
2022-10-03 06:37:38 [INFO ]  
2022-10-03 06:37:38 [INFO ]  Epoch:   10	Loss: 2.2374	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:37:40 [INFO ]  Epoch:   11	Loss: 2.2148	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:42 [INFO ]  Epoch:   12	Loss: 2.2163	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 06:37:44 [INFO ]  Epoch:   13	Loss: 2.1889	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:37:46 [INFO ]  Epoch:   14	Loss: 2.1701	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:47 [INFO ]  Epoch:   15	Loss: 2.1175	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:37:49 [INFO ]  Epoch:   16	Loss: 2.0795	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:51 [INFO ]  Epoch:   17	Loss: 2.1695	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:37:52 [INFO ]  Epoch:   18	Loss: 2.0216	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:37:54 [INFO ]  Epoch:   19	Loss: 1.9873	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:37:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 06:37:57 [INFO ]  
2022-10-03 06:37:57 [INFO ]  Begin of epoch 20 :
2022-10-03 06:38:00 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:38:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:38:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:38:00 [INFO ]  	   step  1 (lr=0.075233)                   36.81%                   1.9751
2022-10-03 06:38:00 [INFO ]  
2022-10-03 06:38:00 [INFO ]  Epoch:   20	Loss: 1.9689	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:02 [INFO ]  Epoch:   21	Loss: 1.9583	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:38:03 [INFO ]  Epoch:   22	Loss: 1.9376	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:05 [INFO ]  Epoch:   23	Loss: 1.9162	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:07 [INFO ]  Epoch:   24	Loss: 1.6855	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:09 [INFO ]  Epoch:   25	Loss: 1.8657	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:11 [INFO ]  Epoch:   26	Loss: 1.5684	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:38:12 [INFO ]  Epoch:   27	Loss: 1.9303	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:38:14 [INFO ]  Epoch:   28	Loss: 1.5374	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:38:16 [INFO ]  Epoch:   29	Loss: 2.1146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 06:38:19 [INFO ]  
2022-10-03 06:38:19 [INFO ]  Begin of epoch 30 :
2022-10-03 06:38:22 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:38:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:38:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:38:22 [INFO ]  	   step  1 (lr=0.164684)                   50.45%                   1.5217
2022-10-03 06:38:22 [INFO ]  
2022-10-03 06:38:22 [INFO ]  Epoch:   30	Loss: 1.4594	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:38:24 [INFO ]  Epoch:   31	Loss: 1.3418	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:38:25 [INFO ]  Epoch:   32	Loss: 1.4108	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:27 [INFO ]  Epoch:   33	Loss: 1.3495	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:29 [INFO ]  Epoch:   34	Loss: 1.3726	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:30 [INFO ]  Epoch:   35	Loss: 1.3597	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:32 [INFO ]  Epoch:   36	Loss: 1.3003	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:38:34 [INFO ]  Epoch:   37	Loss: 1.4187	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:36 [INFO ]  Epoch:   38	Loss: 1.5669	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 06:38:38 [INFO ]  Epoch:   39	Loss: 1.4366	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 06:38:41 [INFO ]  
2022-10-03 06:38:41 [INFO ]  Begin of epoch 40 :
2022-10-03 06:38:44 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:38:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:38:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:38:44 [INFO ]  	   step  1 (lr=0.193285)                   58.83%                   1.3337
2022-10-03 06:38:44 [INFO ]  
2022-10-03 06:38:44 [INFO ]  Epoch:   40	Loss: 1.2847	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 06:38:45 [INFO ]  Epoch:   41	Loss: 1.4459	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:47 [INFO ]  Epoch:   42	Loss: 1.3461	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:38:49 [INFO ]  Epoch:   43	Loss: 1.1530	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:38:51 [INFO ]  Epoch:   44	Loss: 1.2494	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:52 [INFO ]  Epoch:   45	Loss: 1.1925	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:38:54 [INFO ]  Epoch:   46	Loss: 1.1544	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:38:56 [INFO ]  Epoch:   47	Loss: 1.5367	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:38:58 [INFO ]  Epoch:   48	Loss: 1.3271	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:38:59 [INFO ]  Epoch:   49	Loss: 1.1914	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:39:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 06:39:02 [INFO ]  
2022-10-03 06:39:02 [INFO ]  Begin of epoch 50 :
2022-10-03 06:39:05 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:39:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:39:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:39:05 [INFO ]  	   step  1 (lr=0.202311)                   64.47%                   1.1935
2022-10-03 06:39:05 [INFO ]  
2022-10-03 06:39:05 [INFO ]  Epoch:   50	Loss: 1.2065	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:39:07 [INFO ]  Epoch:   51	Loss: 1.1968	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:39:09 [INFO ]  Epoch:   52	Loss: 1.2280	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:39:10 [INFO ]  Epoch:   53	Loss: 1.0670	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:12 [INFO ]  Epoch:   54	Loss: 1.1968	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:39:14 [INFO ]  Epoch:   55	Loss: 1.1359	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:39:15 [INFO ]  Epoch:   56	Loss: 1.1998	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:17 [INFO ]  Epoch:   57	Loss: 1.4489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:19 [INFO ]  Epoch:   58	Loss: 1.1631	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:39:21 [INFO ]  Epoch:   59	Loss: 1.2291	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:39:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 06:39:24 [INFO ]  
2022-10-03 06:39:24 [INFO ]  Begin of epoch 60 :
2022-10-03 06:39:27 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:39:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:39:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:39:27 [INFO ]  	   step  1 (lr=0.206287)                   66.79%                   1.1207
2022-10-03 06:39:27 [INFO ]  
2022-10-03 06:39:27 [INFO ]  Epoch:   60	Loss: 1.1055	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:39:28 [INFO ]  Epoch:   61	Loss: 1.2335	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:39:30 [INFO ]  Epoch:   62	Loss: 1.1318	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:39:32 [INFO ]  Epoch:   63	Loss: 1.0855	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:39:34 [INFO ]  Epoch:   64	Loss: 1.2290	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:39:36 [INFO ]  Epoch:   65	Loss: 0.9889	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:37 [INFO ]  Epoch:   66	Loss: 1.0238	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:39 [INFO ]  Epoch:   67	Loss: 1.0945	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:39:41 [INFO ]  Epoch:   68	Loss: 1.0356	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:39:43 [INFO ]  Epoch:   69	Loss: 1.0339	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:39:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 06:39:45 [INFO ]  
2022-10-03 06:39:45 [INFO ]  Begin of epoch 70 :
2022-10-03 06:39:48 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:39:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:39:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:39:48 [INFO ]  	   step  1 (lr=0.223240)                   68.54%                   1.0780
2022-10-03 06:39:48 [INFO ]  
2022-10-03 06:39:48 [INFO ]  Epoch:   70	Loss: 1.0522	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 06:39:50 [INFO ]  Epoch:   71	Loss: 0.9838	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:52 [INFO ]  Epoch:   72	Loss: 1.1703	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:39:54 [INFO ]  Epoch:   73	Loss: 1.0471	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:55 [INFO ]  Epoch:   74	Loss: 0.9608	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:57 [INFO ]  Epoch:   75	Loss: 1.0779	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:39:59 [INFO ]  Epoch:   76	Loss: 1.1189	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:40:01 [INFO ]  Epoch:   77	Loss: 1.0247	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:03 [INFO ]  Epoch:   78	Loss: 1.0055	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:40:04 [INFO ]  Epoch:   79	Loss: 1.1123	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 06:40:07 [INFO ]  
2022-10-03 06:40:07 [INFO ]  Begin of epoch 80 :
2022-10-03 06:40:10 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:40:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:40:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:40:10 [INFO ]  	   step  1 (lr=0.233731)                   70.18%                   1.0399
2022-10-03 06:40:10 [INFO ]  
2022-10-03 06:40:11 [INFO ]  Epoch:   80	Loss: 1.0210	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:40:12 [INFO ]  Epoch:   81	Loss: 1.0574	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:14 [INFO ]  Epoch:   82	Loss: 0.9835	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:40:16 [INFO ]  Epoch:   83	Loss: 1.1050	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:17 [INFO ]  Epoch:   84	Loss: 1.0083	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:40:19 [INFO ]  Epoch:   85	Loss: 1.0383	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:40:21 [INFO ]  Epoch:   86	Loss: 1.0950	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:40:23 [INFO ]  Epoch:   87	Loss: 1.0245	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:24 [INFO ]  Epoch:   88	Loss: 0.9884	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:40:26 [INFO ]  Epoch:   89	Loss: 0.9526	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:40:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 06:40:29 [INFO ]  
2022-10-03 06:40:29 [INFO ]  Begin of epoch 90 :
2022-10-03 06:40:32 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:40:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:40:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:40:32 [INFO ]  	   step  1 (lr=0.242650)                   63.44%                   1.2099
2022-10-03 06:40:32 [INFO ]  
2022-10-03 06:40:32 [INFO ]  Epoch:   90	Loss: 1.0732	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 06:40:34 [INFO ]  Epoch:   91	Loss: 1.0097	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:36 [INFO ]  Epoch:   92	Loss: 1.1406	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:40:37 [INFO ]  Epoch:   93	Loss: 0.9819	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:39 [INFO ]  Epoch:   94	Loss: 0.9747	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:41 [INFO ]  Epoch:   95	Loss: 1.0320	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:43 [INFO ]  Epoch:   96	Loss: 0.9500	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:40:45 [INFO ]  Epoch:   97	Loss: 1.0529	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:40:47 [INFO ]  Epoch:   98	Loss: 0.9835	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:40:48 [INFO ]  Epoch:   99	Loss: 0.9402	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:40:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 06:40:51 [INFO ]  
2022-10-03 06:40:51 [INFO ]  Begin of epoch 100 :
2022-10-03 06:40:54 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:40:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:40:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:40:54 [INFO ]  	   step  1 (lr=0.242159)                   70.39%                   1.0145
2022-10-03 06:40:54 [INFO ]  
2022-10-03 06:40:54 [INFO ]  Epoch:  100	Loss: 1.0114	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:40:56 [INFO ]  Epoch:  101	Loss: 0.9622	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:40:58 [INFO ]  Epoch:  102	Loss: 0.9412	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:41:00 [INFO ]  Epoch:  103	Loss: 0.9769	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:41:01 [INFO ]  Epoch:  104	Loss: 0.9851	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:03 [INFO ]  Epoch:  105	Loss: 0.9512	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:41:05 [INFO ]  Epoch:  106	Loss: 0.9967	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:06 [INFO ]  Epoch:  107	Loss: 1.0300	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:08 [INFO ]  Epoch:  108	Loss: 0.9475	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:41:10 [INFO ]  Epoch:  109	Loss: 1.0264	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 06:41:13 [INFO ]  
2022-10-03 06:41:13 [INFO ]  Begin of epoch 110 :
2022-10-03 06:41:16 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:41:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:41:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:41:16 [INFO ]  	   step  1 (lr=0.243193)                   70.35%                   1.0217
2022-10-03 06:41:16 [INFO ]  
2022-10-03 06:41:16 [INFO ]  Epoch:  110	Loss: 0.9686	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 06:41:18 [INFO ]  Epoch:  111	Loss: 0.9646	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:20 [INFO ]  Epoch:  112	Loss: 1.0277	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:41:21 [INFO ]  Epoch:  113	Loss: 1.0265	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:41:23 [INFO ]  Epoch:  114	Loss: 1.0158	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:25 [INFO ]  Epoch:  115	Loss: 1.0054	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:27 [INFO ]  Epoch:  116	Loss: 0.9366	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:41:29 [INFO ]  Epoch:  117	Loss: 0.9076	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:41:31 [INFO ]  Epoch:  118	Loss: 0.8788	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:33 [INFO ]  Epoch:  119	Loss: 1.0285	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 06:41:36 [INFO ]  
2022-10-03 06:41:36 [INFO ]  Begin of epoch 120 :
2022-10-03 06:41:39 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:41:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:41:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:41:39 [INFO ]  	   step  1 (lr=0.245363)                   68.72%                   1.0426
2022-10-03 06:41:39 [INFO ]  
2022-10-03 06:41:39 [INFO ]  Epoch:  120	Loss: 1.0371	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 06:41:41 [INFO ]  Epoch:  121	Loss: 1.0621	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:41:43 [INFO ]  Epoch:  122	Loss: 1.0469	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:41:44 [INFO ]  Epoch:  123	Loss: 1.2125	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:41:46 [INFO ]  Epoch:  124	Loss: 0.9958	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:48 [INFO ]  Epoch:  125	Loss: 1.0708	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:41:50 [INFO ]  Epoch:  126	Loss: 1.0234	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:41:52 [INFO ]  Epoch:  127	Loss: 1.0396	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:41:54 [INFO ]  Epoch:  128	Loss: 0.9289	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:41:55 [INFO ]  Epoch:  129	Loss: 0.9735	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:41:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 06:41:58 [INFO ]  
2022-10-03 06:41:58 [INFO ]  Begin of epoch 130 :
2022-10-03 06:42:01 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:42:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:42:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:42:01 [INFO ]  	   step  1 (lr=0.246000)                   70.47%                   1.0117
2022-10-03 06:42:01 [INFO ]  
2022-10-03 06:42:01 [INFO ]  Epoch:  130	Loss: 0.9301	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:42:03 [INFO ]  Epoch:  131	Loss: 1.0145	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:04 [INFO ]  Epoch:  132	Loss: 0.8916	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:42:06 [INFO ]  Epoch:  133	Loss: 1.0247	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:08 [INFO ]  Epoch:  134	Loss: 0.9546	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:10 [INFO ]  Epoch:  135	Loss: 1.0689	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:42:11 [INFO ]  Epoch:  136	Loss: 0.9309	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:42:13 [INFO ]  Epoch:  137	Loss: 0.9928	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:15 [INFO ]  Epoch:  138	Loss: 0.9672	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:17 [INFO ]  Epoch:  139	Loss: 0.9810	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:42:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 06:42:19 [INFO ]  
2022-10-03 06:42:19 [INFO ]  Begin of epoch 140 :
2022-10-03 06:42:22 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:42:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:42:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:42:22 [INFO ]  	   step  1 (lr=0.247826)                   67.71%                   1.0857
2022-10-03 06:42:22 [INFO ]  
2022-10-03 06:42:22 [INFO ]  Epoch:  140	Loss: 1.0239	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:42:24 [INFO ]  Epoch:  141	Loss: 0.8923	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:42:26 [INFO ]  Epoch:  142	Loss: 0.9910	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:28 [INFO ]  Epoch:  143	Loss: 1.0003	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:42:30 [INFO ]  Epoch:  144	Loss: 1.0691	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:42:31 [INFO ]  Epoch:  145	Loss: 0.9739	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:33 [INFO ]  Epoch:  146	Loss: 0.9628	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:42:35 [INFO ]  Epoch:  147	Loss: 0.9875	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:37 [INFO ]  Epoch:  148	Loss: 1.0095	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:39 [INFO ]  Epoch:  149	Loss: 0.9284	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 06:42:42 [INFO ]  
2022-10-03 06:42:42 [INFO ]  Begin of epoch 150 :
2022-10-03 06:42:45 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:42:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:42:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:42:45 [INFO ]  	   step  1 (lr=0.248296)                   70.13%                   1.0164
2022-10-03 06:42:45 [INFO ]  
2022-10-03 06:42:45 [INFO ]  Epoch:  150	Loss: 1.0172	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 06:42:46 [INFO ]  Epoch:  151	Loss: 0.9821	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:42:48 [INFO ]  Epoch:  152	Loss: 0.9305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:42:50 [INFO ]  Epoch:  153	Loss: 1.0732	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:42:52 [INFO ]  Epoch:  154	Loss: 1.0043	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:42:54 [INFO ]  Epoch:  155	Loss: 1.0474	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:42:56 [INFO ]  Epoch:  156	Loss: 0.9033	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:42:58 [INFO ]  Epoch:  157	Loss: 0.9872	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:42:59 [INFO ]  Epoch:  158	Loss: 1.0103	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:01 [INFO ]  Epoch:  159	Loss: 0.9606	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 06:43:04 [INFO ]  
2022-10-03 06:43:04 [INFO ]  Begin of epoch 160 :
2022-10-03 06:43:07 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:43:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:43:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:43:07 [INFO ]  	   step  1 (lr=0.248603)                   70.00%                   1.0214
2022-10-03 06:43:07 [INFO ]  
2022-10-03 06:43:07 [INFO ]  Epoch:  160	Loss: 0.9069	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 06:43:09 [INFO ]  Epoch:  161	Loss: 0.9279	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:11 [INFO ]  Epoch:  162	Loss: 1.0146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:12 [INFO ]  Epoch:  163	Loss: 1.0810	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:43:14 [INFO ]  Epoch:  164	Loss: 0.9489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:16 [INFO ]  Epoch:  165	Loss: 0.9909	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:43:18 [INFO ]  Epoch:  166	Loss: 1.0939	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:20 [INFO ]  Epoch:  167	Loss: 1.0330	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:21 [INFO ]  Epoch:  168	Loss: 1.0511	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:43:23 [INFO ]  Epoch:  169	Loss: 0.9717	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 06:43:26 [INFO ]  
2022-10-03 06:43:26 [INFO ]  Begin of epoch 170 :
2022-10-03 06:43:29 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:43:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:43:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:43:29 [INFO ]  	   step  1 (lr=0.248245)                   69.21%                   1.0366
2022-10-03 06:43:29 [INFO ]  
2022-10-03 06:43:29 [INFO ]  Epoch:  170	Loss: 1.0445	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 06:43:31 [INFO ]  Epoch:  171	Loss: 1.0112	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:33 [INFO ]  Epoch:  172	Loss: 0.9216	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:35 [INFO ]  Epoch:  173	Loss: 0.9940	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:37 [INFO ]  Epoch:  174	Loss: 1.0544	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:39 [INFO ]  Epoch:  175	Loss: 0.9626	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:43:40 [INFO ]  Epoch:  176	Loss: 1.0157	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:43:42 [INFO ]  Epoch:  177	Loss: 0.9889	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:43:44 [INFO ]  Epoch:  178	Loss: 0.9585	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:46 [INFO ]  Epoch:  179	Loss: 0.9389	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:43:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 06:43:49 [INFO ]  
2022-10-03 06:43:49 [INFO ]  Begin of epoch 180 :
2022-10-03 06:43:52 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:43:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:43:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:43:52 [INFO ]  	   step  1 (lr=0.248744)                   69.60%                   1.0247
2022-10-03 06:43:52 [INFO ]  
2022-10-03 06:43:52 [INFO ]  Epoch:  180	Loss: 1.0892	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:43:54 [INFO ]  Epoch:  181	Loss: 1.0348	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:55 [INFO ]  Epoch:  182	Loss: 0.9607	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:57 [INFO ]  Epoch:  183	Loss: 1.0169	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:43:59 [INFO ]  Epoch:  184	Loss: 1.0109	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:44:01 [INFO ]  Epoch:  185	Loss: 0.9930	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:44:03 [INFO ]  Epoch:  186	Loss: 0.9509	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:44:05 [INFO ]  Epoch:  187	Loss: 1.0050	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:44:07 [INFO ]  Epoch:  188	Loss: 1.0430	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:44:08 [INFO ]  Epoch:  189	Loss: 0.9864	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:44:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 06:44:12 [INFO ]  
2022-10-03 06:44:12 [INFO ]  Begin of epoch 190 :
2022-10-03 06:44:15 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:44:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:44:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:44:15 [INFO ]  	   step  1 (lr=0.249121)                   69.40%                   1.0282
2022-10-03 06:44:15 [INFO ]  
2022-10-03 06:44:15 [INFO ]  Epoch:  190	Loss: 1.0147	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 06:44:16 [INFO ]  Epoch:  191	Loss: 1.0225	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:44:18 [INFO ]  Epoch:  192	Loss: 0.9585	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:44:20 [INFO ]  Epoch:  193	Loss: 0.9534	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:44:22 [INFO ]  Epoch:  194	Loss: 1.0142	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:44:23 [INFO ]  Epoch:  195	Loss: 0.8928	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:44:25 [INFO ]  Epoch:  196	Loss: 1.0025	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:44:27 [INFO ]  Epoch:  197	Loss: 1.1037	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:44:29 [INFO ]  Epoch:  198	Loss: 1.0285	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:44:30 [INFO ]  Epoch:  199	Loss: 1.0303	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:44:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 06:44:33 [INFO ]  
2022-10-03 06:44:33 [INFO ]  Final evaluation for SVHN :
2022-10-03 06:44:36 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:44:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:44:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:44:36 [INFO ]  	   step  1 (lr=0.249069)                   69.08%                   1.0507
2022-10-03 06:44:36 [INFO ]  
2022-10-03 06:44:36 [INFO ]  
2022-10-03 06:44:36 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 06:44:39 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:44:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:44:39 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 06:44:39 [INFO ]  	   step  1 (lr=0.249069)                   16.01%                   5.6662
2022-10-03 06:44:39 [INFO ]  
2022-10-03 06:48:03 [INFO ]  ======================================== 2022-10-03 06:48:03 ========================================
2022-10-03 06:48:03 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 06:48:03 [INFO ]  Options: 
2022-10-03 06:48:03 [INFO ]  	base_dir: null
2022-10-03 06:48:03 [INFO ]  	batch_size: 1024
2022-10-03 06:48:03 [INFO ]  	checkpoint_interval: 10
2022-10-03 06:48:03 [INFO ]  	dataset: SVHN
2022-10-03 06:48:03 [INFO ]  	dataset_labels:
2022-10-03 06:48:03 [INFO ]  	- 0
2022-10-03 06:48:03 [INFO ]  	- 1
2022-10-03 06:48:03 [INFO ]  	- 2
2022-10-03 06:48:03 [INFO ]  	- 3
2022-10-03 06:48:03 [INFO ]  	- 4
2022-10-03 06:48:03 [INFO ]  	- 5
2022-10-03 06:48:03 [INFO ]  	- 6
2022-10-03 06:48:03 [INFO ]  	- 7
2022-10-03 06:48:03 [INFO ]  	- 8
2022-10-03 06:48:03 [INFO ]  	- 9
2022-10-03 06:48:03 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 06:48:03 [INFO ]  	- !!python/tuple
2022-10-03 06:48:03 [INFO ]  	    - 0.4379104971885681
2022-10-03 06:48:03 [INFO ]  	    - 0.44398033618927
2022-10-03 06:48:03 [INFO ]  	    - 0.4729299545288086
2022-10-03 06:48:03 [INFO ]  	- !!python/tuple
2022-10-03 06:48:03 [INFO ]  	    - 0.19803012907505035
2022-10-03 06:48:03 [INFO ]  	    - 0.2010156363248825
2022-10-03 06:48:03 [INFO ]  	    - 0.19703614711761475
2022-10-03 06:48:03 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 06:48:03 [INFO ]  	decay_epochs: 50
2022-10-03 06:48:03 [INFO ]  	decay_factor: 0.1
2022-10-03 06:48:03 [INFO ]  	device_id: 0
2022-10-03 06:48:03 [INFO ]  	distill_epochs: 1
2022-10-03 06:48:03 [INFO ]  	distill_lr: 0.02
2022-10-03 06:48:03 [INFO ]  	distill_steps: 1
2022-10-03 06:48:03 [INFO ]  	epochs: 200
2022-10-03 06:48:03 [INFO ]  	expand_cls: false
2022-10-03 06:48:03 [INFO ]  	forgetting_dataset: null
2022-10-03 06:48:03 [INFO ]  	init: xavier
2022-10-03 06:48:03 [INFO ]  	init_param: 1.0
2022-10-03 06:48:03 [INFO ]  	input_size: 32
2022-10-03 06:48:03 [INFO ]  	ipc: 1
2022-10-03 06:48:03 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 06:48:03 [INFO ]  	log_interval: 100
2022-10-03 06:48:03 [INFO ]  	log_level: INFO
2022-10-03 06:48:03 [INFO ]  	lr: 0.01
2022-10-03 06:48:03 [INFO ]  	mode: distill_adapt
2022-10-03 06:48:03 [INFO ]  	nc: 3
2022-10-03 06:48:03 [INFO ]  	num_classes: 10
2022-10-03 06:48:03 [INFO ]  	num_workers: 8
2022-10-03 06:48:03 [INFO ]  	phase: train
2022-10-03 06:48:03 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 06:48:03 [INFO ]  	start_time: '2022-10-03 06:48:03'
2022-10-03 06:48:03 [INFO ]  	test_batch_size: 1024
2022-10-03 06:48:03 [INFO ]  	
2022-10-03 06:48:05 [INFO ]  train dataset size:	73257
2022-10-03 06:48:05 [INFO ]  test dataset size: 	26032
2022-10-03 06:48:05 [INFO ]  datasets built!
2022-10-03 06:48:05 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 06:48:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 06:48:08 [INFO ]  
2022-10-03 06:48:08 [INFO ]  Begin of epoch 0 :
2022-10-03 06:48:11 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:48:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:48:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:48:11 [INFO ]  	   step  1 (lr=0.020000)                    6.87%                  10.5728
2022-10-03 06:48:11 [INFO ]  
2022-10-03 06:48:11 [INFO ]  Epoch:    0	Loss: 10.0061	Data Time: 0.33s	Train Time: 0.03s
2022-10-03 06:48:12 [INFO ]  Epoch:    1	Loss: 3.9628	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:48:14 [INFO ]  Epoch:    2	Loss: 2.8550	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:48:16 [INFO ]  Epoch:    3	Loss: 2.6396	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:48:18 [INFO ]  Epoch:    4	Loss: 2.4304	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:48:20 [INFO ]  Epoch:    5	Loss: 2.2970	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:48:22 [INFO ]  Epoch:    6	Loss: 2.2799	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:48:24 [INFO ]  Epoch:    7	Loss: 2.2642	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:48:25 [INFO ]  Epoch:    8	Loss: 2.2297	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:48:27 [INFO ]  Epoch:    9	Loss: 2.2273	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:48:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 06:48:30 [INFO ]  
2022-10-03 06:48:30 [INFO ]  Begin of epoch 10 :
2022-10-03 06:48:33 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:48:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:48:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:48:33 [INFO ]  	   step  1 (lr=0.037567)                   23.05%                   2.2149
2022-10-03 06:48:33 [INFO ]  
2022-10-03 06:48:33 [INFO ]  Epoch:   10	Loss: 2.2026	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:48:35 [INFO ]  Epoch:   11	Loss: 2.1758	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:48:37 [INFO ]  Epoch:   12	Loss: 2.1918	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:48:38 [INFO ]  Epoch:   13	Loss: 2.1258	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:48:40 [INFO ]  Epoch:   14	Loss: 2.1146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:48:42 [INFO ]  Epoch:   15	Loss: 2.1509	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:48:44 [INFO ]  Epoch:   16	Loss: 2.0843	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:48:45 [INFO ]  Epoch:   17	Loss: 2.0978	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:48:47 [INFO ]  Epoch:   18	Loss: 2.1021	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:48:49 [INFO ]  Epoch:   19	Loss: 2.0140	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:48:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 06:48:52 [INFO ]  
2022-10-03 06:48:52 [INFO ]  Begin of epoch 20 :
2022-10-03 06:48:55 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:48:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:48:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:48:55 [INFO ]  	   step  1 (lr=0.058992)                   37.08%                   2.0106
2022-10-03 06:48:55 [INFO ]  
2022-10-03 06:48:55 [INFO ]  Epoch:   20	Loss: 2.0069	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:48:57 [INFO ]  Epoch:   21	Loss: 1.9433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:48:58 [INFO ]  Epoch:   22	Loss: 1.9529	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:00 [INFO ]  Epoch:   23	Loss: 1.9141	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:02 [INFO ]  Epoch:   24	Loss: 1.8898	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:49:04 [INFO ]  Epoch:   25	Loss: 1.8595	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:49:06 [INFO ]  Epoch:   26	Loss: 1.9194	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:49:07 [INFO ]  Epoch:   27	Loss: 1.8489	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:49:09 [INFO ]  Epoch:   28	Loss: 1.7637	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:49:11 [INFO ]  Epoch:   29	Loss: 1.9111	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:49:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 06:49:14 [INFO ]  
2022-10-03 06:49:14 [INFO ]  Begin of epoch 30 :
2022-10-03 06:49:17 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:49:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:49:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:49:17 [INFO ]  	   step  1 (lr=0.073837)                   35.05%                   1.9279
2022-10-03 06:49:17 [INFO ]  
2022-10-03 06:49:17 [INFO ]  Epoch:   30	Loss: 1.9105	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:18 [INFO ]  Epoch:   31	Loss: 1.7600	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:20 [INFO ]  Epoch:   32	Loss: 1.5892	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:22 [INFO ]  Epoch:   33	Loss: 1.6464	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:49:24 [INFO ]  Epoch:   34	Loss: 1.5800	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:26 [INFO ]  Epoch:   35	Loss: 1.5501	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:49:28 [INFO ]  Epoch:   36	Loss: 1.5899	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:49:29 [INFO ]  Epoch:   37	Loss: 1.6973	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:49:31 [INFO ]  Epoch:   38	Loss: 1.6661	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:49:33 [INFO ]  Epoch:   39	Loss: 1.5828	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:49:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 06:49:36 [INFO ]  
2022-10-03 06:49:36 [INFO ]  Begin of epoch 40 :
2022-10-03 06:49:39 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:49:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:49:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:49:39 [INFO ]  	   step  1 (lr=0.114705)                   50.40%                   1.6006
2022-10-03 06:49:39 [INFO ]  
2022-10-03 06:49:39 [INFO ]  Epoch:   40	Loss: 1.5544	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:49:41 [INFO ]  Epoch:   41	Loss: 1.6348	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:49:42 [INFO ]  Epoch:   42	Loss: 1.5604	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:49:44 [INFO ]  Epoch:   43	Loss: 1.6821	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 06:49:46 [INFO ]  Epoch:   44	Loss: 1.5516	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:49:48 [INFO ]  Epoch:   45	Loss: 1.5586	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:50 [INFO ]  Epoch:   46	Loss: 1.5767	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:49:51 [INFO ]  Epoch:   47	Loss: 1.7084	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:49:53 [INFO ]  Epoch:   48	Loss: 1.4765	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:49:55 [INFO ]  Epoch:   49	Loss: 1.7285	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:49:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 06:49:58 [INFO ]  
2022-10-03 06:49:58 [INFO ]  Begin of epoch 50 :
2022-10-03 06:50:01 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:50:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:50:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:50:01 [INFO ]  	   step  1 (lr=0.128733)                   52.47%                   1.6367
2022-10-03 06:50:01 [INFO ]  
2022-10-03 06:50:01 [INFO ]  Epoch:   50	Loss: 1.5159	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:50:02 [INFO ]  Epoch:   51	Loss: 1.7048	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:04 [INFO ]  Epoch:   52	Loss: 1.5345	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:50:06 [INFO ]  Epoch:   53	Loss: 1.4751	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:50:08 [INFO ]  Epoch:   54	Loss: 1.3841	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:10 [INFO ]  Epoch:   55	Loss: 1.3876	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:12 [INFO ]  Epoch:   56	Loss: 1.4397	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:50:13 [INFO ]  Epoch:   57	Loss: 1.4010	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:15 [INFO ]  Epoch:   58	Loss: 1.3908	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:50:17 [INFO ]  Epoch:   59	Loss: 1.5478	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:50:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 06:50:20 [INFO ]  
2022-10-03 06:50:20 [INFO ]  Begin of epoch 60 :
2022-10-03 06:50:23 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:50:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:50:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:50:23 [INFO ]  	   step  1 (lr=0.136118)                   56.73%                   1.4560
2022-10-03 06:50:23 [INFO ]  
2022-10-03 06:50:23 [INFO ]  Epoch:   60	Loss: 1.4378	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 06:50:25 [INFO ]  Epoch:   61	Loss: 1.3696	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:27 [INFO ]  Epoch:   62	Loss: 1.3754	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:29 [INFO ]  Epoch:   63	Loss: 1.4786	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:50:30 [INFO ]  Epoch:   64	Loss: 1.5320	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:32 [INFO ]  Epoch:   65	Loss: 1.4107	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:34 [INFO ]  Epoch:   66	Loss: 1.4415	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 06:50:36 [INFO ]  Epoch:   67	Loss: 1.3290	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:50:38 [INFO ]  Epoch:   68	Loss: 1.3413	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 06:50:40 [INFO ]  Epoch:   69	Loss: 1.3144	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:50:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 06:50:42 [INFO ]  
2022-10-03 06:50:42 [INFO ]  Begin of epoch 70 :
2022-10-03 06:50:46 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:50:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:50:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:50:46 [INFO ]  	   step  1 (lr=0.143512)                   59.15%                   1.3620
2022-10-03 06:50:46 [INFO ]  
2022-10-03 06:50:46 [INFO ]  Epoch:   70	Loss: 1.3892	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:50:47 [INFO ]  Epoch:   71	Loss: 1.4064	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:50:49 [INFO ]  Epoch:   72	Loss: 1.3629	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:50:51 [INFO ]  Epoch:   73	Loss: 1.5268	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:50:53 [INFO ]  Epoch:   74	Loss: 1.3241	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:50:55 [INFO ]  Epoch:   75	Loss: 1.4195	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:50:57 [INFO ]  Epoch:   76	Loss: 1.4627	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:50:58 [INFO ]  Epoch:   77	Loss: 1.2764	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:51:00 [INFO ]  Epoch:   78	Loss: 1.3076	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:02 [INFO ]  Epoch:   79	Loss: 1.3811	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:51:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 06:51:05 [INFO ]  
2022-10-03 06:51:05 [INFO ]  Begin of epoch 80 :
2022-10-03 06:51:08 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:51:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:51:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:51:08 [INFO ]  	   step  1 (lr=0.143905)                   57.52%                   1.3977
2022-10-03 06:51:08 [INFO ]  
2022-10-03 06:51:08 [INFO ]  Epoch:   80	Loss: 1.3259	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:51:10 [INFO ]  Epoch:   81	Loss: 1.2547	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:51:12 [INFO ]  Epoch:   82	Loss: 1.2973	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 06:51:14 [INFO ]  Epoch:   83	Loss: 1.4359	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:51:16 [INFO ]  Epoch:   84	Loss: 1.3259	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:51:17 [INFO ]  Epoch:   85	Loss: 1.3580	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:51:19 [INFO ]  Epoch:   86	Loss: 1.3044	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:21 [INFO ]  Epoch:   87	Loss: 1.2941	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:23 [INFO ]  Epoch:   88	Loss: 1.3052	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:25 [INFO ]  Epoch:   89	Loss: 1.4292	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:51:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 06:51:28 [INFO ]  
2022-10-03 06:51:28 [INFO ]  Begin of epoch 90 :
2022-10-03 06:51:31 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:51:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:51:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:51:31 [INFO ]  	   step  1 (lr=0.148872)                   57.25%                   1.4603
2022-10-03 06:51:31 [INFO ]  
2022-10-03 06:51:31 [INFO ]  Epoch:   90	Loss: 1.3377	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:51:33 [INFO ]  Epoch:   91	Loss: 1.2466	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:51:35 [INFO ]  Epoch:   92	Loss: 1.3183	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:51:36 [INFO ]  Epoch:   93	Loss: 1.4785	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:51:38 [INFO ]  Epoch:   94	Loss: 1.4375	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:51:40 [INFO ]  Epoch:   95	Loss: 1.3024	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:42 [INFO ]  Epoch:   96	Loss: 1.3143	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:51:44 [INFO ]  Epoch:   97	Loss: 1.1941	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:46 [INFO ]  Epoch:   98	Loss: 1.2177	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:51:47 [INFO ]  Epoch:   99	Loss: 1.2681	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:51:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 06:51:51 [INFO ]  
2022-10-03 06:51:51 [INFO ]  Begin of epoch 100 :
2022-10-03 06:51:54 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:51:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:51:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:51:54 [INFO ]  	   step  1 (lr=0.159112)                   60.88%                   1.3222
2022-10-03 06:51:54 [INFO ]  
2022-10-03 06:51:54 [INFO ]  Epoch:  100	Loss: 1.2383	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 06:51:55 [INFO ]  Epoch:  101	Loss: 1.2804	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:51:57 [INFO ]  Epoch:  102	Loss: 1.4159	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:51:59 [INFO ]  Epoch:  103	Loss: 1.2754	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:01 [INFO ]  Epoch:  104	Loss: 1.3025	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:02 [INFO ]  Epoch:  105	Loss: 1.3384	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:52:04 [INFO ]  Epoch:  106	Loss: 1.3441	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:52:06 [INFO ]  Epoch:  107	Loss: 1.3216	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 06:52:08 [INFO ]  Epoch:  108	Loss: 1.2523	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:52:10 [INFO ]  Epoch:  109	Loss: 1.2535	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 06:52:13 [INFO ]  
2022-10-03 06:52:13 [INFO ]  Begin of epoch 110 :
2022-10-03 06:52:17 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:52:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:52:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:52:17 [INFO ]  	   step  1 (lr=0.161091)                   60.53%                   1.3400
2022-10-03 06:52:17 [INFO ]  
2022-10-03 06:52:17 [INFO ]  Epoch:  110	Loss: 1.2887	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:52:18 [INFO ]  Epoch:  111	Loss: 1.4580	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:52:20 [INFO ]  Epoch:  112	Loss: 1.2452	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:22 [INFO ]  Epoch:  113	Loss: 1.2880	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:52:24 [INFO ]  Epoch:  114	Loss: 1.2380	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:52:26 [INFO ]  Epoch:  115	Loss: 1.3635	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:28 [INFO ]  Epoch:  116	Loss: 1.3015	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:52:30 [INFO ]  Epoch:  117	Loss: 1.2685	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:52:32 [INFO ]  Epoch:  118	Loss: 1.3942	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:52:34 [INFO ]  Epoch:  119	Loss: 1.3214	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:52:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 06:52:37 [INFO ]  
2022-10-03 06:52:37 [INFO ]  Begin of epoch 120 :
2022-10-03 06:52:40 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:52:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:52:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:52:40 [INFO ]  	   step  1 (lr=0.160698)                   59.49%                   1.3367
2022-10-03 06:52:40 [INFO ]  
2022-10-03 06:52:40 [INFO ]  Epoch:  120	Loss: 1.2723	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:52:41 [INFO ]  Epoch:  121	Loss: 1.3082	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:52:43 [INFO ]  Epoch:  122	Loss: 1.4073	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:52:45 [INFO ]  Epoch:  123	Loss: 1.3138	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 06:52:47 [INFO ]  Epoch:  124	Loss: 1.3054	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:52:49 [INFO ]  Epoch:  125	Loss: 1.2917	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:52:51 [INFO ]  Epoch:  126	Loss: 1.3156	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:52:52 [INFO ]  Epoch:  127	Loss: 1.3344	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:52:54 [INFO ]  Epoch:  128	Loss: 1.3329	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:52:56 [INFO ]  Epoch:  129	Loss: 1.2525	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:52:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 06:52:59 [INFO ]  
2022-10-03 06:52:59 [INFO ]  Begin of epoch 130 :
2022-10-03 06:53:02 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:53:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:53:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:53:02 [INFO ]  	   step  1 (lr=0.161591)                   57.02%                   1.4434
2022-10-03 06:53:02 [INFO ]  
2022-10-03 06:53:02 [INFO ]  Epoch:  130	Loss: 1.4206	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:04 [INFO ]  Epoch:  131	Loss: 1.2217	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:53:06 [INFO ]  Epoch:  132	Loss: 1.2187	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 06:53:08 [INFO ]  Epoch:  133	Loss: 1.2658	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:09 [INFO ]  Epoch:  134	Loss: 1.4329	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:53:11 [INFO ]  Epoch:  135	Loss: 1.3655	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:13 [INFO ]  Epoch:  136	Loss: 1.2919	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:53:15 [INFO ]  Epoch:  137	Loss: 1.3080	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:17 [INFO ]  Epoch:  138	Loss: 1.2832	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:19 [INFO ]  Epoch:  139	Loss: 1.2906	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:53:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 06:53:22 [INFO ]  
2022-10-03 06:53:22 [INFO ]  Begin of epoch 140 :
2022-10-03 06:53:25 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:53:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:53:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:53:25 [INFO ]  	   step  1 (lr=0.162138)                   60.55%                   1.3226
2022-10-03 06:53:25 [INFO ]  
2022-10-03 06:53:25 [INFO ]  Epoch:  140	Loss: 1.2704	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:53:26 [INFO ]  Epoch:  141	Loss: 1.3299	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:53:28 [INFO ]  Epoch:  142	Loss: 1.2720	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:30 [INFO ]  Epoch:  143	Loss: 1.1970	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:32 [INFO ]  Epoch:  144	Loss: 1.2319	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:53:34 [INFO ]  Epoch:  145	Loss: 1.2097	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:35 [INFO ]  Epoch:  146	Loss: 1.3376	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:37 [INFO ]  Epoch:  147	Loss: 1.3238	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:53:39 [INFO ]  Epoch:  148	Loss: 1.3022	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:53:41 [INFO ]  Epoch:  149	Loss: 1.3061	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 06:53:44 [INFO ]  
2022-10-03 06:53:44 [INFO ]  Begin of epoch 150 :
2022-10-03 06:53:47 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:53:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:53:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:53:47 [INFO ]  	   step  1 (lr=0.162930)                   62.27%                   1.3010
2022-10-03 06:53:47 [INFO ]  
2022-10-03 06:53:47 [INFO ]  Epoch:  150	Loss: 1.2387	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:48 [INFO ]  Epoch:  151	Loss: 1.2887	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:53:50 [INFO ]  Epoch:  152	Loss: 1.2673	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:52 [INFO ]  Epoch:  153	Loss: 1.1957	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:53:54 [INFO ]  Epoch:  154	Loss: 1.2593	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:53:56 [INFO ]  Epoch:  155	Loss: 1.2576	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:53:57 [INFO ]  Epoch:  156	Loss: 1.2588	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:53:59 [INFO ]  Epoch:  157	Loss: 1.3560	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 06:54:01 [INFO ]  Epoch:  158	Loss: 1.2197	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:54:03 [INFO ]  Epoch:  159	Loss: 1.3039	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:54:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 06:54:06 [INFO ]  
2022-10-03 06:54:06 [INFO ]  Begin of epoch 160 :
2022-10-03 06:54:09 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:54:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:54:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:54:09 [INFO ]  	   step  1 (lr=0.163317)                   60.36%                   1.3282
2022-10-03 06:54:09 [INFO ]  
2022-10-03 06:54:09 [INFO ]  Epoch:  160	Loss: 1.3235	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 06:54:11 [INFO ]  Epoch:  161	Loss: 1.2848	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:13 [INFO ]  Epoch:  162	Loss: 1.2205	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:54:15 [INFO ]  Epoch:  163	Loss: 1.2636	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:16 [INFO ]  Epoch:  164	Loss: 1.4227	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:54:18 [INFO ]  Epoch:  165	Loss: 1.2614	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:54:20 [INFO ]  Epoch:  166	Loss: 1.2582	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:22 [INFO ]  Epoch:  167	Loss: 1.2557	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:24 [INFO ]  Epoch:  168	Loss: 1.2454	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:54:25 [INFO ]  Epoch:  169	Loss: 1.2194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 06:54:28 [INFO ]  
2022-10-03 06:54:28 [INFO ]  Begin of epoch 170 :
2022-10-03 06:54:31 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:54:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:54:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:54:31 [INFO ]  	   step  1 (lr=0.163351)                   59.58%                   1.3726
2022-10-03 06:54:31 [INFO ]  
2022-10-03 06:54:31 [INFO ]  Epoch:  170	Loss: 1.2884	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:33 [INFO ]  Epoch:  171	Loss: 1.3009	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:54:35 [INFO ]  Epoch:  172	Loss: 1.2367	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:37 [INFO ]  Epoch:  173	Loss: 1.1619	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:54:38 [INFO ]  Epoch:  174	Loss: 1.2090	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:54:40 [INFO ]  Epoch:  175	Loss: 1.3502	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 06:54:42 [INFO ]  Epoch:  176	Loss: 1.2254	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:44 [INFO ]  Epoch:  177	Loss: 1.2139	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:46 [INFO ]  Epoch:  178	Loss: 1.3096	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:54:47 [INFO ]  Epoch:  179	Loss: 1.2800	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:54:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 06:54:50 [INFO ]  
2022-10-03 06:54:50 [INFO ]  Begin of epoch 180 :
2022-10-03 06:54:53 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:54:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:54:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:54:53 [INFO ]  	   step  1 (lr=0.163562)                   60.80%                   1.3132
2022-10-03 06:54:53 [INFO ]  
2022-10-03 06:54:53 [INFO ]  Epoch:  180	Loss: 1.2152	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:54:55 [INFO ]  Epoch:  181	Loss: 1.1954	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:54:57 [INFO ]  Epoch:  182	Loss: 1.3286	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:54:59 [INFO ]  Epoch:  183	Loss: 1.2009	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:55:01 [INFO ]  Epoch:  184	Loss: 1.3186	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 06:55:02 [INFO ]  Epoch:  185	Loss: 1.2278	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:55:04 [INFO ]  Epoch:  186	Loss: 1.2235	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:55:06 [INFO ]  Epoch:  187	Loss: 1.2922	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:55:08 [INFO ]  Epoch:  188	Loss: 1.3396	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:55:10 [INFO ]  Epoch:  189	Loss: 1.2853	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:55:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 06:55:13 [INFO ]  
2022-10-03 06:55:13 [INFO ]  Begin of epoch 190 :
2022-10-03 06:55:16 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:55:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:55:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:55:16 [INFO ]  	   step  1 (lr=0.163532)                   60.80%                   1.3146
2022-10-03 06:55:16 [INFO ]  
2022-10-03 06:55:16 [INFO ]  Epoch:  190	Loss: 1.1812	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 06:55:18 [INFO ]  Epoch:  191	Loss: 1.2362	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:55:20 [INFO ]  Epoch:  192	Loss: 1.2696	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:55:21 [INFO ]  Epoch:  193	Loss: 1.4160	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 06:55:23 [INFO ]  Epoch:  194	Loss: 1.4916	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 06:55:25 [INFO ]  Epoch:  195	Loss: 1.2117	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:55:27 [INFO ]  Epoch:  196	Loss: 1.1997	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 06:55:29 [INFO ]  Epoch:  197	Loss: 1.2505	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:55:30 [INFO ]  Epoch:  198	Loss: 1.2293	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 06:55:32 [INFO ]  Epoch:  199	Loss: 1.4260	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 06:55:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 06:55:35 [INFO ]  
2022-10-03 06:55:35 [INFO ]  Final evaluation for SVHN :
2022-10-03 06:55:38 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:55:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:55:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 06:55:38 [INFO ]  	   step  1 (lr=0.163529)                   59.58%                   1.3703
2022-10-03 06:55:38 [INFO ]  
2022-10-03 06:55:38 [INFO ]  
2022-10-03 06:55:38 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 06:55:41 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 06:55:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 06:55:41 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 06:55:41 [INFO ]  	   step  1 (lr=0.163529)                   24.94%                   3.7251
2022-10-03 06:55:41 [INFO ]  
2022-10-03 07:00:45 [INFO ]  ======================================== 2022-10-03 07:00:45 ========================================
2022-10-03 07:00:45 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:00:45 [INFO ]  Options: 
2022-10-03 07:00:45 [INFO ]  	base_dir: null
2022-10-03 07:00:45 [INFO ]  	batch_size: 1024
2022-10-03 07:00:45 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:00:45 [INFO ]  	dataset: SVHN
2022-10-03 07:00:45 [INFO ]  	dataset_labels:
2022-10-03 07:00:45 [INFO ]  	- 0
2022-10-03 07:00:45 [INFO ]  	- 1
2022-10-03 07:00:45 [INFO ]  	- 2
2022-10-03 07:00:45 [INFO ]  	- 3
2022-10-03 07:00:45 [INFO ]  	- 4
2022-10-03 07:00:45 [INFO ]  	- 5
2022-10-03 07:00:45 [INFO ]  	- 6
2022-10-03 07:00:45 [INFO ]  	- 7
2022-10-03 07:00:45 [INFO ]  	- 8
2022-10-03 07:00:45 [INFO ]  	- 9
2022-10-03 07:00:45 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:00:45 [INFO ]  	- !!python/tuple
2022-10-03 07:00:45 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:00:45 [INFO ]  	    - 0.44398033618927
2022-10-03 07:00:45 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:00:45 [INFO ]  	- !!python/tuple
2022-10-03 07:00:45 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:00:45 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:00:45 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:00:45 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:00:45 [INFO ]  	decay_epochs: 50
2022-10-03 07:00:45 [INFO ]  	decay_factor: 0.1
2022-10-03 07:00:45 [INFO ]  	device_id: 0
2022-10-03 07:00:45 [INFO ]  	distill_epochs: 1
2022-10-03 07:00:45 [INFO ]  	distill_lr: 0.02
2022-10-03 07:00:45 [INFO ]  	distill_steps: 1
2022-10-03 07:00:45 [INFO ]  	epochs: 200
2022-10-03 07:00:45 [INFO ]  	expand_cls: false
2022-10-03 07:00:45 [INFO ]  	forgetting_dataset: null
2022-10-03 07:00:45 [INFO ]  	init: xavier
2022-10-03 07:00:45 [INFO ]  	init_param: 1.0
2022-10-03 07:00:45 [INFO ]  	input_size: 32
2022-10-03 07:00:45 [INFO ]  	ipc: 1
2022-10-03 07:00:45 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:00:45 [INFO ]  	log_interval: 100
2022-10-03 07:00:45 [INFO ]  	log_level: INFO
2022-10-03 07:00:45 [INFO ]  	lr: 0.01
2022-10-03 07:00:45 [INFO ]  	mode: distill_adapt
2022-10-03 07:00:45 [INFO ]  	nc: 3
2022-10-03 07:00:45 [INFO ]  	num_classes: 10
2022-10-03 07:00:45 [INFO ]  	num_workers: 8
2022-10-03 07:00:45 [INFO ]  	phase: train
2022-10-03 07:00:45 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:00:45 [INFO ]  	start_time: '2022-10-03 07:00:45'
2022-10-03 07:00:45 [INFO ]  	test_batch_size: 1024
2022-10-03 07:00:45 [INFO ]  	
2022-10-03 07:00:47 [INFO ]  train dataset size:	73257
2022-10-03 07:00:47 [INFO ]  test dataset size: 	26032
2022-10-03 07:00:47 [INFO ]  datasets built!
2022-10-03 07:00:47 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:00:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:00:50 [INFO ]  
2022-10-03 07:00:50 [INFO ]  Begin of epoch 0 :
2022-10-03 07:00:53 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:00:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:00:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:00:53 [INFO ]  	   step  1 (lr=0.020000)                    8.61%                   7.9217
2022-10-03 07:00:53 [INFO ]  
2022-10-03 07:00:53 [INFO ]  Epoch:    0	Loss: 7.8292	Data Time: 0.34s	Train Time: 0.03s
2022-10-03 07:00:55 [INFO ]  Epoch:    1	Loss: 3.7412	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 07:00:57 [INFO ]  Epoch:    2	Loss: 2.8473	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:00:58 [INFO ]  Epoch:    3	Loss: 2.6384	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:01:00 [INFO ]  Epoch:    4	Loss: 2.5389	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:02 [INFO ]  Epoch:    5	Loss: 2.2965	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:04 [INFO ]  Epoch:    6	Loss: 2.2319	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:01:06 [INFO ]  Epoch:    7	Loss: 2.1949	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:01:07 [INFO ]  Epoch:    8	Loss: 2.2001	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:01:09 [INFO ]  Epoch:    9	Loss: 2.1855	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:01:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:01:12 [INFO ]  
2022-10-03 07:01:12 [INFO ]  Begin of epoch 10 :
2022-10-03 07:01:15 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:01:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:01:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:01:15 [INFO ]  	   step  1 (lr=0.049855)                   24.86%                   2.1792
2022-10-03 07:01:15 [INFO ]  
2022-10-03 07:01:15 [INFO ]  Epoch:   10	Loss: 2.1635	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:01:17 [INFO ]  Epoch:   11	Loss: 2.1586	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:01:19 [INFO ]  Epoch:   12	Loss: 2.1579	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:01:20 [INFO ]  Epoch:   13	Loss: 2.1251	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:01:22 [INFO ]  Epoch:   14	Loss: 2.0872	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:24 [INFO ]  Epoch:   15	Loss: 2.1180	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:26 [INFO ]  Epoch:   16	Loss: 2.0515	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:01:28 [INFO ]  Epoch:   17	Loss: 2.2264	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:01:29 [INFO ]  Epoch:   18	Loss: 2.0721	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:01:31 [INFO ]  Epoch:   19	Loss: 1.9589	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:01:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:01:34 [INFO ]  
2022-10-03 07:01:34 [INFO ]  Begin of epoch 20 :
2022-10-03 07:01:37 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:01:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:01:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:01:37 [INFO ]  	   step  1 (lr=0.082390)                   29.81%                   2.0853
2022-10-03 07:01:37 [INFO ]  
2022-10-03 07:01:37 [INFO ]  Epoch:   20	Loss: 2.1574	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:01:39 [INFO ]  Epoch:   21	Loss: 2.0068	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:01:41 [INFO ]  Epoch:   22	Loss: 1.9278	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:01:42 [INFO ]  Epoch:   23	Loss: 1.8120	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 07:01:44 [INFO ]  Epoch:   24	Loss: 1.6941	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:46 [INFO ]  Epoch:   25	Loss: 1.7199	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:01:48 [INFO ]  Epoch:   26	Loss: 1.7438	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:01:49 [INFO ]  Epoch:   27	Loss: 1.6876	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:01:51 [INFO ]  Epoch:   28	Loss: 1.6230	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:01:53 [INFO ]  Epoch:   29	Loss: 1.4396	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:01:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:01:56 [INFO ]  
2022-10-03 07:01:56 [INFO ]  Begin of epoch 30 :
2022-10-03 07:01:59 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:01:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:01:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:01:59 [INFO ]  	   step  1 (lr=0.158473)                   49.57%                   1.6423
2022-10-03 07:01:59 [INFO ]  
2022-10-03 07:01:59 [INFO ]  Epoch:   30	Loss: 1.6039	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:01 [INFO ]  Epoch:   31	Loss: 2.1882	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:02:03 [INFO ]  Epoch:   32	Loss: 1.6188	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:02:04 [INFO ]  Epoch:   33	Loss: 1.6770	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:06 [INFO ]  Epoch:   34	Loss: 1.6316	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:02:08 [INFO ]  Epoch:   35	Loss: 1.6537	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:02:10 [INFO ]  Epoch:   36	Loss: 1.7527	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:11 [INFO ]  Epoch:   37	Loss: 1.5219	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:02:13 [INFO ]  Epoch:   38	Loss: 1.4761	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:02:15 [INFO ]  Epoch:   39	Loss: 1.4141	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:02:18 [INFO ]  
2022-10-03 07:02:18 [INFO ]  Begin of epoch 40 :
2022-10-03 07:02:22 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:02:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:02:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:02:22 [INFO ]  	   step  1 (lr=0.170876)                   52.32%                   1.5500
2022-10-03 07:02:22 [INFO ]  
2022-10-03 07:02:22 [INFO ]  Epoch:   40	Loss: 1.4576	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 07:02:23 [INFO ]  Epoch:   41	Loss: 1.4267	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:02:25 [INFO ]  Epoch:   42	Loss: 1.6605	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:27 [INFO ]  Epoch:   43	Loss: 1.3658	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:29 [INFO ]  Epoch:   44	Loss: 1.4606	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:02:30 [INFO ]  Epoch:   45	Loss: 1.6346	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:32 [INFO ]  Epoch:   46	Loss: 1.4381	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:02:34 [INFO ]  Epoch:   47	Loss: 1.2956	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:35 [INFO ]  Epoch:   48	Loss: 1.2841	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:02:37 [INFO ]  Epoch:   49	Loss: 1.6995	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:02:40 [INFO ]  
2022-10-03 07:02:40 [INFO ]  Begin of epoch 50 :
2022-10-03 07:02:43 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:02:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:02:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:02:43 [INFO ]  	   step  1 (lr=0.181632)                   56.09%                   1.4204
2022-10-03 07:02:43 [INFO ]  
2022-10-03 07:02:43 [INFO ]  Epoch:   50	Loss: 1.4662	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:45 [INFO ]  Epoch:   51	Loss: 1.3609	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:02:47 [INFO ]  Epoch:   52	Loss: 1.3917	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:02:49 [INFO ]  Epoch:   53	Loss: 1.2521	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:02:51 [INFO ]  Epoch:   54	Loss: 1.3023	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:02:52 [INFO ]  Epoch:   55	Loss: 1.4766	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:02:54 [INFO ]  Epoch:   56	Loss: 1.5064	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:02:56 [INFO ]  Epoch:   57	Loss: 1.3152	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:02:58 [INFO ]  Epoch:   58	Loss: 1.5552	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:02:59 [INFO ]  Epoch:   59	Loss: 1.2728	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:03:02 [INFO ]  
2022-10-03 07:03:02 [INFO ]  Begin of epoch 60 :
2022-10-03 07:03:05 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:03:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:03:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:03:05 [INFO ]  	   step  1 (lr=0.185335)                   59.15%                   1.3453
2022-10-03 07:03:05 [INFO ]  
2022-10-03 07:03:05 [INFO ]  Epoch:   60	Loss: 1.3284	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:07 [INFO ]  Epoch:   61	Loss: 1.5008	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:03:09 [INFO ]  Epoch:   62	Loss: 1.2142	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:11 [INFO ]  Epoch:   63	Loss: 1.2510	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:03:13 [INFO ]  Epoch:   64	Loss: 1.3334	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:14 [INFO ]  Epoch:   65	Loss: 1.2305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:16 [INFO ]  Epoch:   66	Loss: 1.1980	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:03:18 [INFO ]  Epoch:   67	Loss: 1.3190	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:03:20 [INFO ]  Epoch:   68	Loss: 1.3652	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:03:22 [INFO ]  Epoch:   69	Loss: 1.3345	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:03:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:03:25 [INFO ]  
2022-10-03 07:03:25 [INFO ]  Begin of epoch 70 :
2022-10-03 07:03:28 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:03:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:03:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:03:28 [INFO ]  	   step  1 (lr=0.188826)                   59.50%                   1.3357
2022-10-03 07:03:28 [INFO ]  
2022-10-03 07:03:28 [INFO ]  Epoch:   70	Loss: 1.2978	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:03:30 [INFO ]  Epoch:   71	Loss: 1.4285	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:03:32 [INFO ]  Epoch:   72	Loss: 1.3162	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:03:33 [INFO ]  Epoch:   73	Loss: 1.2867	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:03:35 [INFO ]  Epoch:   74	Loss: 1.2939	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:37 [INFO ]  Epoch:   75	Loss: 1.2703	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:39 [INFO ]  Epoch:   76	Loss: 1.3206	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:41 [INFO ]  Epoch:   77	Loss: 1.2288	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:43 [INFO ]  Epoch:   78	Loss: 1.2434	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:03:45 [INFO ]  Epoch:   79	Loss: 1.1680	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:03:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:03:48 [INFO ]  
2022-10-03 07:03:48 [INFO ]  Begin of epoch 80 :
2022-10-03 07:03:51 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:03:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:03:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:03:51 [INFO ]  	   step  1 (lr=0.199880)                   49.98%                   1.6214
2022-10-03 07:03:51 [INFO ]  
2022-10-03 07:03:51 [INFO ]  Epoch:   80	Loss: 1.6617	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:52 [INFO ]  Epoch:   81	Loss: 1.2492	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:54 [INFO ]  Epoch:   82	Loss: 1.2367	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:03:56 [INFO ]  Epoch:   83	Loss: 1.3036	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:03:58 [INFO ]  Epoch:   84	Loss: 1.1890	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:04:00 [INFO ]  Epoch:   85	Loss: 1.1988	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:04:02 [INFO ]  Epoch:   86	Loss: 1.2809	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:04:04 [INFO ]  Epoch:   87	Loss: 1.1619	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:04:05 [INFO ]  Epoch:   88	Loss: 1.3489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:04:07 [INFO ]  Epoch:   89	Loss: 1.2249	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:04:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:04:10 [INFO ]  
2022-10-03 07:04:10 [INFO ]  Begin of epoch 90 :
2022-10-03 07:04:13 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:04:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:04:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:04:13 [INFO ]  	   step  1 (lr=0.209040)                   63.21%                   1.2403
2022-10-03 07:04:13 [INFO ]  
2022-10-03 07:04:13 [INFO ]  Epoch:   90	Loss: 1.1989	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:04:15 [INFO ]  Epoch:   91	Loss: 1.3173	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:04:16 [INFO ]  Epoch:   92	Loss: 1.2528	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:04:18 [INFO ]  Epoch:   93	Loss: 1.1875	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:04:20 [INFO ]  Epoch:   94	Loss: 1.1991	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:22 [INFO ]  Epoch:   95	Loss: 1.2327	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:23 [INFO ]  Epoch:   96	Loss: 1.1879	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:25 [INFO ]  Epoch:   97	Loss: 1.1651	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:04:27 [INFO ]  Epoch:   98	Loss: 1.3208	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:29 [INFO ]  Epoch:   99	Loss: 1.2627	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:04:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:04:32 [INFO ]  
2022-10-03 07:04:32 [INFO ]  Begin of epoch 100 :
2022-10-03 07:04:35 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:04:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:04:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:04:35 [INFO ]  	   step  1 (lr=0.213754)                   64.46%                   1.2216
2022-10-03 07:04:35 [INFO ]  
2022-10-03 07:04:35 [INFO ]  Epoch:  100	Loss: 1.1493	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:04:37 [INFO ]  Epoch:  101	Loss: 1.2154	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:04:39 [INFO ]  Epoch:  102	Loss: 1.1270	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:04:40 [INFO ]  Epoch:  103	Loss: 1.1587	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:04:42 [INFO ]  Epoch:  104	Loss: 1.1978	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:04:44 [INFO ]  Epoch:  105	Loss: 1.1652	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:04:45 [INFO ]  Epoch:  106	Loss: 1.1979	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:04:47 [INFO ]  Epoch:  107	Loss: 1.1786	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:49 [INFO ]  Epoch:  108	Loss: 1.1961	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:04:51 [INFO ]  Epoch:  109	Loss: 1.1696	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:04:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:04:54 [INFO ]  
2022-10-03 07:04:54 [INFO ]  Begin of epoch 110 :
2022-10-03 07:04:57 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:04:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:04:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:04:57 [INFO ]  	   step  1 (lr=0.214252)                   62.45%                   1.2715
2022-10-03 07:04:57 [INFO ]  
2022-10-03 07:04:57 [INFO ]  Epoch:  110	Loss: 1.1399	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:04:59 [INFO ]  Epoch:  111	Loss: 1.1670	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:05:01 [INFO ]  Epoch:  112	Loss: 1.2185	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:05:03 [INFO ]  Epoch:  113	Loss: 1.2236	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:05:04 [INFO ]  Epoch:  114	Loss: 1.1402	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:06 [INFO ]  Epoch:  115	Loss: 1.2332	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:05:08 [INFO ]  Epoch:  116	Loss: 1.1928	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:05:10 [INFO ]  Epoch:  117	Loss: 1.1695	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:12 [INFO ]  Epoch:  118	Loss: 1.1583	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:05:14 [INFO ]  Epoch:  119	Loss: 1.1563	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:05:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:05:17 [INFO ]  
2022-10-03 07:05:17 [INFO ]  Begin of epoch 120 :
2022-10-03 07:05:20 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:05:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:05:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:05:20 [INFO ]  	   step  1 (lr=0.216626)                   62.51%                   1.2817
2022-10-03 07:05:20 [INFO ]  
2022-10-03 07:05:20 [INFO ]  Epoch:  120	Loss: 1.1822	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:05:22 [INFO ]  Epoch:  121	Loss: 1.1952	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:05:24 [INFO ]  Epoch:  122	Loss: 1.2099	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:26 [INFO ]  Epoch:  123	Loss: 1.2172	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:27 [INFO ]  Epoch:  124	Loss: 1.2133	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:29 [INFO ]  Epoch:  125	Loss: 1.2540	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:05:31 [INFO ]  Epoch:  126	Loss: 1.2343	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:33 [INFO ]  Epoch:  127	Loss: 1.2016	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:35 [INFO ]  Epoch:  128	Loss: 1.2442	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:05:37 [INFO ]  Epoch:  129	Loss: 1.1873	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:05:40 [INFO ]  
2022-10-03 07:05:40 [INFO ]  Begin of epoch 130 :
2022-10-03 07:05:43 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:05:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:05:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:05:43 [INFO ]  	   step  1 (lr=0.213169)                   63.04%                   1.2556
2022-10-03 07:05:43 [INFO ]  
2022-10-03 07:05:43 [INFO ]  Epoch:  130	Loss: 1.2158	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:05:44 [INFO ]  Epoch:  131	Loss: 1.2548	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:05:46 [INFO ]  Epoch:  132	Loss: 1.1690	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:48 [INFO ]  Epoch:  133	Loss: 1.1521	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:05:50 [INFO ]  Epoch:  134	Loss: 1.2139	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:05:51 [INFO ]  Epoch:  135	Loss: 1.2011	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:53 [INFO ]  Epoch:  136	Loss: 1.2584	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:05:55 [INFO ]  Epoch:  137	Loss: 1.1789	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:57 [INFO ]  Epoch:  138	Loss: 1.1586	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:05:59 [INFO ]  Epoch:  139	Loss: 1.1833	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:06:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 07:06:02 [INFO ]  
2022-10-03 07:06:02 [INFO ]  Begin of epoch 140 :
2022-10-03 07:06:05 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:06:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:06:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:06:05 [INFO ]  	   step  1 (lr=0.215470)                   64.04%                   1.2180
2022-10-03 07:06:05 [INFO ]  
2022-10-03 07:06:05 [INFO ]  Epoch:  140	Loss: 1.2002	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:06:07 [INFO ]  Epoch:  141	Loss: 1.2581	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:06:09 [INFO ]  Epoch:  142	Loss: 1.1477	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:11 [INFO ]  Epoch:  143	Loss: 1.1684	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:13 [INFO ]  Epoch:  144	Loss: 1.1419	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:06:14 [INFO ]  Epoch:  145	Loss: 1.2019	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:06:16 [INFO ]  Epoch:  146	Loss: 1.1949	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:06:18 [INFO ]  Epoch:  147	Loss: 1.1674	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:20 [INFO ]  Epoch:  148	Loss: 1.2018	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:06:22 [INFO ]  Epoch:  149	Loss: 1.1819	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:06:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 07:06:25 [INFO ]  
2022-10-03 07:06:25 [INFO ]  Begin of epoch 150 :
2022-10-03 07:06:28 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:06:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:06:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:06:28 [INFO ]  	   step  1 (lr=0.217983)                   64.48%                   1.2146
2022-10-03 07:06:28 [INFO ]  
2022-10-03 07:06:28 [INFO ]  Epoch:  150	Loss: 1.1685	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:06:29 [INFO ]  Epoch:  151	Loss: 1.1794	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:31 [INFO ]  Epoch:  152	Loss: 1.2731	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:06:33 [INFO ]  Epoch:  153	Loss: 1.1833	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:06:35 [INFO ]  Epoch:  154	Loss: 1.1460	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:06:37 [INFO ]  Epoch:  155	Loss: 1.1918	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:39 [INFO ]  Epoch:  156	Loss: 1.2812	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:06:41 [INFO ]  Epoch:  157	Loss: 1.1585	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:42 [INFO ]  Epoch:  158	Loss: 1.2414	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:44 [INFO ]  Epoch:  159	Loss: 1.1841	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 07:06:47 [INFO ]  
2022-10-03 07:06:47 [INFO ]  Begin of epoch 160 :
2022-10-03 07:06:50 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:06:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:06:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:06:50 [INFO ]  	   step  1 (lr=0.217842)                   60.84%                   1.2904
2022-10-03 07:06:50 [INFO ]  
2022-10-03 07:06:50 [INFO ]  Epoch:  160	Loss: 1.2374	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:06:52 [INFO ]  Epoch:  161	Loss: 1.2495	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:06:54 [INFO ]  Epoch:  162	Loss: 1.2005	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:06:55 [INFO ]  Epoch:  163	Loss: 1.1809	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:06:57 [INFO ]  Epoch:  164	Loss: 1.1140	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:06:59 [INFO ]  Epoch:  165	Loss: 1.2453	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:07:01 [INFO ]  Epoch:  166	Loss: 1.0794	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:03 [INFO ]  Epoch:  167	Loss: 1.1682	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:07:05 [INFO ]  Epoch:  168	Loss: 1.2969	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:07 [INFO ]  Epoch:  169	Loss: 1.2415	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:07:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 07:07:10 [INFO ]  
2022-10-03 07:07:10 [INFO ]  Begin of epoch 170 :
2022-10-03 07:07:13 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:07:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:07:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:07:13 [INFO ]  	   step  1 (lr=0.217591)                   63.30%                   1.2535
2022-10-03 07:07:13 [INFO ]  
2022-10-03 07:07:13 [INFO ]  Epoch:  170	Loss: 1.1611	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:14 [INFO ]  Epoch:  171	Loss: 1.1962	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:16 [INFO ]  Epoch:  172	Loss: 1.5430	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:07:18 [INFO ]  Epoch:  173	Loss: 1.2991	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:20 [INFO ]  Epoch:  174	Loss: 1.2379	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:07:22 [INFO ]  Epoch:  175	Loss: 1.2420	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:23 [INFO ]  Epoch:  176	Loss: 1.1865	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:25 [INFO ]  Epoch:  177	Loss: 1.1586	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:27 [INFO ]  Epoch:  178	Loss: 1.2225	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:07:29 [INFO ]  Epoch:  179	Loss: 1.2325	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 07:07:32 [INFO ]  
2022-10-03 07:07:32 [INFO ]  Begin of epoch 180 :
2022-10-03 07:07:35 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:07:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:07:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:07:35 [INFO ]  	   step  1 (lr=0.216651)                   63.21%                   1.2528
2022-10-03 07:07:35 [INFO ]  
2022-10-03 07:07:35 [INFO ]  Epoch:  180	Loss: 1.1819	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:07:37 [INFO ]  Epoch:  181	Loss: 1.2004	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:07:39 [INFO ]  Epoch:  182	Loss: 1.1541	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:41 [INFO ]  Epoch:  183	Loss: 1.1918	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:42 [INFO ]  Epoch:  184	Loss: 1.2075	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:44 [INFO ]  Epoch:  185	Loss: 1.1841	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:46 [INFO ]  Epoch:  186	Loss: 1.1456	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:07:48 [INFO ]  Epoch:  187	Loss: 1.1570	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:07:50 [INFO ]  Epoch:  188	Loss: 1.1345	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:07:52 [INFO ]  Epoch:  189	Loss: 1.2088	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:07:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 07:07:56 [INFO ]  
2022-10-03 07:07:56 [INFO ]  Begin of epoch 190 :
2022-10-03 07:07:59 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:07:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:07:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:07:59 [INFO ]  	   step  1 (lr=0.217031)                   64.07%                   1.2460
2022-10-03 07:07:59 [INFO ]  
2022-10-03 07:07:59 [INFO ]  Epoch:  190	Loss: 1.1990	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:08:00 [INFO ]  Epoch:  191	Loss: 1.2213	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:08:02 [INFO ]  Epoch:  192	Loss: 1.1720	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:08:04 [INFO ]  Epoch:  193	Loss: 1.1267	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:08:06 [INFO ]  Epoch:  194	Loss: 1.1316	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:08:08 [INFO ]  Epoch:  195	Loss: 1.1754	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:08:10 [INFO ]  Epoch:  196	Loss: 1.1413	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:08:12 [INFO ]  Epoch:  197	Loss: 1.1808	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:08:14 [INFO ]  Epoch:  198	Loss: 1.1881	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:08:16 [INFO ]  Epoch:  199	Loss: 1.2090	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:08:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 07:08:19 [INFO ]  
2022-10-03 07:08:19 [INFO ]  Final evaluation for SVHN :
2022-10-03 07:08:22 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:08:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:08:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:08:22 [INFO ]  	   step  1 (lr=0.217589)                   64.89%                   1.2054
2022-10-03 07:08:22 [INFO ]  
2022-10-03 07:08:22 [INFO ]  
2022-10-03 07:08:22 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 07:08:25 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:08:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:08:25 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 07:08:25 [INFO ]  	   step  1 (lr=0.217589)                   20.83%                   5.2287
2022-10-03 07:08:25 [INFO ]  
2022-10-03 07:11:14 [INFO ]  ======================================== 2022-10-03 07:11:14 ========================================
2022-10-03 07:11:14 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:11:14 [INFO ]  Options: 
2022-10-03 07:11:14 [INFO ]  	base_dir: null
2022-10-03 07:11:14 [INFO ]  	batch_size: 1024
2022-10-03 07:11:14 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:11:14 [INFO ]  	dataset: SVHN
2022-10-03 07:11:14 [INFO ]  	dataset_labels:
2022-10-03 07:11:14 [INFO ]  	- 0
2022-10-03 07:11:14 [INFO ]  	- 1
2022-10-03 07:11:14 [INFO ]  	- 2
2022-10-03 07:11:14 [INFO ]  	- 3
2022-10-03 07:11:14 [INFO ]  	- 4
2022-10-03 07:11:14 [INFO ]  	- 5
2022-10-03 07:11:14 [INFO ]  	- 6
2022-10-03 07:11:14 [INFO ]  	- 7
2022-10-03 07:11:14 [INFO ]  	- 8
2022-10-03 07:11:14 [INFO ]  	- 9
2022-10-03 07:11:14 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:11:14 [INFO ]  	- !!python/tuple
2022-10-03 07:11:14 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:11:14 [INFO ]  	    - 0.44398033618927
2022-10-03 07:11:14 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:11:14 [INFO ]  	- !!python/tuple
2022-10-03 07:11:14 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:11:14 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:11:14 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:11:14 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:11:14 [INFO ]  	decay_epochs: 50
2022-10-03 07:11:14 [INFO ]  	decay_factor: 0.1
2022-10-03 07:11:14 [INFO ]  	device_id: 0
2022-10-03 07:11:14 [INFO ]  	distill_epochs: 1
2022-10-03 07:11:14 [INFO ]  	distill_lr: 0.02
2022-10-03 07:11:14 [INFO ]  	distill_steps: 1
2022-10-03 07:11:14 [INFO ]  	epochs: 200
2022-10-03 07:11:14 [INFO ]  	expand_cls: false
2022-10-03 07:11:14 [INFO ]  	forgetting_dataset: null
2022-10-03 07:11:14 [INFO ]  	init: xavier
2022-10-03 07:11:14 [INFO ]  	init_param: 1.0
2022-10-03 07:11:14 [INFO ]  	input_size: 32
2022-10-03 07:11:14 [INFO ]  	ipc: 1
2022-10-03 07:11:14 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:11:14 [INFO ]  	log_interval: 100
2022-10-03 07:11:14 [INFO ]  	log_level: INFO
2022-10-03 07:11:14 [INFO ]  	lr: 0.01
2022-10-03 07:11:14 [INFO ]  	mode: distill_adapt
2022-10-03 07:11:14 [INFO ]  	nc: 3
2022-10-03 07:11:14 [INFO ]  	num_classes: 10
2022-10-03 07:11:14 [INFO ]  	num_workers: 8
2022-10-03 07:11:14 [INFO ]  	phase: train
2022-10-03 07:11:14 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:11:14 [INFO ]  	start_time: '2022-10-03 07:11:14'
2022-10-03 07:11:14 [INFO ]  	test_batch_size: 1024
2022-10-03 07:11:14 [INFO ]  	
2022-10-03 07:11:16 [INFO ]  train dataset size:	73257
2022-10-03 07:11:16 [INFO ]  test dataset size: 	26032
2022-10-03 07:11:16 [INFO ]  datasets built!
2022-10-03 07:11:16 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:11:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:11:19 [INFO ]  
2022-10-03 07:11:19 [INFO ]  Begin of epoch 0 :
2022-10-03 07:11:22 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:11:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:11:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:11:22 [INFO ]  	   step  1 (lr=0.020000)                    6.73%                  12.0900
2022-10-03 07:11:22 [INFO ]  
2022-10-03 07:11:22 [INFO ]  Epoch:    0	Loss: 11.9790	Data Time: 0.46s	Train Time: 0.03s
2022-10-03 07:11:24 [INFO ]  Epoch:    1	Loss: 3.6268	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 07:11:26 [INFO ]  Epoch:    2	Loss: 3.0918	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:11:28 [INFO ]  Epoch:    3	Loss: 2.5145	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:11:29 [INFO ]  Epoch:    4	Loss: 2.3774	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:11:31 [INFO ]  Epoch:    5	Loss: 2.2775	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:11:33 [INFO ]  Epoch:    6	Loss: 2.2104	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:11:35 [INFO ]  Epoch:    7	Loss: 2.2195	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:11:37 [INFO ]  Epoch:    8	Loss: 2.2058	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:11:39 [INFO ]  Epoch:    9	Loss: 2.1962	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:11:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:11:42 [INFO ]  
2022-10-03 07:11:42 [INFO ]  Begin of epoch 10 :
2022-10-03 07:11:45 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:11:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:11:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:11:45 [INFO ]  	   step  1 (lr=0.042065)                   29.05%                   2.1371
2022-10-03 07:11:45 [INFO ]  
2022-10-03 07:11:45 [INFO ]  Epoch:   10	Loss: 2.1415	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:11:47 [INFO ]  Epoch:   11	Loss: 2.1835	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:11:48 [INFO ]  Epoch:   12	Loss: 2.1389	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:11:50 [INFO ]  Epoch:   13	Loss: 2.1556	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:11:52 [INFO ]  Epoch:   14	Loss: 2.0987	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:11:54 [INFO ]  Epoch:   15	Loss: 2.0375	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:11:56 [INFO ]  Epoch:   16	Loss: 2.0352	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:11:58 [INFO ]  Epoch:   17	Loss: 1.9920	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:11:59 [INFO ]  Epoch:   18	Loss: 1.9348	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:02 [INFO ]  Epoch:   19	Loss: 2.0406	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:12:05 [INFO ]  
2022-10-03 07:12:05 [INFO ]  Begin of epoch 20 :
2022-10-03 07:12:08 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:12:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:12:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:12:08 [INFO ]  	   step  1 (lr=0.082623)                   38.58%                   1.8567
2022-10-03 07:12:08 [INFO ]  
2022-10-03 07:12:08 [INFO ]  Epoch:   20	Loss: 1.8271	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:12:09 [INFO ]  Epoch:   21	Loss: 1.8213	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:11 [INFO ]  Epoch:   22	Loss: 1.7800	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:12:13 [INFO ]  Epoch:   23	Loss: 1.6762	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:15 [INFO ]  Epoch:   24	Loss: 1.8528	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:12:17 [INFO ]  Epoch:   25	Loss: 1.6291	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:19 [INFO ]  Epoch:   26	Loss: 1.5500	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:12:21 [INFO ]  Epoch:   27	Loss: 1.5748	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:12:23 [INFO ]  Epoch:   28	Loss: 1.4290	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:12:24 [INFO ]  Epoch:   29	Loss: 1.4143	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:12:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:12:27 [INFO ]  
2022-10-03 07:12:27 [INFO ]  Begin of epoch 30 :
2022-10-03 07:12:31 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:12:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:12:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:12:31 [INFO ]  	   step  1 (lr=0.145493)                   56.80%                   1.3933
2022-10-03 07:12:31 [INFO ]  
2022-10-03 07:12:31 [INFO ]  Epoch:   30	Loss: 1.3415	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:12:32 [INFO ]  Epoch:   31	Loss: 1.5094	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:12:34 [INFO ]  Epoch:   32	Loss: 1.4415	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:12:36 [INFO ]  Epoch:   33	Loss: 1.4308	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:12:38 [INFO ]  Epoch:   34	Loss: 1.7888	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:12:40 [INFO ]  Epoch:   35	Loss: 1.3877	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:12:42 [INFO ]  Epoch:   36	Loss: 1.4082	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:12:43 [INFO ]  Epoch:   37	Loss: 1.4785	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:12:45 [INFO ]  Epoch:   38	Loss: 1.2550	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:12:47 [INFO ]  Epoch:   39	Loss: 1.1810	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:12:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:12:50 [INFO ]  
2022-10-03 07:12:50 [INFO ]  Begin of epoch 40 :
2022-10-03 07:12:53 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:12:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:12:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:12:53 [INFO ]  	   step  1 (lr=0.163373)                   62.86%                   1.2528
2022-10-03 07:12:53 [INFO ]  
2022-10-03 07:12:53 [INFO ]  Epoch:   40	Loss: 1.2494	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:12:55 [INFO ]  Epoch:   41	Loss: 1.2619	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:12:57 [INFO ]  Epoch:   42	Loss: 1.2467	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:12:59 [INFO ]  Epoch:   43	Loss: 1.3396	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:13:01 [INFO ]  Epoch:   44	Loss: 1.2914	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:13:02 [INFO ]  Epoch:   45	Loss: 1.2975	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:13:04 [INFO ]  Epoch:   46	Loss: 1.2295	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:13:06 [INFO ]  Epoch:   47	Loss: 1.1694	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:13:08 [INFO ]  Epoch:   48	Loss: 1.1201	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:13:10 [INFO ]  Epoch:   49	Loss: 1.2531	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:13:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:13:12 [INFO ]  
2022-10-03 07:13:12 [INFO ]  Begin of epoch 50 :
2022-10-03 07:13:16 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:13:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:13:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:13:16 [INFO ]  	   step  1 (lr=0.172358)                   58.94%                   1.3488
2022-10-03 07:13:16 [INFO ]  
2022-10-03 07:13:16 [INFO ]  Epoch:   50	Loss: 1.2219	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:13:17 [INFO ]  Epoch:   51	Loss: 1.4658	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:13:19 [INFO ]  Epoch:   52	Loss: 1.1513	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:21 [INFO ]  Epoch:   53	Loss: 1.1606	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:23 [INFO ]  Epoch:   54	Loss: 1.1126	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:13:25 [INFO ]  Epoch:   55	Loss: 1.3085	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:13:27 [INFO ]  Epoch:   56	Loss: 1.1043	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:13:28 [INFO ]  Epoch:   57	Loss: 1.2125	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:30 [INFO ]  Epoch:   58	Loss: 1.2147	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:13:32 [INFO ]  Epoch:   59	Loss: 1.0920	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:13:35 [INFO ]  
2022-10-03 07:13:35 [INFO ]  Begin of epoch 60 :
2022-10-03 07:13:39 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:13:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:13:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:13:39 [INFO ]  	   step  1 (lr=0.185079)                   65.17%                   1.1778
2022-10-03 07:13:39 [INFO ]  
2022-10-03 07:13:39 [INFO ]  Epoch:   60	Loss: 1.1074	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:13:40 [INFO ]  Epoch:   61	Loss: 1.1072	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:13:42 [INFO ]  Epoch:   62	Loss: 1.1550	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:13:44 [INFO ]  Epoch:   63	Loss: 1.0798	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:13:46 [INFO ]  Epoch:   64	Loss: 1.0912	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:13:47 [INFO ]  Epoch:   65	Loss: 1.1356	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:49 [INFO ]  Epoch:   66	Loss: 1.1052	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:51 [INFO ]  Epoch:   67	Loss: 1.0795	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:13:53 [INFO ]  Epoch:   68	Loss: 1.0386	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:13:55 [INFO ]  Epoch:   69	Loss: 1.0589	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:13:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:13:58 [INFO ]  
2022-10-03 07:13:58 [INFO ]  Begin of epoch 70 :
2022-10-03 07:14:01 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:14:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:14:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:14:01 [INFO ]  	   step  1 (lr=0.191175)                   66.70%                   1.1319
2022-10-03 07:14:01 [INFO ]  
2022-10-03 07:14:01 [INFO ]  Epoch:   70	Loss: 1.1022	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:14:03 [INFO ]  Epoch:   71	Loss: 1.0948	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:14:05 [INFO ]  Epoch:   72	Loss: 1.0897	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:07 [INFO ]  Epoch:   73	Loss: 1.0784	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:14:09 [INFO ]  Epoch:   74	Loss: 1.1229	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:14:11 [INFO ]  Epoch:   75	Loss: 1.0300	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:14:13 [INFO ]  Epoch:   76	Loss: 1.1177	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:14:15 [INFO ]  Epoch:   77	Loss: 1.0401	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:14:16 [INFO ]  Epoch:   78	Loss: 1.0865	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:14:18 [INFO ]  Epoch:   79	Loss: 1.2033	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:14:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:14:21 [INFO ]  
2022-10-03 07:14:21 [INFO ]  Begin of epoch 80 :
2022-10-03 07:14:25 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:14:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:14:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:14:25 [INFO ]  	   step  1 (lr=0.191668)                   61.78%                   1.2679
2022-10-03 07:14:25 [INFO ]  
2022-10-03 07:14:25 [INFO ]  Epoch:   80	Loss: 1.1179	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:26 [INFO ]  Epoch:   81	Loss: 1.2148	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:14:28 [INFO ]  Epoch:   82	Loss: 1.2130	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:14:30 [INFO ]  Epoch:   83	Loss: 1.0158	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:14:32 [INFO ]  Epoch:   84	Loss: 1.1367	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:14:33 [INFO ]  Epoch:   85	Loss: 1.0322	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:35 [INFO ]  Epoch:   86	Loss: 1.1991	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:14:37 [INFO ]  Epoch:   87	Loss: 1.1269	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:14:39 [INFO ]  Epoch:   88	Loss: 1.0649	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:41 [INFO ]  Epoch:   89	Loss: 1.0454	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:14:44 [INFO ]  
2022-10-03 07:14:44 [INFO ]  Begin of epoch 90 :
2022-10-03 07:14:47 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:14:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:14:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:14:47 [INFO ]  	   step  1 (lr=0.194330)                   62.42%                   1.2674
2022-10-03 07:14:47 [INFO ]  
2022-10-03 07:14:47 [INFO ]  Epoch:   90	Loss: 1.2867	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:14:49 [INFO ]  Epoch:   91	Loss: 1.1095	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:51 [INFO ]  Epoch:   92	Loss: 1.0897	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:14:53 [INFO ]  Epoch:   93	Loss: 1.0040	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:14:55 [INFO ]  Epoch:   94	Loss: 1.0309	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:14:56 [INFO ]  Epoch:   95	Loss: 1.0738	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:14:58 [INFO ]  Epoch:   96	Loss: 1.0181	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:15:00 [INFO ]  Epoch:   97	Loss: 0.9173	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:15:02 [INFO ]  Epoch:   98	Loss: 1.0278	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:15:04 [INFO ]  Epoch:   99	Loss: 0.9743	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:15:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:15:07 [INFO ]  
2022-10-03 07:15:07 [INFO ]  Begin of epoch 100 :
2022-10-03 07:15:10 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:15:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:15:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:15:10 [INFO ]  	   step  1 (lr=0.200154)                   69.33%                   1.0639
2022-10-03 07:15:10 [INFO ]  
2022-10-03 07:15:10 [INFO ]  Epoch:  100	Loss: 0.9955	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:15:12 [INFO ]  Epoch:  101	Loss: 0.9644	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:15:14 [INFO ]  Epoch:  102	Loss: 1.0607	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:15:15 [INFO ]  Epoch:  103	Loss: 1.0110	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:15:17 [INFO ]  Epoch:  104	Loss: 1.0187	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:15:19 [INFO ]  Epoch:  105	Loss: 1.0410	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:15:21 [INFO ]  Epoch:  106	Loss: 1.0303	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:15:22 [INFO ]  Epoch:  107	Loss: 1.0559	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:15:24 [INFO ]  Epoch:  108	Loss: 1.0459	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:15:26 [INFO ]  Epoch:  109	Loss: 0.9775	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:15:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:15:29 [INFO ]  
2022-10-03 07:15:29 [INFO ]  Begin of epoch 110 :
2022-10-03 07:15:33 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:15:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:15:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:15:33 [INFO ]  	   step  1 (lr=0.201691)                   66.66%                   1.1290
2022-10-03 07:15:33 [INFO ]  
2022-10-03 07:15:33 [INFO ]  Epoch:  110	Loss: 1.1025	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 07:15:34 [INFO ]  Epoch:  111	Loss: 1.0447	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:15:36 [INFO ]  Epoch:  112	Loss: 1.0396	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:15:38 [INFO ]  Epoch:  113	Loss: 0.9871	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:15:40 [INFO ]  Epoch:  114	Loss: 0.9863	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:15:42 [INFO ]  Epoch:  115	Loss: 0.9757	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:15:44 [INFO ]  Epoch:  116	Loss: 1.0298	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:15:46 [INFO ]  Epoch:  117	Loss: 1.0522	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:15:48 [INFO ]  Epoch:  118	Loss: 1.0787	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:15:50 [INFO ]  Epoch:  119	Loss: 1.0090	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:15:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:15:53 [INFO ]  
2022-10-03 07:15:53 [INFO ]  Begin of epoch 120 :
2022-10-03 07:15:56 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:15:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:15:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:15:56 [INFO ]  	   step  1 (lr=0.204359)                   68.13%                   1.0822
2022-10-03 07:15:56 [INFO ]  
2022-10-03 07:15:56 [INFO ]  Epoch:  120	Loss: 1.0679	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:15:58 [INFO ]  Epoch:  121	Loss: 1.1454	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:16:00 [INFO ]  Epoch:  122	Loss: 0.9685	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:02 [INFO ]  Epoch:  123	Loss: 1.0599	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:03 [INFO ]  Epoch:  124	Loss: 1.0494	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:16:05 [INFO ]  Epoch:  125	Loss: 1.0100	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:16:07 [INFO ]  Epoch:  126	Loss: 1.0396	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:16:09 [INFO ]  Epoch:  127	Loss: 1.0101	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:16:11 [INFO ]  Epoch:  128	Loss: 0.9962	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:16:13 [INFO ]  Epoch:  129	Loss: 0.9974	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:16:16 [INFO ]  
2022-10-03 07:16:16 [INFO ]  Begin of epoch 130 :
2022-10-03 07:16:19 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:16:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:16:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:16:19 [INFO ]  	   step  1 (lr=0.208839)                   68.97%                   1.0596
2022-10-03 07:16:19 [INFO ]  
2022-10-03 07:16:19 [INFO ]  Epoch:  130	Loss: 1.0752	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:16:20 [INFO ]  Epoch:  131	Loss: 1.0493	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:16:22 [INFO ]  Epoch:  132	Loss: 1.0126	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:16:24 [INFO ]  Epoch:  133	Loss: 1.0557	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:26 [INFO ]  Epoch:  134	Loss: 1.1149	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:28 [INFO ]  Epoch:  135	Loss: 1.0635	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:16:30 [INFO ]  Epoch:  136	Loss: 1.0227	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:16:32 [INFO ]  Epoch:  137	Loss: 0.9903	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:16:34 [INFO ]  Epoch:  138	Loss: 0.9643	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:16:36 [INFO ]  Epoch:  139	Loss: 0.9548	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 07:16:39 [INFO ]  
2022-10-03 07:16:39 [INFO ]  Begin of epoch 140 :
2022-10-03 07:16:42 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:16:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:16:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:16:42 [INFO ]  	   step  1 (lr=0.211124)                   69.14%                   1.0602
2022-10-03 07:16:42 [INFO ]  
2022-10-03 07:16:42 [INFO ]  Epoch:  140	Loss: 0.9566	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:16:44 [INFO ]  Epoch:  141	Loss: 0.9681	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:45 [INFO ]  Epoch:  142	Loss: 1.0287	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:47 [INFO ]  Epoch:  143	Loss: 1.0627	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:16:49 [INFO ]  Epoch:  144	Loss: 1.0104	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:16:51 [INFO ]  Epoch:  145	Loss: 1.0327	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:16:53 [INFO ]  Epoch:  146	Loss: 0.9577	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:16:55 [INFO ]  Epoch:  147	Loss: 1.0143	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:16:57 [INFO ]  Epoch:  148	Loss: 1.1639	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:16:58 [INFO ]  Epoch:  149	Loss: 1.0208	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 07:17:01 [INFO ]  
2022-10-03 07:17:01 [INFO ]  Begin of epoch 150 :
2022-10-03 07:17:05 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:17:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:17:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:17:05 [INFO ]  	   step  1 (lr=0.212357)                   69.40%                   1.0514
2022-10-03 07:17:05 [INFO ]  
2022-10-03 07:17:05 [INFO ]  Epoch:  150	Loss: 0.9816	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:17:06 [INFO ]  Epoch:  151	Loss: 1.0337	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:08 [INFO ]  Epoch:  152	Loss: 1.0115	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:17:10 [INFO ]  Epoch:  153	Loss: 1.0206	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:12 [INFO ]  Epoch:  154	Loss: 1.0627	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:14 [INFO ]  Epoch:  155	Loss: 0.9752	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:16 [INFO ]  Epoch:  156	Loss: 0.9470	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:17:18 [INFO ]  Epoch:  157	Loss: 1.0378	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:20 [INFO ]  Epoch:  158	Loss: 1.0053	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:17:22 [INFO ]  Epoch:  159	Loss: 1.0606	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 07:17:24 [INFO ]  
2022-10-03 07:17:24 [INFO ]  Begin of epoch 160 :
2022-10-03 07:17:28 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:17:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:17:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:17:28 [INFO ]  	   step  1 (lr=0.212747)                   68.66%                   1.0760
2022-10-03 07:17:28 [INFO ]  
2022-10-03 07:17:28 [INFO ]  Epoch:  160	Loss: 1.1012	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:17:29 [INFO ]  Epoch:  161	Loss: 1.0864	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:31 [INFO ]  Epoch:  162	Loss: 0.9613	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:33 [INFO ]  Epoch:  163	Loss: 1.0142	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:35 [INFO ]  Epoch:  164	Loss: 1.0132	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:37 [INFO ]  Epoch:  165	Loss: 1.0326	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:39 [INFO ]  Epoch:  166	Loss: 1.0298	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:17:41 [INFO ]  Epoch:  167	Loss: 0.9994	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:17:43 [INFO ]  Epoch:  168	Loss: 0.9465	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:17:44 [INFO ]  Epoch:  169	Loss: 1.0099	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:17:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 07:17:47 [INFO ]  
2022-10-03 07:17:47 [INFO ]  Begin of epoch 170 :
2022-10-03 07:17:50 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:17:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:17:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:17:50 [INFO ]  	   step  1 (lr=0.212644)                   70.03%                   1.0346
2022-10-03 07:17:50 [INFO ]  
2022-10-03 07:17:50 [INFO ]  Epoch:  170	Loss: 1.0380	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:17:52 [INFO ]  Epoch:  171	Loss: 1.1350	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:54 [INFO ]  Epoch:  172	Loss: 1.0100	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:17:56 [INFO ]  Epoch:  173	Loss: 1.0296	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:17:58 [INFO ]  Epoch:  174	Loss: 0.9777	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:18:00 [INFO ]  Epoch:  175	Loss: 0.9883	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:01 [INFO ]  Epoch:  176	Loss: 1.0010	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:03 [INFO ]  Epoch:  177	Loss: 0.9781	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:18:05 [INFO ]  Epoch:  178	Loss: 0.9484	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:07 [INFO ]  Epoch:  179	Loss: 0.9834	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 07:18:10 [INFO ]  
2022-10-03 07:18:10 [INFO ]  Begin of epoch 180 :
2022-10-03 07:18:13 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:18:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:18:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:18:13 [INFO ]  	   step  1 (lr=0.212753)                   70.08%                   1.0376
2022-10-03 07:18:13 [INFO ]  
2022-10-03 07:18:13 [INFO ]  Epoch:  180	Loss: 0.9642	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:15 [INFO ]  Epoch:  181	Loss: 1.0259	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:18:17 [INFO ]  Epoch:  182	Loss: 1.0303	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:18:19 [INFO ]  Epoch:  183	Loss: 0.9873	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:18:20 [INFO ]  Epoch:  184	Loss: 0.9918	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:22 [INFO ]  Epoch:  185	Loss: 1.0622	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:18:24 [INFO ]  Epoch:  186	Loss: 0.9897	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:26 [INFO ]  Epoch:  187	Loss: 1.0566	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:18:28 [INFO ]  Epoch:  188	Loss: 0.9405	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:18:30 [INFO ]  Epoch:  189	Loss: 0.9662	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:18:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 07:18:33 [INFO ]  
2022-10-03 07:18:33 [INFO ]  Begin of epoch 190 :
2022-10-03 07:18:36 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:18:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:18:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:18:36 [INFO ]  	   step  1 (lr=0.213068)                   68.38%                   1.0748
2022-10-03 07:18:36 [INFO ]  
2022-10-03 07:18:36 [INFO ]  Epoch:  190	Loss: 1.0163	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:18:38 [INFO ]  Epoch:  191	Loss: 1.0523	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:18:40 [INFO ]  Epoch:  192	Loss: 0.9863	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:18:42 [INFO ]  Epoch:  193	Loss: 1.0464	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:18:44 [INFO ]  Epoch:  194	Loss: 0.9418	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:46 [INFO ]  Epoch:  195	Loss: 1.0658	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:48 [INFO ]  Epoch:  196	Loss: 0.9229	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:49 [INFO ]  Epoch:  197	Loss: 1.0082	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:18:51 [INFO ]  Epoch:  198	Loss: 1.0256	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:53 [INFO ]  Epoch:  199	Loss: 1.0457	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:18:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 07:18:55 [INFO ]  
2022-10-03 07:18:55 [INFO ]  Final evaluation for SVHN :
2022-10-03 07:18:59 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:18:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:18:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:18:59 [INFO ]  	   step  1 (lr=0.213209)                   69.05%                   1.0548
2022-10-03 07:18:59 [INFO ]  
2022-10-03 07:18:59 [INFO ]  
2022-10-03 07:18:59 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 07:19:02 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:19:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:19:02 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 07:19:02 [INFO ]  	   step  1 (lr=0.213209)                   20.13%                   4.7690
2022-10-03 07:19:02 [INFO ]  
2022-10-03 07:23:09 [INFO ]  ======================================== 2022-10-03 07:23:09 ========================================
2022-10-03 07:23:09 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:23:09 [INFO ]  Options: 
2022-10-03 07:23:09 [INFO ]  	base_dir: null
2022-10-03 07:23:09 [INFO ]  	batch_size: 1024
2022-10-03 07:23:09 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:23:09 [INFO ]  	dataset: SVHN
2022-10-03 07:23:09 [INFO ]  	dataset_labels:
2022-10-03 07:23:09 [INFO ]  	- 0
2022-10-03 07:23:09 [INFO ]  	- 1
2022-10-03 07:23:09 [INFO ]  	- 2
2022-10-03 07:23:09 [INFO ]  	- 3
2022-10-03 07:23:09 [INFO ]  	- 4
2022-10-03 07:23:09 [INFO ]  	- 5
2022-10-03 07:23:09 [INFO ]  	- 6
2022-10-03 07:23:09 [INFO ]  	- 7
2022-10-03 07:23:09 [INFO ]  	- 8
2022-10-03 07:23:09 [INFO ]  	- 9
2022-10-03 07:23:09 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:23:09 [INFO ]  	- !!python/tuple
2022-10-03 07:23:09 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:23:09 [INFO ]  	    - 0.44398033618927
2022-10-03 07:23:09 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:23:09 [INFO ]  	- !!python/tuple
2022-10-03 07:23:09 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:23:09 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:23:09 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:23:09 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:23:09 [INFO ]  	decay_epochs: 50
2022-10-03 07:23:09 [INFO ]  	decay_factor: 0.1
2022-10-03 07:23:09 [INFO ]  	device_id: 0
2022-10-03 07:23:09 [INFO ]  	distill_epochs: 1
2022-10-03 07:23:09 [INFO ]  	distill_lr: 0.02
2022-10-03 07:23:09 [INFO ]  	distill_steps: 1
2022-10-03 07:23:09 [INFO ]  	epochs: 200
2022-10-03 07:23:09 [INFO ]  	expand_cls: false
2022-10-03 07:23:09 [INFO ]  	forgetting_dataset: null
2022-10-03 07:23:09 [INFO ]  	init: xavier
2022-10-03 07:23:09 [INFO ]  	init_param: 1.0
2022-10-03 07:23:09 [INFO ]  	input_size: 32
2022-10-03 07:23:09 [INFO ]  	ipc: 1
2022-10-03 07:23:09 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:23:09 [INFO ]  	log_interval: 100
2022-10-03 07:23:09 [INFO ]  	log_level: INFO
2022-10-03 07:23:09 [INFO ]  	lr: 0.01
2022-10-03 07:23:09 [INFO ]  	mode: distill_adapt
2022-10-03 07:23:09 [INFO ]  	nc: 3
2022-10-03 07:23:09 [INFO ]  	num_classes: 10
2022-10-03 07:23:09 [INFO ]  	num_workers: 8
2022-10-03 07:23:09 [INFO ]  	phase: train
2022-10-03 07:23:09 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:23:09 [INFO ]  	start_time: '2022-10-03 07:23:09'
2022-10-03 07:23:09 [INFO ]  	test_batch_size: 1024
2022-10-03 07:23:09 [INFO ]  	
2022-10-03 07:23:11 [INFO ]  train dataset size:	73257
2022-10-03 07:23:11 [INFO ]  test dataset size: 	26032
2022-10-03 07:23:11 [INFO ]  datasets built!
2022-10-03 07:23:11 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:23:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:23:14 [INFO ]  
2022-10-03 07:23:14 [INFO ]  Begin of epoch 0 :
2022-10-03 07:23:17 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:23:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:23:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:23:17 [INFO ]  	   step  1 (lr=0.020000)                    7.93%                   8.0070
2022-10-03 07:23:17 [INFO ]  
2022-10-03 07:23:17 [INFO ]  Epoch:    0	Loss: 7.3064	Data Time: 0.35s	Train Time: 0.03s
2022-10-03 07:23:19 [INFO ]  Epoch:    1	Loss: 3.3229	Data Time: 0.13s	Train Time: 0.01s
2022-10-03 07:23:21 [INFO ]  Epoch:    2	Loss: 2.6993	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:23:22 [INFO ]  Epoch:    3	Loss: 2.4212	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:24 [INFO ]  Epoch:    4	Loss: 2.3585	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:23:26 [INFO ]  Epoch:    5	Loss: 2.2517	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:23:28 [INFO ]  Epoch:    6	Loss: 2.2032	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:30 [INFO ]  Epoch:    7	Loss: 2.1814	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:32 [INFO ]  Epoch:    8	Loss: 2.1745	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:33 [INFO ]  Epoch:    9	Loss: 2.1520	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:23:36 [INFO ]  
2022-10-03 07:23:36 [INFO ]  Begin of epoch 10 :
2022-10-03 07:23:40 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:23:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:23:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:23:40 [INFO ]  	   step  1 (lr=0.056030)                   31.60%                   2.1217
2022-10-03 07:23:40 [INFO ]  
2022-10-03 07:23:40 [INFO ]  Epoch:   10	Loss: 2.0990	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:23:41 [INFO ]  Epoch:   11	Loss: 2.1184	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:43 [INFO ]  Epoch:   12	Loss: 2.0284	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:23:45 [INFO ]  Epoch:   13	Loss: 1.9754	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:23:47 [INFO ]  Epoch:   14	Loss: 1.8507	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:23:49 [INFO ]  Epoch:   15	Loss: 2.0196	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:23:50 [INFO ]  Epoch:   16	Loss: 1.7943	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:23:52 [INFO ]  Epoch:   17	Loss: 1.8004	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:23:54 [INFO ]  Epoch:   18	Loss: 1.6629	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:23:56 [INFO ]  Epoch:   19	Loss: 1.5970	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:23:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:23:59 [INFO ]  
2022-10-03 07:23:59 [INFO ]  Begin of epoch 20 :
2022-10-03 07:24:02 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:24:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:24:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:24:02 [INFO ]  	   step  1 (lr=0.134456)                   33.25%                   1.8941
2022-10-03 07:24:02 [INFO ]  
2022-10-03 07:24:02 [INFO ]  Epoch:   20	Loss: 1.7472	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 07:24:04 [INFO ]  Epoch:   21	Loss: 1.5133	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:06 [INFO ]  Epoch:   22	Loss: 1.8321	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:24:08 [INFO ]  Epoch:   23	Loss: 1.5003	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:09 [INFO ]  Epoch:   24	Loss: 1.4013	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:24:11 [INFO ]  Epoch:   25	Loss: 1.5101	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:24:13 [INFO ]  Epoch:   26	Loss: 1.4792	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:24:15 [INFO ]  Epoch:   27	Loss: 1.4173	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:17 [INFO ]  Epoch:   28	Loss: 1.4416	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:19 [INFO ]  Epoch:   29	Loss: 1.3782	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:24:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:24:22 [INFO ]  
2022-10-03 07:24:22 [INFO ]  Begin of epoch 30 :
2022-10-03 07:24:25 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:24:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:24:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:24:25 [INFO ]  	   step  1 (lr=0.189430)                   57.23%                   1.3793
2022-10-03 07:24:25 [INFO ]  
2022-10-03 07:24:25 [INFO ]  Epoch:   30	Loss: 1.2954	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:24:26 [INFO ]  Epoch:   31	Loss: 1.3922	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:24:28 [INFO ]  Epoch:   32	Loss: 1.3258	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:24:30 [INFO ]  Epoch:   33	Loss: 1.2122	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:24:32 [INFO ]  Epoch:   34	Loss: 1.2380	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:34 [INFO ]  Epoch:   35	Loss: 1.2150	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:35 [INFO ]  Epoch:   36	Loss: 1.3866	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:24:37 [INFO ]  Epoch:   37	Loss: 1.5461	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:39 [INFO ]  Epoch:   38	Loss: 1.3039	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:41 [INFO ]  Epoch:   39	Loss: 1.4093	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:24:44 [INFO ]  
2022-10-03 07:24:44 [INFO ]  Begin of epoch 40 :
2022-10-03 07:24:47 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:24:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:24:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:24:47 [INFO ]  	   step  1 (lr=0.191136)                   51.01%                   1.7012
2022-10-03 07:24:47 [INFO ]  
2022-10-03 07:24:47 [INFO ]  Epoch:   40	Loss: 1.6351	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:24:49 [INFO ]  Epoch:   41	Loss: 1.4726	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:24:51 [INFO ]  Epoch:   42	Loss: 1.4277	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:24:53 [INFO ]  Epoch:   43	Loss: 1.2691	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:55 [INFO ]  Epoch:   44	Loss: 1.3071	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:24:57 [INFO ]  Epoch:   45	Loss: 1.1688	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:24:58 [INFO ]  Epoch:   46	Loss: 1.3042	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:25:00 [INFO ]  Epoch:   47	Loss: 1.3651	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:25:02 [INFO ]  Epoch:   48	Loss: 1.2762	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:25:04 [INFO ]  Epoch:   49	Loss: 1.3066	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:25:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:25:07 [INFO ]  
2022-10-03 07:25:07 [INFO ]  Begin of epoch 50 :
2022-10-03 07:25:10 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:25:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:25:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:25:10 [INFO ]  	   step  1 (lr=0.189189)                   58.57%                   1.3458
2022-10-03 07:25:10 [INFO ]  
2022-10-03 07:25:10 [INFO ]  Epoch:   50	Loss: 1.3254	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:25:12 [INFO ]  Epoch:   51	Loss: 1.3478	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:25:13 [INFO ]  Epoch:   52	Loss: 1.2702	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:25:16 [INFO ]  Epoch:   53	Loss: 1.2880	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:25:17 [INFO ]  Epoch:   54	Loss: 1.2953	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:25:19 [INFO ]  Epoch:   55	Loss: 1.2241	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:25:21 [INFO ]  Epoch:   56	Loss: 1.2007	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:25:23 [INFO ]  Epoch:   57	Loss: 1.2393	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:25:25 [INFO ]  Epoch:   58	Loss: 1.2537	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:25:27 [INFO ]  Epoch:   59	Loss: 1.3242	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:25:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:25:30 [INFO ]  
2022-10-03 07:25:30 [INFO ]  Begin of epoch 60 :
2022-10-03 07:25:33 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:25:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:25:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:25:33 [INFO ]  	   step  1 (lr=0.192451)                   63.08%                   1.2257
2022-10-03 07:25:33 [INFO ]  
2022-10-03 07:25:33 [INFO ]  Epoch:   60	Loss: 1.1959	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:25:35 [INFO ]  Epoch:   61	Loss: 1.1655	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:25:37 [INFO ]  Epoch:   62	Loss: 1.2897	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:25:38 [INFO ]  Epoch:   63	Loss: 1.3615	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:25:40 [INFO ]  Epoch:   64	Loss: 1.1827	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:25:42 [INFO ]  Epoch:   65	Loss: 1.2108	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:25:44 [INFO ]  Epoch:   66	Loss: 1.3455	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:25:46 [INFO ]  Epoch:   67	Loss: 1.2972	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:25:48 [INFO ]  Epoch:   68	Loss: 1.2743	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:25:49 [INFO ]  Epoch:   69	Loss: 1.2498	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:25:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:25:52 [INFO ]  
2022-10-03 07:25:52 [INFO ]  Begin of epoch 70 :
2022-10-03 07:25:56 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:25:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:25:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:25:56 [INFO ]  	   step  1 (lr=0.184777)                   61.88%                   1.2346
2022-10-03 07:25:56 [INFO ]  
2022-10-03 07:25:56 [INFO ]  Epoch:   70	Loss: 1.2515	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:25:57 [INFO ]  Epoch:   71	Loss: 1.2036	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:25:59 [INFO ]  Epoch:   72	Loss: 1.1808	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:01 [INFO ]  Epoch:   73	Loss: 1.1846	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:03 [INFO ]  Epoch:   74	Loss: 1.2284	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:26:05 [INFO ]  Epoch:   75	Loss: 1.1598	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:26:07 [INFO ]  Epoch:   76	Loss: 1.1923	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:09 [INFO ]  Epoch:   77	Loss: 1.1340	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:11 [INFO ]  Epoch:   78	Loss: 1.1249	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:13 [INFO ]  Epoch:   79	Loss: 2.1972	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:26:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:26:16 [INFO ]  
2022-10-03 07:26:16 [INFO ]  Begin of epoch 80 :
2022-10-03 07:26:19 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:26:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:26:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:26:19 [INFO ]  	   step  1 (lr=0.208726)                   62.51%                   1.2411
2022-10-03 07:26:19 [INFO ]  
2022-10-03 07:26:19 [INFO ]  Epoch:   80	Loss: 1.2092	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:21 [INFO ]  Epoch:   81	Loss: 1.1594	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:26:23 [INFO ]  Epoch:   82	Loss: 1.2813	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:26:25 [INFO ]  Epoch:   83	Loss: 1.2093	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:27 [INFO ]  Epoch:   84	Loss: 1.1217	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:26:29 [INFO ]  Epoch:   85	Loss: 1.1834	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:26:30 [INFO ]  Epoch:   86	Loss: 1.0779	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:32 [INFO ]  Epoch:   87	Loss: 1.1424	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:34 [INFO ]  Epoch:   88	Loss: 1.0817	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:26:36 [INFO ]  Epoch:   89	Loss: 1.1898	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:26:39 [INFO ]  
2022-10-03 07:26:39 [INFO ]  Begin of epoch 90 :
2022-10-03 07:26:42 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:26:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:26:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:26:42 [INFO ]  	   step  1 (lr=0.213081)                   64.71%                   1.1728
2022-10-03 07:26:42 [INFO ]  
2022-10-03 07:26:42 [INFO ]  Epoch:   90	Loss: 1.0606	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:26:44 [INFO ]  Epoch:   91	Loss: 1.2101	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:26:46 [INFO ]  Epoch:   92	Loss: 1.0791	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:26:48 [INFO ]  Epoch:   93	Loss: 1.1348	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:26:50 [INFO ]  Epoch:   94	Loss: 1.1101	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:51 [INFO ]  Epoch:   95	Loss: 1.1572	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:26:53 [INFO ]  Epoch:   96	Loss: 1.0880	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:26:55 [INFO ]  Epoch:   97	Loss: 1.2200	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:57 [INFO ]  Epoch:   98	Loss: 1.2580	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:26:59 [INFO ]  Epoch:   99	Loss: 1.2938	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:27:02 [INFO ]  
2022-10-03 07:27:02 [INFO ]  Begin of epoch 100 :
2022-10-03 07:27:05 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:27:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:27:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:27:05 [INFO ]  	   step  1 (lr=0.222804)                   65.41%                   1.1659
2022-10-03 07:27:05 [INFO ]  
2022-10-03 07:27:05 [INFO ]  Epoch:  100	Loss: 1.0717	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 07:27:07 [INFO ]  Epoch:  101	Loss: 1.1487	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:27:08 [INFO ]  Epoch:  102	Loss: 1.1378	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:10 [INFO ]  Epoch:  103	Loss: 1.0410	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:27:12 [INFO ]  Epoch:  104	Loss: 1.1826	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:27:14 [INFO ]  Epoch:  105	Loss: 1.0964	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:16 [INFO ]  Epoch:  106	Loss: 1.4374	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:27:18 [INFO ]  Epoch:  107	Loss: 1.2575	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:27:20 [INFO ]  Epoch:  108	Loss: 1.2404	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:27:22 [INFO ]  Epoch:  109	Loss: 1.6684	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:27:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:27:25 [INFO ]  
2022-10-03 07:27:25 [INFO ]  Begin of epoch 110 :
2022-10-03 07:27:28 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:27:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:27:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:27:28 [INFO ]  	   step  1 (lr=0.215618)                   58.82%                   1.3771
2022-10-03 07:27:28 [INFO ]  
2022-10-03 07:27:28 [INFO ]  Epoch:  110	Loss: 1.3373	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 07:27:30 [INFO ]  Epoch:  111	Loss: 1.3755	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:27:32 [INFO ]  Epoch:  112	Loss: 1.1507	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:27:34 [INFO ]  Epoch:  113	Loss: 1.2060	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:27:36 [INFO ]  Epoch:  114	Loss: 1.2233	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:38 [INFO ]  Epoch:  115	Loss: 1.2239	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:27:40 [INFO ]  Epoch:  116	Loss: 1.1840	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:27:42 [INFO ]  Epoch:  117	Loss: 1.1665	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:44 [INFO ]  Epoch:  118	Loss: 1.1546	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:46 [INFO ]  Epoch:  119	Loss: 1.1996	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:27:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:27:49 [INFO ]  
2022-10-03 07:27:49 [INFO ]  Begin of epoch 120 :
2022-10-03 07:27:52 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:27:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:27:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:27:52 [INFO ]  	   step  1 (lr=0.216638)                   62.68%                   1.2304
2022-10-03 07:27:52 [INFO ]  
2022-10-03 07:27:52 [INFO ]  Epoch:  120	Loss: 1.1838	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:27:54 [INFO ]  Epoch:  121	Loss: 1.1268	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:56 [INFO ]  Epoch:  122	Loss: 1.1726	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:27:58 [INFO ]  Epoch:  123	Loss: 1.2199	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:27:59 [INFO ]  Epoch:  124	Loss: 1.2224	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:01 [INFO ]  Epoch:  125	Loss: 1.1797	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:03 [INFO ]  Epoch:  126	Loss: 1.2276	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:05 [INFO ]  Epoch:  127	Loss: 1.7686	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:28:07 [INFO ]  Epoch:  128	Loss: 1.2776	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:28:09 [INFO ]  Epoch:  129	Loss: 1.2054	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:28:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:28:12 [INFO ]  
2022-10-03 07:28:12 [INFO ]  Begin of epoch 130 :
2022-10-03 07:28:15 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:28:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:28:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:28:15 [INFO ]  	   step  1 (lr=0.215518)                   63.34%                   1.2144
2022-10-03 07:28:15 [INFO ]  
2022-10-03 07:28:15 [INFO ]  Epoch:  130	Loss: 1.0729	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:28:17 [INFO ]  Epoch:  131	Loss: 1.1605	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:28:19 [INFO ]  Epoch:  132	Loss: 1.0976	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:28:21 [INFO ]  Epoch:  133	Loss: 1.2012	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:28:22 [INFO ]  Epoch:  134	Loss: 1.1849	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:28:24 [INFO ]  Epoch:  135	Loss: 1.1243	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:26 [INFO ]  Epoch:  136	Loss: 1.1090	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:28 [INFO ]  Epoch:  137	Loss: 1.1436	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:30 [INFO ]  Epoch:  138	Loss: 1.0679	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:31 [INFO ]  Epoch:  139	Loss: 1.1458	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:28:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 07:28:34 [INFO ]  
2022-10-03 07:28:34 [INFO ]  Begin of epoch 140 :
2022-10-03 07:28:38 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:28:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:28:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:28:38 [INFO ]  	   step  1 (lr=0.219593)                   65.17%                   1.1750
2022-10-03 07:28:38 [INFO ]  
2022-10-03 07:28:38 [INFO ]  Epoch:  140	Loss: 1.0550	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:28:39 [INFO ]  Epoch:  141	Loss: 1.9933	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:28:41 [INFO ]  Epoch:  142	Loss: 1.1489	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:28:43 [INFO ]  Epoch:  143	Loss: 1.1182	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:28:45 [INFO ]  Epoch:  144	Loss: 1.1990	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:28:46 [INFO ]  Epoch:  145	Loss: 1.2558	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:28:49 [INFO ]  Epoch:  146	Loss: 1.1781	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:28:50 [INFO ]  Epoch:  147	Loss: 1.1902	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 07:28:52 [INFO ]  Epoch:  148	Loss: 1.1252	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:28:54 [INFO ]  Epoch:  149	Loss: 1.2048	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:28:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 07:28:57 [INFO ]  
2022-10-03 07:28:57 [INFO ]  Begin of epoch 150 :
2022-10-03 07:29:00 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:29:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:29:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:29:00 [INFO ]  	   step  1 (lr=0.214794)                   62.93%                   1.2226
2022-10-03 07:29:00 [INFO ]  
2022-10-03 07:29:00 [INFO ]  Epoch:  150	Loss: 1.1382	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:29:02 [INFO ]  Epoch:  151	Loss: 1.1485	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:04 [INFO ]  Epoch:  152	Loss: 1.1800	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:29:05 [INFO ]  Epoch:  153	Loss: 1.7849	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:29:07 [INFO ]  Epoch:  154	Loss: 1.1604	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:29:09 [INFO ]  Epoch:  155	Loss: 1.1917	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:29:11 [INFO ]  Epoch:  156	Loss: 1.1949	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:29:13 [INFO ]  Epoch:  157	Loss: 1.1144	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:29:15 [INFO ]  Epoch:  158	Loss: 1.9312	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:17 [INFO ]  Epoch:  159	Loss: 1.1473	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:29:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 07:29:20 [INFO ]  
2022-10-03 07:29:20 [INFO ]  Begin of epoch 160 :
2022-10-03 07:29:23 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:29:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:29:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:29:23 [INFO ]  	   step  1 (lr=0.214485)                   62.95%                   1.2282
2022-10-03 07:29:23 [INFO ]  
2022-10-03 07:29:23 [INFO ]  Epoch:  160	Loss: 1.1901	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:25 [INFO ]  Epoch:  161	Loss: 1.1885	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:27 [INFO ]  Epoch:  162	Loss: 1.8491	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:29:28 [INFO ]  Epoch:  163	Loss: 1.1633	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:30 [INFO ]  Epoch:  164	Loss: 1.1839	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:29:32 [INFO ]  Epoch:  165	Loss: 1.1373	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:29:34 [INFO ]  Epoch:  166	Loss: 1.1702	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:29:36 [INFO ]  Epoch:  167	Loss: 1.1426	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:29:38 [INFO ]  Epoch:  168	Loss: 1.1284	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 07:29:39 [INFO ]  Epoch:  169	Loss: 1.1661	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:29:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 07:29:42 [INFO ]  
2022-10-03 07:29:42 [INFO ]  Begin of epoch 170 :
2022-10-03 07:29:46 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:29:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:29:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:29:46 [INFO ]  	   step  1 (lr=0.214356)                   63.20%                   1.2139
2022-10-03 07:29:46 [INFO ]  
2022-10-03 07:29:46 [INFO ]  Epoch:  170	Loss: 1.1317	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:29:47 [INFO ]  Epoch:  171	Loss: 1.1681	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:29:49 [INFO ]  Epoch:  172	Loss: 1.2012	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:29:51 [INFO ]  Epoch:  173	Loss: 1.0988	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:29:53 [INFO ]  Epoch:  174	Loss: 1.1279	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:55 [INFO ]  Epoch:  175	Loss: 1.2029	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:29:57 [INFO ]  Epoch:  176	Loss: 1.2604	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:29:59 [INFO ]  Epoch:  177	Loss: 1.1222	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:01 [INFO ]  Epoch:  178	Loss: 1.6696	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:30:02 [INFO ]  Epoch:  179	Loss: 1.2016	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:30:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 07:30:06 [INFO ]  
2022-10-03 07:30:06 [INFO ]  Begin of epoch 180 :
2022-10-03 07:30:09 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:30:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:30:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:30:09 [INFO ]  	   step  1 (lr=0.213959)                   48.02%                   1.6922
2022-10-03 07:30:09 [INFO ]  
2022-10-03 07:30:09 [INFO ]  Epoch:  180	Loss: 1.6904	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:30:10 [INFO ]  Epoch:  181	Loss: 1.2534	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:12 [INFO ]  Epoch:  182	Loss: 1.1845	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:14 [INFO ]  Epoch:  183	Loss: 1.4700	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:30:16 [INFO ]  Epoch:  184	Loss: 1.4525	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:30:18 [INFO ]  Epoch:  185	Loss: 1.5464	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:20 [INFO ]  Epoch:  186	Loss: 1.3048	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:22 [INFO ]  Epoch:  187	Loss: 1.3068	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:24 [INFO ]  Epoch:  188	Loss: 1.4477	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:26 [INFO ]  Epoch:  189	Loss: 1.4688	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:30:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 07:30:29 [INFO ]  
2022-10-03 07:30:29 [INFO ]  Begin of epoch 190 :
2022-10-03 07:30:32 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:30:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:30:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:30:32 [INFO ]  	   step  1 (lr=0.213179)                   57.36%                   1.3495
2022-10-03 07:30:32 [INFO ]  
2022-10-03 07:30:32 [INFO ]  Epoch:  190	Loss: 1.2596	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:30:34 [INFO ]  Epoch:  191	Loss: 1.2903	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:36 [INFO ]  Epoch:  192	Loss: 1.4937	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:30:38 [INFO ]  Epoch:  193	Loss: 1.4796	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:40 [INFO ]  Epoch:  194	Loss: 1.3215	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:42 [INFO ]  Epoch:  195	Loss: 1.3249	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:30:44 [INFO ]  Epoch:  196	Loss: 1.3525	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:30:45 [INFO ]  Epoch:  197	Loss: 1.3363	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:47 [INFO ]  Epoch:  198	Loss: 1.4756	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:30:49 [INFO ]  Epoch:  199	Loss: 1.5861	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:30:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 07:30:51 [INFO ]  
2022-10-03 07:30:51 [INFO ]  Final evaluation for SVHN :
2022-10-03 07:30:55 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:30:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:30:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:30:55 [INFO ]  	   step  1 (lr=0.211087)                   51.24%                   1.5620
2022-10-03 07:30:55 [INFO ]  
2022-10-03 07:30:55 [INFO ]  
2022-10-03 07:30:55 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 07:30:58 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:30:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:30:58 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 07:30:58 [INFO ]  	   step  1 (lr=0.211087)                   15.89%                   5.2667
2022-10-03 07:30:58 [INFO ]  
2022-10-03 07:32:20 [INFO ]  ======================================== 2022-10-03 07:32:20 ========================================
2022-10-03 07:32:20 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:32:20 [INFO ]  Options: 
2022-10-03 07:32:20 [INFO ]  	base_dir: null
2022-10-03 07:32:20 [INFO ]  	batch_size: 1024
2022-10-03 07:32:20 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:32:20 [INFO ]  	dataset: SVHN
2022-10-03 07:32:20 [INFO ]  	dataset_labels:
2022-10-03 07:32:20 [INFO ]  	- 0
2022-10-03 07:32:20 [INFO ]  	- 1
2022-10-03 07:32:20 [INFO ]  	- 2
2022-10-03 07:32:20 [INFO ]  	- 3
2022-10-03 07:32:20 [INFO ]  	- 4
2022-10-03 07:32:20 [INFO ]  	- 5
2022-10-03 07:32:20 [INFO ]  	- 6
2022-10-03 07:32:20 [INFO ]  	- 7
2022-10-03 07:32:20 [INFO ]  	- 8
2022-10-03 07:32:20 [INFO ]  	- 9
2022-10-03 07:32:20 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:32:20 [INFO ]  	- !!python/tuple
2022-10-03 07:32:20 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:32:20 [INFO ]  	    - 0.44398033618927
2022-10-03 07:32:20 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:32:20 [INFO ]  	- !!python/tuple
2022-10-03 07:32:20 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:32:20 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:32:20 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:32:20 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:32:20 [INFO ]  	decay_epochs: 50
2022-10-03 07:32:20 [INFO ]  	decay_factor: 0.1
2022-10-03 07:32:20 [INFO ]  	device_id: 0
2022-10-03 07:32:20 [INFO ]  	distill_epochs: 1
2022-10-03 07:32:20 [INFO ]  	distill_lr: 0.02
2022-10-03 07:32:20 [INFO ]  	distill_steps: 1
2022-10-03 07:32:20 [INFO ]  	epochs: 200
2022-10-03 07:32:20 [INFO ]  	expand_cls: false
2022-10-03 07:32:20 [INFO ]  	forgetting_dataset: null
2022-10-03 07:32:20 [INFO ]  	init: xavier
2022-10-03 07:32:20 [INFO ]  	init_param: 1.0
2022-10-03 07:32:20 [INFO ]  	input_size: 32
2022-10-03 07:32:20 [INFO ]  	ipc: 2
2022-10-03 07:32:20 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:32:20 [INFO ]  	log_interval: 100
2022-10-03 07:32:20 [INFO ]  	log_level: INFO
2022-10-03 07:32:20 [INFO ]  	lr: 0.01
2022-10-03 07:32:20 [INFO ]  	mode: distill_adapt
2022-10-03 07:32:20 [INFO ]  	nc: 3
2022-10-03 07:32:20 [INFO ]  	num_classes: 10
2022-10-03 07:32:20 [INFO ]  	num_workers: 8
2022-10-03 07:32:20 [INFO ]  	phase: train
2022-10-03 07:32:20 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:32:20 [INFO ]  	start_time: '2022-10-03 07:32:20'
2022-10-03 07:32:20 [INFO ]  	test_batch_size: 1024
2022-10-03 07:32:20 [INFO ]  	
2022-10-03 07:32:23 [INFO ]  train dataset size:	73257
2022-10-03 07:32:23 [INFO ]  test dataset size: 	26032
2022-10-03 07:32:23 [INFO ]  datasets built!
2022-10-03 07:32:23 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:32:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:32:26 [INFO ]  
2022-10-03 07:32:26 [INFO ]  Begin of epoch 0 :
2022-10-03 07:32:30 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:32:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:32:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:32:30 [INFO ]  	   step  1 (lr=0.020000)                    7.60%                   9.4601
2022-10-03 07:32:30 [INFO ]  
2022-10-03 07:32:30 [INFO ]  Epoch:    0	Loss: 8.6519	Data Time: 0.38s	Train Time: 0.03s
2022-10-03 07:32:31 [INFO ]  Epoch:    1	Loss: 3.3152	Data Time: 0.13s	Train Time: 0.01s
2022-10-03 07:32:33 [INFO ]  Epoch:    2	Loss: 2.5712	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:32:35 [INFO ]  Epoch:    3	Loss: 2.2889	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:32:37 [INFO ]  Epoch:    4	Loss: 2.2396	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:32:39 [INFO ]  Epoch:    5	Loss: 2.2047	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:32:41 [INFO ]  Epoch:    6	Loss: 2.1934	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:32:42 [INFO ]  Epoch:    7	Loss: 2.1525	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:32:44 [INFO ]  Epoch:    8	Loss: 2.1310	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:32:46 [INFO ]  Epoch:    9	Loss: 2.1175	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:32:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:32:50 [INFO ]  
2022-10-03 07:32:50 [INFO ]  Begin of epoch 10 :
2022-10-03 07:32:53 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:32:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:32:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:32:53 [INFO ]  	   step  1 (lr=0.053489)                   32.40%                   2.0539
2022-10-03 07:32:53 [INFO ]  
2022-10-03 07:32:53 [INFO ]  Epoch:   10	Loss: 2.0611	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 07:32:55 [INFO ]  Epoch:   11	Loss: 1.9649	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:32:57 [INFO ]  Epoch:   12	Loss: 1.9258	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:32:59 [INFO ]  Epoch:   13	Loss: 1.7474	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:33:00 [INFO ]  Epoch:   14	Loss: 1.7328	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:02 [INFO ]  Epoch:   15	Loss: 1.6018	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:04 [INFO ]  Epoch:   16	Loss: 1.8110	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:33:06 [INFO ]  Epoch:   17	Loss: 1.6163	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:08 [INFO ]  Epoch:   18	Loss: 1.5444	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:10 [INFO ]  Epoch:   19	Loss: 1.4592	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:33:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:33:14 [INFO ]  
2022-10-03 07:33:14 [INFO ]  Begin of epoch 20 :
2022-10-03 07:33:17 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:33:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:33:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:33:17 [INFO ]  	   step  1 (lr=0.149978)                   56.73%                   1.4255
2022-10-03 07:33:17 [INFO ]  
2022-10-03 07:33:17 [INFO ]  Epoch:   20	Loss: 1.3143	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:18 [INFO ]  Epoch:   21	Loss: 1.3931	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:33:20 [INFO ]  Epoch:   22	Loss: 1.4449	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:22 [INFO ]  Epoch:   23	Loss: 1.3704	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:33:24 [INFO ]  Epoch:   24	Loss: 1.2855	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:33:26 [INFO ]  Epoch:   25	Loss: 1.3558	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:33:28 [INFO ]  Epoch:   26	Loss: 1.3823	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:33:29 [INFO ]  Epoch:   27	Loss: 1.1581	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:33:31 [INFO ]  Epoch:   28	Loss: 1.1816	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:33 [INFO ]  Epoch:   29	Loss: 1.1879	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:33:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:33:37 [INFO ]  
2022-10-03 07:33:37 [INFO ]  Begin of epoch 30 :
2022-10-03 07:33:41 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:33:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:33:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:33:41 [INFO ]  	   step  1 (lr=0.201263)                   65.62%                   1.2050
2022-10-03 07:33:41 [INFO ]  
2022-10-03 07:33:41 [INFO ]  Epoch:   30	Loss: 1.1817	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 07:33:42 [INFO ]  Epoch:   31	Loss: 1.1367	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:33:44 [INFO ]  Epoch:   32	Loss: 1.1577	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:46 [INFO ]  Epoch:   33	Loss: 1.3516	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:48 [INFO ]  Epoch:   34	Loss: 1.0805	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:49 [INFO ]  Epoch:   35	Loss: 1.1405	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:33:51 [INFO ]  Epoch:   36	Loss: 1.1534	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:33:53 [INFO ]  Epoch:   37	Loss: 0.9943	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:55 [INFO ]  Epoch:   38	Loss: 1.0586	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:33:57 [INFO ]  Epoch:   39	Loss: 1.0088	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 07:34:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:34:01 [INFO ]  
2022-10-03 07:34:01 [INFO ]  Begin of epoch 40 :
2022-10-03 07:34:04 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:34:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:34:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:34:04 [INFO ]  	   step  1 (lr=0.213298)                   65.12%                   1.1405
2022-10-03 07:34:04 [INFO ]  
2022-10-03 07:34:04 [INFO ]  Epoch:   40	Loss: 1.1171	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:34:05 [INFO ]  Epoch:   41	Loss: 1.0405	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:34:07 [INFO ]  Epoch:   42	Loss: 0.9335	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:34:09 [INFO ]  Epoch:   43	Loss: 1.0910	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:34:11 [INFO ]  Epoch:   44	Loss: 1.0142	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:34:13 [INFO ]  Epoch:   45	Loss: 1.0104	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:34:15 [INFO ]  Epoch:   46	Loss: 1.0330	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:34:16 [INFO ]  Epoch:   47	Loss: 0.8764	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:34:18 [INFO ]  Epoch:   48	Loss: 0.9705	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:34:20 [INFO ]  Epoch:   49	Loss: 0.8905	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 07:34:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:34:24 [INFO ]  
2022-10-03 07:34:24 [INFO ]  Begin of epoch 50 :
2022-10-03 07:34:27 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:34:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:34:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:34:27 [INFO ]  	   step  1 (lr=0.239038)                   74.72%                   0.9032
2022-10-03 07:34:27 [INFO ]  
2022-10-03 07:34:27 [INFO ]  Epoch:   50	Loss: 0.9085	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 07:34:29 [INFO ]  Epoch:   51	Loss: 0.8730	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:34:30 [INFO ]  Epoch:   52	Loss: 0.7625	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:34:32 [INFO ]  Epoch:   53	Loss: 0.8127	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:34:34 [INFO ]  Epoch:   54	Loss: 0.8308	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:34:36 [INFO ]  Epoch:   55	Loss: 0.8467	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:34:38 [INFO ]  Epoch:   56	Loss: 0.8629	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:34:40 [INFO ]  Epoch:   57	Loss: 0.8124	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:34:42 [INFO ]  Epoch:   58	Loss: 0.9705	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:34:44 [INFO ]  Epoch:   59	Loss: 0.8362	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:34:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:34:48 [INFO ]  
2022-10-03 07:34:48 [INFO ]  Begin of epoch 60 :
2022-10-03 07:34:51 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:34:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:34:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:34:51 [INFO ]  	   step  1 (lr=0.243371)                   75.68%                   0.8882
2022-10-03 07:34:51 [INFO ]  
2022-10-03 07:34:51 [INFO ]  Epoch:   60	Loss: 0.7770	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:34:53 [INFO ]  Epoch:   61	Loss: 0.8719	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:34:54 [INFO ]  Epoch:   62	Loss: 0.8222	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:34:56 [INFO ]  Epoch:   63	Loss: 0.8473	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:34:58 [INFO ]  Epoch:   64	Loss: 0.7920	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:35:00 [INFO ]  Epoch:   65	Loss: 0.8462	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:02 [INFO ]  Epoch:   66	Loss: 0.8174	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:04 [INFO ]  Epoch:   67	Loss: 0.8427	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:35:06 [INFO ]  Epoch:   68	Loss: 0.7932	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:35:08 [INFO ]  Epoch:   69	Loss: 0.8502	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:35:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:35:11 [INFO ]  
2022-10-03 07:35:11 [INFO ]  Begin of epoch 70 :
2022-10-03 07:35:15 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:35:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:35:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:35:15 [INFO ]  	   step  1 (lr=0.248980)                   76.69%                   0.8534
2022-10-03 07:35:15 [INFO ]  
2022-10-03 07:35:15 [INFO ]  Epoch:   70	Loss: 0.7901	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:35:16 [INFO ]  Epoch:   71	Loss: 0.8112	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:35:18 [INFO ]  Epoch:   72	Loss: 0.7837	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:35:20 [INFO ]  Epoch:   73	Loss: 0.7614	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:35:22 [INFO ]  Epoch:   74	Loss: 0.8709	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:35:24 [INFO ]  Epoch:   75	Loss: 0.8198	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:35:26 [INFO ]  Epoch:   76	Loss: 0.8048	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:28 [INFO ]  Epoch:   77	Loss: 0.7984	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:35:30 [INFO ]  Epoch:   78	Loss: 0.7517	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:35:32 [INFO ]  Epoch:   79	Loss: 0.8242	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:35:36 [INFO ]  
2022-10-03 07:35:36 [INFO ]  Begin of epoch 80 :
2022-10-03 07:35:39 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:35:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:35:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:35:39 [INFO ]  	   step  1 (lr=0.254682)                   75.22%                   0.8811
2022-10-03 07:35:39 [INFO ]  
2022-10-03 07:35:39 [INFO ]  Epoch:   80	Loss: 0.8304	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:35:41 [INFO ]  Epoch:   81	Loss: 0.8524	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:35:42 [INFO ]  Epoch:   82	Loss: 0.7537	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:35:44 [INFO ]  Epoch:   83	Loss: 0.7690	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:35:46 [INFO ]  Epoch:   84	Loss: 0.9234	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 07:35:48 [INFO ]  Epoch:   85	Loss: 0.8881	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:35:50 [INFO ]  Epoch:   86	Loss: 0.6719	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:52 [INFO ]  Epoch:   87	Loss: 0.7607	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:35:53 [INFO ]  Epoch:   88	Loss: 0.8147	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:35:55 [INFO ]  Epoch:   89	Loss: 0.8326	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:35:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:35:59 [INFO ]  
2022-10-03 07:35:59 [INFO ]  Begin of epoch 90 :
2022-10-03 07:36:03 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:36:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:36:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:36:03 [INFO ]  	   step  1 (lr=0.263174)                   76.01%                   0.8517
2022-10-03 07:36:03 [INFO ]  
2022-10-03 07:36:03 [INFO ]  Epoch:   90	Loss: 0.8262	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:36:04 [INFO ]  Epoch:   91	Loss: 0.7936	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:36:06 [INFO ]  Epoch:   92	Loss: 0.7300	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:36:08 [INFO ]  Epoch:   93	Loss: 0.8723	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:36:10 [INFO ]  Epoch:   94	Loss: 0.7310	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:36:11 [INFO ]  Epoch:   95	Loss: 0.7843	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:13 [INFO ]  Epoch:   96	Loss: 0.7896	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:36:15 [INFO ]  Epoch:   97	Loss: 0.7688	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:17 [INFO ]  Epoch:   98	Loss: 0.8310	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:36:19 [INFO ]  Epoch:   99	Loss: 0.8558	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:36:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:36:23 [INFO ]  
2022-10-03 07:36:23 [INFO ]  Begin of epoch 100 :
2022-10-03 07:36:26 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:36:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:36:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:36:26 [INFO ]  	   step  1 (lr=0.265317)                   77.08%                   0.8371
2022-10-03 07:36:26 [INFO ]  
2022-10-03 07:36:26 [INFO ]  Epoch:  100	Loss: 0.6896	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:36:28 [INFO ]  Epoch:  101	Loss: 0.7201	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:36:29 [INFO ]  Epoch:  102	Loss: 0.7626	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:31 [INFO ]  Epoch:  103	Loss: 0.7504	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:33 [INFO ]  Epoch:  104	Loss: 0.7825	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:36:35 [INFO ]  Epoch:  105	Loss: 0.7905	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:37 [INFO ]  Epoch:  106	Loss: 0.7584	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:36:39 [INFO ]  Epoch:  107	Loss: 0.7577	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:36:40 [INFO ]  Epoch:  108	Loss: 0.7553	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:36:42 [INFO ]  Epoch:  109	Loss: 0.8021	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:36:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:36:46 [INFO ]  
2022-10-03 07:36:46 [INFO ]  Begin of epoch 110 :
2022-10-03 07:36:49 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:36:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:36:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:36:49 [INFO ]  	   step  1 (lr=0.268280)                   76.86%                   0.8359
2022-10-03 07:36:49 [INFO ]  
2022-10-03 07:36:49 [INFO ]  Epoch:  110	Loss: 0.8310	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:36:51 [INFO ]  Epoch:  111	Loss: 0.8451	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:53 [INFO ]  Epoch:  112	Loss: 0.8063	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:36:55 [INFO ]  Epoch:  113	Loss: 0.7788	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:36:56 [INFO ]  Epoch:  114	Loss: 0.8744	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:36:58 [INFO ]  Epoch:  115	Loss: 0.8406	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:00 [INFO ]  Epoch:  116	Loss: 0.7466	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:37:02 [INFO ]  Epoch:  117	Loss: 0.7870	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:37:04 [INFO ]  Epoch:  118	Loss: 0.8263	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:05 [INFO ]  Epoch:  119	Loss: 0.7661	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:37:09 [INFO ]  
2022-10-03 07:37:09 [INFO ]  Begin of epoch 120 :
2022-10-03 07:37:13 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:37:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:37:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:37:13 [INFO ]  	   step  1 (lr=0.267579)                   77.04%                   0.8335
2022-10-03 07:37:13 [INFO ]  
2022-10-03 07:37:13 [INFO ]  Epoch:  120	Loss: 0.7914	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:14 [INFO ]  Epoch:  121	Loss: 0.8953	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:16 [INFO ]  Epoch:  122	Loss: 0.8027	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:18 [INFO ]  Epoch:  123	Loss: 0.8172	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:37:20 [INFO ]  Epoch:  124	Loss: 0.8683	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:22 [INFO ]  Epoch:  125	Loss: 0.8009	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:23 [INFO ]  Epoch:  126	Loss: 0.7849	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:37:25 [INFO ]  Epoch:  127	Loss: 0.7918	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:27 [INFO ]  Epoch:  128	Loss: 1.1034	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:37:29 [INFO ]  Epoch:  129	Loss: 0.9130	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:37:33 [INFO ]  
2022-10-03 07:37:33 [INFO ]  Begin of epoch 130 :
2022-10-03 07:37:36 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:37:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:37:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:37:36 [INFO ]  	   step  1 (lr=0.263027)                   76.50%                   0.8450
2022-10-03 07:37:36 [INFO ]  
2022-10-03 07:37:36 [INFO ]  Epoch:  130	Loss: 0.8202	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 07:37:38 [INFO ]  Epoch:  131	Loss: 0.8194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:40 [INFO ]  Epoch:  132	Loss: 0.7615	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:37:41 [INFO ]  Epoch:  133	Loss: 0.8299	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:43 [INFO ]  Epoch:  134	Loss: 0.7728	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:37:45 [INFO ]  Epoch:  135	Loss: 0.6716	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:47 [INFO ]  Epoch:  136	Loss: 0.7507	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:49 [INFO ]  Epoch:  137	Loss: 0.7320	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:51 [INFO ]  Epoch:  138	Loss: 0.7846	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:37:53 [INFO ]  Epoch:  139	Loss: 0.7949	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:37:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 07:37:56 [INFO ]  
2022-10-03 07:37:56 [INFO ]  Begin of epoch 140 :
2022-10-03 07:37:59 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:37:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:37:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:37:59 [INFO ]  	   step  1 (lr=0.264230)                   75.93%                   0.8542
2022-10-03 07:37:59 [INFO ]  
2022-10-03 07:38:00 [INFO ]  Epoch:  140	Loss: 0.7697	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:01 [INFO ]  Epoch:  141	Loss: 0.7800	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:03 [INFO ]  Epoch:  142	Loss: 0.8283	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:05 [INFO ]  Epoch:  143	Loss: 0.8050	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:38:07 [INFO ]  Epoch:  144	Loss: 0.7886	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:09 [INFO ]  Epoch:  145	Loss: 0.8507	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:10 [INFO ]  Epoch:  146	Loss: 0.7783	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:38:13 [INFO ]  Epoch:  147	Loss: 0.7893	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:38:14 [INFO ]  Epoch:  148	Loss: 0.8140	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:38:16 [INFO ]  Epoch:  149	Loss: 0.8886	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:38:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 07:38:20 [INFO ]  
2022-10-03 07:38:20 [INFO ]  Begin of epoch 150 :
2022-10-03 07:38:23 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:38:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:38:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:38:23 [INFO ]  	   step  1 (lr=0.263047)                   75.24%                   0.8742
2022-10-03 07:38:23 [INFO ]  
2022-10-03 07:38:23 [INFO ]  Epoch:  150	Loss: 0.7996	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:25 [INFO ]  Epoch:  151	Loss: 0.7687	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:38:27 [INFO ]  Epoch:  152	Loss: 0.8200	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:29 [INFO ]  Epoch:  153	Loss: 0.9270	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:38:31 [INFO ]  Epoch:  154	Loss: 0.8270	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:32 [INFO ]  Epoch:  155	Loss: 0.8336	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:34 [INFO ]  Epoch:  156	Loss: 0.8330	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:38:36 [INFO ]  Epoch:  157	Loss: 0.7861	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:38 [INFO ]  Epoch:  158	Loss: 0.8246	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:40 [INFO ]  Epoch:  159	Loss: 0.7924	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:38:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 07:38:43 [INFO ]  
2022-10-03 07:38:43 [INFO ]  Begin of epoch 160 :
2022-10-03 07:38:47 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:38:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:38:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:38:47 [INFO ]  	   step  1 (lr=0.263584)                   75.84%                   0.8606
2022-10-03 07:38:47 [INFO ]  
2022-10-03 07:38:47 [INFO ]  Epoch:  160	Loss: 0.8162	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:48 [INFO ]  Epoch:  161	Loss: 0.8416	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:50 [INFO ]  Epoch:  162	Loss: 0.9565	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:38:52 [INFO ]  Epoch:  163	Loss: 0.7967	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:54 [INFO ]  Epoch:  164	Loss: 0.7409	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:38:56 [INFO ]  Epoch:  165	Loss: 0.8133	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:38:57 [INFO ]  Epoch:  166	Loss: 0.7176	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:38:59 [INFO ]  Epoch:  167	Loss: 0.7418	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:39:01 [INFO ]  Epoch:  168	Loss: 1.7111	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:39:03 [INFO ]  Epoch:  169	Loss: 1.4479	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:39:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 07:39:07 [INFO ]  
2022-10-03 07:39:07 [INFO ]  Begin of epoch 170 :
2022-10-03 07:39:10 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:39:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:39:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:39:10 [INFO ]  	   step  1 (lr=0.262764)                   64.05%                   1.3673
2022-10-03 07:39:10 [INFO ]  
2022-10-03 07:39:10 [INFO ]  Epoch:  170	Loss: 1.4155	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:39:12 [INFO ]  Epoch:  171	Loss: 1.3413	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:39:14 [INFO ]  Epoch:  172	Loss: 1.1669	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:39:15 [INFO ]  Epoch:  173	Loss: 1.1016	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:39:17 [INFO ]  Epoch:  174	Loss: 1.1843	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:39:19 [INFO ]  Epoch:  175	Loss: 1.0422	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:21 [INFO ]  Epoch:  176	Loss: 1.0859	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:39:23 [INFO ]  Epoch:  177	Loss: 1.0168	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:24 [INFO ]  Epoch:  178	Loss: 1.0524	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:26 [INFO ]  Epoch:  179	Loss: 1.0397	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 07:39:30 [INFO ]  
2022-10-03 07:39:30 [INFO ]  Begin of epoch 180 :
2022-10-03 07:39:33 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:39:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:39:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:39:33 [INFO ]  	   step  1 (lr=0.260615)                   72.44%                   0.9966
2022-10-03 07:39:33 [INFO ]  
2022-10-03 07:39:33 [INFO ]  Epoch:  180	Loss: 0.9649	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:39:35 [INFO ]  Epoch:  181	Loss: 0.9739	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:37 [INFO ]  Epoch:  182	Loss: 0.9277	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:39 [INFO ]  Epoch:  183	Loss: 0.9631	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:39:41 [INFO ]  Epoch:  184	Loss: 0.8763	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:39:43 [INFO ]  Epoch:  185	Loss: 0.8993	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:39:45 [INFO ]  Epoch:  186	Loss: 0.8457	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:39:47 [INFO ]  Epoch:  187	Loss: 0.9850	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:39:49 [INFO ]  Epoch:  188	Loss: 0.9542	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:39:51 [INFO ]  Epoch:  189	Loss: 0.8442	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:39:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 07:39:55 [INFO ]  
2022-10-03 07:39:55 [INFO ]  Begin of epoch 190 :
2022-10-03 07:39:58 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:39:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:39:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:39:58 [INFO ]  	   step  1 (lr=0.259870)                   75.47%                   0.8901
2022-10-03 07:39:58 [INFO ]  
2022-10-03 07:39:58 [INFO ]  Epoch:  190	Loss: 0.8498	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:40:00 [INFO ]  Epoch:  191	Loss: 0.8905	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:40:02 [INFO ]  Epoch:  192	Loss: 0.8245	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:40:04 [INFO ]  Epoch:  193	Loss: 0.8480	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:40:06 [INFO ]  Epoch:  194	Loss: 0.8472	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:40:07 [INFO ]  Epoch:  195	Loss: 0.8030	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:40:09 [INFO ]  Epoch:  196	Loss: 0.8958	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:40:11 [INFO ]  Epoch:  197	Loss: 0.7746	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:40:13 [INFO ]  Epoch:  198	Loss: 0.7814	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:40:15 [INFO ]  Epoch:  199	Loss: 0.8514	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:40:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 07:40:18 [INFO ]  
2022-10-03 07:40:18 [INFO ]  Final evaluation for SVHN :
2022-10-03 07:40:22 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:40:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:40:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:40:22 [INFO ]  	   step  1 (lr=0.259767)                   75.46%                   0.8844
2022-10-03 07:40:22 [INFO ]  
2022-10-03 07:40:22 [INFO ]  
2022-10-03 07:40:22 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 07:40:24 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:40:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:40:24 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 07:40:24 [INFO ]  	   step  1 (lr=0.259767)                   17.81%                   4.3752
2022-10-03 07:40:24 [INFO ]  
2022-10-03 07:45:19 [INFO ]  ======================================== 2022-10-03 07:45:19 ========================================
2022-10-03 07:45:19 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:45:19 [INFO ]  Options: 
2022-10-03 07:45:19 [INFO ]  	base_dir: null
2022-10-03 07:45:19 [INFO ]  	batch_size: 1024
2022-10-03 07:45:19 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:45:19 [INFO ]  	dataset: SVHN
2022-10-03 07:45:19 [INFO ]  	dataset_labels:
2022-10-03 07:45:19 [INFO ]  	- 0
2022-10-03 07:45:19 [INFO ]  	- 1
2022-10-03 07:45:19 [INFO ]  	- 2
2022-10-03 07:45:19 [INFO ]  	- 3
2022-10-03 07:45:19 [INFO ]  	- 4
2022-10-03 07:45:19 [INFO ]  	- 5
2022-10-03 07:45:19 [INFO ]  	- 6
2022-10-03 07:45:19 [INFO ]  	- 7
2022-10-03 07:45:19 [INFO ]  	- 8
2022-10-03 07:45:19 [INFO ]  	- 9
2022-10-03 07:45:19 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:45:19 [INFO ]  	- !!python/tuple
2022-10-03 07:45:19 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:45:19 [INFO ]  	    - 0.44398033618927
2022-10-03 07:45:19 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:45:19 [INFO ]  	- !!python/tuple
2022-10-03 07:45:19 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:45:19 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:45:19 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:45:19 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:45:19 [INFO ]  	decay_epochs: 50
2022-10-03 07:45:19 [INFO ]  	decay_factor: 0.1
2022-10-03 07:45:19 [INFO ]  	device_id: 0
2022-10-03 07:45:19 [INFO ]  	distill_epochs: 1
2022-10-03 07:45:19 [INFO ]  	distill_lr: 0.02
2022-10-03 07:45:19 [INFO ]  	distill_steps: 1
2022-10-03 07:45:19 [INFO ]  	epochs: 200
2022-10-03 07:45:19 [INFO ]  	expand_cls: false
2022-10-03 07:45:19 [INFO ]  	forgetting_dataset: null
2022-10-03 07:45:19 [INFO ]  	init: xavier
2022-10-03 07:45:19 [INFO ]  	init_param: 1.0
2022-10-03 07:45:19 [INFO ]  	input_size: 32
2022-10-03 07:45:19 [INFO ]  	ipc: 2
2022-10-03 07:45:19 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:45:19 [INFO ]  	log_interval: 100
2022-10-03 07:45:19 [INFO ]  	log_level: INFO
2022-10-03 07:45:19 [INFO ]  	lr: 0.01
2022-10-03 07:45:19 [INFO ]  	mode: distill_adapt
2022-10-03 07:45:19 [INFO ]  	nc: 3
2022-10-03 07:45:19 [INFO ]  	num_classes: 10
2022-10-03 07:45:19 [INFO ]  	num_workers: 8
2022-10-03 07:45:19 [INFO ]  	phase: train
2022-10-03 07:45:19 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:45:19 [INFO ]  	start_time: '2022-10-03 07:45:19'
2022-10-03 07:45:19 [INFO ]  	test_batch_size: 1024
2022-10-03 07:45:19 [INFO ]  	
2022-10-03 07:45:21 [INFO ]  train dataset size:	73257
2022-10-03 07:45:21 [INFO ]  test dataset size: 	26032
2022-10-03 07:45:21 [INFO ]  datasets built!
2022-10-03 07:45:21 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:45:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:45:25 [INFO ]  
2022-10-03 07:45:25 [INFO ]  Begin of epoch 0 :
2022-10-03 07:45:28 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:45:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:45:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:45:28 [INFO ]  	   step  1 (lr=0.020000)                    7.28%                   8.6245
2022-10-03 07:45:28 [INFO ]  
2022-10-03 07:45:28 [INFO ]  Epoch:    0	Loss: 8.1569	Data Time: 0.41s	Train Time: 0.03s
2022-10-03 07:45:30 [INFO ]  Epoch:    1	Loss: 3.4194	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 07:45:32 [INFO ]  Epoch:    2	Loss: 2.6677	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:34 [INFO ]  Epoch:    3	Loss: 2.3826	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:35 [INFO ]  Epoch:    4	Loss: 2.2663	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:45:37 [INFO ]  Epoch:    5	Loss: 2.2520	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:45:39 [INFO ]  Epoch:    6	Loss: 2.2242	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:45:41 [INFO ]  Epoch:    7	Loss: 2.2106	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:43 [INFO ]  Epoch:    8	Loss: 2.1848	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:45 [INFO ]  Epoch:    9	Loss: 2.1532	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:45:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:45:49 [INFO ]  
2022-10-03 07:45:49 [INFO ]  Begin of epoch 10 :
2022-10-03 07:45:52 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:45:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:45:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:45:52 [INFO ]  	   step  1 (lr=0.048173)                   30.74%                   2.1043
2022-10-03 07:45:52 [INFO ]  
2022-10-03 07:45:52 [INFO ]  Epoch:   10	Loss: 2.1050	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:53 [INFO ]  Epoch:   11	Loss: 2.1516	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:55 [INFO ]  Epoch:   12	Loss: 2.0425	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:45:57 [INFO ]  Epoch:   13	Loss: 2.0395	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:45:59 [INFO ]  Epoch:   14	Loss: 1.8247	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:46:01 [INFO ]  Epoch:   15	Loss: 1.7299	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:03 [INFO ]  Epoch:   16	Loss: 1.6054	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:46:05 [INFO ]  Epoch:   17	Loss: 1.6335	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:46:07 [INFO ]  Epoch:   18	Loss: 1.5042	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:09 [INFO ]  Epoch:   19	Loss: 1.5658	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:46:13 [INFO ]  
2022-10-03 07:46:13 [INFO ]  Begin of epoch 20 :
2022-10-03 07:46:16 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:46:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:46:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:46:16 [INFO ]  	   step  1 (lr=0.145824)                   54.27%                   1.4764
2022-10-03 07:46:16 [INFO ]  
2022-10-03 07:46:16 [INFO ]  Epoch:   20	Loss: 1.3613	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:46:17 [INFO ]  Epoch:   21	Loss: 1.6856	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:46:19 [INFO ]  Epoch:   22	Loss: 1.4081	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:21 [INFO ]  Epoch:   23	Loss: 1.6276	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:46:23 [INFO ]  Epoch:   24	Loss: 1.5199	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:25 [INFO ]  Epoch:   25	Loss: 1.4278	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:46:27 [INFO ]  Epoch:   26	Loss: 1.2270	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:29 [INFO ]  Epoch:   27	Loss: 1.3411	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:46:31 [INFO ]  Epoch:   28	Loss: 1.1653	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:46:32 [INFO ]  Epoch:   29	Loss: 1.1816	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:46:36 [INFO ]  
2022-10-03 07:46:36 [INFO ]  Begin of epoch 30 :
2022-10-03 07:46:39 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:46:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:46:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:46:39 [INFO ]  	   step  1 (lr=0.149437)                   57.92%                   1.4254
2022-10-03 07:46:39 [INFO ]  
2022-10-03 07:46:39 [INFO ]  Epoch:   30	Loss: 1.3961	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:46:41 [INFO ]  Epoch:   31	Loss: 1.2683	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:43 [INFO ]  Epoch:   32	Loss: 1.2584	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:46:45 [INFO ]  Epoch:   33	Loss: 1.1768	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:47 [INFO ]  Epoch:   34	Loss: 1.3232	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:46:48 [INFO ]  Epoch:   35	Loss: 1.1843	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:50 [INFO ]  Epoch:   36	Loss: 1.3159	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:46:52 [INFO ]  Epoch:   37	Loss: 1.0731	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:46:54 [INFO ]  Epoch:   38	Loss: 1.2286	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:46:56 [INFO ]  Epoch:   39	Loss: 1.1526	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:47:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:47:00 [INFO ]  
2022-10-03 07:47:00 [INFO ]  Begin of epoch 40 :
2022-10-03 07:47:03 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:47:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:47:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:47:03 [INFO ]  	   step  1 (lr=0.221778)                   64.99%                   1.1828
2022-10-03 07:47:03 [INFO ]  
2022-10-03 07:47:03 [INFO ]  Epoch:   40	Loss: 1.1233	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 07:47:05 [INFO ]  Epoch:   41	Loss: 1.1609	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:47:07 [INFO ]  Epoch:   42	Loss: 1.1293	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:08 [INFO ]  Epoch:   43	Loss: 0.9775	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:47:10 [INFO ]  Epoch:   44	Loss: 1.0247	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:12 [INFO ]  Epoch:   45	Loss: 1.0436	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:47:14 [INFO ]  Epoch:   46	Loss: 0.9975	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:47:16 [INFO ]  Epoch:   47	Loss: 0.9701	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:47:18 [INFO ]  Epoch:   48	Loss: 1.0408	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:47:19 [INFO ]  Epoch:   49	Loss: 1.0654	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:47:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:47:23 [INFO ]  
2022-10-03 07:47:23 [INFO ]  Begin of epoch 50 :
2022-10-03 07:47:26 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:47:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:47:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:47:26 [INFO ]  	   step  1 (lr=0.244085)                   72.63%                   0.9583
2022-10-03 07:47:26 [INFO ]  
2022-10-03 07:47:26 [INFO ]  Epoch:   50	Loss: 0.8696	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 07:47:28 [INFO ]  Epoch:   51	Loss: 0.9087	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:30 [INFO ]  Epoch:   52	Loss: 0.9249	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:32 [INFO ]  Epoch:   53	Loss: 0.8857	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:47:34 [INFO ]  Epoch:   54	Loss: 0.9497	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:36 [INFO ]  Epoch:   55	Loss: 0.9522	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:47:37 [INFO ]  Epoch:   56	Loss: 0.9121	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:47:39 [INFO ]  Epoch:   57	Loss: 0.9093	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:47:41 [INFO ]  Epoch:   58	Loss: 0.9141	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:43 [INFO ]  Epoch:   59	Loss: 0.9701	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:47:47 [INFO ]  
2022-10-03 07:47:47 [INFO ]  Begin of epoch 60 :
2022-10-03 07:47:50 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:47:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:47:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:47:50 [INFO ]  	   step  1 (lr=0.255360)                   73.87%                   0.9172
2022-10-03 07:47:50 [INFO ]  
2022-10-03 07:47:50 [INFO ]  Epoch:   60	Loss: 0.8605	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:47:52 [INFO ]  Epoch:   61	Loss: 0.8635	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:47:53 [INFO ]  Epoch:   62	Loss: 0.8805	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:47:55 [INFO ]  Epoch:   63	Loss: 0.9174	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:47:57 [INFO ]  Epoch:   64	Loss: 0.9067	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:47:59 [INFO ]  Epoch:   65	Loss: 0.7994	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:48:01 [INFO ]  Epoch:   66	Loss: 0.8767	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:48:03 [INFO ]  Epoch:   67	Loss: 0.8686	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:48:05 [INFO ]  Epoch:   68	Loss: 0.9043	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:48:07 [INFO ]  Epoch:   69	Loss: 0.9108	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:48:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:48:10 [INFO ]  
2022-10-03 07:48:10 [INFO ]  Begin of epoch 70 :
2022-10-03 07:48:14 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:48:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:48:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:48:14 [INFO ]  	   step  1 (lr=0.256701)                   74.00%                   0.9164
2022-10-03 07:48:14 [INFO ]  
2022-10-03 07:48:14 [INFO ]  Epoch:   70	Loss: 0.9026	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:48:16 [INFO ]  Epoch:   71	Loss: 0.8492	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:18 [INFO ]  Epoch:   72	Loss: 0.8451	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:20 [INFO ]  Epoch:   73	Loss: 0.8983	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:22 [INFO ]  Epoch:   74	Loss: 0.8147	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:48:24 [INFO ]  Epoch:   75	Loss: 1.0364	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:26 [INFO ]  Epoch:   76	Loss: 0.9603	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:28 [INFO ]  Epoch:   77	Loss: 0.8393	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:48:30 [INFO ]  Epoch:   78	Loss: 0.8455	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:32 [INFO ]  Epoch:   79	Loss: 0.8839	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:48:35 [INFO ]  
2022-10-03 07:48:35 [INFO ]  Begin of epoch 80 :
2022-10-03 07:48:39 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:48:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:48:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:48:39 [INFO ]  	   step  1 (lr=0.266747)                   74.66%                   0.8983
2022-10-03 07:48:39 [INFO ]  
2022-10-03 07:48:39 [INFO ]  Epoch:   80	Loss: 0.9159	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:41 [INFO ]  Epoch:   81	Loss: 0.8805	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:48:43 [INFO ]  Epoch:   82	Loss: 0.9120	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:48:45 [INFO ]  Epoch:   83	Loss: 0.9703	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:48:46 [INFO ]  Epoch:   84	Loss: 0.8621	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:48 [INFO ]  Epoch:   85	Loss: 0.8630	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:50 [INFO ]  Epoch:   86	Loss: 0.8826	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:48:52 [INFO ]  Epoch:   87	Loss: 0.8638	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:48:54 [INFO ]  Epoch:   88	Loss: 0.8271	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:48:56 [INFO ]  Epoch:   89	Loss: 0.8081	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:48:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:48:59 [INFO ]  
2022-10-03 07:48:59 [INFO ]  Begin of epoch 90 :
2022-10-03 07:49:03 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:49:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:49:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:49:03 [INFO ]  	   step  1 (lr=0.270377)                   75.06%                   0.8896
2022-10-03 07:49:03 [INFO ]  
2022-10-03 07:49:03 [INFO ]  Epoch:   90	Loss: 0.8407	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 07:49:04 [INFO ]  Epoch:   91	Loss: 0.9094	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:49:06 [INFO ]  Epoch:   92	Loss: 0.8047	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:49:08 [INFO ]  Epoch:   93	Loss: 0.8079	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:49:10 [INFO ]  Epoch:   94	Loss: 1.5019	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:49:12 [INFO ]  Epoch:   95	Loss: 0.8537	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:49:14 [INFO ]  Epoch:   96	Loss: 0.9117	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:49:16 [INFO ]  Epoch:   97	Loss: 0.8638	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:49:18 [INFO ]  Epoch:   98	Loss: 1.0941	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:49:19 [INFO ]  Epoch:   99	Loss: 0.9321	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:49:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:49:23 [INFO ]  
2022-10-03 07:49:23 [INFO ]  Begin of epoch 100 :
2022-10-03 07:49:27 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:49:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:49:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:49:27 [INFO ]  	   step  1 (lr=0.274590)                   73.93%                   0.9197
2022-10-03 07:49:27 [INFO ]  
2022-10-03 07:49:27 [INFO ]  Epoch:  100	Loss: 0.8149	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:29 [INFO ]  Epoch:  101	Loss: 0.8540	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:49:30 [INFO ]  Epoch:  102	Loss: 0.7793	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:32 [INFO ]  Epoch:  103	Loss: 0.7767	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:34 [INFO ]  Epoch:  104	Loss: 0.8666	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:49:36 [INFO ]  Epoch:  105	Loss: 0.8200	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:38 [INFO ]  Epoch:  106	Loss: 0.8715	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:39 [INFO ]  Epoch:  107	Loss: 0.8377	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:41 [INFO ]  Epoch:  108	Loss: 0.7740	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:49:43 [INFO ]  Epoch:  109	Loss: 0.8524	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:49:47 [INFO ]  
2022-10-03 07:49:47 [INFO ]  Begin of epoch 110 :
2022-10-03 07:49:50 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:49:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:49:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:49:50 [INFO ]  	   step  1 (lr=0.275270)                   75.32%                   0.8820
2022-10-03 07:49:50 [INFO ]  
2022-10-03 07:49:50 [INFO ]  Epoch:  110	Loss: 0.8802	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:49:52 [INFO ]  Epoch:  111	Loss: 0.8671	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:49:54 [INFO ]  Epoch:  112	Loss: 0.9798	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:49:56 [INFO ]  Epoch:  113	Loss: 0.9019	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:49:58 [INFO ]  Epoch:  114	Loss: 0.9077	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:49:59 [INFO ]  Epoch:  115	Loss: 0.7767	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:50:01 [INFO ]  Epoch:  116	Loss: 0.8712	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:50:03 [INFO ]  Epoch:  117	Loss: 0.9601	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:50:05 [INFO ]  Epoch:  118	Loss: 0.9046	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:50:07 [INFO ]  Epoch:  119	Loss: 0.8609	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:50:11 [INFO ]  
2022-10-03 07:50:11 [INFO ]  Begin of epoch 120 :
2022-10-03 07:50:14 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:50:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:50:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:50:14 [INFO ]  	   step  1 (lr=0.275805)                   74.07%                   0.9128
2022-10-03 07:50:14 [INFO ]  
2022-10-03 07:50:14 [INFO ]  Epoch:  120	Loss: 0.8752	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:50:16 [INFO ]  Epoch:  121	Loss: 0.8402	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:17 [INFO ]  Epoch:  122	Loss: 1.2724	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:50:19 [INFO ]  Epoch:  123	Loss: 0.8238	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:21 [INFO ]  Epoch:  124	Loss: 0.8714	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:23 [INFO ]  Epoch:  125	Loss: 0.8809	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:25 [INFO ]  Epoch:  126	Loss: 0.7883	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:50:27 [INFO ]  Epoch:  127	Loss: 0.7933	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:28 [INFO ]  Epoch:  128	Loss: 0.7638	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:50:30 [INFO ]  Epoch:  129	Loss: 0.8214	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:50:34 [INFO ]  
2022-10-03 07:50:34 [INFO ]  Begin of epoch 130 :
2022-10-03 07:50:38 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:50:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:50:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:50:38 [INFO ]  	   step  1 (lr=0.277536)                   75.44%                   0.8741
2022-10-03 07:50:38 [INFO ]  
2022-10-03 07:50:38 [INFO ]  Epoch:  130	Loss: 0.7931	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:50:39 [INFO ]  Epoch:  131	Loss: 0.8436	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:50:41 [INFO ]  Epoch:  132	Loss: 0.8928	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:50:43 [INFO ]  Epoch:  133	Loss: 0.8277	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:45 [INFO ]  Epoch:  134	Loss: 0.8848	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:50:47 [INFO ]  Epoch:  135	Loss: 0.7956	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:50:49 [INFO ]  Epoch:  136	Loss: 0.8960	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:50:50 [INFO ]  Epoch:  137	Loss: 0.8723	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:50:52 [INFO ]  Epoch:  138	Loss: 0.7611	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:50:54 [INFO ]  Epoch:  139	Loss: 0.8528	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:50:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 07:50:58 [INFO ]  
2022-10-03 07:50:58 [INFO ]  Begin of epoch 140 :
2022-10-03 07:51:01 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:51:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:51:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:51:01 [INFO ]  	   step  1 (lr=0.279793)                   75.03%                   0.8823
2022-10-03 07:51:01 [INFO ]  
2022-10-03 07:51:01 [INFO ]  Epoch:  140	Loss: 0.8851	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 07:51:03 [INFO ]  Epoch:  141	Loss: 0.9018	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:51:05 [INFO ]  Epoch:  142	Loss: 0.9008	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:51:07 [INFO ]  Epoch:  143	Loss: 0.8684	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:51:08 [INFO ]  Epoch:  144	Loss: 0.8994	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:51:11 [INFO ]  Epoch:  145	Loss: 0.8570	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:51:12 [INFO ]  Epoch:  146	Loss: 0.8978	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:51:14 [INFO ]  Epoch:  147	Loss: 0.8742	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:51:16 [INFO ]  Epoch:  148	Loss: 0.8637	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:51:18 [INFO ]  Epoch:  149	Loss: 0.8398	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:51:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 07:51:22 [INFO ]  
2022-10-03 07:51:22 [INFO ]  Begin of epoch 150 :
2022-10-03 07:51:25 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:51:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:51:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:51:25 [INFO ]  	   step  1 (lr=0.279453)                   73.20%                   0.9275
2022-10-03 07:51:25 [INFO ]  
2022-10-03 07:51:25 [INFO ]  Epoch:  150	Loss: 0.9065	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:51:26 [INFO ]  Epoch:  151	Loss: 0.8757	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:51:28 [INFO ]  Epoch:  152	Loss: 0.8347	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:51:30 [INFO ]  Epoch:  153	Loss: 0.8616	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:51:32 [INFO ]  Epoch:  154	Loss: 0.8163	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:51:34 [INFO ]  Epoch:  155	Loss: 0.8495	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:51:36 [INFO ]  Epoch:  156	Loss: 0.8263	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:51:38 [INFO ]  Epoch:  157	Loss: 0.8316	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:51:40 [INFO ]  Epoch:  158	Loss: 0.8089	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:51:42 [INFO ]  Epoch:  159	Loss: 0.9002	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:51:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 07:51:45 [INFO ]  
2022-10-03 07:51:45 [INFO ]  Begin of epoch 160 :
2022-10-03 07:51:49 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:51:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:51:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:51:49 [INFO ]  	   step  1 (lr=0.279934)                   74.92%                   0.8919
2022-10-03 07:51:49 [INFO ]  
2022-10-03 07:51:49 [INFO ]  Epoch:  160	Loss: 0.7951	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:51:50 [INFO ]  Epoch:  161	Loss: 0.9147	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:51:52 [INFO ]  Epoch:  162	Loss: 0.7602	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:51:54 [INFO ]  Epoch:  163	Loss: 0.8512	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:51:56 [INFO ]  Epoch:  164	Loss: 0.8544	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:51:58 [INFO ]  Epoch:  165	Loss: 0.8423	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:52:00 [INFO ]  Epoch:  166	Loss: 0.8336	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:52:02 [INFO ]  Epoch:  167	Loss: 0.8028	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:52:04 [INFO ]  Epoch:  168	Loss: 0.9059	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:52:06 [INFO ]  Epoch:  169	Loss: 0.8424	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 07:52:10 [INFO ]  
2022-10-03 07:52:10 [INFO ]  Begin of epoch 170 :
2022-10-03 07:52:13 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:52:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:52:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:52:13 [INFO ]  	   step  1 (lr=0.280320)                   74.61%                   0.8926
2022-10-03 07:52:13 [INFO ]  
2022-10-03 07:52:13 [INFO ]  Epoch:  170	Loss: 0.8119	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:52:15 [INFO ]  Epoch:  171	Loss: 0.8930	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:52:17 [INFO ]  Epoch:  172	Loss: 0.8500	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:52:19 [INFO ]  Epoch:  173	Loss: 0.8465	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:52:21 [INFO ]  Epoch:  174	Loss: 0.8900	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:22 [INFO ]  Epoch:  175	Loss: 0.8552	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:52:24 [INFO ]  Epoch:  176	Loss: 0.8171	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:26 [INFO ]  Epoch:  177	Loss: 0.8144	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:52:28 [INFO ]  Epoch:  178	Loss: 0.8823	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:52:30 [INFO ]  Epoch:  179	Loss: 0.7945	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:52:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 07:52:34 [INFO ]  
2022-10-03 07:52:34 [INFO ]  Begin of epoch 180 :
2022-10-03 07:52:38 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:52:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:52:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:52:38 [INFO ]  	   step  1 (lr=0.280709)                   75.20%                   0.8751
2022-10-03 07:52:38 [INFO ]  
2022-10-03 07:52:38 [INFO ]  Epoch:  180	Loss: 0.7940	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:52:40 [INFO ]  Epoch:  181	Loss: 0.8556	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:52:41 [INFO ]  Epoch:  182	Loss: 0.8377	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:52:43 [INFO ]  Epoch:  183	Loss: 0.8306	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:52:45 [INFO ]  Epoch:  184	Loss: 0.8768	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:47 [INFO ]  Epoch:  185	Loss: 0.8020	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:52:49 [INFO ]  Epoch:  186	Loss: 0.7817	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:51 [INFO ]  Epoch:  187	Loss: 0.8250	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:52:53 [INFO ]  Epoch:  188	Loss: 0.7530	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:52:55 [INFO ]  Epoch:  189	Loss: 0.7776	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 07:52:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 07:52:59 [INFO ]  
2022-10-03 07:52:59 [INFO ]  Begin of epoch 190 :
2022-10-03 07:53:02 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:53:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:53:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:53:02 [INFO ]  	   step  1 (lr=0.281283)                   75.58%                   0.8667
2022-10-03 07:53:02 [INFO ]  
2022-10-03 07:53:02 [INFO ]  Epoch:  190	Loss: 0.8540	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:53:04 [INFO ]  Epoch:  191	Loss: 0.8260	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:53:07 [INFO ]  Epoch:  192	Loss: 0.9048	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:53:09 [INFO ]  Epoch:  193	Loss: 0.8670	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:53:10 [INFO ]  Epoch:  194	Loss: 0.8903	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:53:12 [INFO ]  Epoch:  195	Loss: 0.8225	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:53:14 [INFO ]  Epoch:  196	Loss: 0.7984	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:53:16 [INFO ]  Epoch:  197	Loss: 0.8422	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:53:18 [INFO ]  Epoch:  198	Loss: 0.7943	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:53:19 [INFO ]  Epoch:  199	Loss: 0.8475	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:53:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 07:53:23 [INFO ]  
2022-10-03 07:53:23 [INFO ]  Final evaluation for SVHN :
2022-10-03 07:53:26 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:53:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:53:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:53:26 [INFO ]  	   step  1 (lr=0.280908)                   75.77%                   0.8699
2022-10-03 07:53:26 [INFO ]  
2022-10-03 07:53:26 [INFO ]  
2022-10-03 07:53:26 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 07:53:29 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:53:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:53:29 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 07:53:29 [INFO ]  	   step  1 (lr=0.280908)                   18.41%                   4.6977
2022-10-03 07:53:29 [INFO ]  
2022-10-03 07:54:27 [INFO ]  ======================================== 2022-10-03 07:54:27 ========================================
2022-10-03 07:54:27 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 07:54:27 [INFO ]  Options: 
2022-10-03 07:54:27 [INFO ]  	base_dir: null
2022-10-03 07:54:27 [INFO ]  	batch_size: 1024
2022-10-03 07:54:27 [INFO ]  	checkpoint_interval: 10
2022-10-03 07:54:27 [INFO ]  	dataset: SVHN
2022-10-03 07:54:27 [INFO ]  	dataset_labels:
2022-10-03 07:54:27 [INFO ]  	- 0
2022-10-03 07:54:27 [INFO ]  	- 1
2022-10-03 07:54:27 [INFO ]  	- 2
2022-10-03 07:54:27 [INFO ]  	- 3
2022-10-03 07:54:27 [INFO ]  	- 4
2022-10-03 07:54:27 [INFO ]  	- 5
2022-10-03 07:54:27 [INFO ]  	- 6
2022-10-03 07:54:27 [INFO ]  	- 7
2022-10-03 07:54:27 [INFO ]  	- 8
2022-10-03 07:54:27 [INFO ]  	- 9
2022-10-03 07:54:27 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 07:54:27 [INFO ]  	- !!python/tuple
2022-10-03 07:54:27 [INFO ]  	    - 0.4379104971885681
2022-10-03 07:54:27 [INFO ]  	    - 0.44398033618927
2022-10-03 07:54:27 [INFO ]  	    - 0.4729299545288086
2022-10-03 07:54:27 [INFO ]  	- !!python/tuple
2022-10-03 07:54:27 [INFO ]  	    - 0.19803012907505035
2022-10-03 07:54:27 [INFO ]  	    - 0.2010156363248825
2022-10-03 07:54:27 [INFO ]  	    - 0.19703614711761475
2022-10-03 07:54:27 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 07:54:27 [INFO ]  	decay_epochs: 50
2022-10-03 07:54:27 [INFO ]  	decay_factor: 0.1
2022-10-03 07:54:27 [INFO ]  	device_id: 0
2022-10-03 07:54:27 [INFO ]  	distill_epochs: 1
2022-10-03 07:54:27 [INFO ]  	distill_lr: 0.02
2022-10-03 07:54:27 [INFO ]  	distill_steps: 1
2022-10-03 07:54:27 [INFO ]  	epochs: 200
2022-10-03 07:54:27 [INFO ]  	expand_cls: false
2022-10-03 07:54:27 [INFO ]  	forgetting_dataset: null
2022-10-03 07:54:27 [INFO ]  	init: xavier
2022-10-03 07:54:27 [INFO ]  	init_param: 1.0
2022-10-03 07:54:27 [INFO ]  	input_size: 32
2022-10-03 07:54:27 [INFO ]  	ipc: 2
2022-10-03 07:54:27 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 07:54:27 [INFO ]  	log_interval: 100
2022-10-03 07:54:27 [INFO ]  	log_level: INFO
2022-10-03 07:54:27 [INFO ]  	lr: 0.01
2022-10-03 07:54:27 [INFO ]  	mode: distill_adapt
2022-10-03 07:54:27 [INFO ]  	nc: 3
2022-10-03 07:54:27 [INFO ]  	num_classes: 10
2022-10-03 07:54:27 [INFO ]  	num_workers: 8
2022-10-03 07:54:27 [INFO ]  	phase: train
2022-10-03 07:54:27 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 07:54:27 [INFO ]  	start_time: '2022-10-03 07:54:27'
2022-10-03 07:54:27 [INFO ]  	test_batch_size: 1024
2022-10-03 07:54:27 [INFO ]  	
2022-10-03 07:54:29 [INFO ]  train dataset size:	73257
2022-10-03 07:54:29 [INFO ]  test dataset size: 	26032
2022-10-03 07:54:29 [INFO ]  datasets built!
2022-10-03 07:54:29 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 07:54:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 07:54:33 [INFO ]  
2022-10-03 07:54:33 [INFO ]  Begin of epoch 0 :
2022-10-03 07:54:36 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:54:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:54:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:54:36 [INFO ]  	   step  1 (lr=0.020000)                    6.94%                   8.9556
2022-10-03 07:54:36 [INFO ]  
2022-10-03 07:54:36 [INFO ]  Epoch:    0	Loss: 9.1377	Data Time: 0.36s	Train Time: 0.03s
2022-10-03 07:54:38 [INFO ]  Epoch:    1	Loss: 3.3107	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:54:40 [INFO ]  Epoch:    2	Loss: 2.5839	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:54:42 [INFO ]  Epoch:    3	Loss: 2.3447	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:54:43 [INFO ]  Epoch:    4	Loss: 2.2858	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:54:45 [INFO ]  Epoch:    5	Loss: 2.2178	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:54:47 [INFO ]  Epoch:    6	Loss: 2.1883	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:54:49 [INFO ]  Epoch:    7	Loss: 2.1698	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:54:51 [INFO ]  Epoch:    8	Loss: 2.1573	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:54:53 [INFO ]  Epoch:    9	Loss: 2.1136	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:54:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 07:54:56 [INFO ]  
2022-10-03 07:54:56 [INFO ]  Begin of epoch 10 :
2022-10-03 07:55:00 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:55:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:55:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:55:00 [INFO ]  	   step  1 (lr=0.054238)                   32.86%                   2.0489
2022-10-03 07:55:00 [INFO ]  
2022-10-03 07:55:00 [INFO ]  Epoch:   10	Loss: 2.0360	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 07:55:01 [INFO ]  Epoch:   11	Loss: 2.0466	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:55:03 [INFO ]  Epoch:   12	Loss: 1.9374	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:05 [INFO ]  Epoch:   13	Loss: 1.7722	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:07 [INFO ]  Epoch:   14	Loss: 1.8155	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:09 [INFO ]  Epoch:   15	Loss: 1.6488	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:55:11 [INFO ]  Epoch:   16	Loss: 1.8015	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:13 [INFO ]  Epoch:   17	Loss: 1.6037	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:14 [INFO ]  Epoch:   18	Loss: 1.6110	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:16 [INFO ]  Epoch:   19	Loss: 1.4726	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 07:55:20 [INFO ]  
2022-10-03 07:55:20 [INFO ]  Begin of epoch 20 :
2022-10-03 07:55:23 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:55:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:55:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:55:23 [INFO ]  	   step  1 (lr=0.166771)                   53.30%                   1.4871
2022-10-03 07:55:23 [INFO ]  
2022-10-03 07:55:23 [INFO ]  Epoch:   20	Loss: 1.4095	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:25 [INFO ]  Epoch:   21	Loss: 1.3935	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:27 [INFO ]  Epoch:   22	Loss: 1.3185	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:29 [INFO ]  Epoch:   23	Loss: 1.2857	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:30 [INFO ]  Epoch:   24	Loss: 1.2841	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:32 [INFO ]  Epoch:   25	Loss: 1.4307	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:55:34 [INFO ]  Epoch:   26	Loss: 1.2665	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:55:36 [INFO ]  Epoch:   27	Loss: 1.1942	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:55:38 [INFO ]  Epoch:   28	Loss: 1.3684	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:40 [INFO ]  Epoch:   29	Loss: 1.2377	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:55:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 07:55:43 [INFO ]  
2022-10-03 07:55:43 [INFO ]  Begin of epoch 30 :
2022-10-03 07:55:47 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:55:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:55:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:55:47 [INFO ]  	   step  1 (lr=0.227527)                   63.65%                   1.2433
2022-10-03 07:55:47 [INFO ]  
2022-10-03 07:55:47 [INFO ]  Epoch:   30	Loss: 1.1536	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:55:48 [INFO ]  Epoch:   31	Loss: 1.1757	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:50 [INFO ]  Epoch:   32	Loss: 1.1561	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:52 [INFO ]  Epoch:   33	Loss: 1.1523	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:54 [INFO ]  Epoch:   34	Loss: 1.0658	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:55:56 [INFO ]  Epoch:   35	Loss: 1.2194	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:55:57 [INFO ]  Epoch:   36	Loss: 1.0842	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:55:59 [INFO ]  Epoch:   37	Loss: 1.5708	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:01 [INFO ]  Epoch:   38	Loss: 1.0500	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:56:03 [INFO ]  Epoch:   39	Loss: 1.2469	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:56:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 07:56:07 [INFO ]  
2022-10-03 07:56:07 [INFO ]  Begin of epoch 40 :
2022-10-03 07:56:10 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:56:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:56:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:56:10 [INFO ]  	   step  1 (lr=0.262338)                   63.86%                   1.2516
2022-10-03 07:56:10 [INFO ]  
2022-10-03 07:56:10 [INFO ]  Epoch:   40	Loss: 1.1446	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 07:56:12 [INFO ]  Epoch:   41	Loss: 0.9843	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:56:14 [INFO ]  Epoch:   42	Loss: 1.0383	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:16 [INFO ]  Epoch:   43	Loss: 0.9478	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:18 [INFO ]  Epoch:   44	Loss: 0.9377	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:56:19 [INFO ]  Epoch:   45	Loss: 0.9701	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:56:21 [INFO ]  Epoch:   46	Loss: 0.9850	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:23 [INFO ]  Epoch:   47	Loss: 0.8233	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:25 [INFO ]  Epoch:   48	Loss: 0.8218	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:27 [INFO ]  Epoch:   49	Loss: 0.9540	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 07:56:30 [INFO ]  
2022-10-03 07:56:30 [INFO ]  Begin of epoch 50 :
2022-10-03 07:56:34 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:56:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:56:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:56:34 [INFO ]  	   step  1 (lr=0.267520)                   73.95%                   0.9126
2022-10-03 07:56:34 [INFO ]  
2022-10-03 07:56:34 [INFO ]  Epoch:   50	Loss: 0.8800	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:35 [INFO ]  Epoch:   51	Loss: 0.8413	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:37 [INFO ]  Epoch:   52	Loss: 0.8424	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:56:39 [INFO ]  Epoch:   53	Loss: 0.8042	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:56:41 [INFO ]  Epoch:   54	Loss: 0.8582	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:56:43 [INFO ]  Epoch:   55	Loss: 0.7948	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:56:44 [INFO ]  Epoch:   56	Loss: 0.8760	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:56:46 [INFO ]  Epoch:   57	Loss: 0.8225	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:48 [INFO ]  Epoch:   58	Loss: 0.9108	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:50 [INFO ]  Epoch:   59	Loss: 0.8706	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:56:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 07:56:54 [INFO ]  
2022-10-03 07:56:54 [INFO ]  Begin of epoch 60 :
2022-10-03 07:56:57 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:56:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:56:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:56:57 [INFO ]  	   step  1 (lr=0.280536)                   69.91%                   1.0417
2022-10-03 07:56:57 [INFO ]  
2022-10-03 07:56:57 [INFO ]  Epoch:   60	Loss: 0.9599	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 07:56:59 [INFO ]  Epoch:   61	Loss: 0.7980	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:57:01 [INFO ]  Epoch:   62	Loss: 0.8887	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:57:02 [INFO ]  Epoch:   63	Loss: 0.8758	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:57:04 [INFO ]  Epoch:   64	Loss: 0.8194	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:57:06 [INFO ]  Epoch:   65	Loss: 0.8668	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:08 [INFO ]  Epoch:   66	Loss: 0.8886	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:10 [INFO ]  Epoch:   67	Loss: 0.7940	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:57:12 [INFO ]  Epoch:   68	Loss: 0.8243	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:57:14 [INFO ]  Epoch:   69	Loss: 0.7791	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:57:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 07:57:17 [INFO ]  
2022-10-03 07:57:17 [INFO ]  Begin of epoch 70 :
2022-10-03 07:57:21 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:57:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:57:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:57:21 [INFO ]  	   step  1 (lr=0.288301)                   76.51%                   0.8468
2022-10-03 07:57:21 [INFO ]  
2022-10-03 07:57:21 [INFO ]  Epoch:   70	Loss: 0.8274	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 07:57:23 [INFO ]  Epoch:   71	Loss: 0.7557	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:57:25 [INFO ]  Epoch:   72	Loss: 0.8071	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:57:27 [INFO ]  Epoch:   73	Loss: 0.8610	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:57:29 [INFO ]  Epoch:   74	Loss: 0.9248	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:57:31 [INFO ]  Epoch:   75	Loss: 0.8272	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:57:33 [INFO ]  Epoch:   76	Loss: 0.9223	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:34 [INFO ]  Epoch:   77	Loss: 0.8254	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 07:57:36 [INFO ]  Epoch:   78	Loss: 0.7690	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:38 [INFO ]  Epoch:   79	Loss: 0.8373	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 07:57:42 [INFO ]  
2022-10-03 07:57:42 [INFO ]  Begin of epoch 80 :
2022-10-03 07:57:46 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:57:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:57:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:57:46 [INFO ]  	   step  1 (lr=0.298594)                   75.79%                   0.8548
2022-10-03 07:57:46 [INFO ]  
2022-10-03 07:57:46 [INFO ]  Epoch:   80	Loss: 0.8163	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:57:47 [INFO ]  Epoch:   81	Loss: 0.8946	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:57:49 [INFO ]  Epoch:   82	Loss: 0.8506	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:57:51 [INFO ]  Epoch:   83	Loss: 0.8290	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:57:53 [INFO ]  Epoch:   84	Loss: 0.8184	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:57:55 [INFO ]  Epoch:   85	Loss: 0.8449	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:57:57 [INFO ]  Epoch:   86	Loss: 0.8020	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:57:58 [INFO ]  Epoch:   87	Loss: 0.8552	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:58:00 [INFO ]  Epoch:   88	Loss: 0.7415	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:02 [INFO ]  Epoch:   89	Loss: 0.8259	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 07:58:06 [INFO ]  
2022-10-03 07:58:06 [INFO ]  Begin of epoch 90 :
2022-10-03 07:58:09 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:58:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:58:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:58:09 [INFO ]  	   step  1 (lr=0.304732)                   74.22%                   0.9030
2022-10-03 07:58:09 [INFO ]  
2022-10-03 07:58:09 [INFO ]  Epoch:   90	Loss: 0.7901	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:11 [INFO ]  Epoch:   91	Loss: 0.7867	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:58:13 [INFO ]  Epoch:   92	Loss: 0.8462	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:14 [INFO ]  Epoch:   93	Loss: 0.7636	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:58:17 [INFO ]  Epoch:   94	Loss: 0.8145	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:58:19 [INFO ]  Epoch:   95	Loss: 0.7307	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:58:20 [INFO ]  Epoch:   96	Loss: 0.7255	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:58:22 [INFO ]  Epoch:   97	Loss: 0.7442	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:58:24 [INFO ]  Epoch:   98	Loss: 0.8126	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:58:26 [INFO ]  Epoch:   99	Loss: 0.7659	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:58:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 07:58:30 [INFO ]  
2022-10-03 07:58:30 [INFO ]  Begin of epoch 100 :
2022-10-03 07:58:33 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:58:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:58:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:58:33 [INFO ]  	   step  1 (lr=0.312776)                   77.64%                   0.7991
2022-10-03 07:58:33 [INFO ]  
2022-10-03 07:58:33 [INFO ]  Epoch:  100	Loss: 0.7385	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:58:35 [INFO ]  Epoch:  101	Loss: 0.7401	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:58:36 [INFO ]  Epoch:  102	Loss: 0.7223	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:38 [INFO ]  Epoch:  103	Loss: 0.7611	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:58:40 [INFO ]  Epoch:  104	Loss: 0.7788	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:58:42 [INFO ]  Epoch:  105	Loss: 0.7603	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:44 [INFO ]  Epoch:  106	Loss: 0.6845	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:46 [INFO ]  Epoch:  107	Loss: 0.7581	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:58:48 [INFO ]  Epoch:  108	Loss: 0.7565	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:58:49 [INFO ]  Epoch:  109	Loss: 0.7778	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:58:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 07:58:53 [INFO ]  
2022-10-03 07:58:53 [INFO ]  Begin of epoch 110 :
2022-10-03 07:58:57 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:58:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:58:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:58:57 [INFO ]  	   step  1 (lr=0.315867)                   77.88%                   0.7911
2022-10-03 07:58:57 [INFO ]  
2022-10-03 07:58:57 [INFO ]  Epoch:  110	Loss: 0.8107	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:58:58 [INFO ]  Epoch:  111	Loss: 0.7443	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:59:00 [INFO ]  Epoch:  112	Loss: 0.8412	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:59:02 [INFO ]  Epoch:  113	Loss: 0.7493	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:59:04 [INFO ]  Epoch:  114	Loss: 0.8044	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:05 [INFO ]  Epoch:  115	Loss: 0.8585	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:59:07 [INFO ]  Epoch:  116	Loss: 0.8450	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:09 [INFO ]  Epoch:  117	Loss: 0.7883	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 07:59:11 [INFO ]  Epoch:  118	Loss: 0.7965	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:59:13 [INFO ]  Epoch:  119	Loss: 0.7349	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:59:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 07:59:17 [INFO ]  
2022-10-03 07:59:17 [INFO ]  Begin of epoch 120 :
2022-10-03 07:59:20 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:59:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:59:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:59:20 [INFO ]  	   step  1 (lr=0.313339)                   77.29%                   0.8122
2022-10-03 07:59:20 [INFO ]  
2022-10-03 07:59:20 [INFO ]  Epoch:  120	Loss: 0.7277	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 07:59:22 [INFO ]  Epoch:  121	Loss: 0.7842	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:24 [INFO ]  Epoch:  122	Loss: 0.7941	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:26 [INFO ]  Epoch:  123	Loss: 0.7691	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:59:28 [INFO ]  Epoch:  124	Loss: 0.8095	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 07:59:29 [INFO ]  Epoch:  125	Loss: 0.7436	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 07:59:31 [INFO ]  Epoch:  126	Loss: 0.7383	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 07:59:33 [INFO ]  Epoch:  127	Loss: 0.7307	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:35 [INFO ]  Epoch:  128	Loss: 0.8222	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:59:37 [INFO ]  Epoch:  129	Loss: 0.7098	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 07:59:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 07:59:41 [INFO ]  
2022-10-03 07:59:41 [INFO ]  Begin of epoch 130 :
2022-10-03 07:59:44 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 07:59:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 07:59:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 07:59:44 [INFO ]  	   step  1 (lr=0.316005)                   77.93%                   0.7990
2022-10-03 07:59:44 [INFO ]  
2022-10-03 07:59:44 [INFO ]  Epoch:  130	Loss: 0.7117	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 07:59:46 [INFO ]  Epoch:  131	Loss: 0.7666	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:48 [INFO ]  Epoch:  132	Loss: 0.7122	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:50 [INFO ]  Epoch:  133	Loss: 0.7235	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 07:59:51 [INFO ]  Epoch:  134	Loss: 0.7573	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 07:59:53 [INFO ]  Epoch:  135	Loss: 0.8496	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 07:59:55 [INFO ]  Epoch:  136	Loss: 0.7836	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:59:57 [INFO ]  Epoch:  137	Loss: 0.7970	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 07:59:59 [INFO ]  Epoch:  138	Loss: 0.7478	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:01 [INFO ]  Epoch:  139	Loss: 0.8235	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:00:05 [INFO ]  
2022-10-03 08:00:05 [INFO ]  Begin of epoch 140 :
2022-10-03 08:00:08 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:00:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:00:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:00:08 [INFO ]  	   step  1 (lr=0.317278)                   77.15%                   0.8120
2022-10-03 08:00:08 [INFO ]  
2022-10-03 08:00:08 [INFO ]  Epoch:  140	Loss: 0.7861	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:10 [INFO ]  Epoch:  141	Loss: 0.7736	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:12 [INFO ]  Epoch:  142	Loss: 0.7547	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:00:14 [INFO ]  Epoch:  143	Loss: 0.7137	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:00:16 [INFO ]  Epoch:  144	Loss: 0.7734	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:18 [INFO ]  Epoch:  145	Loss: 0.7421	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:00:20 [INFO ]  Epoch:  146	Loss: 0.7525	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:00:21 [INFO ]  Epoch:  147	Loss: 0.7986	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:23 [INFO ]  Epoch:  148	Loss: 0.7215	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:25 [INFO ]  Epoch:  149	Loss: 0.7907	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:00:29 [INFO ]  
2022-10-03 08:00:29 [INFO ]  Begin of epoch 150 :
2022-10-03 08:00:32 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:00:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:00:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:00:32 [INFO ]  	   step  1 (lr=0.315693)                   76.62%                   0.8258
2022-10-03 08:00:32 [INFO ]  
2022-10-03 08:00:32 [INFO ]  Epoch:  150	Loss: 0.8146	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:34 [INFO ]  Epoch:  151	Loss: 0.7776	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:00:36 [INFO ]  Epoch:  152	Loss: 0.7575	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:38 [INFO ]  Epoch:  153	Loss: 0.7483	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:00:40 [INFO ]  Epoch:  154	Loss: 0.7485	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:00:42 [INFO ]  Epoch:  155	Loss: 0.7095	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:00:44 [INFO ]  Epoch:  156	Loss: 0.7403	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:00:46 [INFO ]  Epoch:  157	Loss: 0.7359	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:48 [INFO ]  Epoch:  158	Loss: 0.7274	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:00:50 [INFO ]  Epoch:  159	Loss: 0.7391	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:00:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:00:54 [INFO ]  
2022-10-03 08:00:54 [INFO ]  Begin of epoch 160 :
2022-10-03 08:00:57 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:00:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:00:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:00:57 [INFO ]  	   step  1 (lr=0.315365)                   77.32%                   0.8073
2022-10-03 08:00:57 [INFO ]  
2022-10-03 08:00:57 [INFO ]  Epoch:  160	Loss: 0.7358	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:00:59 [INFO ]  Epoch:  161	Loss: 0.7377	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:01:01 [INFO ]  Epoch:  162	Loss: 0.7462	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:03 [INFO ]  Epoch:  163	Loss: 0.7113	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:01:05 [INFO ]  Epoch:  164	Loss: 0.7202	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:07 [INFO ]  Epoch:  165	Loss: 0.7660	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:01:08 [INFO ]  Epoch:  166	Loss: 0.8094	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:01:10 [INFO ]  Epoch:  167	Loss: 0.7864	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:12 [INFO ]  Epoch:  168	Loss: 0.8073	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:01:14 [INFO ]  Epoch:  169	Loss: 0.6758	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:01:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:01:18 [INFO ]  
2022-10-03 08:01:18 [INFO ]  Begin of epoch 170 :
2022-10-03 08:01:21 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:01:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:01:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:01:21 [INFO ]  	   step  1 (lr=0.315222)                   77.47%                   0.8054
2022-10-03 08:01:21 [INFO ]  
2022-10-03 08:01:21 [INFO ]  Epoch:  170	Loss: 0.6936	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:01:23 [INFO ]  Epoch:  171	Loss: 0.8052	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:01:25 [INFO ]  Epoch:  172	Loss: 0.7915	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:01:27 [INFO ]  Epoch:  173	Loss: 0.7947	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:29 [INFO ]  Epoch:  174	Loss: 0.7369	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:01:31 [INFO ]  Epoch:  175	Loss: 0.7789	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:01:32 [INFO ]  Epoch:  176	Loss: 0.7882	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:34 [INFO ]  Epoch:  177	Loss: 0.7503	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:01:36 [INFO ]  Epoch:  178	Loss: 0.7316	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:01:38 [INFO ]  Epoch:  179	Loss: 0.7972	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:01:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:01:42 [INFO ]  
2022-10-03 08:01:42 [INFO ]  Begin of epoch 180 :
2022-10-03 08:01:46 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:01:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:01:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:01:46 [INFO ]  	   step  1 (lr=0.315136)                   76.39%                   0.8400
2022-10-03 08:01:46 [INFO ]  
2022-10-03 08:01:46 [INFO ]  Epoch:  180	Loss: 0.7720	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:01:47 [INFO ]  Epoch:  181	Loss: 0.7477	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:01:49 [INFO ]  Epoch:  182	Loss: 0.7978	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:01:51 [INFO ]  Epoch:  183	Loss: 0.7108	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:01:53 [INFO ]  Epoch:  184	Loss: 0.7642	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:01:55 [INFO ]  Epoch:  185	Loss: 0.7499	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:01:57 [INFO ]  Epoch:  186	Loss: 0.7017	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:01:59 [INFO ]  Epoch:  187	Loss: 0.7773	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:01 [INFO ]  Epoch:  188	Loss: 0.7426	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:03 [INFO ]  Epoch:  189	Loss: 0.7471	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:02:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:02:07 [INFO ]  
2022-10-03 08:02:07 [INFO ]  Begin of epoch 190 :
2022-10-03 08:02:10 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:02:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:02:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:02:10 [INFO ]  	   step  1 (lr=0.314955)                   77.08%                   0.8194
2022-10-03 08:02:10 [INFO ]  
2022-10-03 08:02:10 [INFO ]  Epoch:  190	Loss: 0.7936	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:12 [INFO ]  Epoch:  191	Loss: 0.6970	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:14 [INFO ]  Epoch:  192	Loss: 0.7374	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:16 [INFO ]  Epoch:  193	Loss: 0.7511	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:18 [INFO ]  Epoch:  194	Loss: 0.7992	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:02:20 [INFO ]  Epoch:  195	Loss: 0.7488	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:02:22 [INFO ]  Epoch:  196	Loss: 0.8069	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:23 [INFO ]  Epoch:  197	Loss: 0.7731	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:02:25 [INFO ]  Epoch:  198	Loss: 0.8085	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:02:27 [INFO ]  Epoch:  199	Loss: 0.6889	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:02:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:02:31 [INFO ]  
2022-10-03 08:02:31 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:02:34 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:02:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:02:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:02:34 [INFO ]  	   step  1 (lr=0.314633)                   77.58%                   0.8114
2022-10-03 08:02:34 [INFO ]  
2022-10-03 08:02:34 [INFO ]  
2022-10-03 08:02:34 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:02:37 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:02:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:02:37 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:02:37 [INFO ]  	   step  1 (lr=0.314633)                   15.09%                   5.2656
2022-10-03 08:02:37 [INFO ]  
2022-10-03 08:03:28 [INFO ]  ======================================== 2022-10-03 08:03:28 ========================================
2022-10-03 08:03:28 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 08:03:28 [INFO ]  Options: 
2022-10-03 08:03:28 [INFO ]  	base_dir: null
2022-10-03 08:03:28 [INFO ]  	batch_size: 1024
2022-10-03 08:03:28 [INFO ]  	checkpoint_interval: 10
2022-10-03 08:03:28 [INFO ]  	dataset: SVHN
2022-10-03 08:03:28 [INFO ]  	dataset_labels:
2022-10-03 08:03:28 [INFO ]  	- 0
2022-10-03 08:03:28 [INFO ]  	- 1
2022-10-03 08:03:28 [INFO ]  	- 2
2022-10-03 08:03:28 [INFO ]  	- 3
2022-10-03 08:03:28 [INFO ]  	- 4
2022-10-03 08:03:28 [INFO ]  	- 5
2022-10-03 08:03:28 [INFO ]  	- 6
2022-10-03 08:03:28 [INFO ]  	- 7
2022-10-03 08:03:28 [INFO ]  	- 8
2022-10-03 08:03:28 [INFO ]  	- 9
2022-10-03 08:03:28 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 08:03:28 [INFO ]  	- !!python/tuple
2022-10-03 08:03:28 [INFO ]  	    - 0.4379104971885681
2022-10-03 08:03:28 [INFO ]  	    - 0.44398033618927
2022-10-03 08:03:28 [INFO ]  	    - 0.4729299545288086
2022-10-03 08:03:28 [INFO ]  	- !!python/tuple
2022-10-03 08:03:28 [INFO ]  	    - 0.19803012907505035
2022-10-03 08:03:28 [INFO ]  	    - 0.2010156363248825
2022-10-03 08:03:28 [INFO ]  	    - 0.19703614711761475
2022-10-03 08:03:28 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 08:03:28 [INFO ]  	decay_epochs: 50
2022-10-03 08:03:28 [INFO ]  	decay_factor: 0.1
2022-10-03 08:03:28 [INFO ]  	device_id: 0
2022-10-03 08:03:28 [INFO ]  	distill_epochs: 1
2022-10-03 08:03:28 [INFO ]  	distill_lr: 0.02
2022-10-03 08:03:28 [INFO ]  	distill_steps: 1
2022-10-03 08:03:28 [INFO ]  	epochs: 200
2022-10-03 08:03:28 [INFO ]  	expand_cls: false
2022-10-03 08:03:28 [INFO ]  	forgetting_dataset: null
2022-10-03 08:03:28 [INFO ]  	init: xavier
2022-10-03 08:03:28 [INFO ]  	init_param: 1.0
2022-10-03 08:03:28 [INFO ]  	input_size: 32
2022-10-03 08:03:28 [INFO ]  	ipc: 2
2022-10-03 08:03:28 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 08:03:28 [INFO ]  	log_interval: 100
2022-10-03 08:03:28 [INFO ]  	log_level: INFO
2022-10-03 08:03:28 [INFO ]  	lr: 0.01
2022-10-03 08:03:28 [INFO ]  	mode: distill_adapt
2022-10-03 08:03:28 [INFO ]  	nc: 3
2022-10-03 08:03:28 [INFO ]  	num_classes: 10
2022-10-03 08:03:28 [INFO ]  	num_workers: 8
2022-10-03 08:03:28 [INFO ]  	phase: train
2022-10-03 08:03:28 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 08:03:28 [INFO ]  	start_time: '2022-10-03 08:03:28'
2022-10-03 08:03:28 [INFO ]  	test_batch_size: 1024
2022-10-03 08:03:28 [INFO ]  	
2022-10-03 08:03:31 [INFO ]  train dataset size:	73257
2022-10-03 08:03:31 [INFO ]  test dataset size: 	26032
2022-10-03 08:03:31 [INFO ]  datasets built!
2022-10-03 08:03:31 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 08:03:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 08:03:34 [INFO ]  
2022-10-03 08:03:34 [INFO ]  Begin of epoch 0 :
2022-10-03 08:03:38 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:03:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:03:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:03:38 [INFO ]  	   step  1 (lr=0.020000)                    6.95%                   8.3069
2022-10-03 08:03:38 [INFO ]  
2022-10-03 08:03:38 [INFO ]  Epoch:    0	Loss: 7.6884	Data Time: 0.38s	Train Time: 0.03s
2022-10-03 08:03:39 [INFO ]  Epoch:    1	Loss: 3.2447	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:03:41 [INFO ]  Epoch:    2	Loss: 2.6779	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:03:43 [INFO ]  Epoch:    3	Loss: 2.3725	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:03:45 [INFO ]  Epoch:    4	Loss: 2.2682	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:03:47 [INFO ]  Epoch:    5	Loss: 2.1999	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:03:49 [INFO ]  Epoch:    6	Loss: 2.2282	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:03:51 [INFO ]  Epoch:    7	Loss: 2.1663	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:03:52 [INFO ]  Epoch:    8	Loss: 2.1470	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:03:54 [INFO ]  Epoch:    9	Loss: 2.1201	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:03:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 08:03:58 [INFO ]  
2022-10-03 08:03:58 [INFO ]  Begin of epoch 10 :
2022-10-03 08:04:02 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:04:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:04:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:04:02 [INFO ]  	   step  1 (lr=0.057354)                   29.09%                   2.1058
2022-10-03 08:04:02 [INFO ]  
2022-10-03 08:04:02 [INFO ]  Epoch:   10	Loss: 2.0968	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:03 [INFO ]  Epoch:   11	Loss: 2.0334	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:04:05 [INFO ]  Epoch:   12	Loss: 1.9997	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:04:07 [INFO ]  Epoch:   13	Loss: 2.0182	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:09 [INFO ]  Epoch:   14	Loss: 1.7718	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:11 [INFO ]  Epoch:   15	Loss: 1.9185	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:04:13 [INFO ]  Epoch:   16	Loss: 1.6447	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:04:14 [INFO ]  Epoch:   17	Loss: 1.6685	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:04:16 [INFO ]  Epoch:   18	Loss: 1.5702	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:18 [INFO ]  Epoch:   19	Loss: 1.6249	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:04:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 08:04:22 [INFO ]  
2022-10-03 08:04:22 [INFO ]  Begin of epoch 20 :
2022-10-03 08:04:25 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:04:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:04:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:04:25 [INFO ]  	   step  1 (lr=0.161969)                   54.02%                   1.4900
2022-10-03 08:04:25 [INFO ]  
2022-10-03 08:04:25 [INFO ]  Epoch:   20	Loss: 1.4414	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:27 [INFO ]  Epoch:   21	Loss: 1.3286	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:29 [INFO ]  Epoch:   22	Loss: 1.5839	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:31 [INFO ]  Epoch:   23	Loss: 1.4055	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:04:33 [INFO ]  Epoch:   24	Loss: 1.4650	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:04:35 [INFO ]  Epoch:   25	Loss: 1.3873	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:04:37 [INFO ]  Epoch:   26	Loss: 1.3978	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:04:38 [INFO ]  Epoch:   27	Loss: 1.4484	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:04:40 [INFO ]  Epoch:   28	Loss: 1.4083	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:04:42 [INFO ]  Epoch:   29	Loss: 1.3695	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:04:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 08:04:46 [INFO ]  
2022-10-03 08:04:46 [INFO ]  Begin of epoch 30 :
2022-10-03 08:04:49 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:04:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:04:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:04:49 [INFO ]  	   step  1 (lr=0.186846)                   57.89%                   1.3625
2022-10-03 08:04:49 [INFO ]  
2022-10-03 08:04:49 [INFO ]  Epoch:   30	Loss: 1.4499	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 08:04:51 [INFO ]  Epoch:   31	Loss: 1.2686	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:04:53 [INFO ]  Epoch:   32	Loss: 1.5044	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:04:55 [INFO ]  Epoch:   33	Loss: 1.1704	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:04:57 [INFO ]  Epoch:   34	Loss: 1.2842	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:04:59 [INFO ]  Epoch:   35	Loss: 1.3553	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:05:00 [INFO ]  Epoch:   36	Loss: 1.0369	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:02 [INFO ]  Epoch:   37	Loss: 1.2143	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:05:04 [INFO ]  Epoch:   38	Loss: 1.1378	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:05:06 [INFO ]  Epoch:   39	Loss: 1.0842	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 08:05:10 [INFO ]  
2022-10-03 08:05:10 [INFO ]  Begin of epoch 40 :
2022-10-03 08:05:13 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:05:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:05:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:05:13 [INFO ]  	   step  1 (lr=0.228853)                   67.49%                   1.1189
2022-10-03 08:05:13 [INFO ]  
2022-10-03 08:05:13 [INFO ]  Epoch:   40	Loss: 1.0429	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:05:15 [INFO ]  Epoch:   41	Loss: 1.1169	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:17 [INFO ]  Epoch:   42	Loss: 1.1510	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:05:19 [INFO ]  Epoch:   43	Loss: 1.1443	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:21 [INFO ]  Epoch:   44	Loss: 1.5191	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:05:22 [INFO ]  Epoch:   45	Loss: 1.1299	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:05:24 [INFO ]  Epoch:   46	Loss: 1.1808	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:26 [INFO ]  Epoch:   47	Loss: 1.3279	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:28 [INFO ]  Epoch:   48	Loss: 1.1363	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:30 [INFO ]  Epoch:   49	Loss: 1.0596	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:05:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 08:05:34 [INFO ]  
2022-10-03 08:05:34 [INFO ]  Begin of epoch 50 :
2022-10-03 08:05:37 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:05:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:05:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:05:37 [INFO ]  	   step  1 (lr=0.248421)                   72.76%                   0.9777
2022-10-03 08:05:37 [INFO ]  
2022-10-03 08:05:37 [INFO ]  Epoch:   50	Loss: 0.9664	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:39 [INFO ]  Epoch:   51	Loss: 0.9921	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:05:41 [INFO ]  Epoch:   52	Loss: 0.9291	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:43 [INFO ]  Epoch:   53	Loss: 0.9119	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:05:45 [INFO ]  Epoch:   54	Loss: 0.9656	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:47 [INFO ]  Epoch:   55	Loss: 0.9441	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:49 [INFO ]  Epoch:   56	Loss: 0.9980	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:05:50 [INFO ]  Epoch:   57	Loss: 0.9415	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:52 [INFO ]  Epoch:   58	Loss: 0.9744	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:05:54 [INFO ]  Epoch:   59	Loss: 0.8873	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:05:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 08:05:58 [INFO ]  
2022-10-03 08:05:58 [INFO ]  Begin of epoch 60 :
2022-10-03 08:06:01 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:06:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:06:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:06:01 [INFO ]  	   step  1 (lr=0.257080)                   72.83%                   0.9648
2022-10-03 08:06:01 [INFO ]  
2022-10-03 08:06:01 [INFO ]  Epoch:   60	Loss: 0.8829	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:06:03 [INFO ]  Epoch:   61	Loss: 0.8960	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:06:05 [INFO ]  Epoch:   62	Loss: 0.8629	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:06:07 [INFO ]  Epoch:   63	Loss: 0.9375	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:06:09 [INFO ]  Epoch:   64	Loss: 0.8813	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:06:11 [INFO ]  Epoch:   65	Loss: 0.8937	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:06:12 [INFO ]  Epoch:   66	Loss: 0.9674	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:06:14 [INFO ]  Epoch:   67	Loss: 0.8613	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:06:16 [INFO ]  Epoch:   68	Loss: 1.0620	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:06:18 [INFO ]  Epoch:   69	Loss: 0.9790	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:06:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 08:06:22 [INFO ]  
2022-10-03 08:06:22 [INFO ]  Begin of epoch 70 :
2022-10-03 08:06:26 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:06:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:06:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:06:26 [INFO ]  	   step  1 (lr=0.261118)                   73.61%                   0.9432
2022-10-03 08:06:26 [INFO ]  
2022-10-03 08:06:26 [INFO ]  Epoch:   70	Loss: 0.9242	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:06:28 [INFO ]  Epoch:   71	Loss: 0.9688	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:06:30 [INFO ]  Epoch:   72	Loss: 0.9340	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:06:32 [INFO ]  Epoch:   73	Loss: 0.9447	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:06:34 [INFO ]  Epoch:   74	Loss: 0.9126	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:06:36 [INFO ]  Epoch:   75	Loss: 0.9007	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:06:38 [INFO ]  Epoch:   76	Loss: 1.0620	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:06:40 [INFO ]  Epoch:   77	Loss: 0.9096	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:06:42 [INFO ]  Epoch:   78	Loss: 0.9083	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:06:44 [INFO ]  Epoch:   79	Loss: 0.9816	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:06:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 08:06:48 [INFO ]  
2022-10-03 08:06:48 [INFO ]  Begin of epoch 80 :
2022-10-03 08:06:51 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:06:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:06:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:06:51 [INFO ]  	   step  1 (lr=0.265515)                   74.16%                   0.9203
2022-10-03 08:06:51 [INFO ]  
2022-10-03 08:06:51 [INFO ]  Epoch:   80	Loss: 0.8473	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 08:06:53 [INFO ]  Epoch:   81	Loss: 0.9043	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:06:55 [INFO ]  Epoch:   82	Loss: 0.8539	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:06:57 [INFO ]  Epoch:   83	Loss: 0.9210	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:06:59 [INFO ]  Epoch:   84	Loss: 0.9118	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:07:01 [INFO ]  Epoch:   85	Loss: 0.8733	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:07:03 [INFO ]  Epoch:   86	Loss: 0.9287	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:04 [INFO ]  Epoch:   87	Loss: 0.8770	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:06 [INFO ]  Epoch:   88	Loss: 0.9661	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:07:08 [INFO ]  Epoch:   89	Loss: 0.8756	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:07:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 08:07:12 [INFO ]  
2022-10-03 08:07:12 [INFO ]  Begin of epoch 90 :
2022-10-03 08:07:15 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:07:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:07:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:07:15 [INFO ]  	   step  1 (lr=0.268675)                   74.32%                   0.9055
2022-10-03 08:07:15 [INFO ]  
2022-10-03 08:07:15 [INFO ]  Epoch:   90	Loss: 0.9142	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:17 [INFO ]  Epoch:   91	Loss: 0.8949	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:19 [INFO ]  Epoch:   92	Loss: 0.8227	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:07:21 [INFO ]  Epoch:   93	Loss: 0.7831	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:07:23 [INFO ]  Epoch:   94	Loss: 0.8251	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:07:25 [INFO ]  Epoch:   95	Loss: 0.8482	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:07:26 [INFO ]  Epoch:   96	Loss: 0.9004	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:07:28 [INFO ]  Epoch:   97	Loss: 0.8066	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:07:30 [INFO ]  Epoch:   98	Loss: 1.0591	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:32 [INFO ]  Epoch:   99	Loss: 0.9691	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:07:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 08:07:36 [INFO ]  
2022-10-03 08:07:36 [INFO ]  Begin of epoch 100 :
2022-10-03 08:07:39 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:07:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:07:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:07:39 [INFO ]  	   step  1 (lr=0.276105)                   71.53%                   0.9550
2022-10-03 08:07:39 [INFO ]  
2022-10-03 08:07:39 [INFO ]  Epoch:  100	Loss: 0.9135	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:07:41 [INFO ]  Epoch:  101	Loss: 0.9140	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:07:43 [INFO ]  Epoch:  102	Loss: 0.8803	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:07:45 [INFO ]  Epoch:  103	Loss: 0.8558	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:07:47 [INFO ]  Epoch:  104	Loss: 0.9057	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:07:48 [INFO ]  Epoch:  105	Loss: 0.9697	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:07:50 [INFO ]  Epoch:  106	Loss: 0.9874	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:07:52 [INFO ]  Epoch:  107	Loss: 0.9106	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:07:54 [INFO ]  Epoch:  108	Loss: 0.8105	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:07:56 [INFO ]  Epoch:  109	Loss: 0.8828	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 08:08:00 [INFO ]  
2022-10-03 08:08:00 [INFO ]  Begin of epoch 110 :
2022-10-03 08:08:03 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:08:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:08:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:08:03 [INFO ]  	   step  1 (lr=0.279867)                   74.11%                   0.8978
2022-10-03 08:08:03 [INFO ]  
2022-10-03 08:08:03 [INFO ]  Epoch:  110	Loss: 0.7993	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:05 [INFO ]  Epoch:  111	Loss: 0.9821	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:08:07 [INFO ]  Epoch:  112	Loss: 0.8759	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:08:09 [INFO ]  Epoch:  113	Loss: 1.0181	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:08:11 [INFO ]  Epoch:  114	Loss: 0.9552	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:08:12 [INFO ]  Epoch:  115	Loss: 0.9469	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:08:15 [INFO ]  Epoch:  116	Loss: 0.8195	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 08:08:16 [INFO ]  Epoch:  117	Loss: 1.0677	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:08:18 [INFO ]  Epoch:  118	Loss: 0.9691	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:20 [INFO ]  Epoch:  119	Loss: 0.8899	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:08:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 08:08:24 [INFO ]  
2022-10-03 08:08:24 [INFO ]  Begin of epoch 120 :
2022-10-03 08:08:27 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:08:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:08:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:08:27 [INFO ]  	   step  1 (lr=0.281919)                   73.91%                   0.9209
2022-10-03 08:08:27 [INFO ]  
2022-10-03 08:08:27 [INFO ]  Epoch:  120	Loss: 0.8847	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 08:08:29 [INFO ]  Epoch:  121	Loss: 0.9120	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:31 [INFO ]  Epoch:  122	Loss: 0.8952	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:33 [INFO ]  Epoch:  123	Loss: 0.8274	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:08:35 [INFO ]  Epoch:  124	Loss: 0.8031	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:08:37 [INFO ]  Epoch:  125	Loss: 0.8384	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:08:38 [INFO ]  Epoch:  126	Loss: 0.8490	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:40 [INFO ]  Epoch:  127	Loss: 0.7920	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:08:42 [INFO ]  Epoch:  128	Loss: 0.8992	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:08:44 [INFO ]  Epoch:  129	Loss: 0.8394	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 08:08:48 [INFO ]  
2022-10-03 08:08:48 [INFO ]  Begin of epoch 130 :
2022-10-03 08:08:51 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:08:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:08:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:08:51 [INFO ]  	   step  1 (lr=0.285853)                   73.61%                   0.9237
2022-10-03 08:08:51 [INFO ]  
2022-10-03 08:08:51 [INFO ]  Epoch:  130	Loss: 0.8244	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:08:53 [INFO ]  Epoch:  131	Loss: 0.8398	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:08:54 [INFO ]  Epoch:  132	Loss: 0.8659	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:08:57 [INFO ]  Epoch:  133	Loss: 0.8756	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:08:58 [INFO ]  Epoch:  134	Loss: 0.9289	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:09:00 [INFO ]  Epoch:  135	Loss: 0.7981	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:09:02 [INFO ]  Epoch:  136	Loss: 0.8843	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:04 [INFO ]  Epoch:  137	Loss: 0.8267	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:06 [INFO ]  Epoch:  138	Loss: 0.7509	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:09:08 [INFO ]  Epoch:  139	Loss: 0.8300	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:09:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:09:12 [INFO ]  
2022-10-03 08:09:12 [INFO ]  Begin of epoch 140 :
2022-10-03 08:09:15 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:09:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:09:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:09:15 [INFO ]  	   step  1 (lr=0.288278)                   74.83%                   0.8826
2022-10-03 08:09:15 [INFO ]  
2022-10-03 08:09:15 [INFO ]  Epoch:  140	Loss: 0.8181	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:09:17 [INFO ]  Epoch:  141	Loss: 0.8362	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:09:19 [INFO ]  Epoch:  142	Loss: 0.7470	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:09:21 [INFO ]  Epoch:  143	Loss: 0.8130	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:09:23 [INFO ]  Epoch:  144	Loss: 0.8235	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:25 [INFO ]  Epoch:  145	Loss: 0.8558	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:26 [INFO ]  Epoch:  146	Loss: 0.8391	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:09:28 [INFO ]  Epoch:  147	Loss: 0.8454	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:09:30 [INFO ]  Epoch:  148	Loss: 0.8131	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:09:32 [INFO ]  Epoch:  149	Loss: 0.7813	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:09:36 [INFO ]  
2022-10-03 08:09:36 [INFO ]  Begin of epoch 150 :
2022-10-03 08:09:39 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:09:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:09:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:09:39 [INFO ]  	   step  1 (lr=0.290462)                   75.35%                   0.8766
2022-10-03 08:09:39 [INFO ]  
2022-10-03 08:09:39 [INFO ]  Epoch:  150	Loss: 0.7974	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:09:41 [INFO ]  Epoch:  151	Loss: 0.8763	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:09:43 [INFO ]  Epoch:  152	Loss: 0.8311	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:44 [INFO ]  Epoch:  153	Loss: 0.7559	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:46 [INFO ]  Epoch:  154	Loss: 0.8073	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:48 [INFO ]  Epoch:  155	Loss: 0.8294	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:09:50 [INFO ]  Epoch:  156	Loss: 0.7522	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:09:52 [INFO ]  Epoch:  157	Loss: 0.7455	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:54 [INFO ]  Epoch:  158	Loss: 0.9052	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:09:56 [INFO ]  Epoch:  159	Loss: 0.8350	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:09:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:09:59 [INFO ]  
2022-10-03 08:09:59 [INFO ]  Begin of epoch 160 :
2022-10-03 08:10:03 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:10:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:10:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:10:03 [INFO ]  	   step  1 (lr=0.290791)                   75.69%                   0.8656
2022-10-03 08:10:03 [INFO ]  
2022-10-03 08:10:03 [INFO ]  Epoch:  160	Loss: 0.8490	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:10:04 [INFO ]  Epoch:  161	Loss: 0.7862	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:10:06 [INFO ]  Epoch:  162	Loss: 0.7986	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:10:08 [INFO ]  Epoch:  163	Loss: 0.8292	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:10:10 [INFO ]  Epoch:  164	Loss: 0.8379	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:10:12 [INFO ]  Epoch:  165	Loss: 0.8305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:10:13 [INFO ]  Epoch:  166	Loss: 0.8666	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:10:16 [INFO ]  Epoch:  167	Loss: 0.8197	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:10:18 [INFO ]  Epoch:  168	Loss: 0.7947	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:10:19 [INFO ]  Epoch:  169	Loss: 0.7968	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:10:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:10:23 [INFO ]  
2022-10-03 08:10:23 [INFO ]  Begin of epoch 170 :
2022-10-03 08:10:26 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:10:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:10:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:10:26 [INFO ]  	   step  1 (lr=0.291395)                   75.53%                   0.8673
2022-10-03 08:10:26 [INFO ]  
2022-10-03 08:10:26 [INFO ]  Epoch:  170	Loss: 0.7897	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 08:10:28 [INFO ]  Epoch:  171	Loss: 0.8477	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:10:30 [INFO ]  Epoch:  172	Loss: 0.7551	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:10:32 [INFO ]  Epoch:  173	Loss: 0.8656	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:10:34 [INFO ]  Epoch:  174	Loss: 0.8225	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:10:35 [INFO ]  Epoch:  175	Loss: 0.8288	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:10:37 [INFO ]  Epoch:  176	Loss: 0.8119	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:10:39 [INFO ]  Epoch:  177	Loss: 0.8290	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:10:41 [INFO ]  Epoch:  178	Loss: 0.8697	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:10:43 [INFO ]  Epoch:  179	Loss: 0.8272	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:10:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:10:47 [INFO ]  
2022-10-03 08:10:47 [INFO ]  Begin of epoch 180 :
2022-10-03 08:10:51 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:10:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:10:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:10:51 [INFO ]  	   step  1 (lr=0.291455)                   75.49%                   0.8657
2022-10-03 08:10:51 [INFO ]  
2022-10-03 08:10:51 [INFO ]  Epoch:  180	Loss: 0.7757	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:10:52 [INFO ]  Epoch:  181	Loss: 0.8210	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:10:54 [INFO ]  Epoch:  182	Loss: 0.8336	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:10:56 [INFO ]  Epoch:  183	Loss: 0.8478	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:10:58 [INFO ]  Epoch:  184	Loss: 0.6988	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:00 [INFO ]  Epoch:  185	Loss: 0.8621	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:11:02 [INFO ]  Epoch:  186	Loss: 0.8238	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:04 [INFO ]  Epoch:  187	Loss: 0.7845	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:11:06 [INFO ]  Epoch:  188	Loss: 0.8751	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:11:08 [INFO ]  Epoch:  189	Loss: 0.8816	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:11:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:11:12 [INFO ]  
2022-10-03 08:11:12 [INFO ]  Begin of epoch 190 :
2022-10-03 08:11:15 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:11:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:11:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:11:15 [INFO ]  	   step  1 (lr=0.291916)                   60.44%                   1.4018
2022-10-03 08:11:15 [INFO ]  
2022-10-03 08:11:15 [INFO ]  Epoch:  190	Loss: 1.2730	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:17 [INFO ]  Epoch:  191	Loss: 1.0990	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:19 [INFO ]  Epoch:  192	Loss: 0.9593	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:21 [INFO ]  Epoch:  193	Loss: 0.9041	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:11:23 [INFO ]  Epoch:  194	Loss: 0.9410	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:11:25 [INFO ]  Epoch:  195	Loss: 0.9228	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:11:27 [INFO ]  Epoch:  196	Loss: 0.9696	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:11:29 [INFO ]  Epoch:  197	Loss: 1.0182	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:11:30 [INFO ]  Epoch:  198	Loss: 0.9463	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:11:32 [INFO ]  Epoch:  199	Loss: 0.8405	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:11:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:11:36 [INFO ]  
2022-10-03 08:11:36 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:11:39 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:11:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:11:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:11:39 [INFO ]  	   step  1 (lr=0.292007)                   73.64%                   0.9443
2022-10-03 08:11:39 [INFO ]  
2022-10-03 08:11:39 [INFO ]  
2022-10-03 08:11:39 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:11:42 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:11:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:11:42 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:11:42 [INFO ]  	   step  1 (lr=0.292007)                   16.60%                   5.0346
2022-10-03 08:11:42 [INFO ]  
2022-10-03 08:12:49 [INFO ]  ======================================== 2022-10-03 08:12:49 ========================================
2022-10-03 08:12:49 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 08:12:49 [INFO ]  Options: 
2022-10-03 08:12:49 [INFO ]  	base_dir: null
2022-10-03 08:12:49 [INFO ]  	batch_size: 1024
2022-10-03 08:12:49 [INFO ]  	checkpoint_interval: 10
2022-10-03 08:12:49 [INFO ]  	dataset: SVHN
2022-10-03 08:12:49 [INFO ]  	dataset_labels:
2022-10-03 08:12:49 [INFO ]  	- 0
2022-10-03 08:12:49 [INFO ]  	- 1
2022-10-03 08:12:49 [INFO ]  	- 2
2022-10-03 08:12:49 [INFO ]  	- 3
2022-10-03 08:12:49 [INFO ]  	- 4
2022-10-03 08:12:49 [INFO ]  	- 5
2022-10-03 08:12:49 [INFO ]  	- 6
2022-10-03 08:12:49 [INFO ]  	- 7
2022-10-03 08:12:49 [INFO ]  	- 8
2022-10-03 08:12:49 [INFO ]  	- 9
2022-10-03 08:12:49 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 08:12:49 [INFO ]  	- !!python/tuple
2022-10-03 08:12:49 [INFO ]  	    - 0.4379104971885681
2022-10-03 08:12:49 [INFO ]  	    - 0.44398033618927
2022-10-03 08:12:49 [INFO ]  	    - 0.4729299545288086
2022-10-03 08:12:49 [INFO ]  	- !!python/tuple
2022-10-03 08:12:49 [INFO ]  	    - 0.19803012907505035
2022-10-03 08:12:49 [INFO ]  	    - 0.2010156363248825
2022-10-03 08:12:49 [INFO ]  	    - 0.19703614711761475
2022-10-03 08:12:49 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 08:12:49 [INFO ]  	decay_epochs: 50
2022-10-03 08:12:49 [INFO ]  	decay_factor: 0.1
2022-10-03 08:12:49 [INFO ]  	device_id: 0
2022-10-03 08:12:49 [INFO ]  	distill_epochs: 1
2022-10-03 08:12:49 [INFO ]  	distill_lr: 0.02
2022-10-03 08:12:49 [INFO ]  	distill_steps: 1
2022-10-03 08:12:49 [INFO ]  	epochs: 200
2022-10-03 08:12:49 [INFO ]  	expand_cls: false
2022-10-03 08:12:49 [INFO ]  	forgetting_dataset: null
2022-10-03 08:12:49 [INFO ]  	init: xavier
2022-10-03 08:12:49 [INFO ]  	init_param: 1.0
2022-10-03 08:12:49 [INFO ]  	input_size: 32
2022-10-03 08:12:49 [INFO ]  	ipc: 2
2022-10-03 08:12:49 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 08:12:49 [INFO ]  	log_interval: 100
2022-10-03 08:12:49 [INFO ]  	log_level: INFO
2022-10-03 08:12:49 [INFO ]  	lr: 0.01
2022-10-03 08:12:49 [INFO ]  	mode: distill_adapt
2022-10-03 08:12:49 [INFO ]  	nc: 3
2022-10-03 08:12:49 [INFO ]  	num_classes: 10
2022-10-03 08:12:49 [INFO ]  	num_workers: 8
2022-10-03 08:12:49 [INFO ]  	phase: train
2022-10-03 08:12:49 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 08:12:49 [INFO ]  	start_time: '2022-10-03 08:12:49'
2022-10-03 08:12:49 [INFO ]  	test_batch_size: 1024
2022-10-03 08:12:49 [INFO ]  	
2022-10-03 08:12:51 [INFO ]  train dataset size:	73257
2022-10-03 08:12:51 [INFO ]  test dataset size: 	26032
2022-10-03 08:12:51 [INFO ]  datasets built!
2022-10-03 08:12:51 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 08:12:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 08:12:55 [INFO ]  
2022-10-03 08:12:55 [INFO ]  Begin of epoch 0 :
2022-10-03 08:12:58 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:12:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:12:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:12:58 [INFO ]  	   step  1 (lr=0.020000)                   10.35%                   7.3665
2022-10-03 08:12:58 [INFO ]  
2022-10-03 08:12:58 [INFO ]  Epoch:    0	Loss: 7.7393	Data Time: 0.39s	Train Time: 0.03s
2022-10-03 08:13:00 [INFO ]  Epoch:    1	Loss: 3.1850	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:13:02 [INFO ]  Epoch:    2	Loss: 2.5634	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:04 [INFO ]  Epoch:    3	Loss: 2.3581	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:13:06 [INFO ]  Epoch:    4	Loss: 2.2510	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:07 [INFO ]  Epoch:    5	Loss: 2.2515	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:09 [INFO ]  Epoch:    6	Loss: 2.1763	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:11 [INFO ]  Epoch:    7	Loss: 2.1733	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:13:13 [INFO ]  Epoch:    8	Loss: 2.0920	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:13:15 [INFO ]  Epoch:    9	Loss: 2.0870	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:13:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 08:13:19 [INFO ]  
2022-10-03 08:13:19 [INFO ]  Begin of epoch 10 :
2022-10-03 08:13:22 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:13:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:13:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:13:22 [INFO ]  	   step  1 (lr=0.054263)                   35.84%                   2.0167
2022-10-03 08:13:22 [INFO ]  
2022-10-03 08:13:22 [INFO ]  Epoch:   10	Loss: 2.0069	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:24 [INFO ]  Epoch:   11	Loss: 1.9809	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:26 [INFO ]  Epoch:   12	Loss: 1.8221	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:28 [INFO ]  Epoch:   13	Loss: 1.8280	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:13:29 [INFO ]  Epoch:   14	Loss: 1.6311	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:13:31 [INFO ]  Epoch:   15	Loss: 1.4997	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:13:33 [INFO ]  Epoch:   16	Loss: 1.6562	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:35 [INFO ]  Epoch:   17	Loss: 1.5112	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:13:37 [INFO ]  Epoch:   18	Loss: 1.6318	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:39 [INFO ]  Epoch:   19	Loss: 1.4677	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 08:13:43 [INFO ]  
2022-10-03 08:13:43 [INFO ]  Begin of epoch 20 :
2022-10-03 08:13:46 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:13:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:13:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:13:46 [INFO ]  	   step  1 (lr=0.175913)                   56.57%                   1.4454
2022-10-03 08:13:46 [INFO ]  
2022-10-03 08:13:46 [INFO ]  Epoch:   20	Loss: 1.3732	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:13:48 [INFO ]  Epoch:   21	Loss: 1.4016	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:13:50 [INFO ]  Epoch:   22	Loss: 1.6281	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:13:51 [INFO ]  Epoch:   23	Loss: 1.2017	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:13:53 [INFO ]  Epoch:   24	Loss: 1.2144	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:55 [INFO ]  Epoch:   25	Loss: 1.3763	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:13:57 [INFO ]  Epoch:   26	Loss: 1.2242	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:13:59 [INFO ]  Epoch:   27	Loss: 1.3349	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:01 [INFO ]  Epoch:   28	Loss: 1.1521	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:03 [INFO ]  Epoch:   29	Loss: 1.1055	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:14:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 08:14:07 [INFO ]  
2022-10-03 08:14:07 [INFO ]  Begin of epoch 30 :
2022-10-03 08:14:10 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:14:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:14:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:14:10 [INFO ]  	   step  1 (lr=0.221571)                   60.68%                   1.2720
2022-10-03 08:14:10 [INFO ]  
2022-10-03 08:14:10 [INFO ]  Epoch:   30	Loss: 1.2542	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:14:12 [INFO ]  Epoch:   31	Loss: 1.2277	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:13 [INFO ]  Epoch:   32	Loss: 1.1935	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:15 [INFO ]  Epoch:   33	Loss: 1.0817	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:17 [INFO ]  Epoch:   34	Loss: 1.0942	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:19 [INFO ]  Epoch:   35	Loss: 1.1994	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:21 [INFO ]  Epoch:   36	Loss: 1.1171	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:14:23 [INFO ]  Epoch:   37	Loss: 1.0337	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:25 [INFO ]  Epoch:   38	Loss: 1.0954	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:27 [INFO ]  Epoch:   39	Loss: 1.0661	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:14:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 08:14:30 [INFO ]  
2022-10-03 08:14:30 [INFO ]  Begin of epoch 40 :
2022-10-03 08:14:34 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:14:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:14:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:14:34 [INFO ]  	   step  1 (lr=0.238301)                   65.46%                   1.1572
2022-10-03 08:14:34 [INFO ]  
2022-10-03 08:14:34 [INFO ]  Epoch:   40	Loss: 1.1321	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:35 [INFO ]  Epoch:   41	Loss: 1.1414	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:14:37 [INFO ]  Epoch:   42	Loss: 1.0291	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:39 [INFO ]  Epoch:   43	Loss: 0.9979	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:14:41 [INFO ]  Epoch:   44	Loss: 1.1216	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:14:43 [INFO ]  Epoch:   45	Loss: 1.0736	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:14:44 [INFO ]  Epoch:   46	Loss: 0.9996	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:46 [INFO ]  Epoch:   47	Loss: 1.0123	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:14:48 [INFO ]  Epoch:   48	Loss: 1.0881	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:14:50 [INFO ]  Epoch:   49	Loss: 0.9723	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 08:14:54 [INFO ]  
2022-10-03 08:14:54 [INFO ]  Begin of epoch 50 :
2022-10-03 08:14:57 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:14:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:14:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:14:57 [INFO ]  	   step  1 (lr=0.249078)                   72.13%                   0.9851
2022-10-03 08:14:57 [INFO ]  
2022-10-03 08:14:57 [INFO ]  Epoch:   50	Loss: 0.9260	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:14:59 [INFO ]  Epoch:   51	Loss: 0.8940	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:01 [INFO ]  Epoch:   52	Loss: 0.9144	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:02 [INFO ]  Epoch:   53	Loss: 0.9083	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:04 [INFO ]  Epoch:   54	Loss: 0.9239	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:06 [INFO ]  Epoch:   55	Loss: 0.9732	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:15:08 [INFO ]  Epoch:   56	Loss: 1.1944	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:15:10 [INFO ]  Epoch:   57	Loss: 0.9229	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:15:12 [INFO ]  Epoch:   58	Loss: 1.0225	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:15:14 [INFO ]  Epoch:   59	Loss: 0.9505	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 08:15:17 [INFO ]  
2022-10-03 08:15:17 [INFO ]  Begin of epoch 60 :
2022-10-03 08:15:21 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:15:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:15:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:15:21 [INFO ]  	   step  1 (lr=0.259848)                   70.49%                   1.0333
2022-10-03 08:15:21 [INFO ]  
2022-10-03 08:15:21 [INFO ]  Epoch:   60	Loss: 0.9953	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:22 [INFO ]  Epoch:   61	Loss: 0.9949	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:24 [INFO ]  Epoch:   62	Loss: 1.0416	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:15:26 [INFO ]  Epoch:   63	Loss: 0.9764	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:15:28 [INFO ]  Epoch:   64	Loss: 1.0184	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:29 [INFO ]  Epoch:   65	Loss: 0.9446	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:31 [INFO ]  Epoch:   66	Loss: 0.9868	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:33 [INFO ]  Epoch:   67	Loss: 0.8600	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:15:35 [INFO ]  Epoch:   68	Loss: 1.0245	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:37 [INFO ]  Epoch:   69	Loss: 0.9142	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 08:15:41 [INFO ]  
2022-10-03 08:15:41 [INFO ]  Begin of epoch 70 :
2022-10-03 08:15:44 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:15:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:15:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:15:44 [INFO ]  	   step  1 (lr=0.269497)                   70.33%                   1.0264
2022-10-03 08:15:44 [INFO ]  
2022-10-03 08:15:44 [INFO ]  Epoch:   70	Loss: 0.9108	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:15:46 [INFO ]  Epoch:   71	Loss: 1.0164	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:48 [INFO ]  Epoch:   72	Loss: 0.9522	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:15:49 [INFO ]  Epoch:   73	Loss: 0.9316	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:15:51 [INFO ]  Epoch:   74	Loss: 0.9366	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:15:53 [INFO ]  Epoch:   75	Loss: 0.9725	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:15:55 [INFO ]  Epoch:   76	Loss: 0.9355	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:15:57 [INFO ]  Epoch:   77	Loss: 0.8605	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:15:59 [INFO ]  Epoch:   78	Loss: 0.8641	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:16:01 [INFO ]  Epoch:   79	Loss: 0.9282	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:16:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 08:16:05 [INFO ]  
2022-10-03 08:16:05 [INFO ]  Begin of epoch 80 :
2022-10-03 08:16:08 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:16:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:16:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:16:08 [INFO ]  	   step  1 (lr=0.275721)                   72.73%                   0.9653
2022-10-03 08:16:08 [INFO ]  
2022-10-03 08:16:08 [INFO ]  Epoch:   80	Loss: 0.9108	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:16:10 [INFO ]  Epoch:   81	Loss: 0.9314	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:12 [INFO ]  Epoch:   82	Loss: 0.8818	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:14 [INFO ]  Epoch:   83	Loss: 0.9243	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:16 [INFO ]  Epoch:   84	Loss: 0.8897	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:17 [INFO ]  Epoch:   85	Loss: 0.9455	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:19 [INFO ]  Epoch:   86	Loss: 1.0476	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:21 [INFO ]  Epoch:   87	Loss: 0.8673	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:16:23 [INFO ]  Epoch:   88	Loss: 0.9171	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:25 [INFO ]  Epoch:   89	Loss: 0.9312	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:16:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 08:16:29 [INFO ]  
2022-10-03 08:16:29 [INFO ]  Begin of epoch 90 :
2022-10-03 08:16:32 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:16:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:16:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:16:32 [INFO ]  	   step  1 (lr=0.284660)                   71.00%                   1.0086
2022-10-03 08:16:32 [INFO ]  
2022-10-03 08:16:32 [INFO ]  Epoch:   90	Loss: 0.9262	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 08:16:34 [INFO ]  Epoch:   91	Loss: 0.9441	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:36 [INFO ]  Epoch:   92	Loss: 0.9158	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:16:38 [INFO ]  Epoch:   93	Loss: 0.9789	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:39 [INFO ]  Epoch:   94	Loss: 0.9100	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:41 [INFO ]  Epoch:   95	Loss: 0.9234	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:16:43 [INFO ]  Epoch:   96	Loss: 0.8696	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:16:45 [INFO ]  Epoch:   97	Loss: 0.9751	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:47 [INFO ]  Epoch:   98	Loss: 0.9304	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:16:49 [INFO ]  Epoch:   99	Loss: 0.9943	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 08:16:53 [INFO ]  
2022-10-03 08:16:53 [INFO ]  Begin of epoch 100 :
2022-10-03 08:16:56 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:16:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:16:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:16:56 [INFO ]  	   step  1 (lr=0.289475)                   72.34%                   0.9604
2022-10-03 08:16:56 [INFO ]  
2022-10-03 08:16:56 [INFO ]  Epoch:  100	Loss: 0.9157	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:16:58 [INFO ]  Epoch:  101	Loss: 0.9720	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:16:59 [INFO ]  Epoch:  102	Loss: 0.8865	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:01 [INFO ]  Epoch:  103	Loss: 0.9234	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:03 [INFO ]  Epoch:  104	Loss: 0.8952	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:17:05 [INFO ]  Epoch:  105	Loss: 0.9198	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:07 [INFO ]  Epoch:  106	Loss: 0.8900	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:09 [INFO ]  Epoch:  107	Loss: 0.9636	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:11 [INFO ]  Epoch:  108	Loss: 1.0295	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:12 [INFO ]  Epoch:  109	Loss: 0.9784	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:17:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 08:17:16 [INFO ]  
2022-10-03 08:17:16 [INFO ]  Begin of epoch 110 :
2022-10-03 08:17:20 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:17:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:17:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:17:20 [INFO ]  	   step  1 (lr=0.285733)                   69.47%                   1.0587
2022-10-03 08:17:20 [INFO ]  
2022-10-03 08:17:20 [INFO ]  Epoch:  110	Loss: 0.9960	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:17:21 [INFO ]  Epoch:  111	Loss: 0.9002	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:17:23 [INFO ]  Epoch:  112	Loss: 0.9521	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:17:25 [INFO ]  Epoch:  113	Loss: 1.0489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:27 [INFO ]  Epoch:  114	Loss: 1.0327	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:17:29 [INFO ]  Epoch:  115	Loss: 1.0469	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:17:31 [INFO ]  Epoch:  116	Loss: 0.9905	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:33 [INFO ]  Epoch:  117	Loss: 1.0592	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:17:34 [INFO ]  Epoch:  118	Loss: 0.8604	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:36 [INFO ]  Epoch:  119	Loss: 0.8667	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:17:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 08:17:40 [INFO ]  
2022-10-03 08:17:40 [INFO ]  Begin of epoch 120 :
2022-10-03 08:17:43 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:17:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:17:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:17:43 [INFO ]  	   step  1 (lr=0.284724)                   73.36%                   0.9530
2022-10-03 08:17:43 [INFO ]  
2022-10-03 08:17:43 [INFO ]  Epoch:  120	Loss: 0.8902	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:17:45 [INFO ]  Epoch:  121	Loss: 1.0132	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:17:47 [INFO ]  Epoch:  122	Loss: 0.9244	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:17:49 [INFO ]  Epoch:  123	Loss: 0.9380	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:51 [INFO ]  Epoch:  124	Loss: 1.0912	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:17:53 [INFO ]  Epoch:  125	Loss: 0.9308	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:17:55 [INFO ]  Epoch:  126	Loss: 0.9168	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:56 [INFO ]  Epoch:  127	Loss: 0.8582	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:17:58 [INFO ]  Epoch:  128	Loss: 0.8903	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:18:00 [INFO ]  Epoch:  129	Loss: 0.9699	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:18:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 08:18:04 [INFO ]  
2022-10-03 08:18:04 [INFO ]  Begin of epoch 130 :
2022-10-03 08:18:07 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:18:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:18:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:18:07 [INFO ]  	   step  1 (lr=0.285489)                   73.68%                   0.9274
2022-10-03 08:18:07 [INFO ]  
2022-10-03 08:18:07 [INFO ]  Epoch:  130	Loss: 0.8210	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:18:09 [INFO ]  Epoch:  131	Loss: 0.9245	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:11 [INFO ]  Epoch:  132	Loss: 0.9373	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:12 [INFO ]  Epoch:  133	Loss: 0.8968	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:18:14 [INFO ]  Epoch:  134	Loss: 0.8938	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:18:16 [INFO ]  Epoch:  135	Loss: 0.9303	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:18:18 [INFO ]  Epoch:  136	Loss: 0.8970	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:18:20 [INFO ]  Epoch:  137	Loss: 0.8520	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:18:22 [INFO ]  Epoch:  138	Loss: 0.8666	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:18:24 [INFO ]  Epoch:  139	Loss: 0.9005	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:18:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:18:28 [INFO ]  
2022-10-03 08:18:28 [INFO ]  Begin of epoch 140 :
2022-10-03 08:18:31 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:18:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:18:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:18:31 [INFO ]  	   step  1 (lr=0.290148)                   73.95%                   0.9223
2022-10-03 08:18:31 [INFO ]  
2022-10-03 08:18:31 [INFO ]  Epoch:  140	Loss: 0.9368	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 08:18:33 [INFO ]  Epoch:  141	Loss: 1.3306	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:35 [INFO ]  Epoch:  142	Loss: 0.9392	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:18:37 [INFO ]  Epoch:  143	Loss: 0.8271	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:39 [INFO ]  Epoch:  144	Loss: 0.9300	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:18:41 [INFO ]  Epoch:  145	Loss: 0.8602	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:43 [INFO ]  Epoch:  146	Loss: 0.8437	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:18:44 [INFO ]  Epoch:  147	Loss: 0.9231	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:18:46 [INFO ]  Epoch:  148	Loss: 0.8342	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:18:48 [INFO ]  Epoch:  149	Loss: 0.8365	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:18:52 [INFO ]  
2022-10-03 08:18:52 [INFO ]  Begin of epoch 150 :
2022-10-03 08:18:56 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:18:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:18:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:18:56 [INFO ]  	   step  1 (lr=0.288371)                   73.97%                   0.9150
2022-10-03 08:18:56 [INFO ]  
2022-10-03 08:18:56 [INFO ]  Epoch:  150	Loss: 0.8761	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:18:57 [INFO ]  Epoch:  151	Loss: 0.8138	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:18:59 [INFO ]  Epoch:  152	Loss: 0.8854	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:01 [INFO ]  Epoch:  153	Loss: 0.9340	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:03 [INFO ]  Epoch:  154	Loss: 0.8741	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:19:05 [INFO ]  Epoch:  155	Loss: 0.9067	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 08:19:07 [INFO ]  Epoch:  156	Loss: 0.9273	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:08 [INFO ]  Epoch:  157	Loss: 0.8499	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:10 [INFO ]  Epoch:  158	Loss: 0.8983	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:12 [INFO ]  Epoch:  159	Loss: 0.8305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:19:16 [INFO ]  
2022-10-03 08:19:16 [INFO ]  Begin of epoch 160 :
2022-10-03 08:19:19 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:19:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:19:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:19:19 [INFO ]  	   step  1 (lr=0.288810)                   74.14%                   0.9093
2022-10-03 08:19:19 [INFO ]  
2022-10-03 08:19:19 [INFO ]  Epoch:  160	Loss: 0.8982	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:19:21 [INFO ]  Epoch:  161	Loss: 0.8205	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:23 [INFO ]  Epoch:  162	Loss: 0.8581	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:25 [INFO ]  Epoch:  163	Loss: 0.8501	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:19:27 [INFO ]  Epoch:  164	Loss: 0.8536	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:19:29 [INFO ]  Epoch:  165	Loss: 0.9289	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:30 [INFO ]  Epoch:  166	Loss: 0.7306	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:19:32 [INFO ]  Epoch:  167	Loss: 0.8875	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:34 [INFO ]  Epoch:  168	Loss: 0.9445	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:36 [INFO ]  Epoch:  169	Loss: 0.8708	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:19:40 [INFO ]  
2022-10-03 08:19:40 [INFO ]  Begin of epoch 170 :
2022-10-03 08:19:43 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:19:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:19:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:19:43 [INFO ]  	   step  1 (lr=0.289307)                   73.31%                   0.9430
2022-10-03 08:19:43 [INFO ]  
2022-10-03 08:19:43 [INFO ]  Epoch:  170	Loss: 0.8812	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:19:45 [INFO ]  Epoch:  171	Loss: 0.8690	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:19:47 [INFO ]  Epoch:  172	Loss: 0.8575	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:19:49 [INFO ]  Epoch:  173	Loss: 0.9502	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:19:51 [INFO ]  Epoch:  174	Loss: 0.8443	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:19:52 [INFO ]  Epoch:  175	Loss: 0.8915	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:19:54 [INFO ]  Epoch:  176	Loss: 0.8837	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:19:56 [INFO ]  Epoch:  177	Loss: 0.8663	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:19:58 [INFO ]  Epoch:  178	Loss: 0.8495	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:00 [INFO ]  Epoch:  179	Loss: 0.9161	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:20:04 [INFO ]  
2022-10-03 08:20:04 [INFO ]  Begin of epoch 180 :
2022-10-03 08:20:07 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:20:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:20:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:20:07 [INFO ]  	   step  1 (lr=0.289972)                   73.23%                   0.9511
2022-10-03 08:20:07 [INFO ]  
2022-10-03 08:20:07 [INFO ]  Epoch:  180	Loss: 0.8784	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:20:09 [INFO ]  Epoch:  181	Loss: 0.8914	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:11 [INFO ]  Epoch:  182	Loss: 0.8662	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:13 [INFO ]  Epoch:  183	Loss: 0.8764	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:15 [INFO ]  Epoch:  184	Loss: 0.8978	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:17 [INFO ]  Epoch:  185	Loss: 0.8637	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:19 [INFO ]  Epoch:  186	Loss: 0.8521	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:20:21 [INFO ]  Epoch:  187	Loss: 0.8413	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:20:23 [INFO ]  Epoch:  188	Loss: 0.8476	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:20:25 [INFO ]  Epoch:  189	Loss: 0.9059	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:20:29 [INFO ]  
2022-10-03 08:20:29 [INFO ]  Begin of epoch 190 :
2022-10-03 08:20:32 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:20:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:20:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:20:32 [INFO ]  	   step  1 (lr=0.290776)                   73.30%                   0.9427
2022-10-03 08:20:32 [INFO ]  
2022-10-03 08:20:32 [INFO ]  Epoch:  190	Loss: 0.9030	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:20:34 [INFO ]  Epoch:  191	Loss: 0.7715	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:36 [INFO ]  Epoch:  192	Loss: 0.9374	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:38 [INFO ]  Epoch:  193	Loss: 0.8722	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:20:39 [INFO ]  Epoch:  194	Loss: 0.8715	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:41 [INFO ]  Epoch:  195	Loss: 0.7986	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:20:43 [INFO ]  Epoch:  196	Loss: 0.8510	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:20:45 [INFO ]  Epoch:  197	Loss: 0.8344	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:20:47 [INFO ]  Epoch:  198	Loss: 0.8924	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:20:49 [INFO ]  Epoch:  199	Loss: 0.8463	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:20:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:20:52 [INFO ]  
2022-10-03 08:20:52 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:20:55 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:20:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:20:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:20:55 [INFO ]  	   step  1 (lr=0.291365)                   73.21%                   0.9476
2022-10-03 08:20:55 [INFO ]  
2022-10-03 08:20:55 [INFO ]  
2022-10-03 08:20:55 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:20:58 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:20:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:20:58 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:20:58 [INFO ]  	   step  1 (lr=0.291365)                   18.64%                   4.6600
2022-10-03 08:20:58 [INFO ]  
2022-10-03 08:21:30 [INFO ]  ======================================== 2022-10-03 08:21:30 ========================================
2022-10-03 08:21:30 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 08:21:30 [INFO ]  Options: 
2022-10-03 08:21:30 [INFO ]  	base_dir: null
2022-10-03 08:21:30 [INFO ]  	batch_size: 1024
2022-10-03 08:21:30 [INFO ]  	checkpoint_interval: 10
2022-10-03 08:21:30 [INFO ]  	dataset: SVHN
2022-10-03 08:21:30 [INFO ]  	dataset_labels:
2022-10-03 08:21:30 [INFO ]  	- 0
2022-10-03 08:21:30 [INFO ]  	- 1
2022-10-03 08:21:30 [INFO ]  	- 2
2022-10-03 08:21:30 [INFO ]  	- 3
2022-10-03 08:21:30 [INFO ]  	- 4
2022-10-03 08:21:30 [INFO ]  	- 5
2022-10-03 08:21:30 [INFO ]  	- 6
2022-10-03 08:21:30 [INFO ]  	- 7
2022-10-03 08:21:30 [INFO ]  	- 8
2022-10-03 08:21:30 [INFO ]  	- 9
2022-10-03 08:21:30 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 08:21:30 [INFO ]  	- !!python/tuple
2022-10-03 08:21:30 [INFO ]  	    - 0.4379104971885681
2022-10-03 08:21:30 [INFO ]  	    - 0.44398033618927
2022-10-03 08:21:30 [INFO ]  	    - 0.4729299545288086
2022-10-03 08:21:30 [INFO ]  	- !!python/tuple
2022-10-03 08:21:30 [INFO ]  	    - 0.19803012907505035
2022-10-03 08:21:30 [INFO ]  	    - 0.2010156363248825
2022-10-03 08:21:30 [INFO ]  	    - 0.19703614711761475
2022-10-03 08:21:30 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 08:21:30 [INFO ]  	decay_epochs: 50
2022-10-03 08:21:30 [INFO ]  	decay_factor: 0.1
2022-10-03 08:21:30 [INFO ]  	device_id: 0
2022-10-03 08:21:30 [INFO ]  	distill_epochs: 1
2022-10-03 08:21:30 [INFO ]  	distill_lr: 0.02
2022-10-03 08:21:30 [INFO ]  	distill_steps: 1
2022-10-03 08:21:30 [INFO ]  	epochs: 200
2022-10-03 08:21:30 [INFO ]  	expand_cls: false
2022-10-03 08:21:30 [INFO ]  	forgetting_dataset: null
2022-10-03 08:21:30 [INFO ]  	init: xavier
2022-10-03 08:21:30 [INFO ]  	init_param: 1.0
2022-10-03 08:21:30 [INFO ]  	input_size: 32
2022-10-03 08:21:30 [INFO ]  	ipc: 5
2022-10-03 08:21:30 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 08:21:30 [INFO ]  	log_interval: 100
2022-10-03 08:21:30 [INFO ]  	log_level: INFO
2022-10-03 08:21:30 [INFO ]  	lr: 0.01
2022-10-03 08:21:30 [INFO ]  	mode: distill_adapt
2022-10-03 08:21:30 [INFO ]  	nc: 3
2022-10-03 08:21:30 [INFO ]  	num_classes: 10
2022-10-03 08:21:30 [INFO ]  	num_workers: 8
2022-10-03 08:21:30 [INFO ]  	phase: train
2022-10-03 08:21:30 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 08:21:30 [INFO ]  	start_time: '2022-10-03 08:21:30'
2022-10-03 08:21:30 [INFO ]  	test_batch_size: 1024
2022-10-03 08:21:30 [INFO ]  	
2022-10-03 08:21:32 [INFO ]  train dataset size:	73257
2022-10-03 08:21:32 [INFO ]  test dataset size: 	26032
2022-10-03 08:21:32 [INFO ]  datasets built!
2022-10-03 08:21:32 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 08:21:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 08:21:38 [INFO ]  
2022-10-03 08:21:38 [INFO ]  Begin of epoch 0 :
2022-10-03 08:21:41 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:21:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:21:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:21:41 [INFO ]  	   step  1 (lr=0.020000)                    7.31%                   8.2459
2022-10-03 08:21:41 [INFO ]  
2022-10-03 08:21:41 [INFO ]  Epoch:    0	Loss: 8.7710	Data Time: 0.38s	Train Time: 0.03s
2022-10-03 08:21:43 [INFO ]  Epoch:    1	Loss: 3.1753	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:21:45 [INFO ]  Epoch:    2	Loss: 2.5958	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:21:47 [INFO ]  Epoch:    3	Loss: 2.3305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:21:49 [INFO ]  Epoch:    4	Loss: 2.2184	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:21:51 [INFO ]  Epoch:    5	Loss: 2.2398	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:21:53 [INFO ]  Epoch:    6	Loss: 2.1743	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:21:55 [INFO ]  Epoch:    7	Loss: 2.1393	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:21:57 [INFO ]  Epoch:    8	Loss: 2.1100	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:21:59 [INFO ]  Epoch:    9	Loss: 2.0410	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:22:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 08:22:05 [INFO ]  
2022-10-03 08:22:05 [INFO ]  Begin of epoch 10 :
2022-10-03 08:22:08 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:22:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:22:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:22:08 [INFO ]  	   step  1 (lr=0.065146)                   36.70%                   1.9698
2022-10-03 08:22:08 [INFO ]  
2022-10-03 08:22:08 [INFO ]  Epoch:   10	Loss: 1.9803	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:22:10 [INFO ]  Epoch:   11	Loss: 1.9212	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:22:12 [INFO ]  Epoch:   12	Loss: 1.8187	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:22:13 [INFO ]  Epoch:   13	Loss: 1.7229	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:15 [INFO ]  Epoch:   14	Loss: 1.5911	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:22:17 [INFO ]  Epoch:   15	Loss: 1.4547	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:22:19 [INFO ]  Epoch:   16	Loss: 1.4278	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:21 [INFO ]  Epoch:   17	Loss: 1.3657	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:23 [INFO ]  Epoch:   18	Loss: 1.2725	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:22:24 [INFO ]  Epoch:   19	Loss: 1.2269	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 08:22:30 [INFO ]  
2022-10-03 08:22:30 [INFO ]  Begin of epoch 20 :
2022-10-03 08:22:34 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:22:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:22:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:22:34 [INFO ]  	   step  1 (lr=0.195980)                   62.72%                   1.2639
2022-10-03 08:22:34 [INFO ]  
2022-10-03 08:22:34 [INFO ]  Epoch:   20	Loss: 1.2054	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:22:36 [INFO ]  Epoch:   21	Loss: 1.2369	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:22:37 [INFO ]  Epoch:   22	Loss: 1.2134	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:22:39 [INFO ]  Epoch:   23	Loss: 1.0960	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:41 [INFO ]  Epoch:   24	Loss: 1.1459	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:22:43 [INFO ]  Epoch:   25	Loss: 1.0641	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:45 [INFO ]  Epoch:   26	Loss: 1.1379	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:22:47 [INFO ]  Epoch:   27	Loss: 1.0090	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:49 [INFO ]  Epoch:   28	Loss: 1.0874	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:51 [INFO ]  Epoch:   29	Loss: 1.0469	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:22:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 08:22:56 [INFO ]  
2022-10-03 08:22:56 [INFO ]  Begin of epoch 30 :
2022-10-03 08:23:00 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:23:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:23:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:23:00 [INFO ]  	   step  1 (lr=0.243479)                   68.84%                   1.0661
2022-10-03 08:23:00 [INFO ]  
2022-10-03 08:23:00 [INFO ]  Epoch:   30	Loss: 1.0346	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:23:02 [INFO ]  Epoch:   31	Loss: 0.9866	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:23:03 [INFO ]  Epoch:   32	Loss: 0.9952	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:23:05 [INFO ]  Epoch:   33	Loss: 0.9956	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:23:07 [INFO ]  Epoch:   34	Loss: 0.9132	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:09 [INFO ]  Epoch:   35	Loss: 0.9182	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:23:11 [INFO ]  Epoch:   36	Loss: 0.9617	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:12 [INFO ]  Epoch:   37	Loss: 0.9960	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:23:14 [INFO ]  Epoch:   38	Loss: 0.9670	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:23:16 [INFO ]  Epoch:   39	Loss: 0.8017	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:23:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 08:23:22 [INFO ]  
2022-10-03 08:23:22 [INFO ]  Begin of epoch 40 :
2022-10-03 08:23:25 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:23:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:23:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:23:25 [INFO ]  	   step  1 (lr=0.279510)                   71.33%                   1.0144
2022-10-03 08:23:25 [INFO ]  
2022-10-03 08:23:25 [INFO ]  Epoch:   40	Loss: 0.9465	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:27 [INFO ]  Epoch:   41	Loss: 0.8997	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:23:29 [INFO ]  Epoch:   42	Loss: 0.9661	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:23:30 [INFO ]  Epoch:   43	Loss: 0.8498	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:32 [INFO ]  Epoch:   44	Loss: 0.8880	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:23:34 [INFO ]  Epoch:   45	Loss: 0.9047	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:23:36 [INFO ]  Epoch:   46	Loss: 0.8546	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:38 [INFO ]  Epoch:   47	Loss: 0.9295	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:23:40 [INFO ]  Epoch:   48	Loss: 0.8034	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:23:42 [INFO ]  Epoch:   49	Loss: 0.9921	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:23:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 08:23:48 [INFO ]  
2022-10-03 08:23:48 [INFO ]  Begin of epoch 50 :
2022-10-03 08:23:51 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:23:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:23:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:23:51 [INFO ]  	   step  1 (lr=0.299461)                   76.74%                   0.8520
2022-10-03 08:23:51 [INFO ]  
2022-10-03 08:23:51 [INFO ]  Epoch:   50	Loss: 0.8438	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:23:53 [INFO ]  Epoch:   51	Loss: 0.7372	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:23:54 [INFO ]  Epoch:   52	Loss: 0.7617	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:23:56 [INFO ]  Epoch:   53	Loss: 0.8160	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:23:58 [INFO ]  Epoch:   54	Loss: 0.7943	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:24:00 [INFO ]  Epoch:   55	Loss: 0.8425	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:24:02 [INFO ]  Epoch:   56	Loss: 0.7472	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:24:04 [INFO ]  Epoch:   57	Loss: 0.7266	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:24:06 [INFO ]  Epoch:   58	Loss: 0.7803	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:24:07 [INFO ]  Epoch:   59	Loss: 0.7549	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:24:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 08:24:13 [INFO ]  
2022-10-03 08:24:13 [INFO ]  Begin of epoch 60 :
2022-10-03 08:24:17 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:24:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:24:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:24:17 [INFO ]  	   step  1 (lr=0.311239)                   73.82%                   0.9510
2022-10-03 08:24:17 [INFO ]  
2022-10-03 08:24:17 [INFO ]  Epoch:   60	Loss: 0.7981	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:24:19 [INFO ]  Epoch:   61	Loss: 0.7873	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:24:20 [INFO ]  Epoch:   62	Loss: 0.8212	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:24:22 [INFO ]  Epoch:   63	Loss: 0.7827	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 08:24:24 [INFO ]  Epoch:   64	Loss: 0.7360	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:24:26 [INFO ]  Epoch:   65	Loss: 0.7568	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 08:24:28 [INFO ]  Epoch:   66	Loss: 0.7858	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:24:30 [INFO ]  Epoch:   67	Loss: 0.8097	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 08:24:32 [INFO ]  Epoch:   68	Loss: 0.7909	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:24:34 [INFO ]  Epoch:   69	Loss: 0.8260	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:24:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 08:24:40 [INFO ]  
2022-10-03 08:24:40 [INFO ]  Begin of epoch 70 :
2022-10-03 08:24:43 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:24:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:24:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:24:43 [INFO ]  	   step  1 (lr=0.319842)                   77.97%                   0.8092
2022-10-03 08:24:43 [INFO ]  
2022-10-03 08:24:43 [INFO ]  Epoch:   70	Loss: 0.7355	Data Time: 0.32s	Train Time: 0.00s
2022-10-03 08:24:45 [INFO ]  Epoch:   71	Loss: 0.6990	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:24:47 [INFO ]  Epoch:   72	Loss: 0.8014	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:24:49 [INFO ]  Epoch:   73	Loss: 0.8267	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:24:51 [INFO ]  Epoch:   74	Loss: 0.8993	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:24:52 [INFO ]  Epoch:   75	Loss: 0.7601	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:24:54 [INFO ]  Epoch:   76	Loss: 0.7404	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:24:56 [INFO ]  Epoch:   77	Loss: 0.8319	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:24:58 [INFO ]  Epoch:   78	Loss: 0.7450	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:25:00 [INFO ]  Epoch:   79	Loss: 0.7958	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 08:25:06 [INFO ]  
2022-10-03 08:25:06 [INFO ]  Begin of epoch 80 :
2022-10-03 08:25:09 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:25:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:25:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:25:09 [INFO ]  	   step  1 (lr=0.332488)                   77.73%                   0.8071
2022-10-03 08:25:09 [INFO ]  
2022-10-03 08:25:09 [INFO ]  Epoch:   80	Loss: 0.7912	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:25:11 [INFO ]  Epoch:   81	Loss: 0.7311	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:13 [INFO ]  Epoch:   82	Loss: 0.7339	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:25:15 [INFO ]  Epoch:   83	Loss: 0.7627	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:17 [INFO ]  Epoch:   84	Loss: 0.9828	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:19 [INFO ]  Epoch:   85	Loss: 0.7064	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:25:20 [INFO ]  Epoch:   86	Loss: 0.8429	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:22 [INFO ]  Epoch:   87	Loss: 0.7237	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:24 [INFO ]  Epoch:   88	Loss: 0.7594	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:25:26 [INFO ]  Epoch:   89	Loss: 0.7820	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:25:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 08:25:32 [INFO ]  
2022-10-03 08:25:32 [INFO ]  Begin of epoch 90 :
2022-10-03 08:25:35 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:25:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:25:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:25:35 [INFO ]  	   step  1 (lr=0.334181)                   77.59%                   0.8131
2022-10-03 08:25:35 [INFO ]  
2022-10-03 08:25:35 [INFO ]  Epoch:   90	Loss: 0.7647	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 08:25:37 [INFO ]  Epoch:   91	Loss: 0.7752	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:25:39 [INFO ]  Epoch:   92	Loss: 0.8114	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:25:41 [INFO ]  Epoch:   93	Loss: 0.8416	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:25:43 [INFO ]  Epoch:   94	Loss: 0.7943	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:44 [INFO ]  Epoch:   95	Loss: 0.7021	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:25:46 [INFO ]  Epoch:   96	Loss: 0.7279	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:25:48 [INFO ]  Epoch:   97	Loss: 0.7468	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:25:50 [INFO ]  Epoch:   98	Loss: 0.7347	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:25:52 [INFO ]  Epoch:   99	Loss: 0.8136	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:25:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 08:25:58 [INFO ]  
2022-10-03 08:25:58 [INFO ]  Begin of epoch 100 :
2022-10-03 08:26:01 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:26:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:26:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:26:01 [INFO ]  	   step  1 (lr=0.336335)                   77.77%                   0.8031
2022-10-03 08:26:01 [INFO ]  
2022-10-03 08:26:01 [INFO ]  Epoch:  100	Loss: 0.7563	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 08:26:03 [INFO ]  Epoch:  101	Loss: 0.7458	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:26:05 [INFO ]  Epoch:  102	Loss: 0.7160	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:26:07 [INFO ]  Epoch:  103	Loss: 0.7301	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:08 [INFO ]  Epoch:  104	Loss: 0.6892	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:26:10 [INFO ]  Epoch:  105	Loss: 0.7259	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:12 [INFO ]  Epoch:  106	Loss: 0.7870	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:14 [INFO ]  Epoch:  107	Loss: 0.7238	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:26:16 [INFO ]  Epoch:  108	Loss: 0.7125	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:26:18 [INFO ]  Epoch:  109	Loss: 0.7247	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:26:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 08:26:24 [INFO ]  
2022-10-03 08:26:24 [INFO ]  Begin of epoch 110 :
2022-10-03 08:26:27 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:26:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:26:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:26:27 [INFO ]  	   step  1 (lr=0.342180)                   78.62%                   0.7843
2022-10-03 08:26:27 [INFO ]  
2022-10-03 08:26:27 [INFO ]  Epoch:  110	Loss: 0.7723	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:26:29 [INFO ]  Epoch:  111	Loss: 0.7654	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:31 [INFO ]  Epoch:  112	Loss: 0.7131	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:26:33 [INFO ]  Epoch:  113	Loss: 0.7118	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:26:35 [INFO ]  Epoch:  114	Loss: 0.7100	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:37 [INFO ]  Epoch:  115	Loss: 0.7214	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:26:39 [INFO ]  Epoch:  116	Loss: 0.6777	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:41 [INFO ]  Epoch:  117	Loss: 0.7127	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:26:43 [INFO ]  Epoch:  118	Loss: 0.6748	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:26:45 [INFO ]  Epoch:  119	Loss: 0.6555	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:26:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 08:26:51 [INFO ]  
2022-10-03 08:26:51 [INFO ]  Begin of epoch 120 :
2022-10-03 08:26:54 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:26:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:26:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:26:54 [INFO ]  	   step  1 (lr=0.343703)                   78.45%                   0.7764
2022-10-03 08:26:54 [INFO ]  
2022-10-03 08:26:54 [INFO ]  Epoch:  120	Loss: 0.7464	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:26:56 [INFO ]  Epoch:  121	Loss: 0.7351	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:26:58 [INFO ]  Epoch:  122	Loss: 0.7090	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:26:59 [INFO ]  Epoch:  123	Loss: 0.7102	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:27:01 [INFO ]  Epoch:  124	Loss: 0.6488	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:27:03 [INFO ]  Epoch:  125	Loss: 0.7136	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:27:05 [INFO ]  Epoch:  126	Loss: 0.7301	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:27:07 [INFO ]  Epoch:  127	Loss: 0.6158	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:27:09 [INFO ]  Epoch:  128	Loss: 0.9204	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:27:11 [INFO ]  Epoch:  129	Loss: 0.7444	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:27:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 08:27:17 [INFO ]  
2022-10-03 08:27:17 [INFO ]  Begin of epoch 130 :
2022-10-03 08:27:20 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:27:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:27:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:27:20 [INFO ]  	   step  1 (lr=0.342445)                   78.48%                   0.7804
2022-10-03 08:27:20 [INFO ]  
2022-10-03 08:27:20 [INFO ]  Epoch:  130	Loss: 0.7623	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:27:22 [INFO ]  Epoch:  131	Loss: 0.7276	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:27:23 [INFO ]  Epoch:  132	Loss: 0.9018	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:27:25 [INFO ]  Epoch:  133	Loss: 0.7182	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:27:27 [INFO ]  Epoch:  134	Loss: 0.7933	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:27:29 [INFO ]  Epoch:  135	Loss: 0.7113	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:27:31 [INFO ]  Epoch:  136	Loss: 0.6444	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:27:33 [INFO ]  Epoch:  137	Loss: 0.8915	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:27:35 [INFO ]  Epoch:  138	Loss: 0.7529	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:27:37 [INFO ]  Epoch:  139	Loss: 0.6988	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:27:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:27:42 [INFO ]  
2022-10-03 08:27:42 [INFO ]  Begin of epoch 140 :
2022-10-03 08:27:46 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:27:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:27:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:27:46 [INFO ]  	   step  1 (lr=0.341589)                   78.25%                   0.8019
2022-10-03 08:27:46 [INFO ]  
2022-10-03 08:27:46 [INFO ]  Epoch:  140	Loss: 0.7084	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:27:48 [INFO ]  Epoch:  141	Loss: 0.6715	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:27:50 [INFO ]  Epoch:  142	Loss: 0.8185	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:27:51 [INFO ]  Epoch:  143	Loss: 0.7614	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:27:53 [INFO ]  Epoch:  144	Loss: 0.6567	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:27:55 [INFO ]  Epoch:  145	Loss: 0.7412	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:27:57 [INFO ]  Epoch:  146	Loss: 0.7308	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:27:59 [INFO ]  Epoch:  147	Loss: 0.7370	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:00 [INFO ]  Epoch:  148	Loss: 0.7907	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:02 [INFO ]  Epoch:  149	Loss: 0.6595	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:28:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:28:08 [INFO ]  
2022-10-03 08:28:08 [INFO ]  Begin of epoch 150 :
2022-10-03 08:28:12 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:28:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:28:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:28:12 [INFO ]  	   step  1 (lr=0.341705)                   78.95%                   0.7753
2022-10-03 08:28:12 [INFO ]  
2022-10-03 08:28:12 [INFO ]  Epoch:  150	Loss: 0.6659	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:28:13 [INFO ]  Epoch:  151	Loss: 0.6947	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:28:15 [INFO ]  Epoch:  152	Loss: 0.7250	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:28:17 [INFO ]  Epoch:  153	Loss: 0.6709	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:28:19 [INFO ]  Epoch:  154	Loss: 0.7229	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:28:21 [INFO ]  Epoch:  155	Loss: 0.7229	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:28:22 [INFO ]  Epoch:  156	Loss: 0.7008	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:24 [INFO ]  Epoch:  157	Loss: 0.6761	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:26 [INFO ]  Epoch:  158	Loss: 0.7359	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:28:28 [INFO ]  Epoch:  159	Loss: 0.7140	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:28:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:28:34 [INFO ]  
2022-10-03 08:28:34 [INFO ]  Begin of epoch 160 :
2022-10-03 08:28:37 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:28:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:28:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:28:37 [INFO ]  	   step  1 (lr=0.342450)                   79.01%                   0.7714
2022-10-03 08:28:37 [INFO ]  
2022-10-03 08:28:37 [INFO ]  Epoch:  160	Loss: 0.7296	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:28:39 [INFO ]  Epoch:  161	Loss: 0.7600	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:28:41 [INFO ]  Epoch:  162	Loss: 0.6902	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:28:43 [INFO ]  Epoch:  163	Loss: 0.7469	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:28:45 [INFO ]  Epoch:  164	Loss: 0.7460	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:28:47 [INFO ]  Epoch:  165	Loss: 0.7532	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:28:49 [INFO ]  Epoch:  166	Loss: 0.7505	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:28:51 [INFO ]  Epoch:  167	Loss: 0.6401	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:52 [INFO ]  Epoch:  168	Loss: 0.7367	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:28:54 [INFO ]  Epoch:  169	Loss: 0.7682	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:29:00 [INFO ]  
2022-10-03 08:29:00 [INFO ]  Begin of epoch 170 :
2022-10-03 08:29:04 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:29:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:29:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:29:04 [INFO ]  	   step  1 (lr=0.343110)                   78.19%                   0.7885
2022-10-03 08:29:04 [INFO ]  
2022-10-03 08:29:04 [INFO ]  Epoch:  170	Loss: 0.6392	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:06 [INFO ]  Epoch:  171	Loss: 0.7770	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:29:08 [INFO ]  Epoch:  172	Loss: 0.7722	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:29:10 [INFO ]  Epoch:  173	Loss: 0.7925	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:29:12 [INFO ]  Epoch:  174	Loss: 0.7802	Data Time: 0.37s	Train Time: 0.01s
2022-10-03 08:29:14 [INFO ]  Epoch:  175	Loss: 0.8205	Data Time: 0.37s	Train Time: 0.01s
2022-10-03 08:29:16 [INFO ]  Epoch:  176	Loss: 0.7140	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:29:18 [INFO ]  Epoch:  177	Loss: 0.7486	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 08:29:19 [INFO ]  Epoch:  178	Loss: 0.7895	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:29:21 [INFO ]  Epoch:  179	Loss: 0.8366	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:29:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:29:27 [INFO ]  
2022-10-03 08:29:27 [INFO ]  Begin of epoch 180 :
2022-10-03 08:29:31 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:29:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:29:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:29:31 [INFO ]  	   step  1 (lr=0.342191)                   78.71%                   0.7804
2022-10-03 08:29:31 [INFO ]  
2022-10-03 08:29:31 [INFO ]  Epoch:  180	Loss: 0.7553	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 08:29:32 [INFO ]  Epoch:  181	Loss: 0.7691	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:34 [INFO ]  Epoch:  182	Loss: 0.7599	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:29:36 [INFO ]  Epoch:  183	Loss: 0.7505	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:38 [INFO ]  Epoch:  184	Loss: 0.6797	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:29:40 [INFO ]  Epoch:  185	Loss: 0.6652	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:29:41 [INFO ]  Epoch:  186	Loss: 0.7421	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:29:43 [INFO ]  Epoch:  187	Loss: 0.8033	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:29:45 [INFO ]  Epoch:  188	Loss: 0.7185	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:47 [INFO ]  Epoch:  189	Loss: 0.7362	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:29:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:29:53 [INFO ]  
2022-10-03 08:29:53 [INFO ]  Begin of epoch 190 :
2022-10-03 08:29:56 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:29:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:29:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:29:56 [INFO ]  	   step  1 (lr=0.342294)                   78.53%                   0.7878
2022-10-03 08:29:56 [INFO ]  
2022-10-03 08:29:56 [INFO ]  Epoch:  190	Loss: 0.7150	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:29:58 [INFO ]  Epoch:  191	Loss: 0.6925	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:30:00 [INFO ]  Epoch:  192	Loss: 0.6795	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:30:01 [INFO ]  Epoch:  193	Loss: 0.6724	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:30:04 [INFO ]  Epoch:  194	Loss: 0.7260	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:30:05 [INFO ]  Epoch:  195	Loss: 0.7018	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:30:07 [INFO ]  Epoch:  196	Loss: 0.6855	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:30:09 [INFO ]  Epoch:  197	Loss: 0.6849	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:30:11 [INFO ]  Epoch:  198	Loss: 0.6613	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:30:13 [INFO ]  Epoch:  199	Loss: 0.7685	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:30:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:30:18 [INFO ]  
2022-10-03 08:30:18 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:30:22 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:30:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:30:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:30:22 [INFO ]  	   step  1 (lr=0.342563)                   79.03%                   0.7726
2022-10-03 08:30:22 [INFO ]  
2022-10-03 08:30:22 [INFO ]  
2022-10-03 08:30:22 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:30:25 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:30:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:30:25 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:30:25 [INFO ]  	   step  1 (lr=0.342563)                   18.73%                   5.1214
2022-10-03 08:30:25 [INFO ]  
2022-10-03 08:31:25 [INFO ]  ======================================== 2022-10-03 08:31:25 ========================================
2022-10-03 08:31:25 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 08:31:25 [INFO ]  Options: 
2022-10-03 08:31:25 [INFO ]  	base_dir: null
2022-10-03 08:31:25 [INFO ]  	batch_size: 1024
2022-10-03 08:31:25 [INFO ]  	checkpoint_interval: 10
2022-10-03 08:31:25 [INFO ]  	dataset: SVHN
2022-10-03 08:31:25 [INFO ]  	dataset_labels:
2022-10-03 08:31:25 [INFO ]  	- 0
2022-10-03 08:31:25 [INFO ]  	- 1
2022-10-03 08:31:25 [INFO ]  	- 2
2022-10-03 08:31:25 [INFO ]  	- 3
2022-10-03 08:31:25 [INFO ]  	- 4
2022-10-03 08:31:25 [INFO ]  	- 5
2022-10-03 08:31:25 [INFO ]  	- 6
2022-10-03 08:31:25 [INFO ]  	- 7
2022-10-03 08:31:25 [INFO ]  	- 8
2022-10-03 08:31:25 [INFO ]  	- 9
2022-10-03 08:31:25 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 08:31:25 [INFO ]  	- !!python/tuple
2022-10-03 08:31:25 [INFO ]  	    - 0.4379104971885681
2022-10-03 08:31:25 [INFO ]  	    - 0.44398033618927
2022-10-03 08:31:25 [INFO ]  	    - 0.4729299545288086
2022-10-03 08:31:25 [INFO ]  	- !!python/tuple
2022-10-03 08:31:25 [INFO ]  	    - 0.19803012907505035
2022-10-03 08:31:25 [INFO ]  	    - 0.2010156363248825
2022-10-03 08:31:25 [INFO ]  	    - 0.19703614711761475
2022-10-03 08:31:25 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 08:31:25 [INFO ]  	decay_epochs: 50
2022-10-03 08:31:25 [INFO ]  	decay_factor: 0.1
2022-10-03 08:31:25 [INFO ]  	device_id: 0
2022-10-03 08:31:25 [INFO ]  	distill_epochs: 1
2022-10-03 08:31:25 [INFO ]  	distill_lr: 0.02
2022-10-03 08:31:25 [INFO ]  	distill_steps: 1
2022-10-03 08:31:25 [INFO ]  	epochs: 200
2022-10-03 08:31:25 [INFO ]  	expand_cls: false
2022-10-03 08:31:25 [INFO ]  	forgetting_dataset: null
2022-10-03 08:31:25 [INFO ]  	init: xavier
2022-10-03 08:31:25 [INFO ]  	init_param: 1.0
2022-10-03 08:31:25 [INFO ]  	input_size: 32
2022-10-03 08:31:25 [INFO ]  	ipc: 5
2022-10-03 08:31:25 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 08:31:25 [INFO ]  	log_interval: 100
2022-10-03 08:31:25 [INFO ]  	log_level: INFO
2022-10-03 08:31:25 [INFO ]  	lr: 0.01
2022-10-03 08:31:25 [INFO ]  	mode: distill_adapt
2022-10-03 08:31:25 [INFO ]  	nc: 3
2022-10-03 08:31:25 [INFO ]  	num_classes: 10
2022-10-03 08:31:25 [INFO ]  	num_workers: 8
2022-10-03 08:31:25 [INFO ]  	phase: train
2022-10-03 08:31:25 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 08:31:25 [INFO ]  	start_time: '2022-10-03 08:31:25'
2022-10-03 08:31:25 [INFO ]  	test_batch_size: 1024
2022-10-03 08:31:25 [INFO ]  	
2022-10-03 08:31:27 [INFO ]  train dataset size:	73257
2022-10-03 08:31:27 [INFO ]  test dataset size: 	26032
2022-10-03 08:31:27 [INFO ]  datasets built!
2022-10-03 08:31:27 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 08:31:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 08:31:33 [INFO ]  
2022-10-03 08:31:33 [INFO ]  Begin of epoch 0 :
2022-10-03 08:31:36 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:31:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:31:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:31:36 [INFO ]  	   step  1 (lr=0.020000)                    6.94%                   9.3962
2022-10-03 08:31:36 [INFO ]  
2022-10-03 08:31:36 [INFO ]  Epoch:    0	Loss: 9.7529	Data Time: 0.43s	Train Time: 0.04s
2022-10-03 08:31:38 [INFO ]  Epoch:    1	Loss: 3.1949	Data Time: 0.13s	Train Time: 0.01s
2022-10-03 08:31:40 [INFO ]  Epoch:    2	Loss: 2.6433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:31:42 [INFO ]  Epoch:    3	Loss: 2.3481	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:31:44 [INFO ]  Epoch:    4	Loss: 2.2265	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:31:46 [INFO ]  Epoch:    5	Loss: 2.2112	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:31:47 [INFO ]  Epoch:    6	Loss: 2.1727	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:31:49 [INFO ]  Epoch:    7	Loss: 2.1557	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:31:51 [INFO ]  Epoch:    8	Loss: 2.1066	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:31:53 [INFO ]  Epoch:    9	Loss: 2.0334	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:31:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 08:31:59 [INFO ]  
2022-10-03 08:31:59 [INFO ]  Begin of epoch 10 :
2022-10-03 08:32:02 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:32:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:32:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:32:02 [INFO ]  	   step  1 (lr=0.062809)                   35.98%                   2.0155
2022-10-03 08:32:02 [INFO ]  
2022-10-03 08:32:02 [INFO ]  Epoch:   10	Loss: 2.0150	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:32:04 [INFO ]  Epoch:   11	Loss: 1.8933	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:06 [INFO ]  Epoch:   12	Loss: 1.7732	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:32:08 [INFO ]  Epoch:   13	Loss: 1.7132	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:10 [INFO ]  Epoch:   14	Loss: 1.6219	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:12 [INFO ]  Epoch:   15	Loss: 1.5265	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:32:14 [INFO ]  Epoch:   16	Loss: 1.3173	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:32:16 [INFO ]  Epoch:   17	Loss: 1.3521	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:32:17 [INFO ]  Epoch:   18	Loss: 1.3014	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:32:19 [INFO ]  Epoch:   19	Loss: 1.3351	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:32:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 08:32:25 [INFO ]  
2022-10-03 08:32:25 [INFO ]  Begin of epoch 20 :
2022-10-03 08:32:28 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:32:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:32:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:32:28 [INFO ]  	   step  1 (lr=0.197516)                   60.06%                   1.3382
2022-10-03 08:32:28 [INFO ]  
2022-10-03 08:32:28 [INFO ]  Epoch:   20	Loss: 1.2790	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:32:30 [INFO ]  Epoch:   21	Loss: 1.1783	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:32:32 [INFO ]  Epoch:   22	Loss: 1.2632	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:32:34 [INFO ]  Epoch:   23	Loss: 1.1954	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:36 [INFO ]  Epoch:   24	Loss: 1.2008	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:32:37 [INFO ]  Epoch:   25	Loss: 1.0165	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:32:39 [INFO ]  Epoch:   26	Loss: 1.1359	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:41 [INFO ]  Epoch:   27	Loss: 1.1016	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:32:43 [INFO ]  Epoch:   28	Loss: 1.0673	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:32:45 [INFO ]  Epoch:   29	Loss: 1.0249	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:32:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 08:32:51 [INFO ]  
2022-10-03 08:32:51 [INFO ]  Begin of epoch 30 :
2022-10-03 08:32:54 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:32:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:32:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:32:54 [INFO ]  	   step  1 (lr=0.249765)                   67.33%                   1.1170
2022-10-03 08:32:54 [INFO ]  
2022-10-03 08:32:54 [INFO ]  Epoch:   30	Loss: 1.0217	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 08:32:56 [INFO ]  Epoch:   31	Loss: 0.9644	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:32:58 [INFO ]  Epoch:   32	Loss: 1.1669	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:33:00 [INFO ]  Epoch:   33	Loss: 1.0234	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:01 [INFO ]  Epoch:   34	Loss: 1.0351	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:04 [INFO ]  Epoch:   35	Loss: 1.2580	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:33:05 [INFO ]  Epoch:   36	Loss: 1.0510	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:33:08 [INFO ]  Epoch:   37	Loss: 1.0215	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:33:10 [INFO ]  Epoch:   38	Loss: 0.9661	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:33:11 [INFO ]  Epoch:   39	Loss: 1.0097	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 08:33:17 [INFO ]  
2022-10-03 08:33:17 [INFO ]  Begin of epoch 40 :
2022-10-03 08:33:21 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:33:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:33:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:33:21 [INFO ]  	   step  1 (lr=0.288227)                   52.45%                   1.8091
2022-10-03 08:33:21 [INFO ]  
2022-10-03 08:33:21 [INFO ]  Epoch:   40	Loss: 1.5872	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:33:22 [INFO ]  Epoch:   41	Loss: 0.9302	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:24 [INFO ]  Epoch:   42	Loss: 0.9389	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:33:26 [INFO ]  Epoch:   43	Loss: 0.8568	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:33:28 [INFO ]  Epoch:   44	Loss: 0.9151	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:33:30 [INFO ]  Epoch:   45	Loss: 0.9014	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:33:31 [INFO ]  Epoch:   46	Loss: 0.8844	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:33:33 [INFO ]  Epoch:   47	Loss: 0.9334	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:33:35 [INFO ]  Epoch:   48	Loss: 0.9470	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:33:37 [INFO ]  Epoch:   49	Loss: 0.7900	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:33:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 08:33:43 [INFO ]  
2022-10-03 08:33:43 [INFO ]  Begin of epoch 50 :
2022-10-03 08:33:46 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:33:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:33:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:33:46 [INFO ]  	   step  1 (lr=0.321718)                   75.60%                   0.8910
2022-10-03 08:33:46 [INFO ]  
2022-10-03 08:33:46 [INFO ]  Epoch:   50	Loss: 0.7407	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 08:33:48 [INFO ]  Epoch:   51	Loss: 0.9032	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:50 [INFO ]  Epoch:   52	Loss: 0.8466	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:33:52 [INFO ]  Epoch:   53	Loss: 0.7335	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:33:54 [INFO ]  Epoch:   54	Loss: 0.8081	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:33:56 [INFO ]  Epoch:   55	Loss: 0.7575	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:33:57 [INFO ]  Epoch:   56	Loss: 0.7701	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:33:59 [INFO ]  Epoch:   57	Loss: 0.7573	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:34:01 [INFO ]  Epoch:   58	Loss: 0.7394	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:34:03 [INFO ]  Epoch:   59	Loss: 0.8367	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:34:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 08:34:09 [INFO ]  
2022-10-03 08:34:09 [INFO ]  Begin of epoch 60 :
2022-10-03 08:34:13 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:34:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:34:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:34:13 [INFO ]  	   step  1 (lr=0.336660)                   76.40%                   0.8577
2022-10-03 08:34:13 [INFO ]  
2022-10-03 08:34:13 [INFO ]  Epoch:   60	Loss: 0.8152	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:34:14 [INFO ]  Epoch:   61	Loss: 0.8128	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:16 [INFO ]  Epoch:   62	Loss: 0.7827	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:34:18 [INFO ]  Epoch:   63	Loss: 0.7831	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:20 [INFO ]  Epoch:   64	Loss: 0.7393	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:22 [INFO ]  Epoch:   65	Loss: 0.7489	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:24 [INFO ]  Epoch:   66	Loss: 0.7683	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 08:34:26 [INFO ]  Epoch:   67	Loss: 0.8380	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 08:34:27 [INFO ]  Epoch:   68	Loss: 0.7823	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:29 [INFO ]  Epoch:   69	Loss: 0.7209	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 08:34:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 08:34:35 [INFO ]  
2022-10-03 08:34:35 [INFO ]  Begin of epoch 70 :
2022-10-03 08:34:39 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:34:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:34:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:34:39 [INFO ]  	   step  1 (lr=0.338389)                   77.02%                   0.8347
2022-10-03 08:34:39 [INFO ]  
2022-10-03 08:34:39 [INFO ]  Epoch:   70	Loss: 0.7757	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:34:40 [INFO ]  Epoch:   71	Loss: 0.8335	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:34:42 [INFO ]  Epoch:   72	Loss: 0.8081	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:34:44 [INFO ]  Epoch:   73	Loss: 0.8040	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:34:46 [INFO ]  Epoch:   74	Loss: 0.8303	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:34:48 [INFO ]  Epoch:   75	Loss: 0.7842	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:34:50 [INFO ]  Epoch:   76	Loss: 0.8394	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:34:52 [INFO ]  Epoch:   77	Loss: 0.7358	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:34:53 [INFO ]  Epoch:   78	Loss: 0.8834	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:34:55 [INFO ]  Epoch:   79	Loss: 0.8805	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:35:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 08:35:01 [INFO ]  
2022-10-03 08:35:01 [INFO ]  Begin of epoch 80 :
2022-10-03 08:35:04 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:35:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:35:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:35:04 [INFO ]  	   step  1 (lr=0.354164)                   76.69%                   0.8471
2022-10-03 08:35:04 [INFO ]  
2022-10-03 08:35:04 [INFO ]  Epoch:   80	Loss: 0.8228	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:35:06 [INFO ]  Epoch:   81	Loss: 0.7900	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:08 [INFO ]  Epoch:   82	Loss: 0.8055	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:35:10 [INFO ]  Epoch:   83	Loss: 0.8011	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:12 [INFO ]  Epoch:   84	Loss: 0.9174	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:35:13 [INFO ]  Epoch:   85	Loss: 0.7532	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:35:15 [INFO ]  Epoch:   86	Loss: 0.7105	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:35:17 [INFO ]  Epoch:   87	Loss: 0.7127	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:35:19 [INFO ]  Epoch:   88	Loss: 0.7544	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:21 [INFO ]  Epoch:   89	Loss: 0.7686	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:35:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 08:35:27 [INFO ]  
2022-10-03 08:35:27 [INFO ]  Begin of epoch 90 :
2022-10-03 08:35:30 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:35:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:35:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:35:30 [INFO ]  	   step  1 (lr=0.359251)                   76.85%                   0.8495
2022-10-03 08:35:30 [INFO ]  
2022-10-03 08:35:30 [INFO ]  Epoch:   90	Loss: 0.7678	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:32 [INFO ]  Epoch:   91	Loss: 0.8290	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:35:34 [INFO ]  Epoch:   92	Loss: 0.8214	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:35:35 [INFO ]  Epoch:   93	Loss: 0.7919	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:37 [INFO ]  Epoch:   94	Loss: 0.8739	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:35:39 [INFO ]  Epoch:   95	Loss: 0.7535	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:41 [INFO ]  Epoch:   96	Loss: 0.7572	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:35:43 [INFO ]  Epoch:   97	Loss: 0.8281	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:45 [INFO ]  Epoch:   98	Loss: 0.7664	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:35:47 [INFO ]  Epoch:   99	Loss: 0.7637	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:35:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 08:35:53 [INFO ]  
2022-10-03 08:35:53 [INFO ]  Begin of epoch 100 :
2022-10-03 08:35:56 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:35:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:35:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:35:56 [INFO ]  	   step  1 (lr=0.364158)                   77.67%                   0.8041
2022-10-03 08:35:56 [INFO ]  
2022-10-03 08:35:56 [INFO ]  Epoch:  100	Loss: 0.8149	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:35:58 [INFO ]  Epoch:  101	Loss: 0.7369	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:36:00 [INFO ]  Epoch:  102	Loss: 0.7122	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:36:02 [INFO ]  Epoch:  103	Loss: 0.8102	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:36:03 [INFO ]  Epoch:  104	Loss: 0.7612	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:05 [INFO ]  Epoch:  105	Loss: 0.7860	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:36:07 [INFO ]  Epoch:  106	Loss: 0.7281	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:36:09 [INFO ]  Epoch:  107	Loss: 0.7837	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:36:11 [INFO ]  Epoch:  108	Loss: 0.7702	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:13 [INFO ]  Epoch:  109	Loss: 0.7881	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:36:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 08:36:18 [INFO ]  
2022-10-03 08:36:18 [INFO ]  Begin of epoch 110 :
2022-10-03 08:36:22 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:36:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:36:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:36:22 [INFO ]  	   step  1 (lr=0.365738)                   77.78%                   0.8063
2022-10-03 08:36:22 [INFO ]  
2022-10-03 08:36:22 [INFO ]  Epoch:  110	Loss: 0.7585	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:23 [INFO ]  Epoch:  111	Loss: 0.8095	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:36:25 [INFO ]  Epoch:  112	Loss: 0.8061	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:27 [INFO ]  Epoch:  113	Loss: 0.8007	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:29 [INFO ]  Epoch:  114	Loss: 0.7352	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:36:31 [INFO ]  Epoch:  115	Loss: 0.8111	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:33 [INFO ]  Epoch:  116	Loss: 0.8265	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:36:35 [INFO ]  Epoch:  117	Loss: 0.8558	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:37 [INFO ]  Epoch:  118	Loss: 0.7592	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:36:39 [INFO ]  Epoch:  119	Loss: 0.7504	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 08:36:45 [INFO ]  
2022-10-03 08:36:45 [INFO ]  Begin of epoch 120 :
2022-10-03 08:36:48 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:36:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:36:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:36:48 [INFO ]  	   step  1 (lr=0.374620)                   77.87%                   0.8057
2022-10-03 08:36:48 [INFO ]  
2022-10-03 08:36:48 [INFO ]  Epoch:  120	Loss: 0.7829	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 08:36:50 [INFO ]  Epoch:  121	Loss: 0.7045	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:36:52 [INFO ]  Epoch:  122	Loss: 0.7277	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:36:54 [INFO ]  Epoch:  123	Loss: 0.7461	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:36:56 [INFO ]  Epoch:  124	Loss: 0.7581	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:36:58 [INFO ]  Epoch:  125	Loss: 0.7086	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:37:00 [INFO ]  Epoch:  126	Loss: 0.7102	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:02 [INFO ]  Epoch:  127	Loss: 0.7707	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:03 [INFO ]  Epoch:  128	Loss: 0.7809	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:05 [INFO ]  Epoch:  129	Loss: 0.6919	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 08:37:11 [INFO ]  
2022-10-03 08:37:11 [INFO ]  Begin of epoch 130 :
2022-10-03 08:37:14 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:37:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:37:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:37:14 [INFO ]  	   step  1 (lr=0.374126)                   78.15%                   0.7962
2022-10-03 08:37:14 [INFO ]  
2022-10-03 08:37:14 [INFO ]  Epoch:  130	Loss: 0.6774	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:37:16 [INFO ]  Epoch:  131	Loss: 0.7032	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:37:18 [INFO ]  Epoch:  132	Loss: 0.7961	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:37:20 [INFO ]  Epoch:  133	Loss: 0.7931	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:37:21 [INFO ]  Epoch:  134	Loss: 0.7055	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:37:23 [INFO ]  Epoch:  135	Loss: 0.7384	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:37:25 [INFO ]  Epoch:  136	Loss: 0.6531	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:37:27 [INFO ]  Epoch:  137	Loss: 0.6761	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:37:29 [INFO ]  Epoch:  138	Loss: 0.6833	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:31 [INFO ]  Epoch:  139	Loss: 0.7100	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:37:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:37:37 [INFO ]  
2022-10-03 08:37:37 [INFO ]  Begin of epoch 140 :
2022-10-03 08:37:40 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:37:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:37:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:37:40 [INFO ]  	   step  1 (lr=0.376217)                   77.91%                   0.8055
2022-10-03 08:37:40 [INFO ]  
2022-10-03 08:37:40 [INFO ]  Epoch:  140	Loss: 0.7355	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:37:42 [INFO ]  Epoch:  141	Loss: 0.6828	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:37:43 [INFO ]  Epoch:  142	Loss: 0.7325	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:37:45 [INFO ]  Epoch:  143	Loss: 0.6979	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:37:47 [INFO ]  Epoch:  144	Loss: 0.7738	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:37:49 [INFO ]  Epoch:  145	Loss: 0.7301	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:37:51 [INFO ]  Epoch:  146	Loss: 0.7283	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:37:53 [INFO ]  Epoch:  147	Loss: 0.8073	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:55 [INFO ]  Epoch:  148	Loss: 0.8294	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:37:57 [INFO ]  Epoch:  149	Loss: 0.8119	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:38:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:38:02 [INFO ]  
2022-10-03 08:38:02 [INFO ]  Begin of epoch 150 :
2022-10-03 08:38:06 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:38:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:38:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:38:06 [INFO ]  	   step  1 (lr=0.379897)                   78.32%                   0.7855
2022-10-03 08:38:06 [INFO ]  
2022-10-03 08:38:06 [INFO ]  Epoch:  150	Loss: 0.7293	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:38:07 [INFO ]  Epoch:  151	Loss: 0.7403	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:38:09 [INFO ]  Epoch:  152	Loss: 0.7814	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:38:11 [INFO ]  Epoch:  153	Loss: 0.7283	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:38:13 [INFO ]  Epoch:  154	Loss: 0.7424	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:38:15 [INFO ]  Epoch:  155	Loss: 0.7212	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:17 [INFO ]  Epoch:  156	Loss: 0.7472	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:38:19 [INFO ]  Epoch:  157	Loss: 0.8033	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:38:20 [INFO ]  Epoch:  158	Loss: 0.7109	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:22 [INFO ]  Epoch:  159	Loss: 0.7660	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:38:28 [INFO ]  
2022-10-03 08:38:28 [INFO ]  Begin of epoch 160 :
2022-10-03 08:38:31 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:38:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:38:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:38:31 [INFO ]  	   step  1 (lr=0.378908)                   78.13%                   0.7911
2022-10-03 08:38:31 [INFO ]  
2022-10-03 08:38:31 [INFO ]  Epoch:  160	Loss: 0.7301	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 08:38:33 [INFO ]  Epoch:  161	Loss: 0.7349	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:35 [INFO ]  Epoch:  162	Loss: 0.6980	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:38:37 [INFO ]  Epoch:  163	Loss: 0.7209	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:38:39 [INFO ]  Epoch:  164	Loss: 0.6928	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:40 [INFO ]  Epoch:  165	Loss: 0.7200	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:38:42 [INFO ]  Epoch:  166	Loss: 0.7208	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:38:44 [INFO ]  Epoch:  167	Loss: 0.7271	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:38:46 [INFO ]  Epoch:  168	Loss: 0.7178	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:38:48 [INFO ]  Epoch:  169	Loss: 0.7431	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:38:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:38:54 [INFO ]  
2022-10-03 08:38:54 [INFO ]  Begin of epoch 170 :
2022-10-03 08:38:58 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:38:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:38:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:38:58 [INFO ]  	   step  1 (lr=0.379911)                   77.66%                   0.8075
2022-10-03 08:38:58 [INFO ]  
2022-10-03 08:38:58 [INFO ]  Epoch:  170	Loss: 0.7812	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:38:59 [INFO ]  Epoch:  171	Loss: 0.7982	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:39:02 [INFO ]  Epoch:  172	Loss: 0.7018	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 08:39:04 [INFO ]  Epoch:  173	Loss: 0.7851	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:05 [INFO ]  Epoch:  174	Loss: 0.7535	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:07 [INFO ]  Epoch:  175	Loss: 0.7441	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:09 [INFO ]  Epoch:  176	Loss: 0.7277	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:39:11 [INFO ]  Epoch:  177	Loss: 0.6929	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:13 [INFO ]  Epoch:  178	Loss: 0.7837	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 08:39:15 [INFO ]  Epoch:  179	Loss: 0.6956	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:39:21 [INFO ]  
2022-10-03 08:39:21 [INFO ]  Begin of epoch 180 :
2022-10-03 08:39:24 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:39:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:39:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:39:24 [INFO ]  	   step  1 (lr=0.380627)                   77.75%                   0.8048
2022-10-03 08:39:24 [INFO ]  
2022-10-03 08:39:24 [INFO ]  Epoch:  180	Loss: 0.8251	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:39:26 [INFO ]  Epoch:  181	Loss: 0.6966	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:39:28 [INFO ]  Epoch:  182	Loss: 0.7350	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:39:30 [INFO ]  Epoch:  183	Loss: 0.7509	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:39:31 [INFO ]  Epoch:  184	Loss: 0.7818	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:39:33 [INFO ]  Epoch:  185	Loss: 0.6973	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 08:39:35 [INFO ]  Epoch:  186	Loss: 0.7006	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:39:37 [INFO ]  Epoch:  187	Loss: 0.7103	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:39:39 [INFO ]  Epoch:  188	Loss: 0.7466	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:39:41 [INFO ]  Epoch:  189	Loss: 0.7590	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:39:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:39:47 [INFO ]  
2022-10-03 08:39:47 [INFO ]  Begin of epoch 190 :
2022-10-03 08:39:50 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:39:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:39:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:39:50 [INFO ]  	   step  1 (lr=0.380988)                   77.52%                   0.8138
2022-10-03 08:39:50 [INFO ]  
2022-10-03 08:39:50 [INFO ]  Epoch:  190	Loss: 0.7755	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:39:52 [INFO ]  Epoch:  191	Loss: 0.7376	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:39:54 [INFO ]  Epoch:  192	Loss: 0.6947	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:39:55 [INFO ]  Epoch:  193	Loss: 0.7447	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:39:57 [INFO ]  Epoch:  194	Loss: 0.7703	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:39:59 [INFO ]  Epoch:  195	Loss: 0.6614	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:40:01 [INFO ]  Epoch:  196	Loss: 0.7537	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:40:03 [INFO ]  Epoch:  197	Loss: 0.7838	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:40:05 [INFO ]  Epoch:  198	Loss: 0.6879	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:40:07 [INFO ]  Epoch:  199	Loss: 0.7078	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:40:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:40:12 [INFO ]  
2022-10-03 08:40:12 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:40:15 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:40:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:40:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:40:15 [INFO ]  	   step  1 (lr=0.381324)                   77.72%                   0.7989
2022-10-03 08:40:15 [INFO ]  
2022-10-03 08:40:15 [INFO ]  
2022-10-03 08:40:15 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:40:18 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:40:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:40:18 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:40:18 [INFO ]  	   step  1 (lr=0.381324)                   14.87%                   5.3109
2022-10-03 08:40:18 [INFO ]  
2022-10-03 08:41:31 [INFO ]  ======================================== 2022-10-03 08:41:31 ========================================
2022-10-03 08:41:31 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 08:41:31 [INFO ]  Options: 
2022-10-03 08:41:31 [INFO ]  	base_dir: null
2022-10-03 08:41:31 [INFO ]  	batch_size: 1024
2022-10-03 08:41:31 [INFO ]  	checkpoint_interval: 10
2022-10-03 08:41:31 [INFO ]  	dataset: SVHN
2022-10-03 08:41:31 [INFO ]  	dataset_labels:
2022-10-03 08:41:31 [INFO ]  	- 0
2022-10-03 08:41:31 [INFO ]  	- 1
2022-10-03 08:41:31 [INFO ]  	- 2
2022-10-03 08:41:31 [INFO ]  	- 3
2022-10-03 08:41:31 [INFO ]  	- 4
2022-10-03 08:41:31 [INFO ]  	- 5
2022-10-03 08:41:31 [INFO ]  	- 6
2022-10-03 08:41:31 [INFO ]  	- 7
2022-10-03 08:41:31 [INFO ]  	- 8
2022-10-03 08:41:31 [INFO ]  	- 9
2022-10-03 08:41:31 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 08:41:31 [INFO ]  	- !!python/tuple
2022-10-03 08:41:31 [INFO ]  	    - 0.4379104971885681
2022-10-03 08:41:31 [INFO ]  	    - 0.44398033618927
2022-10-03 08:41:31 [INFO ]  	    - 0.4729299545288086
2022-10-03 08:41:31 [INFO ]  	- !!python/tuple
2022-10-03 08:41:31 [INFO ]  	    - 0.19803012907505035
2022-10-03 08:41:31 [INFO ]  	    - 0.2010156363248825
2022-10-03 08:41:31 [INFO ]  	    - 0.19703614711761475
2022-10-03 08:41:31 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 08:41:31 [INFO ]  	decay_epochs: 50
2022-10-03 08:41:31 [INFO ]  	decay_factor: 0.1
2022-10-03 08:41:31 [INFO ]  	device_id: 0
2022-10-03 08:41:31 [INFO ]  	distill_epochs: 1
2022-10-03 08:41:31 [INFO ]  	distill_lr: 0.02
2022-10-03 08:41:31 [INFO ]  	distill_steps: 1
2022-10-03 08:41:31 [INFO ]  	epochs: 200
2022-10-03 08:41:31 [INFO ]  	expand_cls: false
2022-10-03 08:41:31 [INFO ]  	forgetting_dataset: null
2022-10-03 08:41:31 [INFO ]  	init: xavier
2022-10-03 08:41:31 [INFO ]  	init_param: 1.0
2022-10-03 08:41:31 [INFO ]  	input_size: 32
2022-10-03 08:41:31 [INFO ]  	ipc: 5
2022-10-03 08:41:31 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 08:41:31 [INFO ]  	log_interval: 100
2022-10-03 08:41:31 [INFO ]  	log_level: INFO
2022-10-03 08:41:31 [INFO ]  	lr: 0.01
2022-10-03 08:41:31 [INFO ]  	mode: distill_adapt
2022-10-03 08:41:31 [INFO ]  	nc: 3
2022-10-03 08:41:31 [INFO ]  	num_classes: 10
2022-10-03 08:41:31 [INFO ]  	num_workers: 8
2022-10-03 08:41:31 [INFO ]  	phase: train
2022-10-03 08:41:31 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 08:41:31 [INFO ]  	start_time: '2022-10-03 08:41:31'
2022-10-03 08:41:31 [INFO ]  	test_batch_size: 1024
2022-10-03 08:41:31 [INFO ]  	
2022-10-03 08:41:33 [INFO ]  train dataset size:	73257
2022-10-03 08:41:33 [INFO ]  test dataset size: 	26032
2022-10-03 08:41:33 [INFO ]  datasets built!
2022-10-03 08:41:33 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 08:41:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 08:41:39 [INFO ]  
2022-10-03 08:41:39 [INFO ]  Begin of epoch 0 :
2022-10-03 08:41:42 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:41:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:41:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:41:42 [INFO ]  	   step  1 (lr=0.020000)                    6.95%                   9.2125
2022-10-03 08:41:42 [INFO ]  
2022-10-03 08:41:42 [INFO ]  Epoch:    0	Loss: 9.3697	Data Time: 0.45s	Train Time: 0.03s
2022-10-03 08:41:44 [INFO ]  Epoch:    1	Loss: 3.2556	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 08:41:46 [INFO ]  Epoch:    2	Loss: 2.6200	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:41:48 [INFO ]  Epoch:    3	Loss: 2.3291	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:41:50 [INFO ]  Epoch:    4	Loss: 2.2335	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:41:52 [INFO ]  Epoch:    5	Loss: 2.1968	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:41:54 [INFO ]  Epoch:    6	Loss: 2.2081	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:41:56 [INFO ]  Epoch:    7	Loss: 2.1488	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:41:58 [INFO ]  Epoch:    8	Loss: 2.1082	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:42:00 [INFO ]  Epoch:    9	Loss: 2.0490	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:42:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 08:42:06 [INFO ]  
2022-10-03 08:42:06 [INFO ]  Begin of epoch 10 :
2022-10-03 08:42:09 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:42:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:42:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:42:09 [INFO ]  	   step  1 (lr=0.054241)                   34.92%                   2.0335
2022-10-03 08:42:09 [INFO ]  
2022-10-03 08:42:09 [INFO ]  Epoch:   10	Loss: 2.0368	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:42:11 [INFO ]  Epoch:   11	Loss: 1.9279	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:42:13 [INFO ]  Epoch:   12	Loss: 1.8196	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:42:15 [INFO ]  Epoch:   13	Loss: 1.6506	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:42:17 [INFO ]  Epoch:   14	Loss: 1.6980	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:42:18 [INFO ]  Epoch:   15	Loss: 1.4551	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:42:20 [INFO ]  Epoch:   16	Loss: 1.4469	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:42:22 [INFO ]  Epoch:   17	Loss: 1.2582	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:42:24 [INFO ]  Epoch:   18	Loss: 1.4103	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:42:26 [INFO ]  Epoch:   19	Loss: 1.3671	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:42:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 08:42:32 [INFO ]  
2022-10-03 08:42:32 [INFO ]  Begin of epoch 20 :
2022-10-03 08:42:36 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:42:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:42:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:42:36 [INFO ]  	   step  1 (lr=0.199546)                   60.01%                   1.2936
2022-10-03 08:42:36 [INFO ]  
2022-10-03 08:42:36 [INFO ]  Epoch:   20	Loss: 1.2716	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:42:37 [INFO ]  Epoch:   21	Loss: 1.1685	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:42:39 [INFO ]  Epoch:   22	Loss: 1.2799	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:42:41 [INFO ]  Epoch:   23	Loss: 1.1658	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:42:43 [INFO ]  Epoch:   24	Loss: 1.1732	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:42:45 [INFO ]  Epoch:   25	Loss: 1.2098	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:42:47 [INFO ]  Epoch:   26	Loss: 0.9896	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:42:48 [INFO ]  Epoch:   27	Loss: 1.0848	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:42:50 [INFO ]  Epoch:   28	Loss: 0.9914	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:42:52 [INFO ]  Epoch:   29	Loss: 0.9839	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:42:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 08:42:58 [INFO ]  
2022-10-03 08:42:58 [INFO ]  Begin of epoch 30 :
2022-10-03 08:43:01 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:43:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:43:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:43:01 [INFO ]  	   step  1 (lr=0.253780)                   70.29%                   1.0533
2022-10-03 08:43:01 [INFO ]  
2022-10-03 08:43:01 [INFO ]  Epoch:   30	Loss: 1.0366	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:43:03 [INFO ]  Epoch:   31	Loss: 0.9446	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:43:05 [INFO ]  Epoch:   32	Loss: 0.9253	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:43:06 [INFO ]  Epoch:   33	Loss: 1.0228	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:43:08 [INFO ]  Epoch:   34	Loss: 1.5175	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:43:10 [INFO ]  Epoch:   35	Loss: 1.0333	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:43:12 [INFO ]  Epoch:   36	Loss: 0.8414	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:43:14 [INFO ]  Epoch:   37	Loss: 1.1841	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:43:16 [INFO ]  Epoch:   38	Loss: 0.9056	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:43:17 [INFO ]  Epoch:   39	Loss: 1.0401	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:43:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 08:43:23 [INFO ]  
2022-10-03 08:43:23 [INFO ]  Begin of epoch 40 :
2022-10-03 08:43:27 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:43:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:43:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:43:27 [INFO ]  	   step  1 (lr=0.278825)                   63.71%                   1.4015
2022-10-03 08:43:27 [INFO ]  
2022-10-03 08:43:27 [INFO ]  Epoch:   40	Loss: 1.4401	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:43:28 [INFO ]  Epoch:   41	Loss: 0.8703	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:43:30 [INFO ]  Epoch:   42	Loss: 0.9833	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:43:32 [INFO ]  Epoch:   43	Loss: 0.8199	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:43:34 [INFO ]  Epoch:   44	Loss: 1.0059	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:43:36 [INFO ]  Epoch:   45	Loss: 0.8719	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:43:38 [INFO ]  Epoch:   46	Loss: 0.8225	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:43:39 [INFO ]  Epoch:   47	Loss: 0.8049	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:43:41 [INFO ]  Epoch:   48	Loss: 0.7901	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:43:43 [INFO ]  Epoch:   49	Loss: 0.8091	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:43:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 08:43:49 [INFO ]  
2022-10-03 08:43:49 [INFO ]  Begin of epoch 50 :
2022-10-03 08:43:52 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:43:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:43:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:43:52 [INFO ]  	   step  1 (lr=0.297420)                   77.70%                   0.8159
2022-10-03 08:43:52 [INFO ]  
2022-10-03 08:43:52 [INFO ]  Epoch:   50	Loss: 0.7585	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:43:54 [INFO ]  Epoch:   51	Loss: 0.8177	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:43:56 [INFO ]  Epoch:   52	Loss: 0.7425	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:43:57 [INFO ]  Epoch:   53	Loss: 0.8219	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:43:59 [INFO ]  Epoch:   54	Loss: 0.7520	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:44:01 [INFO ]  Epoch:   55	Loss: 0.7657	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:44:03 [INFO ]  Epoch:   56	Loss: 0.7373	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:44:05 [INFO ]  Epoch:   57	Loss: 0.7258	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:44:07 [INFO ]  Epoch:   58	Loss: 0.8349	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:44:09 [INFO ]  Epoch:   59	Loss: 0.8338	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:44:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 08:44:15 [INFO ]  
2022-10-03 08:44:15 [INFO ]  Begin of epoch 60 :
2022-10-03 08:44:19 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:44:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:44:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:44:19 [INFO ]  	   step  1 (lr=0.306363)                   78.09%                   0.7937
2022-10-03 08:44:19 [INFO ]  
2022-10-03 08:44:19 [INFO ]  Epoch:   60	Loss: 0.7519	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:44:21 [INFO ]  Epoch:   61	Loss: 0.7494	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 08:44:23 [INFO ]  Epoch:   62	Loss: 0.6976	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 08:44:25 [INFO ]  Epoch:   63	Loss: 0.8334	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 08:44:27 [INFO ]  Epoch:   64	Loss: 0.7913	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:44:28 [INFO ]  Epoch:   65	Loss: 0.7921	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:44:30 [INFO ]  Epoch:   66	Loss: 0.7281	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:44:32 [INFO ]  Epoch:   67	Loss: 0.7949	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:44:34 [INFO ]  Epoch:   68	Loss: 0.7286	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:44:36 [INFO ]  Epoch:   69	Loss: 0.7672	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 08:44:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 08:44:42 [INFO ]  
2022-10-03 08:44:42 [INFO ]  Begin of epoch 70 :
2022-10-03 08:44:46 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:44:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:44:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:44:46 [INFO ]  	   step  1 (lr=0.309421)                   78.54%                   0.7874
2022-10-03 08:44:46 [INFO ]  
2022-10-03 08:44:46 [INFO ]  Epoch:   70	Loss: 0.6970	Data Time: 0.34s	Train Time: 0.01s
2022-10-03 08:44:47 [INFO ]  Epoch:   71	Loss: 0.8019	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:44:49 [INFO ]  Epoch:   72	Loss: 0.7195	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:44:51 [INFO ]  Epoch:   73	Loss: 0.7616	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:44:53 [INFO ]  Epoch:   74	Loss: 0.9831	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 08:44:55 [INFO ]  Epoch:   75	Loss: 0.7066	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:44:57 [INFO ]  Epoch:   76	Loss: 0.6397	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:44:58 [INFO ]  Epoch:   77	Loss: 0.7794	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:00 [INFO ]  Epoch:   78	Loss: 0.7883	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:02 [INFO ]  Epoch:   79	Loss: 0.7528	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 08:45:08 [INFO ]  
2022-10-03 08:45:08 [INFO ]  Begin of epoch 80 :
2022-10-03 08:45:11 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:45:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:45:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:45:11 [INFO ]  	   step  1 (lr=0.321577)                   78.60%                   0.7863
2022-10-03 08:45:11 [INFO ]  
2022-10-03 08:45:11 [INFO ]  Epoch:   80	Loss: 0.7249	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 08:45:13 [INFO ]  Epoch:   81	Loss: 0.6758	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:45:15 [INFO ]  Epoch:   82	Loss: 0.7821	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:17 [INFO ]  Epoch:   83	Loss: 0.7024	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:19 [INFO ]  Epoch:   84	Loss: 0.7683	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:45:21 [INFO ]  Epoch:   85	Loss: 0.7792	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:45:23 [INFO ]  Epoch:   86	Loss: 0.8135	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:45:25 [INFO ]  Epoch:   87	Loss: 0.7917	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:45:27 [INFO ]  Epoch:   88	Loss: 0.7776	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:45:28 [INFO ]  Epoch:   89	Loss: 0.6917	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 08:45:34 [INFO ]  
2022-10-03 08:45:34 [INFO ]  Begin of epoch 90 :
2022-10-03 08:45:37 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:45:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:45:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:45:37 [INFO ]  	   step  1 (lr=0.327569)                   76.51%                   0.8447
2022-10-03 08:45:37 [INFO ]  
2022-10-03 08:45:38 [INFO ]  Epoch:   90	Loss: 0.7913	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:39 [INFO ]  Epoch:   91	Loss: 0.7468	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:41 [INFO ]  Epoch:   92	Loss: 0.7362	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:45:43 [INFO ]  Epoch:   93	Loss: 0.6628	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:45 [INFO ]  Epoch:   94	Loss: 0.7506	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:46 [INFO ]  Epoch:   95	Loss: 0.7617	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:48 [INFO ]  Epoch:   96	Loss: 0.7538	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:45:50 [INFO ]  Epoch:   97	Loss: 0.8080	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:52 [INFO ]  Epoch:   98	Loss: 0.7033	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:45:54 [INFO ]  Epoch:   99	Loss: 0.8017	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:45:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 08:45:59 [INFO ]  
2022-10-03 08:45:59 [INFO ]  Begin of epoch 100 :
2022-10-03 08:46:03 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:46:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:46:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:46:03 [INFO ]  	   step  1 (lr=0.331224)                   78.71%                   0.7764
2022-10-03 08:46:03 [INFO ]  
2022-10-03 08:46:03 [INFO ]  Epoch:  100	Loss: 0.6547	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:46:04 [INFO ]  Epoch:  101	Loss: 0.7005	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:46:06 [INFO ]  Epoch:  102	Loss: 0.6662	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:46:08 [INFO ]  Epoch:  103	Loss: 0.7161	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:46:10 [INFO ]  Epoch:  104	Loss: 0.7186	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 08:46:12 [INFO ]  Epoch:  105	Loss: 0.6654	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:46:13 [INFO ]  Epoch:  106	Loss: 0.6822	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:46:15 [INFO ]  Epoch:  107	Loss: 0.7399	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:46:17 [INFO ]  Epoch:  108	Loss: 0.6937	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:46:19 [INFO ]  Epoch:  109	Loss: 0.6841	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:46:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 08:46:25 [INFO ]  
2022-10-03 08:46:25 [INFO ]  Begin of epoch 110 :
2022-10-03 08:46:28 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:46:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:46:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:46:28 [INFO ]  	   step  1 (lr=0.331960)                   78.31%                   0.7899
2022-10-03 08:46:28 [INFO ]  
2022-10-03 08:46:28 [INFO ]  Epoch:  110	Loss: 0.7323	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:46:30 [INFO ]  Epoch:  111	Loss: 0.6562	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:46:32 [INFO ]  Epoch:  112	Loss: 0.7405	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:46:33 [INFO ]  Epoch:  113	Loss: 0.7440	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:46:35 [INFO ]  Epoch:  114	Loss: 0.8116	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:46:37 [INFO ]  Epoch:  115	Loss: 0.7302	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:46:39 [INFO ]  Epoch:  116	Loss: 0.6860	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:46:41 [INFO ]  Epoch:  117	Loss: 0.6864	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:46:43 [INFO ]  Epoch:  118	Loss: 0.6765	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:46:45 [INFO ]  Epoch:  119	Loss: 0.7016	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:46:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 08:46:51 [INFO ]  
2022-10-03 08:46:51 [INFO ]  Begin of epoch 120 :
2022-10-03 08:46:54 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:46:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:46:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:46:54 [INFO ]  	   step  1 (lr=0.332540)                   79.48%                   0.7467
2022-10-03 08:46:54 [INFO ]  
2022-10-03 08:46:54 [INFO ]  Epoch:  120	Loss: 0.6998	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 08:46:56 [INFO ]  Epoch:  121	Loss: 0.7055	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:46:58 [INFO ]  Epoch:  122	Loss: 0.7146	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:46:59 [INFO ]  Epoch:  123	Loss: 0.7645	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:01 [INFO ]  Epoch:  124	Loss: 0.7192	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:47:03 [INFO ]  Epoch:  125	Loss: 0.7584	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:05 [INFO ]  Epoch:  126	Loss: 0.7578	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:07 [INFO ]  Epoch:  127	Loss: 0.7159	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:47:09 [INFO ]  Epoch:  128	Loss: 0.7611	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:47:10 [INFO ]  Epoch:  129	Loss: 0.7497	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:47:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 08:47:16 [INFO ]  
2022-10-03 08:47:16 [INFO ]  Begin of epoch 130 :
2022-10-03 08:47:19 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:47:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:47:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:47:19 [INFO ]  	   step  1 (lr=0.332529)                   79.35%                   0.7585
2022-10-03 08:47:19 [INFO ]  
2022-10-03 08:47:19 [INFO ]  Epoch:  130	Loss: 0.7283	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:47:21 [INFO ]  Epoch:  131	Loss: 0.7210	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:23 [INFO ]  Epoch:  132	Loss: 0.7499	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 08:47:25 [INFO ]  Epoch:  133	Loss: 0.6899	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:26 [INFO ]  Epoch:  134	Loss: 0.6612	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:28 [INFO ]  Epoch:  135	Loss: 0.7088	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:30 [INFO ]  Epoch:  136	Loss: 0.7365	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:32 [INFO ]  Epoch:  137	Loss: 0.7163	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:47:34 [INFO ]  Epoch:  138	Loss: 0.7583	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:36 [INFO ]  Epoch:  139	Loss: 0.7989	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 08:47:41 [INFO ]  
2022-10-03 08:47:41 [INFO ]  Begin of epoch 140 :
2022-10-03 08:47:45 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:47:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:47:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:47:45 [INFO ]  	   step  1 (lr=0.333766)                   77.82%                   0.8081
2022-10-03 08:47:45 [INFO ]  
2022-10-03 08:47:45 [INFO ]  Epoch:  140	Loss: 0.6787	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:47:47 [INFO ]  Epoch:  141	Loss: 0.7254	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:47:49 [INFO ]  Epoch:  142	Loss: 0.7413	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:47:50 [INFO ]  Epoch:  143	Loss: 0.7386	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:47:52 [INFO ]  Epoch:  144	Loss: 0.8173	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:47:54 [INFO ]  Epoch:  145	Loss: 0.7228	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:47:56 [INFO ]  Epoch:  146	Loss: 0.7237	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:47:58 [INFO ]  Epoch:  147	Loss: 0.7448	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:48:00 [INFO ]  Epoch:  148	Loss: 0.7604	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:48:02 [INFO ]  Epoch:  149	Loss: 0.7524	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 08:48:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 08:48:07 [INFO ]  
2022-10-03 08:48:07 [INFO ]  Begin of epoch 150 :
2022-10-03 08:48:10 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:48:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:48:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:48:10 [INFO ]  	   step  1 (lr=0.337044)                   79.09%                   0.7614
2022-10-03 08:48:10 [INFO ]  
2022-10-03 08:48:10 [INFO ]  Epoch:  150	Loss: 0.7075	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:12 [INFO ]  Epoch:  151	Loss: 0.6740	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:48:14 [INFO ]  Epoch:  152	Loss: 0.6971	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:16 [INFO ]  Epoch:  153	Loss: 0.8224	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:48:18 [INFO ]  Epoch:  154	Loss: 0.6491	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:20 [INFO ]  Epoch:  155	Loss: 0.7483	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:48:22 [INFO ]  Epoch:  156	Loss: 0.7248	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:23 [INFO ]  Epoch:  157	Loss: 0.7423	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:25 [INFO ]  Epoch:  158	Loss: 0.7270	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:27 [INFO ]  Epoch:  159	Loss: 0.7003	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 08:48:33 [INFO ]  
2022-10-03 08:48:33 [INFO ]  Begin of epoch 160 :
2022-10-03 08:48:36 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:48:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:48:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:48:36 [INFO ]  	   step  1 (lr=0.337579)                   78.56%                   0.7787
2022-10-03 08:48:36 [INFO ]  
2022-10-03 08:48:36 [INFO ]  Epoch:  160	Loss: 0.7416	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:38 [INFO ]  Epoch:  161	Loss: 0.7352	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:48:40 [INFO ]  Epoch:  162	Loss: 0.7225	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:42 [INFO ]  Epoch:  163	Loss: 0.7328	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:44 [INFO ]  Epoch:  164	Loss: 0.6310	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:45 [INFO ]  Epoch:  165	Loss: 0.7465	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:47 [INFO ]  Epoch:  166	Loss: 0.7048	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:48:49 [INFO ]  Epoch:  167	Loss: 0.6276	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:48:51 [INFO ]  Epoch:  168	Loss: 0.7046	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 08:48:53 [INFO ]  Epoch:  169	Loss: 0.7250	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:48:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 08:48:58 [INFO ]  
2022-10-03 08:48:58 [INFO ]  Begin of epoch 170 :
2022-10-03 08:49:02 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:49:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:49:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:49:02 [INFO ]  	   step  1 (lr=0.338228)                   78.89%                   0.7696
2022-10-03 08:49:02 [INFO ]  
2022-10-03 08:49:02 [INFO ]  Epoch:  170	Loss: 0.6460	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:49:04 [INFO ]  Epoch:  171	Loss: 0.6986	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 08:49:06 [INFO ]  Epoch:  172	Loss: 0.7345	Data Time: 0.37s	Train Time: 0.01s
2022-10-03 08:49:08 [INFO ]  Epoch:  173	Loss: 0.6870	Data Time: 0.36s	Train Time: 0.01s
2022-10-03 08:49:10 [INFO ]  Epoch:  174	Loss: 0.7059	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 08:49:12 [INFO ]  Epoch:  175	Loss: 0.7381	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 08:49:14 [INFO ]  Epoch:  176	Loss: 0.7062	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:49:15 [INFO ]  Epoch:  177	Loss: 0.7730	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 08:49:18 [INFO ]  Epoch:  178	Loss: 0.7483	Data Time: 0.37s	Train Time: 0.01s
2022-10-03 08:49:20 [INFO ]  Epoch:  179	Loss: 0.6227	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 08:49:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 08:49:26 [INFO ]  
2022-10-03 08:49:26 [INFO ]  Begin of epoch 180 :
2022-10-03 08:49:29 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:49:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:49:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:49:29 [INFO ]  	   step  1 (lr=0.338462)                   79.24%                   0.7716
2022-10-03 08:49:29 [INFO ]  
2022-10-03 08:49:29 [INFO ]  Epoch:  180	Loss: 0.7253	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 08:49:31 [INFO ]  Epoch:  181	Loss: 0.7270	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:49:33 [INFO ]  Epoch:  182	Loss: 0.7051	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:49:35 [INFO ]  Epoch:  183	Loss: 0.7360	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 08:49:36 [INFO ]  Epoch:  184	Loss: 0.7245	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:49:38 [INFO ]  Epoch:  185	Loss: 0.7761	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:49:40 [INFO ]  Epoch:  186	Loss: 0.6741	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:49:42 [INFO ]  Epoch:  187	Loss: 0.6418	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 08:49:44 [INFO ]  Epoch:  188	Loss: 0.7672	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:49:46 [INFO ]  Epoch:  189	Loss: 0.7415	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:49:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 08:49:51 [INFO ]  
2022-10-03 08:49:51 [INFO ]  Begin of epoch 190 :
2022-10-03 08:49:54 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:49:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:49:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:49:54 [INFO ]  	   step  1 (lr=0.338153)                   79.37%                   0.7638
2022-10-03 08:49:54 [INFO ]  
2022-10-03 08:49:54 [INFO ]  Epoch:  190	Loss: 0.7490	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 08:49:56 [INFO ]  Epoch:  191	Loss: 0.7148	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 08:49:58 [INFO ]  Epoch:  192	Loss: 0.6821	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:50:00 [INFO ]  Epoch:  193	Loss: 0.6863	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:50:02 [INFO ]  Epoch:  194	Loss: 0.6568	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:50:04 [INFO ]  Epoch:  195	Loss: 0.8146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:50:06 [INFO ]  Epoch:  196	Loss: 0.6548	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 08:50:08 [INFO ]  Epoch:  197	Loss: 0.7127	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 08:50:10 [INFO ]  Epoch:  198	Loss: 0.7056	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 08:50:11 [INFO ]  Epoch:  199	Loss: 0.7269	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 08:50:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 08:50:16 [INFO ]  
2022-10-03 08:50:16 [INFO ]  Final evaluation for SVHN :
2022-10-03 08:50:20 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:50:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:50:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 08:50:20 [INFO ]  	   step  1 (lr=0.337844)                   79.19%                   0.7703
2022-10-03 08:50:20 [INFO ]  
2022-10-03 08:50:20 [INFO ]  
2022-10-03 08:50:20 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 08:50:23 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 08:50:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 08:50:23 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 08:50:23 [INFO ]  	   step  1 (lr=0.337844)                   17.64%                   5.1262
2022-10-03 08:50:23 [INFO ]  
2022-10-03 09:29:21 [INFO ]  ======================================== 2022-10-03 09:29:21 ========================================
2022-10-03 09:29:21 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 09:29:21 [INFO ]  Options: 
2022-10-03 09:29:21 [INFO ]  	base_dir: null
2022-10-03 09:29:21 [INFO ]  	batch_size: 1024
2022-10-03 09:29:21 [INFO ]  	checkpoint_interval: 10
2022-10-03 09:29:21 [INFO ]  	dataset: SVHN
2022-10-03 09:29:21 [INFO ]  	dataset_labels:
2022-10-03 09:29:21 [INFO ]  	- 0
2022-10-03 09:29:21 [INFO ]  	- 1
2022-10-03 09:29:21 [INFO ]  	- 2
2022-10-03 09:29:21 [INFO ]  	- 3
2022-10-03 09:29:21 [INFO ]  	- 4
2022-10-03 09:29:21 [INFO ]  	- 5
2022-10-03 09:29:21 [INFO ]  	- 6
2022-10-03 09:29:21 [INFO ]  	- 7
2022-10-03 09:29:21 [INFO ]  	- 8
2022-10-03 09:29:21 [INFO ]  	- 9
2022-10-03 09:29:21 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 09:29:21 [INFO ]  	- !!python/tuple
2022-10-03 09:29:21 [INFO ]  	    - 0.4379104971885681
2022-10-03 09:29:21 [INFO ]  	    - 0.44398033618927
2022-10-03 09:29:21 [INFO ]  	    - 0.4729299545288086
2022-10-03 09:29:21 [INFO ]  	- !!python/tuple
2022-10-03 09:29:21 [INFO ]  	    - 0.19803012907505035
2022-10-03 09:29:21 [INFO ]  	    - 0.2010156363248825
2022-10-03 09:29:21 [INFO ]  	    - 0.19703614711761475
2022-10-03 09:29:21 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 09:29:21 [INFO ]  	decay_epochs: 50
2022-10-03 09:29:21 [INFO ]  	decay_factor: 0.1
2022-10-03 09:29:21 [INFO ]  	device_id: 0
2022-10-03 09:29:21 [INFO ]  	distill_epochs: 1
2022-10-03 09:29:21 [INFO ]  	distill_lr: 0.02
2022-10-03 09:29:21 [INFO ]  	distill_steps: 1
2022-10-03 09:29:21 [INFO ]  	epochs: 200
2022-10-03 09:29:21 [INFO ]  	expand_cls: false
2022-10-03 09:29:21 [INFO ]  	forgetting_dataset: null
2022-10-03 09:29:21 [INFO ]  	init: xavier
2022-10-03 09:29:21 [INFO ]  	init_param: 1.0
2022-10-03 09:29:21 [INFO ]  	input_size: 32
2022-10-03 09:29:21 [INFO ]  	ipc: 5
2022-10-03 09:29:21 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 09:29:21 [INFO ]  	log_interval: 100
2022-10-03 09:29:21 [INFO ]  	log_level: INFO
2022-10-03 09:29:21 [INFO ]  	lr: 0.01
2022-10-03 09:29:21 [INFO ]  	mode: distill_adapt
2022-10-03 09:29:21 [INFO ]  	nc: 3
2022-10-03 09:29:21 [INFO ]  	num_classes: 10
2022-10-03 09:29:21 [INFO ]  	num_workers: 8
2022-10-03 09:29:21 [INFO ]  	phase: train
2022-10-03 09:29:21 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 09:29:21 [INFO ]  	start_time: '2022-10-03 09:29:21'
2022-10-03 09:29:21 [INFO ]  	test_batch_size: 1024
2022-10-03 09:29:21 [INFO ]  	
2022-10-03 09:29:23 [INFO ]  train dataset size:	73257
2022-10-03 09:29:23 [INFO ]  test dataset size: 	26032
2022-10-03 09:29:23 [INFO ]  datasets built!
2022-10-03 09:29:23 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 09:29:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 09:29:29 [INFO ]  
2022-10-03 09:29:29 [INFO ]  Begin of epoch 0 :
2022-10-03 09:29:32 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:29:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:29:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:29:32 [INFO ]  	   step  1 (lr=0.020000)                    8.16%                   7.8990
2022-10-03 09:29:32 [INFO ]  
2022-10-03 09:29:32 [INFO ]  Epoch:    0	Loss: 7.9719	Data Time: 0.43s	Train Time: 0.04s
2022-10-03 09:29:34 [INFO ]  Epoch:    1	Loss: 2.9805	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:29:35 [INFO ]  Epoch:    2	Loss: 2.3854	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:29:37 [INFO ]  Epoch:    3	Loss: 2.2825	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:29:39 [INFO ]  Epoch:    4	Loss: 2.1917	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:29:41 [INFO ]  Epoch:    5	Loss: 2.1986	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:29:43 [INFO ]  Epoch:    6	Loss: 2.1227	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:29:45 [INFO ]  Epoch:    7	Loss: 2.1177	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:29:47 [INFO ]  Epoch:    8	Loss: 2.0411	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:29:49 [INFO ]  Epoch:    9	Loss: 1.9421	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:29:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 09:29:54 [INFO ]  
2022-10-03 09:29:54 [INFO ]  Begin of epoch 10 :
2022-10-03 09:29:58 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:29:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:29:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:29:58 [INFO ]  	   step  1 (lr=0.078184)                   40.55%                   1.8286
2022-10-03 09:29:58 [INFO ]  
2022-10-03 09:29:58 [INFO ]  Epoch:   10	Loss: 1.8135	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:30:00 [INFO ]  Epoch:   11	Loss: 1.6330	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:01 [INFO ]  Epoch:   12	Loss: 1.6554	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:30:03 [INFO ]  Epoch:   13	Loss: 1.4745	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:30:05 [INFO ]  Epoch:   14	Loss: 1.4040	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:30:07 [INFO ]  Epoch:   15	Loss: 1.3372	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:30:09 [INFO ]  Epoch:   16	Loss: 1.3674	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:30:11 [INFO ]  Epoch:   17	Loss: 1.2793	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:13 [INFO ]  Epoch:   18	Loss: 1.1100	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:14 [INFO ]  Epoch:   19	Loss: 1.1925	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:30:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 09:30:20 [INFO ]  
2022-10-03 09:30:20 [INFO ]  Begin of epoch 20 :
2022-10-03 09:30:23 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:30:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:30:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:30:23 [INFO ]  	   step  1 (lr=0.203939)                   67.19%                   1.1320
2022-10-03 09:30:23 [INFO ]  
2022-10-03 09:30:23 [INFO ]  Epoch:   20	Loss: 1.1018	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:25 [INFO ]  Epoch:   21	Loss: 1.1381	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:27 [INFO ]  Epoch:   22	Loss: 1.1825	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:30:29 [INFO ]  Epoch:   23	Loss: 1.1407	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:31 [INFO ]  Epoch:   24	Loss: 0.9385	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:30:32 [INFO ]  Epoch:   25	Loss: 0.9824	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:30:34 [INFO ]  Epoch:   26	Loss: 1.0216	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:36 [INFO ]  Epoch:   27	Loss: 1.0677	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:30:38 [INFO ]  Epoch:   28	Loss: 0.9232	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:40 [INFO ]  Epoch:   29	Loss: 0.9318	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:30:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 09:30:45 [INFO ]  
2022-10-03 09:30:45 [INFO ]  Begin of epoch 30 :
2022-10-03 09:30:49 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:30:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:30:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:30:49 [INFO ]  	   step  1 (lr=0.268495)                   71.96%                   0.9784
2022-10-03 09:30:49 [INFO ]  
2022-10-03 09:30:49 [INFO ]  Epoch:   30	Loss: 0.9688	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:30:50 [INFO ]  Epoch:   31	Loss: 1.0259	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:30:52 [INFO ]  Epoch:   32	Loss: 0.9918	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:30:54 [INFO ]  Epoch:   33	Loss: 1.0325	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 09:30:56 [INFO ]  Epoch:   34	Loss: 0.9066	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:30:58 [INFO ]  Epoch:   35	Loss: 0.8814	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:00 [INFO ]  Epoch:   36	Loss: 0.9632	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:31:01 [INFO ]  Epoch:   37	Loss: 0.9064	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:31:03 [INFO ]  Epoch:   38	Loss: 0.8388	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:31:05 [INFO ]  Epoch:   39	Loss: 0.8436	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:31:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 09:31:11 [INFO ]  
2022-10-03 09:31:11 [INFO ]  Begin of epoch 40 :
2022-10-03 09:31:14 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:31:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:31:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:31:14 [INFO ]  	   step  1 (lr=0.281321)                   73.94%                   0.9144
2022-10-03 09:31:14 [INFO ]  
2022-10-03 09:31:14 [INFO ]  Epoch:   40	Loss: 0.8974	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:16 [INFO ]  Epoch:   41	Loss: 0.9475	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:31:18 [INFO ]  Epoch:   42	Loss: 0.8032	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:20 [INFO ]  Epoch:   43	Loss: 1.2047	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:31:22 [INFO ]  Epoch:   44	Loss: 0.7841	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:31:23 [INFO ]  Epoch:   45	Loss: 0.8318	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:31:25 [INFO ]  Epoch:   46	Loss: 0.9259	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:31:27 [INFO ]  Epoch:   47	Loss: 0.8289	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:29 [INFO ]  Epoch:   48	Loss: 0.7221	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:31 [INFO ]  Epoch:   49	Loss: 0.7492	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 09:31:37 [INFO ]  
2022-10-03 09:31:37 [INFO ]  Begin of epoch 50 :
2022-10-03 09:31:40 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:31:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:31:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:31:40 [INFO ]  	   step  1 (lr=0.307733)                   78.87%                   0.7665
2022-10-03 09:31:40 [INFO ]  
2022-10-03 09:31:40 [INFO ]  Epoch:   50	Loss: 0.6858	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:42 [INFO ]  Epoch:   51	Loss: 0.7067	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:31:44 [INFO ]  Epoch:   52	Loss: 0.7255	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:31:46 [INFO ]  Epoch:   53	Loss: 0.6381	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:47 [INFO ]  Epoch:   54	Loss: 0.7033	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:31:49 [INFO ]  Epoch:   55	Loss: 0.7578	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:51 [INFO ]  Epoch:   56	Loss: 0.7224	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:31:53 [INFO ]  Epoch:   57	Loss: 0.7690	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:55 [INFO ]  Epoch:   58	Loss: 0.7552	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:31:57 [INFO ]  Epoch:   59	Loss: 0.7791	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:32:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 09:32:02 [INFO ]  
2022-10-03 09:32:02 [INFO ]  Begin of epoch 60 :
2022-10-03 09:32:06 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:32:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:32:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:32:06 [INFO ]  	   step  1 (lr=0.312102)                   78.63%                   0.7845
2022-10-03 09:32:06 [INFO ]  
2022-10-03 09:32:06 [INFO ]  Epoch:   60	Loss: 0.7034	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:32:08 [INFO ]  Epoch:   61	Loss: 0.8037	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:32:10 [INFO ]  Epoch:   62	Loss: 0.6743	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:32:12 [INFO ]  Epoch:   63	Loss: 0.7247	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 09:32:14 [INFO ]  Epoch:   64	Loss: 0.7276	Data Time: 0.37s	Train Time: 0.01s
2022-10-03 09:32:16 [INFO ]  Epoch:   65	Loss: 0.6685	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:32:18 [INFO ]  Epoch:   66	Loss: 0.7172	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 09:32:20 [INFO ]  Epoch:   67	Loss: 0.7493	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 09:32:22 [INFO ]  Epoch:   68	Loss: 0.6534	Data Time: 0.33s	Train Time: 0.01s
2022-10-03 09:32:24 [INFO ]  Epoch:   69	Loss: 0.7350	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:32:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 09:32:29 [INFO ]  
2022-10-03 09:32:29 [INFO ]  Begin of epoch 70 :
2022-10-03 09:32:33 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:32:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:32:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:32:33 [INFO ]  	   step  1 (lr=0.327443)                   79.76%                   0.7374
2022-10-03 09:32:33 [INFO ]  
2022-10-03 09:32:33 [INFO ]  Epoch:   70	Loss: 0.7326	Data Time: 0.31s	Train Time: 0.00s
2022-10-03 09:32:34 [INFO ]  Epoch:   71	Loss: 0.7053	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:32:36 [INFO ]  Epoch:   72	Loss: 0.7587	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:32:38 [INFO ]  Epoch:   73	Loss: 0.6848	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:32:40 [INFO ]  Epoch:   74	Loss: 0.7089	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:32:42 [INFO ]  Epoch:   75	Loss: 0.7240	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:32:43 [INFO ]  Epoch:   76	Loss: 0.6895	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:32:45 [INFO ]  Epoch:   77	Loss: 0.6292	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:32:47 [INFO ]  Epoch:   78	Loss: 0.7511	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:32:49 [INFO ]  Epoch:   79	Loss: 0.6937	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:32:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 09:32:55 [INFO ]  
2022-10-03 09:32:55 [INFO ]  Begin of epoch 80 :
2022-10-03 09:32:58 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:32:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:32:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:32:58 [INFO ]  	   step  1 (lr=0.340119)                   79.35%                   0.7455
2022-10-03 09:32:58 [INFO ]  
2022-10-03 09:32:58 [INFO ]  Epoch:   80	Loss: 0.7157	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:00 [INFO ]  Epoch:   81	Loss: 0.6757	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:02 [INFO ]  Epoch:   82	Loss: 0.7074	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:03 [INFO ]  Epoch:   83	Loss: 0.6778	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:33:05 [INFO ]  Epoch:   84	Loss: 0.6553	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:07 [INFO ]  Epoch:   85	Loss: 0.6580	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:09 [INFO ]  Epoch:   86	Loss: 0.6655	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:11 [INFO ]  Epoch:   87	Loss: 0.6775	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:13 [INFO ]  Epoch:   88	Loss: 0.6292	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:33:15 [INFO ]  Epoch:   89	Loss: 0.6984	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:33:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 09:33:20 [INFO ]  
2022-10-03 09:33:20 [INFO ]  Begin of epoch 90 :
2022-10-03 09:33:24 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:33:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:33:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:33:24 [INFO ]  	   step  1 (lr=0.345204)                   80.08%                   0.7186
2022-10-03 09:33:24 [INFO ]  
2022-10-03 09:33:24 [INFO ]  Epoch:   90	Loss: 0.6573	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:25 [INFO ]  Epoch:   91	Loss: 0.6121	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:33:27 [INFO ]  Epoch:   92	Loss: 0.6678	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:33:29 [INFO ]  Epoch:   93	Loss: 0.6661	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:33:31 [INFO ]  Epoch:   94	Loss: 0.7641	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:33:33 [INFO ]  Epoch:   95	Loss: 0.6934	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:33:35 [INFO ]  Epoch:   96	Loss: 0.6988	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:33:36 [INFO ]  Epoch:   97	Loss: 0.6585	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:33:38 [INFO ]  Epoch:   98	Loss: 0.7409	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:40 [INFO ]  Epoch:   99	Loss: 0.6539	Data Time: 0.26s	Train Time: 0.00s
2022-10-03 09:33:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 09:33:46 [INFO ]  
2022-10-03 09:33:46 [INFO ]  Begin of epoch 100 :
2022-10-03 09:33:49 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:33:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:33:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:33:49 [INFO ]  	   step  1 (lr=0.347712)                   79.87%                   0.7306
2022-10-03 09:33:49 [INFO ]  
2022-10-03 09:33:49 [INFO ]  Epoch:  100	Loss: 0.6518	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:33:51 [INFO ]  Epoch:  101	Loss: 0.6645	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:33:53 [INFO ]  Epoch:  102	Loss: 0.6757	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:33:55 [INFO ]  Epoch:  103	Loss: 0.6776	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:56 [INFO ]  Epoch:  104	Loss: 0.6606	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:33:58 [INFO ]  Epoch:  105	Loss: 0.6473	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:34:00 [INFO ]  Epoch:  106	Loss: 0.6809	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:34:02 [INFO ]  Epoch:  107	Loss: 0.7783	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:34:04 [INFO ]  Epoch:  108	Loss: 0.7838	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:34:06 [INFO ]  Epoch:  109	Loss: 0.7563	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:34:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 09:34:11 [INFO ]  
2022-10-03 09:34:11 [INFO ]  Begin of epoch 110 :
2022-10-03 09:34:15 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:34:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:34:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:34:15 [INFO ]  	   step  1 (lr=0.348978)                   79.52%                   0.7591
2022-10-03 09:34:15 [INFO ]  
2022-10-03 09:34:15 [INFO ]  Epoch:  110	Loss: 0.6886	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:34:17 [INFO ]  Epoch:  111	Loss: 0.6958	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:34:19 [INFO ]  Epoch:  112	Loss: 0.7272	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:34:20 [INFO ]  Epoch:  113	Loss: 0.7467	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:34:23 [INFO ]  Epoch:  114	Loss: 0.6586	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:34:25 [INFO ]  Epoch:  115	Loss: 0.7373	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:34:26 [INFO ]  Epoch:  116	Loss: 0.6693	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:34:28 [INFO ]  Epoch:  117	Loss: 0.6712	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:34:30 [INFO ]  Epoch:  118	Loss: 0.7119	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:34:32 [INFO ]  Epoch:  119	Loss: 0.6348	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:34:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 09:34:38 [INFO ]  
2022-10-03 09:34:38 [INFO ]  Begin of epoch 120 :
2022-10-03 09:34:42 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:34:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:34:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:34:42 [INFO ]  	   step  1 (lr=0.353308)                   80.35%                   0.7094
2022-10-03 09:34:42 [INFO ]  
2022-10-03 09:34:42 [INFO ]  Epoch:  120	Loss: 0.6317	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:34:44 [INFO ]  Epoch:  121	Loss: 0.6401	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:34:45 [INFO ]  Epoch:  122	Loss: 0.7180	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:34:47 [INFO ]  Epoch:  123	Loss: 0.6141	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:34:49 [INFO ]  Epoch:  124	Loss: 0.6813	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:34:51 [INFO ]  Epoch:  125	Loss: 0.6288	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:34:53 [INFO ]  Epoch:  126	Loss: 0.6517	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:34:55 [INFO ]  Epoch:  127	Loss: 0.6313	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:34:57 [INFO ]  Epoch:  128	Loss: 0.5899	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:34:59 [INFO ]  Epoch:  129	Loss: 0.6778	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 09:35:04 [INFO ]  
2022-10-03 09:35:04 [INFO ]  Begin of epoch 130 :
2022-10-03 09:35:08 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:35:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:35:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:35:08 [INFO ]  	   step  1 (lr=0.348878)                   80.13%                   0.7293
2022-10-03 09:35:08 [INFO ]  
2022-10-03 09:35:08 [INFO ]  Epoch:  130	Loss: 0.6603	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:09 [INFO ]  Epoch:  131	Loss: 0.6719	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:35:11 [INFO ]  Epoch:  132	Loss: 0.6126	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:35:13 [INFO ]  Epoch:  133	Loss: 0.6658	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:15 [INFO ]  Epoch:  134	Loss: 0.6488	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:35:17 [INFO ]  Epoch:  135	Loss: 0.7048	Data Time: 0.16s	Train Time: 0.02s
2022-10-03 09:35:18 [INFO ]  Epoch:  136	Loss: 0.7121	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:35:20 [INFO ]  Epoch:  137	Loss: 0.6551	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:35:22 [INFO ]  Epoch:  138	Loss: 0.7341	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:35:24 [INFO ]  Epoch:  139	Loss: 0.6382	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:35:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 09:35:30 [INFO ]  
2022-10-03 09:35:30 [INFO ]  Begin of epoch 140 :
2022-10-03 09:35:33 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:35:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:35:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:35:33 [INFO ]  	   step  1 (lr=0.350806)                   80.28%                   0.7142
2022-10-03 09:35:33 [INFO ]  
2022-10-03 09:35:33 [INFO ]  Epoch:  140	Loss: 0.6863	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:35:35 [INFO ]  Epoch:  141	Loss: 0.6271	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:37 [INFO ]  Epoch:  142	Loss: 0.6215	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:35:39 [INFO ]  Epoch:  143	Loss: 0.6789	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:35:40 [INFO ]  Epoch:  144	Loss: 0.6457	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:35:42 [INFO ]  Epoch:  145	Loss: 0.6828	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:35:44 [INFO ]  Epoch:  146	Loss: 0.6518	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:35:46 [INFO ]  Epoch:  147	Loss: 0.6223	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:48 [INFO ]  Epoch:  148	Loss: 0.6841	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:35:50 [INFO ]  Epoch:  149	Loss: 0.6041	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:35:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 09:35:56 [INFO ]  
2022-10-03 09:35:56 [INFO ]  Begin of epoch 150 :
2022-10-03 09:35:59 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:35:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:35:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:35:59 [INFO ]  	   step  1 (lr=0.349466)                   80.58%                   0.7069
2022-10-03 09:35:59 [INFO ]  
2022-10-03 09:35:59 [INFO ]  Epoch:  150	Loss: 0.5771	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:36:01 [INFO ]  Epoch:  151	Loss: 0.6435	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:36:03 [INFO ]  Epoch:  152	Loss: 0.7038	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:36:05 [INFO ]  Epoch:  153	Loss: 0.6985	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:06 [INFO ]  Epoch:  154	Loss: 0.7106	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:36:08 [INFO ]  Epoch:  155	Loss: 0.6924	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:36:10 [INFO ]  Epoch:  156	Loss: 0.6762	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:12 [INFO ]  Epoch:  157	Loss: 0.6981	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:36:14 [INFO ]  Epoch:  158	Loss: 0.7016	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:16 [INFO ]  Epoch:  159	Loss: 0.8175	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 09:36:22 [INFO ]  
2022-10-03 09:36:22 [INFO ]  Begin of epoch 160 :
2022-10-03 09:36:25 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:36:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:36:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:36:25 [INFO ]  	   step  1 (lr=0.350187)                   79.48%                   0.7418
2022-10-03 09:36:25 [INFO ]  
2022-10-03 09:36:25 [INFO ]  Epoch:  160	Loss: 0.6568	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:36:27 [INFO ]  Epoch:  161	Loss: 0.6565	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:36:29 [INFO ]  Epoch:  162	Loss: 0.6767	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:36:31 [INFO ]  Epoch:  163	Loss: 0.6613	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:33 [INFO ]  Epoch:  164	Loss: 0.6734	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:36:35 [INFO ]  Epoch:  165	Loss: 0.6021	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:36:36 [INFO ]  Epoch:  166	Loss: 0.6418	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:36:38 [INFO ]  Epoch:  167	Loss: 0.7084	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:36:40 [INFO ]  Epoch:  168	Loss: 0.6820	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:36:42 [INFO ]  Epoch:  169	Loss: 0.6579	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:36:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 09:36:48 [INFO ]  
2022-10-03 09:36:48 [INFO ]  Begin of epoch 170 :
2022-10-03 09:36:52 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:36:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:36:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:36:52 [INFO ]  	   step  1 (lr=0.351168)                   80.05%                   0.7295
2022-10-03 09:36:52 [INFO ]  
2022-10-03 09:36:52 [INFO ]  Epoch:  170	Loss: 0.6377	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:36:54 [INFO ]  Epoch:  171	Loss: 0.6958	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 09:36:56 [INFO ]  Epoch:  172	Loss: 0.5809	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:36:57 [INFO ]  Epoch:  173	Loss: 0.7106	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:37:00 [INFO ]  Epoch:  174	Loss: 0.6483	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:37:02 [INFO ]  Epoch:  175	Loss: 0.6800	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 09:37:04 [INFO ]  Epoch:  176	Loss: 0.6964	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:37:06 [INFO ]  Epoch:  177	Loss: 0.5895	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:37:07 [INFO ]  Epoch:  178	Loss: 0.6704	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 09:37:09 [INFO ]  Epoch:  179	Loss: 0.6301	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:37:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 09:37:15 [INFO ]  
2022-10-03 09:37:15 [INFO ]  Begin of epoch 180 :
2022-10-03 09:37:19 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:37:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:37:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:37:19 [INFO ]  	   step  1 (lr=0.351166)                   79.22%                   0.7584
2022-10-03 09:37:19 [INFO ]  
2022-10-03 09:37:19 [INFO ]  Epoch:  180	Loss: 0.6492	Data Time: 0.29s	Train Time: 0.00s
2022-10-03 09:37:20 [INFO ]  Epoch:  181	Loss: 0.6837	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:37:22 [INFO ]  Epoch:  182	Loss: 0.7132	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:24 [INFO ]  Epoch:  183	Loss: 0.6342	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:37:26 [INFO ]  Epoch:  184	Loss: 0.6053	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:27 [INFO ]  Epoch:  185	Loss: 0.6747	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:29 [INFO ]  Epoch:  186	Loss: 0.7023	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:37:31 [INFO ]  Epoch:  187	Loss: 0.6512	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:37:33 [INFO ]  Epoch:  188	Loss: 0.6159	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:37:35 [INFO ]  Epoch:  189	Loss: 0.6456	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:37:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 09:37:41 [INFO ]  
2022-10-03 09:37:41 [INFO ]  Begin of epoch 190 :
2022-10-03 09:37:44 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:37:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:37:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:37:44 [INFO ]  	   step  1 (lr=0.350764)                   80.21%                   0.7109
2022-10-03 09:37:44 [INFO ]  
2022-10-03 09:37:44 [INFO ]  Epoch:  190	Loss: 0.7237	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:46 [INFO ]  Epoch:  191	Loss: 0.7047	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:37:48 [INFO ]  Epoch:  192	Loss: 0.6799	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:37:50 [INFO ]  Epoch:  193	Loss: 0.6033	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:37:52 [INFO ]  Epoch:  194	Loss: 0.6362	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:37:54 [INFO ]  Epoch:  195	Loss: 0.6478	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:56 [INFO ]  Epoch:  196	Loss: 0.5917	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:37:58 [INFO ]  Epoch:  197	Loss: 0.6408	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:37:59 [INFO ]  Epoch:  198	Loss: 0.6665	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:38:01 [INFO ]  Epoch:  199	Loss: 0.6950	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:38:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 09:38:06 [INFO ]  
2022-10-03 09:38:06 [INFO ]  Final evaluation for SVHN :
2022-10-03 09:38:10 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:38:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:38:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:38:10 [INFO ]  	   step  1 (lr=0.350861)                   80.15%                   0.7175
2022-10-03 09:38:10 [INFO ]  
2022-10-03 09:38:10 [INFO ]  
2022-10-03 09:38:10 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 09:38:13 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:38:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:38:13 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 09:38:13 [INFO ]  	   step  1 (lr=0.350861)                   17.78%                   5.1256
2022-10-03 09:38:13 [INFO ]  
2022-10-03 09:46:14 [INFO ]  ======================================== 2022-10-03 09:46:14 ========================================
2022-10-03 09:46:14 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 09:46:14 [INFO ]  Options: 
2022-10-03 09:46:14 [INFO ]  	base_dir: null
2022-10-03 09:46:14 [INFO ]  	batch_size: 1024
2022-10-03 09:46:14 [INFO ]  	checkpoint_interval: 10
2022-10-03 09:46:14 [INFO ]  	dataset: SVHN
2022-10-03 09:46:14 [INFO ]  	dataset_labels:
2022-10-03 09:46:14 [INFO ]  	- 0
2022-10-03 09:46:14 [INFO ]  	- 1
2022-10-03 09:46:14 [INFO ]  	- 2
2022-10-03 09:46:14 [INFO ]  	- 3
2022-10-03 09:46:14 [INFO ]  	- 4
2022-10-03 09:46:14 [INFO ]  	- 5
2022-10-03 09:46:14 [INFO ]  	- 6
2022-10-03 09:46:14 [INFO ]  	- 7
2022-10-03 09:46:14 [INFO ]  	- 8
2022-10-03 09:46:14 [INFO ]  	- 9
2022-10-03 09:46:14 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 09:46:14 [INFO ]  	- !!python/tuple
2022-10-03 09:46:14 [INFO ]  	    - 0.4379104971885681
2022-10-03 09:46:14 [INFO ]  	    - 0.44398033618927
2022-10-03 09:46:14 [INFO ]  	    - 0.4729299545288086
2022-10-03 09:46:14 [INFO ]  	- !!python/tuple
2022-10-03 09:46:14 [INFO ]  	    - 0.19803012907505035
2022-10-03 09:46:14 [INFO ]  	    - 0.2010156363248825
2022-10-03 09:46:14 [INFO ]  	    - 0.19703614711761475
2022-10-03 09:46:14 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 09:46:14 [INFO ]  	decay_epochs: 50
2022-10-03 09:46:14 [INFO ]  	decay_factor: 0.1
2022-10-03 09:46:14 [INFO ]  	device_id: 0
2022-10-03 09:46:14 [INFO ]  	distill_epochs: 1
2022-10-03 09:46:14 [INFO ]  	distill_lr: 0.02
2022-10-03 09:46:14 [INFO ]  	distill_steps: 1
2022-10-03 09:46:14 [INFO ]  	epochs: 200
2022-10-03 09:46:14 [INFO ]  	expand_cls: false
2022-10-03 09:46:14 [INFO ]  	forgetting_dataset: null
2022-10-03 09:46:14 [INFO ]  	init: xavier
2022-10-03 09:46:14 [INFO ]  	init_param: 1.0
2022-10-03 09:46:14 [INFO ]  	input_size: 32
2022-10-03 09:46:14 [INFO ]  	ipc: 5
2022-10-03 09:46:14 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 09:46:14 [INFO ]  	log_interval: 100
2022-10-03 09:46:14 [INFO ]  	log_level: INFO
2022-10-03 09:46:14 [INFO ]  	lr: 0.01
2022-10-03 09:46:14 [INFO ]  	mode: distill_adapt
2022-10-03 09:46:14 [INFO ]  	nc: 3
2022-10-03 09:46:14 [INFO ]  	num_classes: 10
2022-10-03 09:46:14 [INFO ]  	num_workers: 8
2022-10-03 09:46:14 [INFO ]  	phase: train
2022-10-03 09:46:14 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 09:46:14 [INFO ]  	start_time: '2022-10-03 09:46:14'
2022-10-03 09:46:14 [INFO ]  	test_batch_size: 1024
2022-10-03 09:46:14 [INFO ]  	
2022-10-03 09:46:16 [INFO ]  train dataset size:	73257
2022-10-03 09:46:16 [INFO ]  test dataset size: 	26032
2022-10-03 09:46:16 [INFO ]  datasets built!
2022-10-03 09:46:16 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 09:46:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 09:46:22 [INFO ]  
2022-10-03 09:46:22 [INFO ]  Begin of epoch 0 :
2022-10-03 09:46:25 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:46:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:46:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:46:25 [INFO ]  	   step  1 (lr=0.020000)                    7.08%                   8.6003
2022-10-03 09:46:25 [INFO ]  
2022-10-03 09:46:25 [INFO ]  Epoch:    0	Loss: 8.0529	Data Time: 0.40s	Train Time: 0.03s
2022-10-03 09:46:27 [INFO ]  Epoch:    1	Loss: 3.0098	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:46:29 [INFO ]  Epoch:    2	Loss: 2.5822	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:46:31 [INFO ]  Epoch:    3	Loss: 2.2962	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:46:33 [INFO ]  Epoch:    4	Loss: 2.2266	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:46:35 [INFO ]  Epoch:    5	Loss: 2.1825	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:46:37 [INFO ]  Epoch:    6	Loss: 2.1667	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:46:38 [INFO ]  Epoch:    7	Loss: 2.0883	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:46:40 [INFO ]  Epoch:    8	Loss: 2.0637	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:46:42 [INFO ]  Epoch:    9	Loss: 1.9867	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:46:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 09:46:48 [INFO ]  
2022-10-03 09:46:48 [INFO ]  Begin of epoch 10 :
2022-10-03 09:46:51 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:46:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:46:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:46:51 [INFO ]  	   step  1 (lr=0.066853)                   36.89%                   1.9087
2022-10-03 09:46:51 [INFO ]  
2022-10-03 09:46:51 [INFO ]  Epoch:   10	Loss: 1.8734	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 09:46:53 [INFO ]  Epoch:   11	Loss: 1.8090	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:46:55 [INFO ]  Epoch:   12	Loss: 1.7608	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:46:57 [INFO ]  Epoch:   13	Loss: 1.5246	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:46:58 [INFO ]  Epoch:   14	Loss: 1.7816	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:47:00 [INFO ]  Epoch:   15	Loss: 1.4259	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:47:02 [INFO ]  Epoch:   16	Loss: 1.5226	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:04 [INFO ]  Epoch:   17	Loss: 1.4480	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:47:06 [INFO ]  Epoch:   18	Loss: 1.3103	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:08 [INFO ]  Epoch:   19	Loss: 1.2901	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:47:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 09:47:13 [INFO ]  
2022-10-03 09:47:13 [INFO ]  Begin of epoch 20 :
2022-10-03 09:47:17 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:47:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:47:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:47:17 [INFO ]  	   step  1 (lr=0.186803)                   61.27%                   1.2684
2022-10-03 09:47:17 [INFO ]  
2022-10-03 09:47:17 [INFO ]  Epoch:   20	Loss: 1.2385	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:47:18 [INFO ]  Epoch:   21	Loss: 1.1984	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:47:20 [INFO ]  Epoch:   22	Loss: 1.2358	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:22 [INFO ]  Epoch:   23	Loss: 1.0754	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:24 [INFO ]  Epoch:   24	Loss: 1.1002	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:26 [INFO ]  Epoch:   25	Loss: 1.1420	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:28 [INFO ]  Epoch:   26	Loss: 1.2434	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:30 [INFO ]  Epoch:   27	Loss: 1.3337	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:31 [INFO ]  Epoch:   28	Loss: 1.0299	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 09:47:33 [INFO ]  Epoch:   29	Loss: 0.9441	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 09:47:39 [INFO ]  
2022-10-03 09:47:39 [INFO ]  Begin of epoch 30 :
2022-10-03 09:47:42 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:47:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:47:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:47:42 [INFO ]  	   step  1 (lr=0.245541)                   72.55%                   0.9608
2022-10-03 09:47:42 [INFO ]  
2022-10-03 09:47:42 [INFO ]  Epoch:   30	Loss: 0.8890	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:44 [INFO ]  Epoch:   31	Loss: 0.9680	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:46 [INFO ]  Epoch:   32	Loss: 1.0276	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:48 [INFO ]  Epoch:   33	Loss: 0.8813	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:47:50 [INFO ]  Epoch:   34	Loss: 0.8644	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:47:52 [INFO ]  Epoch:   35	Loss: 0.8867	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:47:53 [INFO ]  Epoch:   36	Loss: 0.9177	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:47:55 [INFO ]  Epoch:   37	Loss: 1.0075	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:47:57 [INFO ]  Epoch:   38	Loss: 0.7788	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:47:59 [INFO ]  Epoch:   39	Loss: 0.9846	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:48:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 09:48:05 [INFO ]  
2022-10-03 09:48:05 [INFO ]  Begin of epoch 40 :
2022-10-03 09:48:08 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:48:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:48:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:48:08 [INFO ]  	   step  1 (lr=0.265659)                   74.66%                   0.8982
2022-10-03 09:48:08 [INFO ]  
2022-10-03 09:48:08 [INFO ]  Epoch:   40	Loss: 0.8658	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:48:10 [INFO ]  Epoch:   41	Loss: 0.8656	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:11 [INFO ]  Epoch:   42	Loss: 0.8022	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:13 [INFO ]  Epoch:   43	Loss: 0.7773	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:48:15 [INFO ]  Epoch:   44	Loss: 0.8959	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:48:17 [INFO ]  Epoch:   45	Loss: 0.8683	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:19 [INFO ]  Epoch:   46	Loss: 0.8965	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:48:21 [INFO ]  Epoch:   47	Loss: 0.8370	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:23 [INFO ]  Epoch:   48	Loss: 0.8611	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:48:24 [INFO ]  Epoch:   49	Loss: 0.7555	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:48:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 09:48:30 [INFO ]  
2022-10-03 09:48:30 [INFO ]  Begin of epoch 50 :
2022-10-03 09:48:33 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:48:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:48:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:48:33 [INFO ]  	   step  1 (lr=0.277975)                   77.95%                   0.7987
2022-10-03 09:48:33 [INFO ]  
2022-10-03 09:48:33 [INFO ]  Epoch:   50	Loss: 0.7234	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:48:35 [INFO ]  Epoch:   51	Loss: 0.8512	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:37 [INFO ]  Epoch:   52	Loss: 0.7173	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:48:39 [INFO ]  Epoch:   53	Loss: 0.7013	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:48:41 [INFO ]  Epoch:   54	Loss: 0.7849	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:43 [INFO ]  Epoch:   55	Loss: 0.7683	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:45 [INFO ]  Epoch:   56	Loss: 0.8130	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:46 [INFO ]  Epoch:   57	Loss: 0.8142	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:48:48 [INFO ]  Epoch:   58	Loss: 0.7687	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:48:50 [INFO ]  Epoch:   59	Loss: 0.7023	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:48:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 09:48:56 [INFO ]  
2022-10-03 09:48:56 [INFO ]  Begin of epoch 60 :
2022-10-03 09:49:00 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:49:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:49:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:49:00 [INFO ]  	   step  1 (lr=0.291417)                   77.88%                   0.7973
2022-10-03 09:49:00 [INFO ]  
2022-10-03 09:49:00 [INFO ]  Epoch:   60	Loss: 0.7367	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:49:02 [INFO ]  Epoch:   61	Loss: 0.7313	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:49:04 [INFO ]  Epoch:   62	Loss: 0.8777	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 09:49:06 [INFO ]  Epoch:   63	Loss: 0.8166	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 09:49:08 [INFO ]  Epoch:   64	Loss: 0.7221	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:49:10 [INFO ]  Epoch:   65	Loss: 0.7749	Data Time: 0.34s	Train Time: 0.01s
2022-10-03 09:49:12 [INFO ]  Epoch:   66	Loss: 0.7555	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:49:14 [INFO ]  Epoch:   67	Loss: 0.7572	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:49:16 [INFO ]  Epoch:   68	Loss: 0.7147	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 09:49:18 [INFO ]  Epoch:   69	Loss: 0.7761	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:49:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 09:49:23 [INFO ]  
2022-10-03 09:49:23 [INFO ]  Begin of epoch 70 :
2022-10-03 09:49:27 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:49:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:49:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:49:27 [INFO ]  	   step  1 (lr=0.291112)                   76.29%                   0.8596
2022-10-03 09:49:27 [INFO ]  
2022-10-03 09:49:27 [INFO ]  Epoch:   70	Loss: 0.7710	Data Time: 0.29s	Train Time: 0.00s
2022-10-03 09:49:28 [INFO ]  Epoch:   71	Loss: 0.7382	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:49:30 [INFO ]  Epoch:   72	Loss: 0.7140	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:49:32 [INFO ]  Epoch:   73	Loss: 0.7489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:49:34 [INFO ]  Epoch:   74	Loss: 0.6376	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:49:36 [INFO ]  Epoch:   75	Loss: 0.7895	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:49:38 [INFO ]  Epoch:   76	Loss: 0.8061	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:49:39 [INFO ]  Epoch:   77	Loss: 0.7763	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:49:41 [INFO ]  Epoch:   78	Loss: 0.7006	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:49:43 [INFO ]  Epoch:   79	Loss: 0.6846	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:49:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 09:49:48 [INFO ]  
2022-10-03 09:49:48 [INFO ]  Begin of epoch 80 :
2022-10-03 09:49:52 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:49:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:49:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:49:52 [INFO ]  	   step  1 (lr=0.293369)                   78.64%                   0.7684
2022-10-03 09:49:52 [INFO ]  
2022-10-03 09:49:52 [INFO ]  Epoch:   80	Loss: 0.7690	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 09:49:54 [INFO ]  Epoch:   81	Loss: 0.7152	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:49:55 [INFO ]  Epoch:   82	Loss: 0.8176	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:49:57 [INFO ]  Epoch:   83	Loss: 0.7460	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:49:59 [INFO ]  Epoch:   84	Loss: 0.7125	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:01 [INFO ]  Epoch:   85	Loss: 0.6509	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:03 [INFO ]  Epoch:   86	Loss: 0.7052	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:05 [INFO ]  Epoch:   87	Loss: 0.7137	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:07 [INFO ]  Epoch:   88	Loss: 0.8717	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:09 [INFO ]  Epoch:   89	Loss: 0.7237	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 09:50:14 [INFO ]  
2022-10-03 09:50:14 [INFO ]  Begin of epoch 90 :
2022-10-03 09:50:18 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:50:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:50:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:50:18 [INFO ]  	   step  1 (lr=0.301085)                   79.05%                   0.7610
2022-10-03 09:50:18 [INFO ]  
2022-10-03 09:50:18 [INFO ]  Epoch:   90	Loss: 0.7169	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:50:19 [INFO ]  Epoch:   91	Loss: 0.7025	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:21 [INFO ]  Epoch:   92	Loss: 0.7343	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:23 [INFO ]  Epoch:   93	Loss: 0.7369	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:25 [INFO ]  Epoch:   94	Loss: 0.7893	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:27 [INFO ]  Epoch:   95	Loss: 0.7561	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:50:28 [INFO ]  Epoch:   96	Loss: 0.7715	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:30 [INFO ]  Epoch:   97	Loss: 0.7535	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:32 [INFO ]  Epoch:   98	Loss: 0.8071	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:50:34 [INFO ]  Epoch:   99	Loss: 0.6987	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 09:50:40 [INFO ]  
2022-10-03 09:50:40 [INFO ]  Begin of epoch 100 :
2022-10-03 09:50:43 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:50:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:50:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:50:43 [INFO ]  	   step  1 (lr=0.308712)                   79.66%                   0.7442
2022-10-03 09:50:43 [INFO ]  
2022-10-03 09:50:43 [INFO ]  Epoch:  100	Loss: 0.7188	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:45 [INFO ]  Epoch:  101	Loss: 0.8095	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:50:47 [INFO ]  Epoch:  102	Loss: 0.7021	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:50:48 [INFO ]  Epoch:  103	Loss: 0.6551	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:50 [INFO ]  Epoch:  104	Loss: 0.7300	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:50:52 [INFO ]  Epoch:  105	Loss: 0.7012	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:50:54 [INFO ]  Epoch:  106	Loss: 0.6311	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:50:56 [INFO ]  Epoch:  107	Loss: 0.6947	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:50:58 [INFO ]  Epoch:  108	Loss: 0.7672	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:51:00 [INFO ]  Epoch:  109	Loss: 0.7302	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:51:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 09:51:05 [INFO ]  
2022-10-03 09:51:05 [INFO ]  Begin of epoch 110 :
2022-10-03 09:51:08 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:51:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:51:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:51:08 [INFO ]  	   step  1 (lr=0.309612)                   78.25%                   0.7858
2022-10-03 09:51:08 [INFO ]  
2022-10-03 09:51:09 [INFO ]  Epoch:  110	Loss: 0.7017	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:51:10 [INFO ]  Epoch:  111	Loss: 0.7919	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:51:12 [INFO ]  Epoch:  112	Loss: 0.7209	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:51:14 [INFO ]  Epoch:  113	Loss: 0.7297	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:51:17 [INFO ]  Epoch:  114	Loss: 0.7084	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:51:19 [INFO ]  Epoch:  115	Loss: 0.7570	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:51:21 [INFO ]  Epoch:  116	Loss: 0.6932	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:51:23 [INFO ]  Epoch:  117	Loss: 0.6440	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:51:25 [INFO ]  Epoch:  118	Loss: 0.7411	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:51:27 [INFO ]  Epoch:  119	Loss: 0.6759	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:51:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 09:51:32 [INFO ]  
2022-10-03 09:51:32 [INFO ]  Begin of epoch 120 :
2022-10-03 09:51:36 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:51:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:51:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:51:36 [INFO ]  	   step  1 (lr=0.313051)                   79.77%                   0.7483
2022-10-03 09:51:36 [INFO ]  
2022-10-03 09:51:36 [INFO ]  Epoch:  120	Loss: 0.6909	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:51:38 [INFO ]  Epoch:  121	Loss: 0.7433	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:51:40 [INFO ]  Epoch:  122	Loss: 0.6780	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:51:42 [INFO ]  Epoch:  123	Loss: 0.6294	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:51:44 [INFO ]  Epoch:  124	Loss: 0.6691	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:51:46 [INFO ]  Epoch:  125	Loss: 0.6672	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:51:47 [INFO ]  Epoch:  126	Loss: 0.6856	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:51:49 [INFO ]  Epoch:  127	Loss: 0.7190	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:51:51 [INFO ]  Epoch:  128	Loss: 0.7104	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:51:53 [INFO ]  Epoch:  129	Loss: 0.7630	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:51:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 09:51:59 [INFO ]  
2022-10-03 09:51:59 [INFO ]  Begin of epoch 130 :
2022-10-03 09:52:02 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:52:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:52:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:52:02 [INFO ]  	   step  1 (lr=0.308458)                   77.44%                   0.8010
2022-10-03 09:52:02 [INFO ]  
2022-10-03 09:52:02 [INFO ]  Epoch:  130	Loss: 0.8075	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:52:04 [INFO ]  Epoch:  131	Loss: 0.6728	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:52:05 [INFO ]  Epoch:  132	Loss: 0.8017	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:07 [INFO ]  Epoch:  133	Loss: 0.6648	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:52:09 [INFO ]  Epoch:  134	Loss: 0.6734	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:11 [INFO ]  Epoch:  135	Loss: 0.6814	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:52:13 [INFO ]  Epoch:  136	Loss: 0.7184	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:52:15 [INFO ]  Epoch:  137	Loss: 0.7267	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:52:17 [INFO ]  Epoch:  138	Loss: 0.6755	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:52:19 [INFO ]  Epoch:  139	Loss: 0.6883	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:52:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 09:52:24 [INFO ]  
2022-10-03 09:52:24 [INFO ]  Begin of epoch 140 :
2022-10-03 09:52:28 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:52:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:52:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:52:28 [INFO ]  	   step  1 (lr=0.314599)                   79.75%                   0.7454
2022-10-03 09:52:28 [INFO ]  
2022-10-03 09:52:28 [INFO ]  Epoch:  140	Loss: 0.6951	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:52:29 [INFO ]  Epoch:  141	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:52:31 [INFO ]  Epoch:  142	Loss: 0.7721	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:52:33 [INFO ]  Epoch:  143	Loss: 0.6858	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:35 [INFO ]  Epoch:  144	Loss: 0.7441	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 09:52:37 [INFO ]  Epoch:  145	Loss: 0.6890	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:39 [INFO ]  Epoch:  146	Loss: 0.7398	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:40 [INFO ]  Epoch:  147	Loss: 0.6455	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:52:42 [INFO ]  Epoch:  148	Loss: 0.6822	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:52:44 [INFO ]  Epoch:  149	Loss: 0.7273	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:52:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 09:52:50 [INFO ]  
2022-10-03 09:52:50 [INFO ]  Begin of epoch 150 :
2022-10-03 09:52:53 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:52:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:52:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:52:53 [INFO ]  	   step  1 (lr=0.312509)                   79.73%                   0.7454
2022-10-03 09:52:53 [INFO ]  
2022-10-03 09:52:53 [INFO ]  Epoch:  150	Loss: 0.6195	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:52:55 [INFO ]  Epoch:  151	Loss: 0.7275	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:52:57 [INFO ]  Epoch:  152	Loss: 0.6956	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:52:59 [INFO ]  Epoch:  153	Loss: 0.6215	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:53:01 [INFO ]  Epoch:  154	Loss: 0.6576	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:53:03 [INFO ]  Epoch:  155	Loss: 0.6155	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:53:04 [INFO ]  Epoch:  156	Loss: 0.7064	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:53:06 [INFO ]  Epoch:  157	Loss: 0.6965	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:53:08 [INFO ]  Epoch:  158	Loss: 0.6950	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:53:10 [INFO ]  Epoch:  159	Loss: 0.6842	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:53:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 09:53:16 [INFO ]  
2022-10-03 09:53:16 [INFO ]  Begin of epoch 160 :
2022-10-03 09:53:19 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:53:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:53:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:53:19 [INFO ]  	   step  1 (lr=0.312442)                   79.94%                   0.7459
2022-10-03 09:53:19 [INFO ]  
2022-10-03 09:53:19 [INFO ]  Epoch:  160	Loss: 0.7025	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:53:21 [INFO ]  Epoch:  161	Loss: 0.6542	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:53:23 [INFO ]  Epoch:  162	Loss: 0.6711	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:53:25 [INFO ]  Epoch:  163	Loss: 0.6924	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:53:26 [INFO ]  Epoch:  164	Loss: 0.6510	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:53:28 [INFO ]  Epoch:  165	Loss: 0.6598	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:53:30 [INFO ]  Epoch:  166	Loss: 0.6566	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:53:32 [INFO ]  Epoch:  167	Loss: 0.6522	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:53:34 [INFO ]  Epoch:  168	Loss: 0.6725	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:53:36 [INFO ]  Epoch:  169	Loss: 0.6510	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:53:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 09:53:41 [INFO ]  
2022-10-03 09:53:41 [INFO ]  Begin of epoch 170 :
2022-10-03 09:53:45 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:53:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:53:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:53:45 [INFO ]  	   step  1 (lr=0.311834)                   80.04%                   0.7477
2022-10-03 09:53:45 [INFO ]  
2022-10-03 09:53:45 [INFO ]  Epoch:  170	Loss: 0.7052	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:53:47 [INFO ]  Epoch:  171	Loss: 0.7705	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 09:53:49 [INFO ]  Epoch:  172	Loss: 0.7360	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:53:51 [INFO ]  Epoch:  173	Loss: 0.7840	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 09:53:53 [INFO ]  Epoch:  174	Loss: 0.7236	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:53:55 [INFO ]  Epoch:  175	Loss: 0.7536	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:53:57 [INFO ]  Epoch:  176	Loss: 0.6528	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:53:59 [INFO ]  Epoch:  177	Loss: 0.7246	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 09:54:01 [INFO ]  Epoch:  178	Loss: 0.6821	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 09:54:03 [INFO ]  Epoch:  179	Loss: 0.6154	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:54:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 09:54:09 [INFO ]  
2022-10-03 09:54:09 [INFO ]  Begin of epoch 180 :
2022-10-03 09:54:12 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:54:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:54:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:54:12 [INFO ]  	   step  1 (lr=0.311535)                   79.19%                   0.7600
2022-10-03 09:54:12 [INFO ]  
2022-10-03 09:54:12 [INFO ]  Epoch:  180	Loss: 0.6269	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 09:54:14 [INFO ]  Epoch:  181	Loss: 0.7207	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:54:16 [INFO ]  Epoch:  182	Loss: 0.7571	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:54:18 [INFO ]  Epoch:  183	Loss: 0.6690	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:54:20 [INFO ]  Epoch:  184	Loss: 0.6891	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:54:22 [INFO ]  Epoch:  185	Loss: 0.6564	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:54:23 [INFO ]  Epoch:  186	Loss: 0.6511	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:54:25 [INFO ]  Epoch:  187	Loss: 0.7669	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:54:27 [INFO ]  Epoch:  188	Loss: 0.7445	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:54:29 [INFO ]  Epoch:  189	Loss: 0.7288	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:54:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 09:54:35 [INFO ]  
2022-10-03 09:54:35 [INFO ]  Begin of epoch 190 :
2022-10-03 09:54:38 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:54:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:54:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:54:38 [INFO ]  	   step  1 (lr=0.311090)                   78.98%                   0.7783
2022-10-03 09:54:38 [INFO ]  
2022-10-03 09:54:38 [INFO ]  Epoch:  190	Loss: 0.6912	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:54:40 [INFO ]  Epoch:  191	Loss: 0.6845	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:54:42 [INFO ]  Epoch:  192	Loss: 0.6283	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:54:44 [INFO ]  Epoch:  193	Loss: 0.7298	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:54:45 [INFO ]  Epoch:  194	Loss: 0.7482	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:54:47 [INFO ]  Epoch:  195	Loss: 0.6450	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:54:49 [INFO ]  Epoch:  196	Loss: 0.6793	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:54:51 [INFO ]  Epoch:  197	Loss: 0.7682	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:54:53 [INFO ]  Epoch:  198	Loss: 0.6271	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:54:54 [INFO ]  Epoch:  199	Loss: 0.7682	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:55:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 09:55:00 [INFO ]  
2022-10-03 09:55:00 [INFO ]  Final evaluation for SVHN :
2022-10-03 09:55:03 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:55:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:55:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:55:03 [INFO ]  	   step  1 (lr=0.310646)                   79.35%                   0.7764
2022-10-03 09:55:03 [INFO ]  
2022-10-03 09:55:03 [INFO ]  
2022-10-03 09:55:03 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 09:55:06 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:55:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:55:06 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 09:55:06 [INFO ]  	   step  1 (lr=0.310646)                   18.77%                   5.5620
2022-10-03 09:55:06 [INFO ]  
2022-10-03 09:55:25 [INFO ]  ======================================== 2022-10-03 09:55:25 ========================================
2022-10-03 09:55:25 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 09:55:25 [INFO ]  Options: 
2022-10-03 09:55:25 [INFO ]  	base_dir: null
2022-10-03 09:55:25 [INFO ]  	batch_size: 1024
2022-10-03 09:55:25 [INFO ]  	checkpoint_interval: 10
2022-10-03 09:55:25 [INFO ]  	dataset: SVHN
2022-10-03 09:55:25 [INFO ]  	dataset_labels:
2022-10-03 09:55:25 [INFO ]  	- 0
2022-10-03 09:55:25 [INFO ]  	- 1
2022-10-03 09:55:25 [INFO ]  	- 2
2022-10-03 09:55:25 [INFO ]  	- 3
2022-10-03 09:55:25 [INFO ]  	- 4
2022-10-03 09:55:25 [INFO ]  	- 5
2022-10-03 09:55:25 [INFO ]  	- 6
2022-10-03 09:55:25 [INFO ]  	- 7
2022-10-03 09:55:25 [INFO ]  	- 8
2022-10-03 09:55:25 [INFO ]  	- 9
2022-10-03 09:55:25 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 09:55:25 [INFO ]  	- !!python/tuple
2022-10-03 09:55:25 [INFO ]  	    - 0.4379104971885681
2022-10-03 09:55:25 [INFO ]  	    - 0.44398033618927
2022-10-03 09:55:25 [INFO ]  	    - 0.4729299545288086
2022-10-03 09:55:25 [INFO ]  	- !!python/tuple
2022-10-03 09:55:25 [INFO ]  	    - 0.19803012907505035
2022-10-03 09:55:25 [INFO ]  	    - 0.2010156363248825
2022-10-03 09:55:25 [INFO ]  	    - 0.19703614711761475
2022-10-03 09:55:25 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 09:55:25 [INFO ]  	decay_epochs: 50
2022-10-03 09:55:25 [INFO ]  	decay_factor: 0.1
2022-10-03 09:55:25 [INFO ]  	device_id: 0
2022-10-03 09:55:25 [INFO ]  	distill_epochs: 1
2022-10-03 09:55:25 [INFO ]  	distill_lr: 0.02
2022-10-03 09:55:25 [INFO ]  	distill_steps: 1
2022-10-03 09:55:25 [INFO ]  	epochs: 200
2022-10-03 09:55:25 [INFO ]  	expand_cls: false
2022-10-03 09:55:25 [INFO ]  	forgetting_dataset: null
2022-10-03 09:55:25 [INFO ]  	init: xavier
2022-10-03 09:55:25 [INFO ]  	init_param: 1.0
2022-10-03 09:55:25 [INFO ]  	input_size: 32
2022-10-03 09:55:25 [INFO ]  	ipc: 10
2022-10-03 09:55:25 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 09:55:25 [INFO ]  	log_interval: 100
2022-10-03 09:55:25 [INFO ]  	log_level: INFO
2022-10-03 09:55:25 [INFO ]  	lr: 0.01
2022-10-03 09:55:25 [INFO ]  	mode: distill_adapt
2022-10-03 09:55:25 [INFO ]  	nc: 3
2022-10-03 09:55:25 [INFO ]  	num_classes: 10
2022-10-03 09:55:25 [INFO ]  	num_workers: 8
2022-10-03 09:55:25 [INFO ]  	phase: train
2022-10-03 09:55:25 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 09:55:25 [INFO ]  	start_time: '2022-10-03 09:55:25'
2022-10-03 09:55:25 [INFO ]  	test_batch_size: 1024
2022-10-03 09:55:25 [INFO ]  	
2022-10-03 09:55:27 [INFO ]  train dataset size:	73257
2022-10-03 09:55:27 [INFO ]  test dataset size: 	26032
2022-10-03 09:55:27 [INFO ]  datasets built!
2022-10-03 09:55:27 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 09:55:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 09:55:35 [INFO ]  
2022-10-03 09:55:35 [INFO ]  Begin of epoch 0 :
2022-10-03 09:55:39 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:55:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:55:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:55:39 [INFO ]  	   step  1 (lr=0.020000)                    7.87%                   7.9993
2022-10-03 09:55:39 [INFO ]  
2022-10-03 09:55:39 [INFO ]  Epoch:    0	Loss: 7.8593	Data Time: 0.38s	Train Time: 0.04s
2022-10-03 09:55:40 [INFO ]  Epoch:    1	Loss: 2.9959	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:55:42 [INFO ]  Epoch:    2	Loss: 2.3934	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:55:44 [INFO ]  Epoch:    3	Loss: 2.2687	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:55:46 [INFO ]  Epoch:    4	Loss: 2.2271	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:55:48 [INFO ]  Epoch:    5	Loss: 2.1767	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:55:50 [INFO ]  Epoch:    6	Loss: 2.1554	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:55:52 [INFO ]  Epoch:    7	Loss: 2.1022	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:55:54 [INFO ]  Epoch:    8	Loss: 2.0232	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:55:56 [INFO ]  Epoch:    9	Loss: 1.9613	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 09:56:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 09:56:04 [INFO ]  
2022-10-03 09:56:04 [INFO ]  Begin of epoch 10 :
2022-10-03 09:56:08 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:56:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:56:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:56:08 [INFO ]  	   step  1 (lr=0.085556)                   42.50%                   1.8520
2022-10-03 09:56:08 [INFO ]  
2022-10-03 09:56:08 [INFO ]  Epoch:   10	Loss: 1.8296	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 09:56:09 [INFO ]  Epoch:   11	Loss: 1.6343	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:56:11 [INFO ]  Epoch:   12	Loss: 1.4942	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:56:13 [INFO ]  Epoch:   13	Loss: 1.5235	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:56:15 [INFO ]  Epoch:   14	Loss: 1.4648	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:56:17 [INFO ]  Epoch:   15	Loss: 1.1301	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:56:19 [INFO ]  Epoch:   16	Loss: 1.1589	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:56:21 [INFO ]  Epoch:   17	Loss: 1.2265	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:56:22 [INFO ]  Epoch:   18	Loss: 1.0891	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:56:24 [INFO ]  Epoch:   19	Loss: 1.1468	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:56:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 09:56:33 [INFO ]  
2022-10-03 09:56:33 [INFO ]  Begin of epoch 20 :
2022-10-03 09:56:36 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:56:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:56:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:56:36 [INFO ]  	   step  1 (lr=0.247247)                   69.05%                   1.0717
2022-10-03 09:56:36 [INFO ]  
2022-10-03 09:56:36 [INFO ]  Epoch:   20	Loss: 1.0243	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 09:56:38 [INFO ]  Epoch:   21	Loss: 1.0696	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:56:40 [INFO ]  Epoch:   22	Loss: 1.0227	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:56:42 [INFO ]  Epoch:   23	Loss: 1.0065	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:56:43 [INFO ]  Epoch:   24	Loss: 0.9940	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:56:45 [INFO ]  Epoch:   25	Loss: 0.9434	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:56:47 [INFO ]  Epoch:   26	Loss: 1.0374	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:56:49 [INFO ]  Epoch:   27	Loss: 0.9755	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:56:51 [INFO ]  Epoch:   28	Loss: 0.8914	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:56:53 [INFO ]  Epoch:   29	Loss: 0.9545	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 09:57:02 [INFO ]  
2022-10-03 09:57:02 [INFO ]  Begin of epoch 30 :
2022-10-03 09:57:05 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:57:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:57:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:57:05 [INFO ]  	   step  1 (lr=0.311620)                   73.39%                   0.9477
2022-10-03 09:57:05 [INFO ]  
2022-10-03 09:57:05 [INFO ]  Epoch:   30	Loss: 0.8484	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:07 [INFO ]  Epoch:   31	Loss: 0.8049	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:57:09 [INFO ]  Epoch:   32	Loss: 0.8078	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:11 [INFO ]  Epoch:   33	Loss: 0.8976	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:13 [INFO ]  Epoch:   34	Loss: 0.8438	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:14 [INFO ]  Epoch:   35	Loss: 0.7684	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:57:16 [INFO ]  Epoch:   36	Loss: 0.8809	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:57:18 [INFO ]  Epoch:   37	Loss: 0.7026	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:20 [INFO ]  Epoch:   38	Loss: 0.7146	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:57:22 [INFO ]  Epoch:   39	Loss: 0.9896	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 09:57:30 [INFO ]  
2022-10-03 09:57:30 [INFO ]  Begin of epoch 40 :
2022-10-03 09:57:34 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:57:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:57:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:57:34 [INFO ]  	   step  1 (lr=0.332520)                   74.32%                   0.9096
2022-10-03 09:57:34 [INFO ]  
2022-10-03 09:57:34 [INFO ]  Epoch:   40	Loss: 0.8296	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:35 [INFO ]  Epoch:   41	Loss: 0.8319	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:57:37 [INFO ]  Epoch:   42	Loss: 0.7998	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:39 [INFO ]  Epoch:   43	Loss: 0.7730	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:57:41 [INFO ]  Epoch:   44	Loss: 0.7808	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:57:43 [INFO ]  Epoch:   45	Loss: 0.7632	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:57:45 [INFO ]  Epoch:   46	Loss: 0.7558	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:47 [INFO ]  Epoch:   47	Loss: 0.8259	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:49 [INFO ]  Epoch:   48	Loss: 0.8297	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:57:51 [INFO ]  Epoch:   49	Loss: 0.7666	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:58:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 09:58:00 [INFO ]  
2022-10-03 09:58:00 [INFO ]  Begin of epoch 50 :
2022-10-03 09:58:04 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:58:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:58:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:58:04 [INFO ]  	   step  1 (lr=0.349509)                   79.81%                   0.7605
2022-10-03 09:58:04 [INFO ]  
2022-10-03 09:58:04 [INFO ]  Epoch:   50	Loss: 0.6373	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:58:05 [INFO ]  Epoch:   51	Loss: 0.7044	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 09:58:07 [INFO ]  Epoch:   52	Loss: 0.6972	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:58:09 [INFO ]  Epoch:   53	Loss: 0.6913	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:58:11 [INFO ]  Epoch:   54	Loss: 0.6429	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:58:13 [INFO ]  Epoch:   55	Loss: 0.7005	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:58:15 [INFO ]  Epoch:   56	Loss: 0.6732	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:58:17 [INFO ]  Epoch:   57	Loss: 0.7128	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:58:18 [INFO ]  Epoch:   58	Loss: 0.7220	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:58:20 [INFO ]  Epoch:   59	Loss: 0.6930	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:58:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 09:58:29 [INFO ]  
2022-10-03 09:58:29 [INFO ]  Begin of epoch 60 :
2022-10-03 09:58:32 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:58:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:58:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:58:32 [INFO ]  	   step  1 (lr=0.362673)                   79.79%                   0.7327
2022-10-03 09:58:32 [INFO ]  
2022-10-03 09:58:32 [INFO ]  Epoch:   60	Loss: 0.7165	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:58:34 [INFO ]  Epoch:   61	Loss: 0.7234	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:58:36 [INFO ]  Epoch:   62	Loss: 0.6499	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:58:38 [INFO ]  Epoch:   63	Loss: 0.6545	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:58:40 [INFO ]  Epoch:   64	Loss: 0.6116	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:58:42 [INFO ]  Epoch:   65	Loss: 0.6381	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:58:44 [INFO ]  Epoch:   66	Loss: 0.6972	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:58:45 [INFO ]  Epoch:   67	Loss: 0.6530	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:58:47 [INFO ]  Epoch:   68	Loss: 0.6283	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 09:58:49 [INFO ]  Epoch:   69	Loss: 0.6196	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:58:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 09:58:58 [INFO ]  
2022-10-03 09:58:58 [INFO ]  Begin of epoch 70 :
2022-10-03 09:59:01 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:59:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:59:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:59:01 [INFO ]  	   step  1 (lr=0.371880)                   80.08%                   0.7226
2022-10-03 09:59:01 [INFO ]  
2022-10-03 09:59:01 [INFO ]  Epoch:   70	Loss: 0.7040	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 09:59:03 [INFO ]  Epoch:   71	Loss: 0.7433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:59:05 [INFO ]  Epoch:   72	Loss: 0.6375	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 09:59:07 [INFO ]  Epoch:   73	Loss: 0.6762	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:59:08 [INFO ]  Epoch:   74	Loss: 0.6523	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:59:11 [INFO ]  Epoch:   75	Loss: 0.6887	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:59:13 [INFO ]  Epoch:   76	Loss: 0.7067	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:59:14 [INFO ]  Epoch:   77	Loss: 0.5996	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:59:16 [INFO ]  Epoch:   78	Loss: 0.6822	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 09:59:18 [INFO ]  Epoch:   79	Loss: 0.6694	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:59:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 09:59:27 [INFO ]  
2022-10-03 09:59:27 [INFO ]  Begin of epoch 80 :
2022-10-03 09:59:30 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 09:59:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 09:59:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 09:59:30 [INFO ]  	   step  1 (lr=0.379854)                   80.94%                   0.7045
2022-10-03 09:59:30 [INFO ]  
2022-10-03 09:59:30 [INFO ]  Epoch:   80	Loss: 0.5888	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 09:59:32 [INFO ]  Epoch:   81	Loss: 0.6059	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:59:34 [INFO ]  Epoch:   82	Loss: 0.6298	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 09:59:36 [INFO ]  Epoch:   83	Loss: 0.6785	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 09:59:38 [INFO ]  Epoch:   84	Loss: 0.6272	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 09:59:40 [INFO ]  Epoch:   85	Loss: 0.6143	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:59:42 [INFO ]  Epoch:   86	Loss: 0.6650	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:59:44 [INFO ]  Epoch:   87	Loss: 0.6324	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:59:46 [INFO ]  Epoch:   88	Loss: 0.6739	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 09:59:48 [INFO ]  Epoch:   89	Loss: 0.6359	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 09:59:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 09:59:57 [INFO ]  
2022-10-03 09:59:57 [INFO ]  Begin of epoch 90 :
2022-10-03 10:00:01 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:00:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:00:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:00:01 [INFO ]  	   step  1 (lr=0.387412)                   80.64%                   0.7049
2022-10-03 10:00:01 [INFO ]  
2022-10-03 10:00:01 [INFO ]  Epoch:   90	Loss: 0.6099	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:03 [INFO ]  Epoch:   91	Loss: 0.6350	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:00:04 [INFO ]  Epoch:   92	Loss: 0.6327	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:00:06 [INFO ]  Epoch:   93	Loss: 0.5836	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:00:08 [INFO ]  Epoch:   94	Loss: 0.6534	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:00:10 [INFO ]  Epoch:   95	Loss: 0.6901	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:00:12 [INFO ]  Epoch:   96	Loss: 0.6429	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:00:14 [INFO ]  Epoch:   97	Loss: 0.5782	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:00:16 [INFO ]  Epoch:   98	Loss: 0.6680	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:00:18 [INFO ]  Epoch:   99	Loss: 0.6163	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 10:00:27 [INFO ]  
2022-10-03 10:00:27 [INFO ]  Begin of epoch 100 :
2022-10-03 10:00:30 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:00:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:00:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:00:30 [INFO ]  	   step  1 (lr=0.393452)                   80.55%                   0.7149
2022-10-03 10:00:30 [INFO ]  
2022-10-03 10:00:30 [INFO ]  Epoch:  100	Loss: 0.7074	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:32 [INFO ]  Epoch:  101	Loss: 0.6221	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:00:34 [INFO ]  Epoch:  102	Loss: 0.6389	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:36 [INFO ]  Epoch:  103	Loss: 0.6088	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:00:38 [INFO ]  Epoch:  104	Loss: 0.6012	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:00:39 [INFO ]  Epoch:  105	Loss: 0.6120	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:41 [INFO ]  Epoch:  106	Loss: 0.6561	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:00:43 [INFO ]  Epoch:  107	Loss: 0.6435	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:45 [INFO ]  Epoch:  108	Loss: 0.6983	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:00:47 [INFO ]  Epoch:  109	Loss: 0.6135	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:00:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 10:00:55 [INFO ]  
2022-10-03 10:00:55 [INFO ]  Begin of epoch 110 :
2022-10-03 10:00:59 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:00:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:00:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:00:59 [INFO ]  	   step  1 (lr=0.394567)                   81.31%                   0.6887
2022-10-03 10:00:59 [INFO ]  
2022-10-03 10:00:59 [INFO ]  Epoch:  110	Loss: 0.5915	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:01:01 [INFO ]  Epoch:  111	Loss: 0.6378	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:03 [INFO ]  Epoch:  112	Loss: 0.6819	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:01:06 [INFO ]  Epoch:  113	Loss: 0.6147	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:01:08 [INFO ]  Epoch:  114	Loss: 0.5658	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:01:10 [INFO ]  Epoch:  115	Loss: 0.6077	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:12 [INFO ]  Epoch:  116	Loss: 0.5902	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:01:14 [INFO ]  Epoch:  117	Loss: 0.7097	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:16 [INFO ]  Epoch:  118	Loss: 0.6545	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:01:18 [INFO ]  Epoch:  119	Loss: 0.5866	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 10:01:27 [INFO ]  
2022-10-03 10:01:27 [INFO ]  Begin of epoch 120 :
2022-10-03 10:01:30 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:01:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:01:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:01:30 [INFO ]  	   step  1 (lr=0.393062)                   80.92%                   0.6989
2022-10-03 10:01:30 [INFO ]  
2022-10-03 10:01:30 [INFO ]  Epoch:  120	Loss: 0.6507	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:01:32 [INFO ]  Epoch:  121	Loss: 0.5838	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:01:34 [INFO ]  Epoch:  122	Loss: 0.5628	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:01:36 [INFO ]  Epoch:  123	Loss: 0.6475	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:01:38 [INFO ]  Epoch:  124	Loss: 0.6195	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:40 [INFO ]  Epoch:  125	Loss: 0.6572	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:01:41 [INFO ]  Epoch:  126	Loss: 0.6270	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:43 [INFO ]  Epoch:  127	Loss: 0.6169	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:45 [INFO ]  Epoch:  128	Loss: 0.6771	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:01:47 [INFO ]  Epoch:  129	Loss: 0.6626	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:01:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 10:01:56 [INFO ]  
2022-10-03 10:01:56 [INFO ]  Begin of epoch 130 :
2022-10-03 10:01:59 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:01:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:01:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:01:59 [INFO ]  	   step  1 (lr=0.397305)                   81.54%                   0.6814
2022-10-03 10:01:59 [INFO ]  
2022-10-03 10:01:59 [INFO ]  Epoch:  130	Loss: 0.6788	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 10:02:01 [INFO ]  Epoch:  131	Loss: 0.6356	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:02:03 [INFO ]  Epoch:  132	Loss: 0.6435	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:02:05 [INFO ]  Epoch:  133	Loss: 0.6399	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:02:07 [INFO ]  Epoch:  134	Loss: 0.6407	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:09 [INFO ]  Epoch:  135	Loss: 0.6029	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:02:11 [INFO ]  Epoch:  136	Loss: 0.6489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:02:13 [INFO ]  Epoch:  137	Loss: 0.6430	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:02:15 [INFO ]  Epoch:  138	Loss: 0.6420	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:02:16 [INFO ]  Epoch:  139	Loss: 0.6584	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 10:02:25 [INFO ]  
2022-10-03 10:02:25 [INFO ]  Begin of epoch 140 :
2022-10-03 10:02:28 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:02:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:02:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:02:28 [INFO ]  	   step  1 (lr=0.399105)                   81.08%                   0.6910
2022-10-03 10:02:28 [INFO ]  
2022-10-03 10:02:28 [INFO ]  Epoch:  140	Loss: 0.6559	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:02:30 [INFO ]  Epoch:  141	Loss: 0.6669	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:32 [INFO ]  Epoch:  142	Loss: 0.5806	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:02:34 [INFO ]  Epoch:  143	Loss: 0.6805	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:02:36 [INFO ]  Epoch:  144	Loss: 0.6522	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:38 [INFO ]  Epoch:  145	Loss: 0.6789	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:02:40 [INFO ]  Epoch:  146	Loss: 0.6517	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:02:42 [INFO ]  Epoch:  147	Loss: 0.6097	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:02:44 [INFO ]  Epoch:  148	Loss: 0.6389	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:45 [INFO ]  Epoch:  149	Loss: 0.6143	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:02:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 10:02:54 [INFO ]  
2022-10-03 10:02:54 [INFO ]  Begin of epoch 150 :
2022-10-03 10:02:58 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:02:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:02:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:02:58 [INFO ]  	   step  1 (lr=0.398648)                   81.19%                   0.6902
2022-10-03 10:02:58 [INFO ]  
2022-10-03 10:02:58 [INFO ]  Epoch:  150	Loss: 0.6009	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:03:00 [INFO ]  Epoch:  151	Loss: 0.6674	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:03:01 [INFO ]  Epoch:  152	Loss: 0.6965	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:03:03 [INFO ]  Epoch:  153	Loss: 0.6432	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:03:05 [INFO ]  Epoch:  154	Loss: 0.6367	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:07 [INFO ]  Epoch:  155	Loss: 0.6750	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:09 [INFO ]  Epoch:  156	Loss: 0.7139	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:03:11 [INFO ]  Epoch:  157	Loss: 0.6484	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:03:12 [INFO ]  Epoch:  158	Loss: 0.5946	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:14 [INFO ]  Epoch:  159	Loss: 0.6179	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:03:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 10:03:23 [INFO ]  
2022-10-03 10:03:23 [INFO ]  Begin of epoch 160 :
2022-10-03 10:03:27 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:03:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:03:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:03:27 [INFO ]  	   step  1 (lr=0.399486)                   80.95%                   0.6937
2022-10-03 10:03:27 [INFO ]  
2022-10-03 10:03:27 [INFO ]  Epoch:  160	Loss: 0.6040	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 10:03:29 [INFO ]  Epoch:  161	Loss: 0.7122	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:03:30 [INFO ]  Epoch:  162	Loss: 0.7718	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:32 [INFO ]  Epoch:  163	Loss: 0.5937	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:34 [INFO ]  Epoch:  164	Loss: 0.6519	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:03:36 [INFO ]  Epoch:  165	Loss: 0.6938	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:38 [INFO ]  Epoch:  166	Loss: 0.6605	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:03:40 [INFO ]  Epoch:  167	Loss: 0.6311	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:42 [INFO ]  Epoch:  168	Loss: 0.6041	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:03:44 [INFO ]  Epoch:  169	Loss: 0.6528	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:03:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 10:03:53 [INFO ]  
2022-10-03 10:03:53 [INFO ]  Begin of epoch 170 :
2022-10-03 10:03:56 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:03:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:03:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:03:56 [INFO ]  	   step  1 (lr=0.398123)                   81.25%                   0.6918
2022-10-03 10:03:56 [INFO ]  
2022-10-03 10:03:56 [INFO ]  Epoch:  170	Loss: 0.6699	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:03:58 [INFO ]  Epoch:  171	Loss: 0.6553	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:00 [INFO ]  Epoch:  172	Loss: 0.5920	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:01 [INFO ]  Epoch:  173	Loss: 0.5932	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:04:03 [INFO ]  Epoch:  174	Loss: 0.6759	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:04:05 [INFO ]  Epoch:  175	Loss: 0.6361	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:04:07 [INFO ]  Epoch:  176	Loss: 0.6442	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:09 [INFO ]  Epoch:  177	Loss: 0.5794	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:04:11 [INFO ]  Epoch:  178	Loss: 0.6162	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:04:13 [INFO ]  Epoch:  179	Loss: 0.6667	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:04:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 10:04:22 [INFO ]  
2022-10-03 10:04:22 [INFO ]  Begin of epoch 180 :
2022-10-03 10:04:25 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:04:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:04:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:04:25 [INFO ]  	   step  1 (lr=0.397419)                   81.14%                   0.6909
2022-10-03 10:04:25 [INFO ]  
2022-10-03 10:04:25 [INFO ]  Epoch:  180	Loss: 0.6709	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:04:27 [INFO ]  Epoch:  181	Loss: 0.6104	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:04:29 [INFO ]  Epoch:  182	Loss: 0.6259	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:04:31 [INFO ]  Epoch:  183	Loss: 0.6349	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:04:33 [INFO ]  Epoch:  184	Loss: 0.6488	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:35 [INFO ]  Epoch:  185	Loss: 0.5516	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:36 [INFO ]  Epoch:  186	Loss: 0.5833	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:04:38 [INFO ]  Epoch:  187	Loss: 0.5163	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:04:40 [INFO ]  Epoch:  188	Loss: 0.5894	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:04:43 [INFO ]  Epoch:  189	Loss: 0.5917	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:04:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 10:04:51 [INFO ]  
2022-10-03 10:04:51 [INFO ]  Begin of epoch 190 :
2022-10-03 10:04:55 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:04:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:04:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:04:55 [INFO ]  	   step  1 (lr=0.398025)                   80.97%                   0.7005
2022-10-03 10:04:55 [INFO ]  
2022-10-03 10:04:55 [INFO ]  Epoch:  190	Loss: 0.6016	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 10:04:57 [INFO ]  Epoch:  191	Loss: 0.6232	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 10:04:58 [INFO ]  Epoch:  192	Loss: 0.5695	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:05:00 [INFO ]  Epoch:  193	Loss: 0.5685	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:05:02 [INFO ]  Epoch:  194	Loss: 0.6193	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:05:04 [INFO ]  Epoch:  195	Loss: 0.6359	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:05:06 [INFO ]  Epoch:  196	Loss: 0.5949	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:05:08 [INFO ]  Epoch:  197	Loss: 0.6490	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:05:10 [INFO ]  Epoch:  198	Loss: 0.6581	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:05:11 [INFO ]  Epoch:  199	Loss: 0.6173	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:05:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 10:05:20 [INFO ]  
2022-10-03 10:05:20 [INFO ]  Final evaluation for SVHN :
2022-10-03 10:05:23 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:05:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:05:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:05:23 [INFO ]  	   step  1 (lr=0.398314)                   81.19%                   0.6880
2022-10-03 10:05:23 [INFO ]  
2022-10-03 10:05:23 [INFO ]  
2022-10-03 10:05:23 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 10:05:27 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:05:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:05:27 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 10:05:27 [INFO ]  	   step  1 (lr=0.398314)                   16.64%                   5.1484
2022-10-03 10:05:27 [INFO ]  
2022-10-03 10:12:23 [INFO ]  ======================================== 2022-10-03 10:12:23 ========================================
2022-10-03 10:12:23 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 10:12:23 [INFO ]  Options: 
2022-10-03 10:12:23 [INFO ]  	base_dir: null
2022-10-03 10:12:23 [INFO ]  	batch_size: 1024
2022-10-03 10:12:23 [INFO ]  	checkpoint_interval: 10
2022-10-03 10:12:23 [INFO ]  	dataset: SVHN
2022-10-03 10:12:23 [INFO ]  	dataset_labels:
2022-10-03 10:12:23 [INFO ]  	- 0
2022-10-03 10:12:23 [INFO ]  	- 1
2022-10-03 10:12:23 [INFO ]  	- 2
2022-10-03 10:12:23 [INFO ]  	- 3
2022-10-03 10:12:23 [INFO ]  	- 4
2022-10-03 10:12:23 [INFO ]  	- 5
2022-10-03 10:12:23 [INFO ]  	- 6
2022-10-03 10:12:23 [INFO ]  	- 7
2022-10-03 10:12:23 [INFO ]  	- 8
2022-10-03 10:12:23 [INFO ]  	- 9
2022-10-03 10:12:23 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 10:12:23 [INFO ]  	- !!python/tuple
2022-10-03 10:12:23 [INFO ]  	    - 0.4379104971885681
2022-10-03 10:12:23 [INFO ]  	    - 0.44398033618927
2022-10-03 10:12:23 [INFO ]  	    - 0.4729299545288086
2022-10-03 10:12:23 [INFO ]  	- !!python/tuple
2022-10-03 10:12:23 [INFO ]  	    - 0.19803012907505035
2022-10-03 10:12:23 [INFO ]  	    - 0.2010156363248825
2022-10-03 10:12:23 [INFO ]  	    - 0.19703614711761475
2022-10-03 10:12:23 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 10:12:23 [INFO ]  	decay_epochs: 50
2022-10-03 10:12:23 [INFO ]  	decay_factor: 0.1
2022-10-03 10:12:23 [INFO ]  	device_id: 0
2022-10-03 10:12:23 [INFO ]  	distill_epochs: 1
2022-10-03 10:12:23 [INFO ]  	distill_lr: 0.02
2022-10-03 10:12:23 [INFO ]  	distill_steps: 1
2022-10-03 10:12:23 [INFO ]  	epochs: 200
2022-10-03 10:12:23 [INFO ]  	expand_cls: false
2022-10-03 10:12:23 [INFO ]  	forgetting_dataset: null
2022-10-03 10:12:23 [INFO ]  	init: xavier
2022-10-03 10:12:23 [INFO ]  	init_param: 1.0
2022-10-03 10:12:23 [INFO ]  	input_size: 32
2022-10-03 10:12:23 [INFO ]  	ipc: 10
2022-10-03 10:12:23 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 10:12:23 [INFO ]  	log_interval: 100
2022-10-03 10:12:23 [INFO ]  	log_level: INFO
2022-10-03 10:12:23 [INFO ]  	lr: 0.01
2022-10-03 10:12:23 [INFO ]  	mode: distill_adapt
2022-10-03 10:12:23 [INFO ]  	nc: 3
2022-10-03 10:12:23 [INFO ]  	num_classes: 10
2022-10-03 10:12:23 [INFO ]  	num_workers: 8
2022-10-03 10:12:23 [INFO ]  	phase: train
2022-10-03 10:12:23 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 10:12:23 [INFO ]  	start_time: '2022-10-03 10:12:23'
2022-10-03 10:12:23 [INFO ]  	test_batch_size: 1024
2022-10-03 10:12:23 [INFO ]  	
2022-10-03 10:12:25 [INFO ]  train dataset size:	73257
2022-10-03 10:12:25 [INFO ]  test dataset size: 	26032
2022-10-03 10:12:25 [INFO ]  datasets built!
2022-10-03 10:12:25 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 10:12:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 10:12:33 [INFO ]  
2022-10-03 10:12:33 [INFO ]  Begin of epoch 0 :
2022-10-03 10:12:37 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:12:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:12:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:12:37 [INFO ]  	   step  1 (lr=0.020000)                    7.58%                   8.4803
2022-10-03 10:12:37 [INFO ]  
2022-10-03 10:12:37 [INFO ]  Epoch:    0	Loss: 8.1601	Data Time: 0.38s	Train Time: 0.03s
2022-10-03 10:12:38 [INFO ]  Epoch:    1	Loss: 3.0942	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:12:40 [INFO ]  Epoch:    2	Loss: 2.4568	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:12:42 [INFO ]  Epoch:    3	Loss: 2.2588	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:12:44 [INFO ]  Epoch:    4	Loss: 2.2134	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:12:46 [INFO ]  Epoch:    5	Loss: 2.1931	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:12:48 [INFO ]  Epoch:    6	Loss: 2.1527	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:12:50 [INFO ]  Epoch:    7	Loss: 2.0905	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:12:52 [INFO ]  Epoch:    8	Loss: 2.0328	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:12:53 [INFO ]  Epoch:    9	Loss: 1.9197	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:13:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 10:13:02 [INFO ]  
2022-10-03 10:13:02 [INFO ]  Begin of epoch 10 :
2022-10-03 10:13:05 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:13:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:13:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:13:05 [INFO ]  	   step  1 (lr=0.085854)                   41.03%                   1.8755
2022-10-03 10:13:05 [INFO ]  
2022-10-03 10:13:05 [INFO ]  Epoch:   10	Loss: 1.8588	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:13:07 [INFO ]  Epoch:   11	Loss: 1.6407	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:13:09 [INFO ]  Epoch:   12	Loss: 1.5597	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:13:11 [INFO ]  Epoch:   13	Loss: 1.6530	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:13:12 [INFO ]  Epoch:   14	Loss: 1.4080	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:13:14 [INFO ]  Epoch:   15	Loss: 1.4463	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:13:16 [INFO ]  Epoch:   16	Loss: 1.1681	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:13:18 [INFO ]  Epoch:   17	Loss: 1.2017	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:13:19 [INFO ]  Epoch:   18	Loss: 1.0740	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:13:21 [INFO ]  Epoch:   19	Loss: 0.9762	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:13:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 10:13:30 [INFO ]  
2022-10-03 10:13:30 [INFO ]  Begin of epoch 20 :
2022-10-03 10:13:33 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:13:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:13:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:13:33 [INFO ]  	   step  1 (lr=0.243562)                   70.75%                   1.0447
2022-10-03 10:13:33 [INFO ]  
2022-10-03 10:13:33 [INFO ]  Epoch:   20	Loss: 0.9248	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:13:35 [INFO ]  Epoch:   21	Loss: 0.9957	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:13:37 [INFO ]  Epoch:   22	Loss: 1.0267	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:13:39 [INFO ]  Epoch:   23	Loss: 0.9790	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:13:41 [INFO ]  Epoch:   24	Loss: 0.9277	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:13:42 [INFO ]  Epoch:   25	Loss: 0.8625	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 10:13:45 [INFO ]  Epoch:   26	Loss: 1.0074	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:13:46 [INFO ]  Epoch:   27	Loss: 0.8655	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:13:48 [INFO ]  Epoch:   28	Loss: 0.8593	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:13:50 [INFO ]  Epoch:   29	Loss: 0.8432	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:13:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 10:13:59 [INFO ]  
2022-10-03 10:13:59 [INFO ]  Begin of epoch 30 :
2022-10-03 10:14:02 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:14:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:14:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:14:02 [INFO ]  	   step  1 (lr=0.288843)                   76.01%                   0.8604
2022-10-03 10:14:02 [INFO ]  
2022-10-03 10:14:02 [INFO ]  Epoch:   30	Loss: 0.8451	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:14:04 [INFO ]  Epoch:   31	Loss: 0.9264	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:14:06 [INFO ]  Epoch:   32	Loss: 0.8679	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:14:07 [INFO ]  Epoch:   33	Loss: 0.7701	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:14:09 [INFO ]  Epoch:   34	Loss: 0.7846	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:14:11 [INFO ]  Epoch:   35	Loss: 0.8840	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:13 [INFO ]  Epoch:   36	Loss: 0.7470	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:14:15 [INFO ]  Epoch:   37	Loss: 0.8489	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:14:17 [INFO ]  Epoch:   38	Loss: 0.8292	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:14:19 [INFO ]  Epoch:   39	Loss: 0.7836	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:14:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 10:14:27 [INFO ]  
2022-10-03 10:14:27 [INFO ]  Begin of epoch 40 :
2022-10-03 10:14:30 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:14:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:14:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:14:30 [INFO ]  	   step  1 (lr=0.295344)                   76.67%                   0.8432
2022-10-03 10:14:30 [INFO ]  
2022-10-03 10:14:30 [INFO ]  Epoch:   40	Loss: 0.8342	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 10:14:32 [INFO ]  Epoch:   41	Loss: 0.7196	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:34 [INFO ]  Epoch:   42	Loss: 0.7718	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:14:36 [INFO ]  Epoch:   43	Loss: 0.7229	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:38 [INFO ]  Epoch:   44	Loss: 0.7233	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:14:40 [INFO ]  Epoch:   45	Loss: 0.6952	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:41 [INFO ]  Epoch:   46	Loss: 0.7936	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:43 [INFO ]  Epoch:   47	Loss: 0.7810	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:14:45 [INFO ]  Epoch:   48	Loss: 0.7869	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:47 [INFO ]  Epoch:   49	Loss: 0.9011	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:14:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 10:14:56 [INFO ]  
2022-10-03 10:14:56 [INFO ]  Begin of epoch 50 :
2022-10-03 10:15:00 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:15:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:15:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:15:00 [INFO ]  	   step  1 (lr=0.311139)                   80.12%                   0.7239
2022-10-03 10:15:00 [INFO ]  
2022-10-03 10:15:00 [INFO ]  Epoch:   50	Loss: 0.7050	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:15:01 [INFO ]  Epoch:   51	Loss: 0.6749	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:15:03 [INFO ]  Epoch:   52	Loss: 0.6627	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:15:05 [INFO ]  Epoch:   53	Loss: 0.6380	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:15:07 [INFO ]  Epoch:   54	Loss: 0.5939	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:15:09 [INFO ]  Epoch:   55	Loss: 0.6615	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:15:10 [INFO ]  Epoch:   56	Loss: 0.6887	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:15:12 [INFO ]  Epoch:   57	Loss: 0.6560	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:15:14 [INFO ]  Epoch:   58	Loss: 0.6464	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:15:16 [INFO ]  Epoch:   59	Loss: 0.6859	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:15:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 10:15:25 [INFO ]  
2022-10-03 10:15:25 [INFO ]  Begin of epoch 60 :
2022-10-03 10:15:28 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:15:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:15:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:15:28 [INFO ]  	   step  1 (lr=0.320075)                   80.48%                   0.7179
2022-10-03 10:15:28 [INFO ]  
2022-10-03 10:15:28 [INFO ]  Epoch:   60	Loss: 0.6344	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:15:30 [INFO ]  Epoch:   61	Loss: 0.6057	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:15:32 [INFO ]  Epoch:   62	Loss: 0.6196	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:15:33 [INFO ]  Epoch:   63	Loss: 0.6419	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:15:35 [INFO ]  Epoch:   64	Loss: 0.6220	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:15:37 [INFO ]  Epoch:   65	Loss: 0.6717	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:15:39 [INFO ]  Epoch:   66	Loss: 0.7388	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:15:41 [INFO ]  Epoch:   67	Loss: 0.7101	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:15:43 [INFO ]  Epoch:   68	Loss: 0.6784	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:15:45 [INFO ]  Epoch:   69	Loss: 0.7047	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:15:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 10:15:53 [INFO ]  
2022-10-03 10:15:53 [INFO ]  Begin of epoch 70 :
2022-10-03 10:15:57 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:15:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:15:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:15:57 [INFO ]  	   step  1 (lr=0.328093)                   80.39%                   0.7181
2022-10-03 10:15:57 [INFO ]  
2022-10-03 10:15:57 [INFO ]  Epoch:   70	Loss: 0.5918	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:15:59 [INFO ]  Epoch:   71	Loss: 0.6269	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:16:01 [INFO ]  Epoch:   72	Loss: 0.6984	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:16:03 [INFO ]  Epoch:   73	Loss: 0.6520	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:16:04 [INFO ]  Epoch:   74	Loss: 0.6934	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:16:06 [INFO ]  Epoch:   75	Loss: 0.6456	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:16:08 [INFO ]  Epoch:   76	Loss: 0.6481	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:16:10 [INFO ]  Epoch:   77	Loss: 0.6868	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:16:12 [INFO ]  Epoch:   78	Loss: 0.6702	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:16:14 [INFO ]  Epoch:   79	Loss: 0.6024	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:16:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 10:16:23 [INFO ]  
2022-10-03 10:16:23 [INFO ]  Begin of epoch 80 :
2022-10-03 10:16:26 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:16:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:16:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:16:26 [INFO ]  	   step  1 (lr=0.334315)                   80.47%                   0.7077
2022-10-03 10:16:26 [INFO ]  
2022-10-03 10:16:26 [INFO ]  Epoch:   80	Loss: 0.6223	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 10:16:28 [INFO ]  Epoch:   81	Loss: 0.6629	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:16:29 [INFO ]  Epoch:   82	Loss: 0.6217	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:16:32 [INFO ]  Epoch:   83	Loss: 0.6785	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:16:33 [INFO ]  Epoch:   84	Loss: 0.6187	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:16:36 [INFO ]  Epoch:   85	Loss: 0.6630	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:16:38 [INFO ]  Epoch:   86	Loss: 0.7082	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:16:39 [INFO ]  Epoch:   87	Loss: 0.6380	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:16:42 [INFO ]  Epoch:   88	Loss: 0.6972	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:16:44 [INFO ]  Epoch:   89	Loss: 0.6621	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:16:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 10:16:52 [INFO ]  
2022-10-03 10:16:52 [INFO ]  Begin of epoch 90 :
2022-10-03 10:16:56 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:16:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:16:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:16:56 [INFO ]  	   step  1 (lr=0.342241)                   81.41%                   0.6867
2022-10-03 10:16:56 [INFO ]  
2022-10-03 10:16:56 [INFO ]  Epoch:   90	Loss: 0.6255	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 10:16:58 [INFO ]  Epoch:   91	Loss: 0.6087	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:17:00 [INFO ]  Epoch:   92	Loss: 0.6716	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:01 [INFO ]  Epoch:   93	Loss: 0.6297	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:03 [INFO ]  Epoch:   94	Loss: 0.6235	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:05 [INFO ]  Epoch:   95	Loss: 0.6776	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:17:07 [INFO ]  Epoch:   96	Loss: 0.6334	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:09 [INFO ]  Epoch:   97	Loss: 0.6435	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:17:11 [INFO ]  Epoch:   98	Loss: 0.6405	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:13 [INFO ]  Epoch:   99	Loss: 0.5532	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:17:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 10:17:22 [INFO ]  
2022-10-03 10:17:22 [INFO ]  Begin of epoch 100 :
2022-10-03 10:17:25 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:17:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:17:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:17:25 [INFO ]  	   step  1 (lr=0.344892)                   81.23%                   0.6855
2022-10-03 10:17:25 [INFO ]  
2022-10-03 10:17:25 [INFO ]  Epoch:  100	Loss: 0.6717	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:27 [INFO ]  Epoch:  101	Loss: 0.5554	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:29 [INFO ]  Epoch:  102	Loss: 0.6146	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:30 [INFO ]  Epoch:  103	Loss: 0.6466	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:32 [INFO ]  Epoch:  104	Loss: 0.6502	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:17:34 [INFO ]  Epoch:  105	Loss: 0.6409	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:17:36 [INFO ]  Epoch:  106	Loss: 0.5831	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:38 [INFO ]  Epoch:  107	Loss: 0.5989	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:17:40 [INFO ]  Epoch:  108	Loss: 0.6232	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:42 [INFO ]  Epoch:  109	Loss: 0.5915	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:17:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 10:17:51 [INFO ]  
2022-10-03 10:17:51 [INFO ]  Begin of epoch 110 :
2022-10-03 10:17:55 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:17:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:17:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:17:55 [INFO ]  	   step  1 (lr=0.347332)                   81.43%                   0.6867
2022-10-03 10:17:55 [INFO ]  
2022-10-03 10:17:55 [INFO ]  Epoch:  110	Loss: 0.6634	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:17:56 [INFO ]  Epoch:  111	Loss: 0.6310	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:17:58 [INFO ]  Epoch:  112	Loss: 0.6343	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:18:00 [INFO ]  Epoch:  113	Loss: 0.5617	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:18:02 [INFO ]  Epoch:  114	Loss: 0.6201	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:18:04 [INFO ]  Epoch:  115	Loss: 0.6416	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:18:06 [INFO ]  Epoch:  116	Loss: 0.6106	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:18:08 [INFO ]  Epoch:  117	Loss: 0.6130	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:18:10 [INFO ]  Epoch:  118	Loss: 0.6514	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:18:12 [INFO ]  Epoch:  119	Loss: 0.6349	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:18:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 10:18:21 [INFO ]  
2022-10-03 10:18:21 [INFO ]  Begin of epoch 120 :
2022-10-03 10:18:25 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:18:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:18:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:18:25 [INFO ]  	   step  1 (lr=0.349397)                   81.35%                   0.6814
2022-10-03 10:18:25 [INFO ]  
2022-10-03 10:18:25 [INFO ]  Epoch:  120	Loss: 0.6085	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 10:18:27 [INFO ]  Epoch:  121	Loss: 0.5938	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:18:29 [INFO ]  Epoch:  122	Loss: 0.6259	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:18:31 [INFO ]  Epoch:  123	Loss: 0.6888	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:18:32 [INFO ]  Epoch:  124	Loss: 0.5519	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:18:34 [INFO ]  Epoch:  125	Loss: 0.5920	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:18:36 [INFO ]  Epoch:  126	Loss: 0.5599	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:18:38 [INFO ]  Epoch:  127	Loss: 0.6634	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:18:40 [INFO ]  Epoch:  128	Loss: 0.5431	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:18:42 [INFO ]  Epoch:  129	Loss: 0.5796	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:18:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 10:18:50 [INFO ]  
2022-10-03 10:18:50 [INFO ]  Begin of epoch 130 :
2022-10-03 10:18:54 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:18:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:18:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:18:54 [INFO ]  	   step  1 (lr=0.350664)                   81.32%                   0.6940
2022-10-03 10:18:54 [INFO ]  
2022-10-03 10:18:54 [INFO ]  Epoch:  130	Loss: 0.5716	Data Time: 0.26s	Train Time: 0.00s
2022-10-03 10:18:55 [INFO ]  Epoch:  131	Loss: 0.5571	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:18:57 [INFO ]  Epoch:  132	Loss: 0.6658	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:18:59 [INFO ]  Epoch:  133	Loss: 0.6733	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:19:01 [INFO ]  Epoch:  134	Loss: 0.7577	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:03 [INFO ]  Epoch:  135	Loss: 0.6757	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:19:05 [INFO ]  Epoch:  136	Loss: 0.6460	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:19:07 [INFO ]  Epoch:  137	Loss: 0.5771	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:19:09 [INFO ]  Epoch:  138	Loss: 0.6513	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:11 [INFO ]  Epoch:  139	Loss: 0.5951	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 10:19:20 [INFO ]  
2022-10-03 10:19:20 [INFO ]  Begin of epoch 140 :
2022-10-03 10:19:23 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:19:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:19:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:19:23 [INFO ]  	   step  1 (lr=0.350964)                   81.49%                   0.6863
2022-10-03 10:19:23 [INFO ]  
2022-10-03 10:19:23 [INFO ]  Epoch:  140	Loss: 0.6647	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 10:19:25 [INFO ]  Epoch:  141	Loss: 0.6481	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:27 [INFO ]  Epoch:  142	Loss: 0.6120	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:29 [INFO ]  Epoch:  143	Loss: 0.6623	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:19:31 [INFO ]  Epoch:  144	Loss: 0.6192	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:19:32 [INFO ]  Epoch:  145	Loss: 0.6519	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:34 [INFO ]  Epoch:  146	Loss: 0.5763	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:36 [INFO ]  Epoch:  147	Loss: 0.5982	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:19:38 [INFO ]  Epoch:  148	Loss: 0.5685	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 10:19:40 [INFO ]  Epoch:  149	Loss: 0.6222	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:19:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 10:19:49 [INFO ]  
2022-10-03 10:19:49 [INFO ]  Begin of epoch 150 :
2022-10-03 10:19:52 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:19:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:19:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:19:52 [INFO ]  	   step  1 (lr=0.353020)                   81.12%                   0.6882
2022-10-03 10:19:52 [INFO ]  
2022-10-03 10:19:52 [INFO ]  Epoch:  150	Loss: 0.6130	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:19:54 [INFO ]  Epoch:  151	Loss: 0.5915	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:19:56 [INFO ]  Epoch:  152	Loss: 0.6079	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:19:58 [INFO ]  Epoch:  153	Loss: 0.6087	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:20:00 [INFO ]  Epoch:  154	Loss: 0.6211	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:20:01 [INFO ]  Epoch:  155	Loss: 0.5604	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:20:03 [INFO ]  Epoch:  156	Loss: 0.5810	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:20:05 [INFO ]  Epoch:  157	Loss: 0.5631	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:20:07 [INFO ]  Epoch:  158	Loss: 0.5892	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 10:20:09 [INFO ]  Epoch:  159	Loss: 0.6074	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:20:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 10:20:18 [INFO ]  
2022-10-03 10:20:18 [INFO ]  Begin of epoch 160 :
2022-10-03 10:20:21 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:20:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:20:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:20:21 [INFO ]  	   step  1 (lr=0.353165)                   81.47%                   0.6850
2022-10-03 10:20:21 [INFO ]  
2022-10-03 10:20:21 [INFO ]  Epoch:  160	Loss: 0.6584	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:20:23 [INFO ]  Epoch:  161	Loss: 0.6712	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:20:25 [INFO ]  Epoch:  162	Loss: 0.5802	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:20:27 [INFO ]  Epoch:  163	Loss: 0.5971	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:20:29 [INFO ]  Epoch:  164	Loss: 0.7380	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:20:31 [INFO ]  Epoch:  165	Loss: 0.5526	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:20:33 [INFO ]  Epoch:  166	Loss: 0.6370	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:20:34 [INFO ]  Epoch:  167	Loss: 0.6094	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:20:36 [INFO ]  Epoch:  168	Loss: 0.6913	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:20:38 [INFO ]  Epoch:  169	Loss: 0.6514	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:20:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 10:20:47 [INFO ]  
2022-10-03 10:20:47 [INFO ]  Begin of epoch 170 :
2022-10-03 10:20:51 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:20:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:20:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:20:51 [INFO ]  	   step  1 (lr=0.353594)                   81.33%                   0.6827
2022-10-03 10:20:51 [INFO ]  
2022-10-03 10:20:51 [INFO ]  Epoch:  170	Loss: 0.6241	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:20:52 [INFO ]  Epoch:  171	Loss: 0.6820	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:20:55 [INFO ]  Epoch:  172	Loss: 0.5985	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:20:57 [INFO ]  Epoch:  173	Loss: 0.6467	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:20:59 [INFO ]  Epoch:  174	Loss: 0.6066	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:21:00 [INFO ]  Epoch:  175	Loss: 0.5704	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:21:02 [INFO ]  Epoch:  176	Loss: 0.7257	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:21:04 [INFO ]  Epoch:  177	Loss: 0.6095	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:21:06 [INFO ]  Epoch:  178	Loss: 0.6441	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:21:08 [INFO ]  Epoch:  179	Loss: 0.6616	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 10:21:17 [INFO ]  
2022-10-03 10:21:17 [INFO ]  Begin of epoch 180 :
2022-10-03 10:21:20 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:21:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:21:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:21:20 [INFO ]  	   step  1 (lr=0.354234)                   81.08%                   0.6985
2022-10-03 10:21:20 [INFO ]  
2022-10-03 10:21:20 [INFO ]  Epoch:  180	Loss: 0.6219	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:22 [INFO ]  Epoch:  181	Loss: 0.7432	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:21:24 [INFO ]  Epoch:  182	Loss: 0.6430	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:21:26 [INFO ]  Epoch:  183	Loss: 0.5732	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:21:27 [INFO ]  Epoch:  184	Loss: 0.5833	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:21:29 [INFO ]  Epoch:  185	Loss: 0.6382	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:21:31 [INFO ]  Epoch:  186	Loss: 0.6368	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:33 [INFO ]  Epoch:  187	Loss: 0.6486	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:35 [INFO ]  Epoch:  188	Loss: 0.5948	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:37 [INFO ]  Epoch:  189	Loss: 0.5815	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:21:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 10:21:46 [INFO ]  
2022-10-03 10:21:46 [INFO ]  Begin of epoch 190 :
2022-10-03 10:21:49 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:21:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:21:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:21:49 [INFO ]  	   step  1 (lr=0.354530)                   81.53%                   0.6788
2022-10-03 10:21:49 [INFO ]  
2022-10-03 10:21:49 [INFO ]  Epoch:  190	Loss: 0.6220	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:21:51 [INFO ]  Epoch:  191	Loss: 0.6496	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:21:53 [INFO ]  Epoch:  192	Loss: 0.6231	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:21:55 [INFO ]  Epoch:  193	Loss: 0.6453	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:21:57 [INFO ]  Epoch:  194	Loss: 0.6587	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:21:59 [INFO ]  Epoch:  195	Loss: 0.5282	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:22:01 [INFO ]  Epoch:  196	Loss: 0.6283	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:22:02 [INFO ]  Epoch:  197	Loss: 0.6035	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:22:04 [INFO ]  Epoch:  198	Loss: 0.6064	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:22:06 [INFO ]  Epoch:  199	Loss: 0.6306	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:22:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 10:22:14 [INFO ]  
2022-10-03 10:22:14 [INFO ]  Final evaluation for SVHN :
2022-10-03 10:22:18 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:22:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:22:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:22:18 [INFO ]  	   step  1 (lr=0.354676)                   81.26%                   0.6886
2022-10-03 10:22:18 [INFO ]  
2022-10-03 10:22:18 [INFO ]  
2022-10-03 10:22:18 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 10:22:21 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:22:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:22:21 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 10:22:21 [INFO ]  	   step  1 (lr=0.354676)                   16.14%                   5.6350
2022-10-03 10:22:21 [INFO ]  
2022-10-03 10:29:11 [INFO ]  ======================================== 2022-10-03 10:29:11 ========================================
2022-10-03 10:29:11 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 10:29:11 [INFO ]  Options: 
2022-10-03 10:29:11 [INFO ]  	base_dir: null
2022-10-03 10:29:11 [INFO ]  	batch_size: 1024
2022-10-03 10:29:11 [INFO ]  	checkpoint_interval: 10
2022-10-03 10:29:11 [INFO ]  	dataset: SVHN
2022-10-03 10:29:11 [INFO ]  	dataset_labels:
2022-10-03 10:29:11 [INFO ]  	- 0
2022-10-03 10:29:11 [INFO ]  	- 1
2022-10-03 10:29:11 [INFO ]  	- 2
2022-10-03 10:29:11 [INFO ]  	- 3
2022-10-03 10:29:11 [INFO ]  	- 4
2022-10-03 10:29:11 [INFO ]  	- 5
2022-10-03 10:29:11 [INFO ]  	- 6
2022-10-03 10:29:11 [INFO ]  	- 7
2022-10-03 10:29:11 [INFO ]  	- 8
2022-10-03 10:29:11 [INFO ]  	- 9
2022-10-03 10:29:11 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 10:29:11 [INFO ]  	- !!python/tuple
2022-10-03 10:29:11 [INFO ]  	    - 0.4379104971885681
2022-10-03 10:29:11 [INFO ]  	    - 0.44398033618927
2022-10-03 10:29:11 [INFO ]  	    - 0.4729299545288086
2022-10-03 10:29:11 [INFO ]  	- !!python/tuple
2022-10-03 10:29:11 [INFO ]  	    - 0.19803012907505035
2022-10-03 10:29:11 [INFO ]  	    - 0.2010156363248825
2022-10-03 10:29:11 [INFO ]  	    - 0.19703614711761475
2022-10-03 10:29:11 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 10:29:11 [INFO ]  	decay_epochs: 50
2022-10-03 10:29:11 [INFO ]  	decay_factor: 0.1
2022-10-03 10:29:11 [INFO ]  	device_id: 0
2022-10-03 10:29:11 [INFO ]  	distill_epochs: 1
2022-10-03 10:29:11 [INFO ]  	distill_lr: 0.02
2022-10-03 10:29:11 [INFO ]  	distill_steps: 1
2022-10-03 10:29:11 [INFO ]  	epochs: 200
2022-10-03 10:29:11 [INFO ]  	expand_cls: false
2022-10-03 10:29:11 [INFO ]  	forgetting_dataset: null
2022-10-03 10:29:11 [INFO ]  	init: xavier
2022-10-03 10:29:11 [INFO ]  	init_param: 1.0
2022-10-03 10:29:11 [INFO ]  	input_size: 32
2022-10-03 10:29:11 [INFO ]  	ipc: 10
2022-10-03 10:29:11 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 10:29:11 [INFO ]  	log_interval: 100
2022-10-03 10:29:11 [INFO ]  	log_level: INFO
2022-10-03 10:29:11 [INFO ]  	lr: 0.01
2022-10-03 10:29:11 [INFO ]  	mode: distill_adapt
2022-10-03 10:29:11 [INFO ]  	nc: 3
2022-10-03 10:29:11 [INFO ]  	num_classes: 10
2022-10-03 10:29:11 [INFO ]  	num_workers: 8
2022-10-03 10:29:11 [INFO ]  	phase: train
2022-10-03 10:29:11 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 10:29:11 [INFO ]  	start_time: '2022-10-03 10:29:11'
2022-10-03 10:29:11 [INFO ]  	test_batch_size: 1024
2022-10-03 10:29:11 [INFO ]  	
2022-10-03 10:29:13 [INFO ]  train dataset size:	73257
2022-10-03 10:29:13 [INFO ]  test dataset size: 	26032
2022-10-03 10:29:13 [INFO ]  datasets built!
2022-10-03 10:29:13 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 10:29:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 10:29:22 [INFO ]  
2022-10-03 10:29:22 [INFO ]  Begin of epoch 0 :
2022-10-03 10:29:25 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:29:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:29:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:29:25 [INFO ]  	   step  1 (lr=0.020000)                    6.82%                   9.3457
2022-10-03 10:29:25 [INFO ]  
2022-10-03 10:29:25 [INFO ]  Epoch:    0	Loss: 9.6753	Data Time: 0.37s	Train Time: 0.04s
2022-10-03 10:29:27 [INFO ]  Epoch:    1	Loss: 3.2517	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:29:29 [INFO ]  Epoch:    2	Loss: 2.5196	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:29:31 [INFO ]  Epoch:    3	Loss: 2.3025	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:29:33 [INFO ]  Epoch:    4	Loss: 2.1954	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:29:35 [INFO ]  Epoch:    5	Loss: 2.1951	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:29:37 [INFO ]  Epoch:    6	Loss: 2.1497	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:29:38 [INFO ]  Epoch:    7	Loss: 2.1550	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:29:40 [INFO ]  Epoch:    8	Loss: 2.0718	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:29:42 [INFO ]  Epoch:    9	Loss: 2.0074	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:29:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 10:29:51 [INFO ]  
2022-10-03 10:29:51 [INFO ]  Begin of epoch 10 :
2022-10-03 10:29:54 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:29:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:29:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:29:54 [INFO ]  	   step  1 (lr=0.064863)                   38.25%                   1.9290
2022-10-03 10:29:54 [INFO ]  
2022-10-03 10:29:54 [INFO ]  Epoch:   10	Loss: 1.9328	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 10:29:55 [INFO ]  Epoch:   11	Loss: 1.8861	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:29:57 [INFO ]  Epoch:   12	Loss: 1.6919	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:29:59 [INFO ]  Epoch:   13	Loss: 1.6279	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:30:01 [INFO ]  Epoch:   14	Loss: 1.4158	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:30:03 [INFO ]  Epoch:   15	Loss: 1.4089	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:30:05 [INFO ]  Epoch:   16	Loss: 1.3568	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:30:07 [INFO ]  Epoch:   17	Loss: 1.3344	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:30:09 [INFO ]  Epoch:   18	Loss: 1.2491	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:30:11 [INFO ]  Epoch:   19	Loss: 1.2294	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:30:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 10:30:20 [INFO ]  
2022-10-03 10:30:20 [INFO ]  Begin of epoch 20 :
2022-10-03 10:30:23 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:30:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:30:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:30:23 [INFO ]  	   step  1 (lr=0.209885)                   66.48%                   1.1392
2022-10-03 10:30:23 [INFO ]  
2022-10-03 10:30:23 [INFO ]  Epoch:   20	Loss: 1.0819	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:30:25 [INFO ]  Epoch:   21	Loss: 1.1200	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:30:27 [INFO ]  Epoch:   22	Loss: 1.1009	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:30:29 [INFO ]  Epoch:   23	Loss: 1.0332	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:30:30 [INFO ]  Epoch:   24	Loss: 1.4480	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:30:32 [INFO ]  Epoch:   25	Loss: 0.9491	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:30:34 [INFO ]  Epoch:   26	Loss: 0.9898	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:30:36 [INFO ]  Epoch:   27	Loss: 0.9590	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:30:38 [INFO ]  Epoch:   28	Loss: 0.9579	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:30:40 [INFO ]  Epoch:   29	Loss: 0.9788	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:30:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 10:30:49 [INFO ]  
2022-10-03 10:30:49 [INFO ]  Begin of epoch 30 :
2022-10-03 10:30:52 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:30:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:30:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:30:52 [INFO ]  	   step  1 (lr=0.286847)                   72.23%                   1.0056
2022-10-03 10:30:52 [INFO ]  
2022-10-03 10:30:52 [INFO ]  Epoch:   30	Loss: 0.8556	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 10:30:54 [INFO ]  Epoch:   31	Loss: 0.8680	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:30:56 [INFO ]  Epoch:   32	Loss: 0.8927	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:30:57 [INFO ]  Epoch:   33	Loss: 0.9176	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:30:59 [INFO ]  Epoch:   34	Loss: 0.8144	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:31:01 [INFO ]  Epoch:   35	Loss: 0.7887	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:31:03 [INFO ]  Epoch:   36	Loss: 1.1335	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:31:05 [INFO ]  Epoch:   37	Loss: 0.8227	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:07 [INFO ]  Epoch:   38	Loss: 0.8767	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:09 [INFO ]  Epoch:   39	Loss: 0.8126	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 10:31:17 [INFO ]  
2022-10-03 10:31:17 [INFO ]  Begin of epoch 40 :
2022-10-03 10:31:21 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:31:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:31:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:31:21 [INFO ]  	   step  1 (lr=0.315903)                   76.51%                   0.8627
2022-10-03 10:31:21 [INFO ]  
2022-10-03 10:31:21 [INFO ]  Epoch:   40	Loss: 0.7866	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:22 [INFO ]  Epoch:   41	Loss: 0.8214	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:31:24 [INFO ]  Epoch:   42	Loss: 1.0019	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:31:26 [INFO ]  Epoch:   43	Loss: 0.7396	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:31:28 [INFO ]  Epoch:   44	Loss: 0.8392	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:30 [INFO ]  Epoch:   45	Loss: 0.7971	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:31:32 [INFO ]  Epoch:   46	Loss: 0.7250	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:31:34 [INFO ]  Epoch:   47	Loss: 0.8424	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:35 [INFO ]  Epoch:   48	Loss: 0.7993	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:31:37 [INFO ]  Epoch:   49	Loss: 0.7117	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:31:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 10:31:46 [INFO ]  
2022-10-03 10:31:46 [INFO ]  Begin of epoch 50 :
2022-10-03 10:31:50 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:31:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:31:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:31:50 [INFO ]  	   step  1 (lr=0.342636)                   79.49%                   0.7550
2022-10-03 10:31:50 [INFO ]  
2022-10-03 10:31:50 [INFO ]  Epoch:   50	Loss: 0.6527	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:31:51 [INFO ]  Epoch:   51	Loss: 0.7185	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:31:53 [INFO ]  Epoch:   52	Loss: 0.7703	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:31:55 [INFO ]  Epoch:   53	Loss: 0.7255	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:31:57 [INFO ]  Epoch:   54	Loss: 0.6887	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:31:59 [INFO ]  Epoch:   55	Loss: 0.7221	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:00 [INFO ]  Epoch:   56	Loss: 0.6423	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:32:02 [INFO ]  Epoch:   57	Loss: 0.6533	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:32:04 [INFO ]  Epoch:   58	Loss: 0.7449	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 10:32:06 [INFO ]  Epoch:   59	Loss: 0.6550	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:32:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 10:32:15 [INFO ]  
2022-10-03 10:32:15 [INFO ]  Begin of epoch 60 :
2022-10-03 10:32:18 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:32:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:32:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:32:18 [INFO ]  	   step  1 (lr=0.345796)                   80.47%                   0.7249
2022-10-03 10:32:18 [INFO ]  
2022-10-03 10:32:18 [INFO ]  Epoch:   60	Loss: 0.7029	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 10:32:20 [INFO ]  Epoch:   61	Loss: 0.6990	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:32:22 [INFO ]  Epoch:   62	Loss: 0.7076	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:24 [INFO ]  Epoch:   63	Loss: 0.6334	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:26 [INFO ]  Epoch:   64	Loss: 0.6215	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:28 [INFO ]  Epoch:   65	Loss: 0.6573	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:32:29 [INFO ]  Epoch:   66	Loss: 0.7549	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:32:31 [INFO ]  Epoch:   67	Loss: 0.6901	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:33 [INFO ]  Epoch:   68	Loss: 0.5860	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:35 [INFO ]  Epoch:   69	Loss: 0.6038	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:32:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 10:32:44 [INFO ]  
2022-10-03 10:32:44 [INFO ]  Begin of epoch 70 :
2022-10-03 10:32:47 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:32:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:32:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:32:47 [INFO ]  	   step  1 (lr=0.358612)                   79.98%                   0.7345
2022-10-03 10:32:47 [INFO ]  
2022-10-03 10:32:47 [INFO ]  Epoch:   70	Loss: 0.6796	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:32:49 [INFO ]  Epoch:   71	Loss: 0.6816	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:32:51 [INFO ]  Epoch:   72	Loss: 0.6273	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:32:53 [INFO ]  Epoch:   73	Loss: 0.6774	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:55 [INFO ]  Epoch:   74	Loss: 0.6654	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:32:57 [INFO ]  Epoch:   75	Loss: 0.7028	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:32:59 [INFO ]  Epoch:   76	Loss: 0.6647	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:00 [INFO ]  Epoch:   77	Loss: 0.5531	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:02 [INFO ]  Epoch:   78	Loss: 0.6750	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:04 [INFO ]  Epoch:   79	Loss: 0.6966	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 10:33:13 [INFO ]  
2022-10-03 10:33:13 [INFO ]  Begin of epoch 80 :
2022-10-03 10:33:16 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:33:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:33:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:33:16 [INFO ]  	   step  1 (lr=0.365036)                   79.98%                   0.7366
2022-10-03 10:33:16 [INFO ]  
2022-10-03 10:33:16 [INFO ]  Epoch:   80	Loss: 0.6736	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:18 [INFO ]  Epoch:   81	Loss: 0.6631	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:33:20 [INFO ]  Epoch:   82	Loss: 0.6507	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:22 [INFO ]  Epoch:   83	Loss: 0.7455	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:33:24 [INFO ]  Epoch:   84	Loss: 0.7433	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:33:26 [INFO ]  Epoch:   85	Loss: 0.6829	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:28 [INFO ]  Epoch:   86	Loss: 0.5908	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:29 [INFO ]  Epoch:   87	Loss: 0.7134	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:33:31 [INFO ]  Epoch:   88	Loss: 0.6213	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:33 [INFO ]  Epoch:   89	Loss: 0.6779	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 10:33:42 [INFO ]  
2022-10-03 10:33:42 [INFO ]  Begin of epoch 90 :
2022-10-03 10:33:45 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:33:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:33:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:33:45 [INFO ]  	   step  1 (lr=0.371390)                   80.94%                   0.7012
2022-10-03 10:33:45 [INFO ]  
2022-10-03 10:33:45 [INFO ]  Epoch:   90	Loss: 0.5885	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:33:47 [INFO ]  Epoch:   91	Loss: 0.6364	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:33:49 [INFO ]  Epoch:   92	Loss: 0.7147	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:33:51 [INFO ]  Epoch:   93	Loss: 0.7025	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:33:53 [INFO ]  Epoch:   94	Loss: 0.7146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:55 [INFO ]  Epoch:   95	Loss: 0.6102	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:33:56 [INFO ]  Epoch:   96	Loss: 0.6953	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:33:58 [INFO ]  Epoch:   97	Loss: 0.7094	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 10:34:00 [INFO ]  Epoch:   98	Loss: 0.6555	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:02 [INFO ]  Epoch:   99	Loss: 0.6515	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 10:34:11 [INFO ]  
2022-10-03 10:34:11 [INFO ]  Begin of epoch 100 :
2022-10-03 10:34:14 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:34:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:34:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:34:14 [INFO ]  	   step  1 (lr=0.376384)                   81.18%                   0.6992
2022-10-03 10:34:14 [INFO ]  
2022-10-03 10:34:14 [INFO ]  Epoch:  100	Loss: 0.6565	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:16 [INFO ]  Epoch:  101	Loss: 0.7319	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:18 [INFO ]  Epoch:  102	Loss: 0.6539	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:20 [INFO ]  Epoch:  103	Loss: 0.6734	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:22 [INFO ]  Epoch:  104	Loss: 0.6699	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:34:24 [INFO ]  Epoch:  105	Loss: 0.6446	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:34:26 [INFO ]  Epoch:  106	Loss: 0.7020	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:34:28 [INFO ]  Epoch:  107	Loss: 0.6402	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:30 [INFO ]  Epoch:  108	Loss: 0.7044	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:34:32 [INFO ]  Epoch:  109	Loss: 0.6071	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 10:34:40 [INFO ]  
2022-10-03 10:34:40 [INFO ]  Begin of epoch 110 :
2022-10-03 10:34:44 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:34:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:34:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:34:44 [INFO ]  	   step  1 (lr=0.378302)                   81.42%                   0.6861
2022-10-03 10:34:44 [INFO ]  
2022-10-03 10:34:44 [INFO ]  Epoch:  110	Loss: 0.6401	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:46 [INFO ]  Epoch:  111	Loss: 0.6573	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:47 [INFO ]  Epoch:  112	Loss: 0.6373	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:34:49 [INFO ]  Epoch:  113	Loss: 0.6579	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 10:34:51 [INFO ]  Epoch:  114	Loss: 0.6433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:53 [INFO ]  Epoch:  115	Loss: 0.6011	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:55 [INFO ]  Epoch:  116	Loss: 0.6368	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:34:57 [INFO ]  Epoch:  117	Loss: 0.6873	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:34:59 [INFO ]  Epoch:  118	Loss: 0.6915	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:35:01 [INFO ]  Epoch:  119	Loss: 0.6573	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:35:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 10:35:09 [INFO ]  
2022-10-03 10:35:09 [INFO ]  Begin of epoch 120 :
2022-10-03 10:35:13 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:35:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:35:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:35:13 [INFO ]  	   step  1 (lr=0.380529)                   80.58%                   0.7217
2022-10-03 10:35:13 [INFO ]  
2022-10-03 10:35:13 [INFO ]  Epoch:  120	Loss: 0.5525	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 10:35:14 [INFO ]  Epoch:  121	Loss: 0.6165	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:35:16 [INFO ]  Epoch:  122	Loss: 0.6028	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:35:18 [INFO ]  Epoch:  123	Loss: 0.6117	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:35:20 [INFO ]  Epoch:  124	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:35:22 [INFO ]  Epoch:  125	Loss: 0.6308	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:35:23 [INFO ]  Epoch:  126	Loss: 0.6569	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:35:25 [INFO ]  Epoch:  127	Loss: 0.6958	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:35:27 [INFO ]  Epoch:  128	Loss: 0.7211	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:35:29 [INFO ]  Epoch:  129	Loss: 0.6591	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:35:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 10:35:38 [INFO ]  
2022-10-03 10:35:38 [INFO ]  Begin of epoch 130 :
2022-10-03 10:35:41 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:35:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:35:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:35:41 [INFO ]  	   step  1 (lr=0.380943)                   80.93%                   0.7116
2022-10-03 10:35:41 [INFO ]  
2022-10-03 10:35:41 [INFO ]  Epoch:  130	Loss: 0.5921	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:35:43 [INFO ]  Epoch:  131	Loss: 0.6192	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:35:45 [INFO ]  Epoch:  132	Loss: 0.5966	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:35:47 [INFO ]  Epoch:  133	Loss: 0.6885	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:35:49 [INFO ]  Epoch:  134	Loss: 0.6762	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:35:51 [INFO ]  Epoch:  135	Loss: 0.6682	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:35:53 [INFO ]  Epoch:  136	Loss: 0.6576	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:35:55 [INFO ]  Epoch:  137	Loss: 0.6765	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:35:57 [INFO ]  Epoch:  138	Loss: 0.7439	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:35:58 [INFO ]  Epoch:  139	Loss: 0.6093	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:36:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 10:36:07 [INFO ]  
2022-10-03 10:36:07 [INFO ]  Begin of epoch 140 :
2022-10-03 10:36:11 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:36:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:36:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:36:11 [INFO ]  	   step  1 (lr=0.377621)                   80.98%                   0.7152
2022-10-03 10:36:11 [INFO ]  
2022-10-03 10:36:11 [INFO ]  Epoch:  140	Loss: 0.5810	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 10:36:13 [INFO ]  Epoch:  141	Loss: 0.6183	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 10:36:15 [INFO ]  Epoch:  142	Loss: 0.6805	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:17 [INFO ]  Epoch:  143	Loss: 0.6238	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:19 [INFO ]  Epoch:  144	Loss: 0.6180	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:36:21 [INFO ]  Epoch:  145	Loss: 0.6401	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:23 [INFO ]  Epoch:  146	Loss: 0.6457	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:36:25 [INFO ]  Epoch:  147	Loss: 0.6527	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:36:27 [INFO ]  Epoch:  148	Loss: 0.6902	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:36:29 [INFO ]  Epoch:  149	Loss: 0.7645	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:36:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 10:36:38 [INFO ]  
2022-10-03 10:36:38 [INFO ]  Begin of epoch 150 :
2022-10-03 10:36:41 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:36:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:36:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:36:41 [INFO ]  	   step  1 (lr=0.374602)                   80.85%                   0.7151
2022-10-03 10:36:41 [INFO ]  
2022-10-03 10:36:41 [INFO ]  Epoch:  150	Loss: 0.6695	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 10:36:43 [INFO ]  Epoch:  151	Loss: 0.7273	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:45 [INFO ]  Epoch:  152	Loss: 0.7077	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:36:47 [INFO ]  Epoch:  153	Loss: 0.6364	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:36:49 [INFO ]  Epoch:  154	Loss: 0.5792	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:51 [INFO ]  Epoch:  155	Loss: 0.6188	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:36:52 [INFO ]  Epoch:  156	Loss: 0.6979	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:36:54 [INFO ]  Epoch:  157	Loss: 0.6299	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 10:36:56 [INFO ]  Epoch:  158	Loss: 0.5435	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:36:58 [INFO ]  Epoch:  159	Loss: 0.6453	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 10:37:07 [INFO ]  
2022-10-03 10:37:07 [INFO ]  Begin of epoch 160 :
2022-10-03 10:37:10 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:37:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:37:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:37:10 [INFO ]  	   step  1 (lr=0.374940)                   80.32%                   0.7286
2022-10-03 10:37:10 [INFO ]  
2022-10-03 10:37:10 [INFO ]  Epoch:  160	Loss: 0.6066	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 10:37:12 [INFO ]  Epoch:  161	Loss: 0.6258	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:14 [INFO ]  Epoch:  162	Loss: 0.6012	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:16 [INFO ]  Epoch:  163	Loss: 0.5991	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:37:18 [INFO ]  Epoch:  164	Loss: 0.6926	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:37:20 [INFO ]  Epoch:  165	Loss: 0.6805	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:37:22 [INFO ]  Epoch:  166	Loss: 0.6637	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:24 [INFO ]  Epoch:  167	Loss: 0.6190	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:37:26 [INFO ]  Epoch:  168	Loss: 0.6921	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:28 [INFO ]  Epoch:  169	Loss: 0.6825	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 10:37:36 [INFO ]  
2022-10-03 10:37:36 [INFO ]  Begin of epoch 170 :
2022-10-03 10:37:40 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:37:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:37:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:37:40 [INFO ]  	   step  1 (lr=0.375979)                   81.35%                   0.6857
2022-10-03 10:37:40 [INFO ]  
2022-10-03 10:37:40 [INFO ]  Epoch:  170	Loss: 0.6576	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 10:37:42 [INFO ]  Epoch:  171	Loss: 0.7142	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:44 [INFO ]  Epoch:  172	Loss: 0.5881	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:46 [INFO ]  Epoch:  173	Loss: 0.6870	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:48 [INFO ]  Epoch:  174	Loss: 0.6368	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:37:50 [INFO ]  Epoch:  175	Loss: 0.5494	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:52 [INFO ]  Epoch:  176	Loss: 0.6333	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:37:54 [INFO ]  Epoch:  177	Loss: 0.6284	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:37:56 [INFO ]  Epoch:  178	Loss: 0.6198	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:37:58 [INFO ]  Epoch:  179	Loss: 0.7345	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:38:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 10:38:07 [INFO ]  
2022-10-03 10:38:07 [INFO ]  Begin of epoch 180 :
2022-10-03 10:38:10 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:38:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:38:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:38:10 [INFO ]  	   step  1 (lr=0.376275)                   80.89%                   0.7155
2022-10-03 10:38:10 [INFO ]  
2022-10-03 10:38:10 [INFO ]  Epoch:  180	Loss: 0.7147	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:38:12 [INFO ]  Epoch:  181	Loss: 0.6539	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:38:14 [INFO ]  Epoch:  182	Loss: 0.6377	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:38:16 [INFO ]  Epoch:  183	Loss: 0.6371	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:38:18 [INFO ]  Epoch:  184	Loss: 0.6048	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:38:20 [INFO ]  Epoch:  185	Loss: 0.6945	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:38:21 [INFO ]  Epoch:  186	Loss: 0.5907	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:38:23 [INFO ]  Epoch:  187	Loss: 0.6293	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:38:25 [INFO ]  Epoch:  188	Loss: 0.6023	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:38:27 [INFO ]  Epoch:  189	Loss: 0.6283	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 10:38:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 10:38:36 [INFO ]  
2022-10-03 10:38:36 [INFO ]  Begin of epoch 190 :
2022-10-03 10:38:39 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:38:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:38:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:38:39 [INFO ]  	   step  1 (lr=0.376984)                   81.54%                   0.6896
2022-10-03 10:38:39 [INFO ]  
2022-10-03 10:38:39 [INFO ]  Epoch:  190	Loss: 0.5770	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:38:41 [INFO ]  Epoch:  191	Loss: 0.6232	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:38:43 [INFO ]  Epoch:  192	Loss: 0.6330	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:38:45 [INFO ]  Epoch:  193	Loss: 0.5916	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 10:38:47 [INFO ]  Epoch:  194	Loss: 0.6622	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 10:38:49 [INFO ]  Epoch:  195	Loss: 0.5717	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 10:38:51 [INFO ]  Epoch:  196	Loss: 0.6214	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 10:38:53 [INFO ]  Epoch:  197	Loss: 0.6165	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 10:38:55 [INFO ]  Epoch:  198	Loss: 0.6024	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:38:56 [INFO ]  Epoch:  199	Loss: 0.5984	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 10:39:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 10:39:05 [INFO ]  
2022-10-03 10:39:05 [INFO ]  Final evaluation for SVHN :
2022-10-03 10:39:08 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:39:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:39:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 10:39:08 [INFO ]  	   step  1 (lr=0.378167)                   81.27%                   0.6977
2022-10-03 10:39:08 [INFO ]  
2022-10-03 10:39:08 [INFO ]  
2022-10-03 10:39:08 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 10:39:11 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 10:39:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 10:39:11 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 10:39:11 [INFO ]  	   step  1 (lr=0.378167)                   17.03%                   5.4813
2022-10-03 10:39:11 [INFO ]  
2022-10-03 12:49:21 [INFO ]  ======================================== 2022-10-03 12:49:21 ========================================
2022-10-03 12:49:21 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 12:49:21 [INFO ]  Options: 
2022-10-03 12:49:21 [INFO ]  	base_dir: null
2022-10-03 12:49:21 [INFO ]  	batch_size: 1024
2022-10-03 12:49:21 [INFO ]  	checkpoint_interval: 10
2022-10-03 12:49:21 [INFO ]  	dataset: SVHN
2022-10-03 12:49:21 [INFO ]  	dataset_labels:
2022-10-03 12:49:21 [INFO ]  	- 0
2022-10-03 12:49:21 [INFO ]  	- 1
2022-10-03 12:49:21 [INFO ]  	- 2
2022-10-03 12:49:21 [INFO ]  	- 3
2022-10-03 12:49:21 [INFO ]  	- 4
2022-10-03 12:49:21 [INFO ]  	- 5
2022-10-03 12:49:21 [INFO ]  	- 6
2022-10-03 12:49:21 [INFO ]  	- 7
2022-10-03 12:49:21 [INFO ]  	- 8
2022-10-03 12:49:21 [INFO ]  	- 9
2022-10-03 12:49:21 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 12:49:21 [INFO ]  	- !!python/tuple
2022-10-03 12:49:21 [INFO ]  	    - 0.4379104971885681
2022-10-03 12:49:21 [INFO ]  	    - 0.44398033618927
2022-10-03 12:49:21 [INFO ]  	    - 0.4729299545288086
2022-10-03 12:49:21 [INFO ]  	- !!python/tuple
2022-10-03 12:49:21 [INFO ]  	    - 0.19803012907505035
2022-10-03 12:49:21 [INFO ]  	    - 0.2010156363248825
2022-10-03 12:49:21 [INFO ]  	    - 0.19703614711761475
2022-10-03 12:49:21 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 12:49:21 [INFO ]  	decay_epochs: 50
2022-10-03 12:49:21 [INFO ]  	decay_factor: 0.1
2022-10-03 12:49:21 [INFO ]  	device_id: 0
2022-10-03 12:49:21 [INFO ]  	distill_epochs: 1
2022-10-03 12:49:21 [INFO ]  	distill_lr: 0.02
2022-10-03 12:49:21 [INFO ]  	distill_steps: 1
2022-10-03 12:49:21 [INFO ]  	epochs: 200
2022-10-03 12:49:21 [INFO ]  	expand_cls: false
2022-10-03 12:49:21 [INFO ]  	forgetting_dataset: null
2022-10-03 12:49:21 [INFO ]  	init: xavier
2022-10-03 12:49:21 [INFO ]  	init_param: 1.0
2022-10-03 12:49:21 [INFO ]  	input_size: 32
2022-10-03 12:49:21 [INFO ]  	ipc: 10
2022-10-03 12:49:21 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 12:49:21 [INFO ]  	log_interval: 100
2022-10-03 12:49:21 [INFO ]  	log_level: INFO
2022-10-03 12:49:21 [INFO ]  	lr: 0.01
2022-10-03 12:49:21 [INFO ]  	mode: distill_adapt
2022-10-03 12:49:21 [INFO ]  	nc: 3
2022-10-03 12:49:21 [INFO ]  	num_classes: 10
2022-10-03 12:49:21 [INFO ]  	num_workers: 8
2022-10-03 12:49:21 [INFO ]  	phase: train
2022-10-03 12:49:21 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 12:49:21 [INFO ]  	start_time: '2022-10-03 12:49:21'
2022-10-03 12:49:21 [INFO ]  	test_batch_size: 1024
2022-10-03 12:49:21 [INFO ]  	
2022-10-03 12:49:23 [INFO ]  train dataset size:	73257
2022-10-03 12:49:23 [INFO ]  test dataset size: 	26032
2022-10-03 12:49:23 [INFO ]  datasets built!
2022-10-03 12:49:23 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 12:49:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 12:49:31 [INFO ]  
2022-10-03 12:49:31 [INFO ]  Begin of epoch 0 :
2022-10-03 12:49:34 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:49:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:49:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:49:34 [INFO ]  	   step  1 (lr=0.020000)                    6.94%                   9.5556
2022-10-03 12:49:34 [INFO ]  
2022-10-03 12:49:34 [INFO ]  Epoch:    0	Loss: 10.1631	Data Time: 0.44s	Train Time: 0.04s
2022-10-03 12:49:36 [INFO ]  Epoch:    1	Loss: 3.0949	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:49:38 [INFO ]  Epoch:    2	Loss: 2.5843	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:49:39 [INFO ]  Epoch:    3	Loss: 2.3193	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:49:41 [INFO ]  Epoch:    4	Loss: 2.2098	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:49:43 [INFO ]  Epoch:    5	Loss: 2.2274	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:49:45 [INFO ]  Epoch:    6	Loss: 2.2028	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:49:47 [INFO ]  Epoch:    7	Loss: 2.1267	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:49:48 [INFO ]  Epoch:    8	Loss: 2.1090	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:49:50 [INFO ]  Epoch:    9	Loss: 2.0553	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:49:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 12:49:59 [INFO ]  
2022-10-03 12:49:59 [INFO ]  Begin of epoch 10 :
2022-10-03 12:50:02 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:50:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:50:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:50:02 [INFO ]  	   step  1 (lr=0.057137)                   36.63%                   1.9910
2022-10-03 12:50:02 [INFO ]  
2022-10-03 12:50:02 [INFO ]  Epoch:   10	Loss: 2.0103	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:50:04 [INFO ]  Epoch:   11	Loss: 1.9077	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:50:05 [INFO ]  Epoch:   12	Loss: 1.7871	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:50:07 [INFO ]  Epoch:   13	Loss: 1.5781	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:50:09 [INFO ]  Epoch:   14	Loss: 1.4196	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:50:11 [INFO ]  Epoch:   15	Loss: 1.5181	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:50:13 [INFO ]  Epoch:   16	Loss: 1.4491	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:50:14 [INFO ]  Epoch:   17	Loss: 1.3399	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:50:16 [INFO ]  Epoch:   18	Loss: 1.2882	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 12:50:18 [INFO ]  Epoch:   19	Loss: 1.1926	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:50:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 12:50:26 [INFO ]  
2022-10-03 12:50:26 [INFO ]  Begin of epoch 20 :
2022-10-03 12:50:30 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:50:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:50:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:50:30 [INFO ]  	   step  1 (lr=0.216889)                   65.09%                   1.1808
2022-10-03 12:50:30 [INFO ]  
2022-10-03 12:50:30 [INFO ]  Epoch:   20	Loss: 1.1559	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:50:32 [INFO ]  Epoch:   21	Loss: 1.1191	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:50:34 [INFO ]  Epoch:   22	Loss: 1.0363	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:50:35 [INFO ]  Epoch:   23	Loss: 1.0078	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:50:37 [INFO ]  Epoch:   24	Loss: 1.1122	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:50:39 [INFO ]  Epoch:   25	Loss: 1.0250	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:50:41 [INFO ]  Epoch:   26	Loss: 1.0102	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:50:43 [INFO ]  Epoch:   27	Loss: 0.8663	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:50:45 [INFO ]  Epoch:   28	Loss: 0.9597	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:50:47 [INFO ]  Epoch:   29	Loss: 0.9013	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:50:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 12:50:55 [INFO ]  
2022-10-03 12:50:55 [INFO ]  Begin of epoch 30 :
2022-10-03 12:50:58 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:50:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:50:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:50:58 [INFO ]  	   step  1 (lr=0.290205)                   70.54%                   1.0250
2022-10-03 12:50:58 [INFO ]  
2022-10-03 12:50:58 [INFO ]  Epoch:   30	Loss: 0.8636	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:51:00 [INFO ]  Epoch:   31	Loss: 0.8557	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:51:02 [INFO ]  Epoch:   32	Loss: 0.8295	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:51:04 [INFO ]  Epoch:   33	Loss: 0.8633	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:51:06 [INFO ]  Epoch:   34	Loss: 0.8870	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:51:08 [INFO ]  Epoch:   35	Loss: 0.7994	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:51:10 [INFO ]  Epoch:   36	Loss: 0.8436	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:51:12 [INFO ]  Epoch:   37	Loss: 0.8982	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:51:14 [INFO ]  Epoch:   38	Loss: 0.7930	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:51:16 [INFO ]  Epoch:   39	Loss: 0.7859	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 12:51:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 12:51:24 [INFO ]  
2022-10-03 12:51:24 [INFO ]  Begin of epoch 40 :
2022-10-03 12:51:27 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:51:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:51:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:51:27 [INFO ]  	   step  1 (lr=0.311708)                   76.66%                   0.8532
2022-10-03 12:51:27 [INFO ]  
2022-10-03 12:51:27 [INFO ]  Epoch:   40	Loss: 0.7776	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 12:51:29 [INFO ]  Epoch:   41	Loss: 0.8459	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:51:31 [INFO ]  Epoch:   42	Loss: 0.7363	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:51:32 [INFO ]  Epoch:   43	Loss: 0.8322	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:51:34 [INFO ]  Epoch:   44	Loss: 0.7633	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:51:36 [INFO ]  Epoch:   45	Loss: 0.8934	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:51:38 [INFO ]  Epoch:   46	Loss: 0.8683	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:51:40 [INFO ]  Epoch:   47	Loss: 0.7572	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:51:42 [INFO ]  Epoch:   48	Loss: 0.7327	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 12:51:44 [INFO ]  Epoch:   49	Loss: 0.8044	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:51:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 12:51:52 [INFO ]  
2022-10-03 12:51:52 [INFO ]  Begin of epoch 50 :
2022-10-03 12:51:56 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:51:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:51:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:51:56 [INFO ]  	   step  1 (lr=0.327722)                   80.26%                   0.7373
2022-10-03 12:51:56 [INFO ]  
2022-10-03 12:51:56 [INFO ]  Epoch:   50	Loss: 0.6143	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 12:51:58 [INFO ]  Epoch:   51	Loss: 0.6883	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:52:00 [INFO ]  Epoch:   52	Loss: 0.7520	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:52:01 [INFO ]  Epoch:   53	Loss: 0.6442	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:52:03 [INFO ]  Epoch:   54	Loss: 0.6916	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:52:05 [INFO ]  Epoch:   55	Loss: 0.6262	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:52:07 [INFO ]  Epoch:   56	Loss: 0.7742	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:52:09 [INFO ]  Epoch:   57	Loss: 0.6441	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:52:10 [INFO ]  Epoch:   58	Loss: 0.6452	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:52:12 [INFO ]  Epoch:   59	Loss: 0.6337	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:52:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 12:52:21 [INFO ]  
2022-10-03 12:52:21 [INFO ]  Begin of epoch 60 :
2022-10-03 12:52:24 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:52:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:52:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:52:24 [INFO ]  	   step  1 (lr=0.340366)                   80.34%                   0.7395
2022-10-03 12:52:24 [INFO ]  
2022-10-03 12:52:24 [INFO ]  Epoch:   60	Loss: 0.6842	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:52:26 [INFO ]  Epoch:   61	Loss: 0.6187	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:52:28 [INFO ]  Epoch:   62	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:52:30 [INFO ]  Epoch:   63	Loss: 0.7163	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:52:32 [INFO ]  Epoch:   64	Loss: 0.6930	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:52:34 [INFO ]  Epoch:   65	Loss: 0.6492	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:52:36 [INFO ]  Epoch:   66	Loss: 0.6956	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:52:38 [INFO ]  Epoch:   67	Loss: 0.5927	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:52:39 [INFO ]  Epoch:   68	Loss: 0.6269	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:52:41 [INFO ]  Epoch:   69	Loss: 0.6969	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:52:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 12:52:50 [INFO ]  
2022-10-03 12:52:50 [INFO ]  Begin of epoch 70 :
2022-10-03 12:52:53 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:52:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:52:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:52:53 [INFO ]  	   step  1 (lr=0.352301)                   80.63%                   0.7147
2022-10-03 12:52:53 [INFO ]  
2022-10-03 12:52:53 [INFO ]  Epoch:   70	Loss: 0.6058	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:52:55 [INFO ]  Epoch:   71	Loss: 0.6743	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:52:57 [INFO ]  Epoch:   72	Loss: 0.6337	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:52:59 [INFO ]  Epoch:   73	Loss: 0.6805	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:53:01 [INFO ]  Epoch:   74	Loss: 0.6820	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:53:02 [INFO ]  Epoch:   75	Loss: 0.5901	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:53:04 [INFO ]  Epoch:   76	Loss: 0.7252	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:06 [INFO ]  Epoch:   77	Loss: 0.6139	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:53:08 [INFO ]  Epoch:   78	Loss: 0.6078	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:53:10 [INFO ]  Epoch:   79	Loss: 0.7238	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:53:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 12:53:18 [INFO ]  
2022-10-03 12:53:18 [INFO ]  Begin of epoch 80 :
2022-10-03 12:53:22 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:53:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:53:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:53:22 [INFO ]  	   step  1 (lr=0.363442)                   80.69%                   0.7097
2022-10-03 12:53:22 [INFO ]  
2022-10-03 12:53:22 [INFO ]  Epoch:   80	Loss: 0.6259	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 12:53:23 [INFO ]  Epoch:   81	Loss: 0.7386	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:53:25 [INFO ]  Epoch:   82	Loss: 0.6018	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:27 [INFO ]  Epoch:   83	Loss: 0.6763	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:53:29 [INFO ]  Epoch:   84	Loss: 0.6967	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:53:31 [INFO ]  Epoch:   85	Loss: 0.6999	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:53:32 [INFO ]  Epoch:   86	Loss: 0.6695	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:34 [INFO ]  Epoch:   87	Loss: 0.7460	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:53:36 [INFO ]  Epoch:   88	Loss: 0.6693	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:53:38 [INFO ]  Epoch:   89	Loss: 0.6496	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:53:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 12:53:47 [INFO ]  
2022-10-03 12:53:47 [INFO ]  Begin of epoch 90 :
2022-10-03 12:53:50 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:53:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:53:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:53:50 [INFO ]  	   step  1 (lr=0.372178)                   80.29%                   0.7143
2022-10-03 12:53:50 [INFO ]  
2022-10-03 12:53:50 [INFO ]  Epoch:   90	Loss: 0.6352	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:53:52 [INFO ]  Epoch:   91	Loss: 0.6589	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:53 [INFO ]  Epoch:   92	Loss: 0.6318	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:55 [INFO ]  Epoch:   93	Loss: 0.7404	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:53:57 [INFO ]  Epoch:   94	Loss: 0.6240	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:53:59 [INFO ]  Epoch:   95	Loss: 0.6491	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:01 [INFO ]  Epoch:   96	Loss: 0.6491	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:54:03 [INFO ]  Epoch:   97	Loss: 0.6308	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:54:04 [INFO ]  Epoch:   98	Loss: 0.6239	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:54:06 [INFO ]  Epoch:   99	Loss: 0.6716	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:54:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 12:54:15 [INFO ]  
2022-10-03 12:54:15 [INFO ]  Begin of epoch 100 :
2022-10-03 12:54:18 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:54:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:54:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:54:18 [INFO ]  	   step  1 (lr=0.378025)                   80.94%                   0.7069
2022-10-03 12:54:18 [INFO ]  
2022-10-03 12:54:18 [INFO ]  Epoch:  100	Loss: 0.5778	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:20 [INFO ]  Epoch:  101	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:54:21 [INFO ]  Epoch:  102	Loss: 0.5992	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:23 [INFO ]  Epoch:  103	Loss: 0.6124	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:54:25 [INFO ]  Epoch:  104	Loss: 0.5813	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:54:27 [INFO ]  Epoch:  105	Loss: 0.6031	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:54:29 [INFO ]  Epoch:  106	Loss: 0.6133	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:31 [INFO ]  Epoch:  107	Loss: 0.6315	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:54:33 [INFO ]  Epoch:  108	Loss: 0.6984	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:35 [INFO ]  Epoch:  109	Loss: 0.6733	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:54:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 12:54:44 [INFO ]  
2022-10-03 12:54:44 [INFO ]  Begin of epoch 110 :
2022-10-03 12:54:47 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:54:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:54:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:54:47 [INFO ]  	   step  1 (lr=0.377802)                   80.47%                   0.7241
2022-10-03 12:54:47 [INFO ]  
2022-10-03 12:54:47 [INFO ]  Epoch:  110	Loss: 0.6381	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:54:49 [INFO ]  Epoch:  111	Loss: 0.6362	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:54:50 [INFO ]  Epoch:  112	Loss: 0.6394	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:54:52 [INFO ]  Epoch:  113	Loss: 0.6443	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:54:54 [INFO ]  Epoch:  114	Loss: 0.6256	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:54:56 [INFO ]  Epoch:  115	Loss: 0.5842	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:54:58 [INFO ]  Epoch:  116	Loss: 0.7304	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:00 [INFO ]  Epoch:  117	Loss: 0.6560	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:55:01 [INFO ]  Epoch:  118	Loss: 0.6072	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:55:03 [INFO ]  Epoch:  119	Loss: 0.6448	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 12:55:12 [INFO ]  
2022-10-03 12:55:12 [INFO ]  Begin of epoch 120 :
2022-10-03 12:55:15 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:55:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:55:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:55:15 [INFO ]  	   step  1 (lr=0.380385)                   80.39%                   0.7254
2022-10-03 12:55:15 [INFO ]  
2022-10-03 12:55:15 [INFO ]  Epoch:  120	Loss: 0.6321	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 12:55:17 [INFO ]  Epoch:  121	Loss: 0.6023	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:55:19 [INFO ]  Epoch:  122	Loss: 0.5792	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:55:21 [INFO ]  Epoch:  123	Loss: 0.5905	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:55:22 [INFO ]  Epoch:  124	Loss: 0.6110	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:55:24 [INFO ]  Epoch:  125	Loss: 0.6724	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:26 [INFO ]  Epoch:  126	Loss: 0.7099	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:28 [INFO ]  Epoch:  127	Loss: 0.7540	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:30 [INFO ]  Epoch:  128	Loss: 0.6088	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:55:32 [INFO ]  Epoch:  129	Loss: 0.6588	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:55:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 12:55:41 [INFO ]  
2022-10-03 12:55:41 [INFO ]  Begin of epoch 130 :
2022-10-03 12:55:44 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:55:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:55:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:55:44 [INFO ]  	   step  1 (lr=0.380080)                   81.48%                   0.6934
2022-10-03 12:55:44 [INFO ]  
2022-10-03 12:55:44 [INFO ]  Epoch:  130	Loss: 0.5937	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 12:55:46 [INFO ]  Epoch:  131	Loss: 0.6169	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:55:47 [INFO ]  Epoch:  132	Loss: 0.6498	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:55:49 [INFO ]  Epoch:  133	Loss: 0.6430	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:55:51 [INFO ]  Epoch:  134	Loss: 0.6075	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:55:53 [INFO ]  Epoch:  135	Loss: 0.6462	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:55:55 [INFO ]  Epoch:  136	Loss: 0.6479	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 12:55:57 [INFO ]  Epoch:  137	Loss: 0.6528	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:55:59 [INFO ]  Epoch:  138	Loss: 0.6278	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 12:56:01 [INFO ]  Epoch:  139	Loss: 0.5736	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:56:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 12:56:09 [INFO ]  
2022-10-03 12:56:09 [INFO ]  Begin of epoch 140 :
2022-10-03 12:56:13 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:56:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:56:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:56:13 [INFO ]  	   step  1 (lr=0.379593)                   79.68%                   0.7593
2022-10-03 12:56:13 [INFO ]  
2022-10-03 12:56:13 [INFO ]  Epoch:  140	Loss: 0.6572	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:15 [INFO ]  Epoch:  141	Loss: 0.6538	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:56:17 [INFO ]  Epoch:  142	Loss: 0.5944	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:19 [INFO ]  Epoch:  143	Loss: 0.7218	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:56:21 [INFO ]  Epoch:  144	Loss: 0.6120	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:56:23 [INFO ]  Epoch:  145	Loss: 0.7256	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:25 [INFO ]  Epoch:  146	Loss: 0.6846	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:27 [INFO ]  Epoch:  147	Loss: 0.6567	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:56:29 [INFO ]  Epoch:  148	Loss: 0.7029	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:31 [INFO ]  Epoch:  149	Loss: 0.5406	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 12:56:40 [INFO ]  
2022-10-03 12:56:40 [INFO ]  Begin of epoch 150 :
2022-10-03 12:56:43 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:56:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:56:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:56:43 [INFO ]  	   step  1 (lr=0.378719)                   81.26%                   0.6992
2022-10-03 12:56:43 [INFO ]  
2022-10-03 12:56:43 [INFO ]  Epoch:  150	Loss: 0.6104	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 12:56:45 [INFO ]  Epoch:  151	Loss: 0.6658	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:56:47 [INFO ]  Epoch:  152	Loss: 0.6225	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:49 [INFO ]  Epoch:  153	Loss: 0.6233	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:51 [INFO ]  Epoch:  154	Loss: 0.6913	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:56:53 [INFO ]  Epoch:  155	Loss: 0.5927	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:56:54 [INFO ]  Epoch:  156	Loss: 0.6185	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:56:56 [INFO ]  Epoch:  157	Loss: 0.5803	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:56:58 [INFO ]  Epoch:  158	Loss: 0.6523	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:57:00 [INFO ]  Epoch:  159	Loss: 0.7160	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:57:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 12:57:09 [INFO ]  
2022-10-03 12:57:09 [INFO ]  Begin of epoch 160 :
2022-10-03 12:57:12 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:57:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:57:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:57:12 [INFO ]  	   step  1 (lr=0.378660)                   80.99%                   0.7054
2022-10-03 12:57:12 [INFO ]  
2022-10-03 12:57:12 [INFO ]  Epoch:  160	Loss: 0.5959	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:57:14 [INFO ]  Epoch:  161	Loss: 0.6472	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:57:16 [INFO ]  Epoch:  162	Loss: 0.6220	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:57:18 [INFO ]  Epoch:  163	Loss: 0.6547	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:20 [INFO ]  Epoch:  164	Loss: 0.5924	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:22 [INFO ]  Epoch:  165	Loss: 0.6351	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:24 [INFO ]  Epoch:  166	Loss: 0.5783	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:57:26 [INFO ]  Epoch:  167	Loss: 0.6167	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:57:27 [INFO ]  Epoch:  168	Loss: 0.6309	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:29 [INFO ]  Epoch:  169	Loss: 0.6479	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:57:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 12:57:38 [INFO ]  
2022-10-03 12:57:38 [INFO ]  Begin of epoch 170 :
2022-10-03 12:57:42 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:57:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:57:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:57:42 [INFO ]  	   step  1 (lr=0.378970)                   80.88%                   0.7118
2022-10-03 12:57:42 [INFO ]  
2022-10-03 12:57:42 [INFO ]  Epoch:  170	Loss: 0.6070	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:57:44 [INFO ]  Epoch:  171	Loss: 0.6804	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:46 [INFO ]  Epoch:  172	Loss: 0.6607	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:57:47 [INFO ]  Epoch:  173	Loss: 0.6924	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:49 [INFO ]  Epoch:  174	Loss: 0.6532	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:57:51 [INFO ]  Epoch:  175	Loss: 0.6673	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:57:53 [INFO ]  Epoch:  176	Loss: 0.6208	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:57:56 [INFO ]  Epoch:  177	Loss: 0.6641	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:57:58 [INFO ]  Epoch:  178	Loss: 0.6447	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:58:00 [INFO ]  Epoch:  179	Loss: 0.6494	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:58:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 12:58:08 [INFO ]  
2022-10-03 12:58:08 [INFO ]  Begin of epoch 180 :
2022-10-03 12:58:12 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:58:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:58:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:58:12 [INFO ]  	   step  1 (lr=0.377719)                   79.59%                   0.7688
2022-10-03 12:58:12 [INFO ]  
2022-10-03 12:58:12 [INFO ]  Epoch:  180	Loss: 0.6752	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 12:58:13 [INFO ]  Epoch:  181	Loss: 0.6732	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:58:15 [INFO ]  Epoch:  182	Loss: 0.6423	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 12:58:17 [INFO ]  Epoch:  183	Loss: 0.6590	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 12:58:19 [INFO ]  Epoch:  184	Loss: 0.6643	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:58:21 [INFO ]  Epoch:  185	Loss: 0.5925	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:58:23 [INFO ]  Epoch:  186	Loss: 0.6361	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 12:58:24 [INFO ]  Epoch:  187	Loss: 0.6406	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:58:26 [INFO ]  Epoch:  188	Loss: 0.6682	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:58:28 [INFO ]  Epoch:  189	Loss: 0.5855	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 12:58:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 12:58:37 [INFO ]  
2022-10-03 12:58:37 [INFO ]  Begin of epoch 190 :
2022-10-03 12:58:40 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:58:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:58:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:58:40 [INFO ]  	   step  1 (lr=0.378365)                   81.18%                   0.7009
2022-10-03 12:58:40 [INFO ]  
2022-10-03 12:58:40 [INFO ]  Epoch:  190	Loss: 0.6172	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 12:58:42 [INFO ]  Epoch:  191	Loss: 0.6166	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:58:44 [INFO ]  Epoch:  192	Loss: 0.6315	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:58:46 [INFO ]  Epoch:  193	Loss: 0.6392	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 12:58:47 [INFO ]  Epoch:  194	Loss: 0.5496	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:58:49 [INFO ]  Epoch:  195	Loss: 0.6447	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 12:58:51 [INFO ]  Epoch:  196	Loss: 0.6121	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:58:53 [INFO ]  Epoch:  197	Loss: 0.6983	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 12:58:55 [INFO ]  Epoch:  198	Loss: 0.5691	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 12:58:57 [INFO ]  Epoch:  199	Loss: 0.6984	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 12:59:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 12:59:05 [INFO ]  
2022-10-03 12:59:05 [INFO ]  Final evaluation for SVHN :
2022-10-03 12:59:09 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:59:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:59:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 12:59:09 [INFO ]  	   step  1 (lr=0.379035)                   81.10%                   0.7002
2022-10-03 12:59:09 [INFO ]  
2022-10-03 12:59:09 [INFO ]  
2022-10-03 12:59:09 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 12:59:12 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 12:59:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 12:59:12 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 12:59:12 [INFO ]  	   step  1 (lr=0.379035)                   17.88%                   5.3792
2022-10-03 12:59:12 [INFO ]  
2022-10-03 12:59:55 [INFO ]  ======================================== 2022-10-03 12:59:55 ========================================
2022-10-03 12:59:55 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 12:59:55 [INFO ]  Options: 
2022-10-03 12:59:55 [INFO ]  	base_dir: null
2022-10-03 12:59:55 [INFO ]  	batch_size: 1024
2022-10-03 12:59:55 [INFO ]  	checkpoint_interval: 10
2022-10-03 12:59:55 [INFO ]  	dataset: SVHN
2022-10-03 12:59:55 [INFO ]  	dataset_labels:
2022-10-03 12:59:55 [INFO ]  	- 0
2022-10-03 12:59:55 [INFO ]  	- 1
2022-10-03 12:59:55 [INFO ]  	- 2
2022-10-03 12:59:55 [INFO ]  	- 3
2022-10-03 12:59:55 [INFO ]  	- 4
2022-10-03 12:59:55 [INFO ]  	- 5
2022-10-03 12:59:55 [INFO ]  	- 6
2022-10-03 12:59:55 [INFO ]  	- 7
2022-10-03 12:59:55 [INFO ]  	- 8
2022-10-03 12:59:55 [INFO ]  	- 9
2022-10-03 12:59:55 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 12:59:55 [INFO ]  	- !!python/tuple
2022-10-03 12:59:55 [INFO ]  	    - 0.4379104971885681
2022-10-03 12:59:55 [INFO ]  	    - 0.44398033618927
2022-10-03 12:59:55 [INFO ]  	    - 0.4729299545288086
2022-10-03 12:59:55 [INFO ]  	- !!python/tuple
2022-10-03 12:59:55 [INFO ]  	    - 0.19803012907505035
2022-10-03 12:59:55 [INFO ]  	    - 0.2010156363248825
2022-10-03 12:59:55 [INFO ]  	    - 0.19703614711761475
2022-10-03 12:59:55 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 12:59:55 [INFO ]  	decay_epochs: 50
2022-10-03 12:59:55 [INFO ]  	decay_factor: 0.1
2022-10-03 12:59:55 [INFO ]  	device_id: 0
2022-10-03 12:59:55 [INFO ]  	distill_epochs: 1
2022-10-03 12:59:55 [INFO ]  	distill_lr: 0.02
2022-10-03 12:59:55 [INFO ]  	distill_steps: 1
2022-10-03 12:59:55 [INFO ]  	epochs: 200
2022-10-03 12:59:55 [INFO ]  	expand_cls: false
2022-10-03 12:59:55 [INFO ]  	forgetting_dataset: null
2022-10-03 12:59:55 [INFO ]  	init: xavier
2022-10-03 12:59:55 [INFO ]  	init_param: 1.0
2022-10-03 12:59:55 [INFO ]  	input_size: 32
2022-10-03 12:59:55 [INFO ]  	ipc: 10
2022-10-03 12:59:55 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 12:59:55 [INFO ]  	log_interval: 100
2022-10-03 12:59:55 [INFO ]  	log_level: INFO
2022-10-03 12:59:55 [INFO ]  	lr: 0.01
2022-10-03 12:59:55 [INFO ]  	mode: distill_adapt
2022-10-03 12:59:55 [INFO ]  	nc: 3
2022-10-03 12:59:55 [INFO ]  	num_classes: 10
2022-10-03 12:59:55 [INFO ]  	num_workers: 8
2022-10-03 12:59:55 [INFO ]  	phase: train
2022-10-03 12:59:55 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 12:59:55 [INFO ]  	start_time: '2022-10-03 12:59:55'
2022-10-03 12:59:55 [INFO ]  	test_batch_size: 1024
2022-10-03 12:59:55 [INFO ]  	
2022-10-03 12:59:57 [INFO ]  train dataset size:	73257
2022-10-03 12:59:57 [INFO ]  test dataset size: 	26032
2022-10-03 12:59:57 [INFO ]  datasets built!
2022-10-03 12:59:57 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:00:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:00:05 [INFO ]  
2022-10-03 13:00:05 [INFO ]  Begin of epoch 0 :
2022-10-03 13:00:09 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:00:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:00:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:00:09 [INFO ]  	   step  1 (lr=0.020000)                    6.94%                   9.0419
2022-10-03 13:00:09 [INFO ]  
2022-10-03 13:00:09 [INFO ]  Epoch:    0	Loss: 8.4090	Data Time: 0.42s	Train Time: 0.03s
2022-10-03 13:00:10 [INFO ]  Epoch:    1	Loss: 3.1079	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 13:00:12 [INFO ]  Epoch:    2	Loss: 2.5304	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:14 [INFO ]  Epoch:    3	Loss: 2.3127	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:00:16 [INFO ]  Epoch:    4	Loss: 2.2353	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:18 [INFO ]  Epoch:    5	Loss: 2.1857	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:20 [INFO ]  Epoch:    6	Loss: 2.1594	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:21 [INFO ]  Epoch:    7	Loss: 2.1279	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:00:23 [INFO ]  Epoch:    8	Loss: 2.0372	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:25 [INFO ]  Epoch:    9	Loss: 1.9819	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:00:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 13:00:34 [INFO ]  
2022-10-03 13:00:34 [INFO ]  Begin of epoch 10 :
2022-10-03 13:00:37 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:00:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:00:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:00:37 [INFO ]  	   step  1 (lr=0.074316)                   39.70%                   1.8903
2022-10-03 13:00:37 [INFO ]  
2022-10-03 13:00:37 [INFO ]  Epoch:   10	Loss: 1.8776	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:38 [INFO ]  Epoch:   11	Loss: 1.6813	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:00:40 [INFO ]  Epoch:   12	Loss: 1.5563	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:00:42 [INFO ]  Epoch:   13	Loss: 1.4486	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:00:44 [INFO ]  Epoch:   14	Loss: 1.3545	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:00:46 [INFO ]  Epoch:   15	Loss: 1.4461	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:00:48 [INFO ]  Epoch:   16	Loss: 1.2091	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:00:50 [INFO ]  Epoch:   17	Loss: 1.2564	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:52 [INFO ]  Epoch:   18	Loss: 1.2388	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:00:53 [INFO ]  Epoch:   19	Loss: 1.1612	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 13:01:02 [INFO ]  
2022-10-03 13:01:02 [INFO ]  Begin of epoch 20 :
2022-10-03 13:01:05 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:01:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:01:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:01:05 [INFO ]  	   step  1 (lr=0.230325)                   66.74%                   1.1282
2022-10-03 13:01:05 [INFO ]  
2022-10-03 13:01:05 [INFO ]  Epoch:   20	Loss: 1.1166	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:01:07 [INFO ]  Epoch:   21	Loss: 1.0743	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:09 [INFO ]  Epoch:   22	Loss: 1.0486	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:01:11 [INFO ]  Epoch:   23	Loss: 0.9740	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:01:13 [INFO ]  Epoch:   24	Loss: 1.0243	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:15 [INFO ]  Epoch:   25	Loss: 1.0173	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:16 [INFO ]  Epoch:   26	Loss: 0.9760	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:01:18 [INFO ]  Epoch:   27	Loss: 0.9142	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:01:20 [INFO ]  Epoch:   28	Loss: 1.1476	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:01:22 [INFO ]  Epoch:   29	Loss: 0.8703	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 13:01:31 [INFO ]  
2022-10-03 13:01:31 [INFO ]  Begin of epoch 30 :
2022-10-03 13:01:34 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:01:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:01:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:01:34 [INFO ]  	   step  1 (lr=0.280684)                   74.44%                   0.9170
2022-10-03 13:01:34 [INFO ]  
2022-10-03 13:01:34 [INFO ]  Epoch:   30	Loss: 0.8330	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:01:36 [INFO ]  Epoch:   31	Loss: 0.8507	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:38 [INFO ]  Epoch:   32	Loss: 0.8300	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:01:39 [INFO ]  Epoch:   33	Loss: 0.9354	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:41 [INFO ]  Epoch:   34	Loss: 0.8660	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:01:43 [INFO ]  Epoch:   35	Loss: 0.9582	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:01:45 [INFO ]  Epoch:   36	Loss: 1.0146	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:01:47 [INFO ]  Epoch:   37	Loss: 0.8444	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:01:49 [INFO ]  Epoch:   38	Loss: 0.8406	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:01:51 [INFO ]  Epoch:   39	Loss: 0.6924	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:02:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 13:02:00 [INFO ]  
2022-10-03 13:02:00 [INFO ]  Begin of epoch 40 :
2022-10-03 13:02:03 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:02:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:02:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:02:03 [INFO ]  	   step  1 (lr=0.316391)                   76.28%                   0.8671
2022-10-03 13:02:03 [INFO ]  
2022-10-03 13:02:03 [INFO ]  Epoch:   40	Loss: 0.7800	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:02:05 [INFO ]  Epoch:   41	Loss: 0.7982	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:02:07 [INFO ]  Epoch:   42	Loss: 0.7573	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:02:09 [INFO ]  Epoch:   43	Loss: 1.0525	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:02:11 [INFO ]  Epoch:   44	Loss: 0.8092	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:02:12 [INFO ]  Epoch:   45	Loss: 0.7597	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:02:14 [INFO ]  Epoch:   46	Loss: 0.8334	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:02:16 [INFO ]  Epoch:   47	Loss: 0.8246	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:02:18 [INFO ]  Epoch:   48	Loss: 0.8233	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:02:20 [INFO ]  Epoch:   49	Loss: 0.7829	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:02:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 13:02:28 [INFO ]  
2022-10-03 13:02:28 [INFO ]  Begin of epoch 50 :
2022-10-03 13:02:32 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:02:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:02:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:02:32 [INFO ]  	   step  1 (lr=0.335506)                   78.89%                   0.7846
2022-10-03 13:02:32 [INFO ]  
2022-10-03 13:02:32 [INFO ]  Epoch:   50	Loss: 0.7607	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 13:02:34 [INFO ]  Epoch:   51	Loss: 0.6124	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:02:35 [INFO ]  Epoch:   52	Loss: 0.7124	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:02:37 [INFO ]  Epoch:   53	Loss: 0.6319	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:02:39 [INFO ]  Epoch:   54	Loss: 0.7029	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:02:41 [INFO ]  Epoch:   55	Loss: 0.6611	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:02:43 [INFO ]  Epoch:   56	Loss: 0.6723	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:02:45 [INFO ]  Epoch:   57	Loss: 0.7142	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:02:47 [INFO ]  Epoch:   58	Loss: 0.7376	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:02:49 [INFO ]  Epoch:   59	Loss: 0.6625	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:02:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 13:02:58 [INFO ]  
2022-10-03 13:02:58 [INFO ]  Begin of epoch 60 :
2022-10-03 13:03:02 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:03:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:03:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:03:02 [INFO ]  	   step  1 (lr=0.348086)                   79.16%                   0.7856
2022-10-03 13:03:02 [INFO ]  
2022-10-03 13:03:02 [INFO ]  Epoch:   60	Loss: 0.7623	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:03:03 [INFO ]  Epoch:   61	Loss: 0.6815	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:05 [INFO ]  Epoch:   62	Loss: 0.6730	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:07 [INFO ]  Epoch:   63	Loss: 0.7371	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:09 [INFO ]  Epoch:   64	Loss: 0.7078	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:03:11 [INFO ]  Epoch:   65	Loss: 0.6337	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:03:13 [INFO ]  Epoch:   66	Loss: 0.6841	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:15 [INFO ]  Epoch:   67	Loss: 0.6742	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:03:17 [INFO ]  Epoch:   68	Loss: 0.6301	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:03:19 [INFO ]  Epoch:   69	Loss: 0.7032	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:03:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 13:03:27 [INFO ]  
2022-10-03 13:03:27 [INFO ]  Begin of epoch 70 :
2022-10-03 13:03:31 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:03:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:03:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:03:31 [INFO ]  	   step  1 (lr=0.358136)                   79.25%                   0.7904
2022-10-03 13:03:31 [INFO ]  
2022-10-03 13:03:31 [INFO ]  Epoch:   70	Loss: 0.7937	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:03:32 [INFO ]  Epoch:   71	Loss: 0.6766	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:34 [INFO ]  Epoch:   72	Loss: 0.7014	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:03:36 [INFO ]  Epoch:   73	Loss: 0.7021	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:03:38 [INFO ]  Epoch:   74	Loss: 0.6353	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:03:40 [INFO ]  Epoch:   75	Loss: 0.7113	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:03:42 [INFO ]  Epoch:   76	Loss: 0.6558	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:03:44 [INFO ]  Epoch:   77	Loss: 0.5803	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:03:46 [INFO ]  Epoch:   78	Loss: 0.6707	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:03:48 [INFO ]  Epoch:   79	Loss: 0.6277	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:03:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 13:03:56 [INFO ]  
2022-10-03 13:03:56 [INFO ]  Begin of epoch 80 :
2022-10-03 13:04:00 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:04:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:04:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:04:00 [INFO ]  	   step  1 (lr=0.359634)                   80.54%                   0.7193
2022-10-03 13:04:00 [INFO ]  
2022-10-03 13:04:00 [INFO ]  Epoch:   80	Loss: 0.6727	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:04:02 [INFO ]  Epoch:   81	Loss: 0.6255	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:04:04 [INFO ]  Epoch:   82	Loss: 0.6521	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:04:05 [INFO ]  Epoch:   83	Loss: 0.7127	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:04:07 [INFO ]  Epoch:   84	Loss: 0.6677	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:09 [INFO ]  Epoch:   85	Loss: 0.7001	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:04:11 [INFO ]  Epoch:   86	Loss: 0.5979	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:04:13 [INFO ]  Epoch:   87	Loss: 0.7015	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:04:15 [INFO ]  Epoch:   88	Loss: 0.6176	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:04:17 [INFO ]  Epoch:   89	Loss: 0.6313	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:04:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 13:04:26 [INFO ]  
2022-10-03 13:04:26 [INFO ]  Begin of epoch 90 :
2022-10-03 13:04:29 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:04:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:04:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:04:29 [INFO ]  	   step  1 (lr=0.368918)                   80.65%                   0.7205
2022-10-03 13:04:29 [INFO ]  
2022-10-03 13:04:29 [INFO ]  Epoch:   90	Loss: 0.6511	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:04:31 [INFO ]  Epoch:   91	Loss: 0.6591	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:04:33 [INFO ]  Epoch:   92	Loss: 0.6519	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:04:34 [INFO ]  Epoch:   93	Loss: 0.7131	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:04:36 [INFO ]  Epoch:   94	Loss: 0.6888	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:38 [INFO ]  Epoch:   95	Loss: 0.6944	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:40 [INFO ]  Epoch:   96	Loss: 0.6547	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:42 [INFO ]  Epoch:   97	Loss: 0.6195	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:44 [INFO ]  Epoch:   98	Loss: 0.6430	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:04:46 [INFO ]  Epoch:   99	Loss: 0.6889	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:04:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 13:04:54 [INFO ]  
2022-10-03 13:04:54 [INFO ]  Begin of epoch 100 :
2022-10-03 13:04:58 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:04:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:04:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:04:58 [INFO ]  	   step  1 (lr=0.377785)                   80.94%                   0.7060
2022-10-03 13:04:58 [INFO ]  
2022-10-03 13:04:58 [INFO ]  Epoch:  100	Loss: 0.6000	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:04:59 [INFO ]  Epoch:  101	Loss: 0.6036	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:05:01 [INFO ]  Epoch:  102	Loss: 0.6438	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:05:03 [INFO ]  Epoch:  103	Loss: 0.6618	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:05:05 [INFO ]  Epoch:  104	Loss: 0.6342	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:05:07 [INFO ]  Epoch:  105	Loss: 0.6767	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:05:09 [INFO ]  Epoch:  106	Loss: 0.5870	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:05:11 [INFO ]  Epoch:  107	Loss: 0.6389	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:05:13 [INFO ]  Epoch:  108	Loss: 0.6305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:05:15 [INFO ]  Epoch:  109	Loss: 0.5904	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:05:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 13:05:23 [INFO ]  
2022-10-03 13:05:23 [INFO ]  Begin of epoch 110 :
2022-10-03 13:05:27 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:05:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:05:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:05:27 [INFO ]  	   step  1 (lr=0.377937)                   81.05%                   0.7015
2022-10-03 13:05:27 [INFO ]  
2022-10-03 13:05:27 [INFO ]  Epoch:  110	Loss: 0.6156	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:05:28 [INFO ]  Epoch:  111	Loss: 0.6158	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:05:31 [INFO ]  Epoch:  112	Loss: 0.6614	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:05:33 [INFO ]  Epoch:  113	Loss: 0.6141	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:05:35 [INFO ]  Epoch:  114	Loss: 0.6336	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:05:37 [INFO ]  Epoch:  115	Loss: 0.6554	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:05:39 [INFO ]  Epoch:  116	Loss: 0.6240	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:05:41 [INFO ]  Epoch:  117	Loss: 0.5818	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:05:43 [INFO ]  Epoch:  118	Loss: 0.6663	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:05:45 [INFO ]  Epoch:  119	Loss: 0.6536	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:05:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 13:05:54 [INFO ]  
2022-10-03 13:05:54 [INFO ]  Begin of epoch 120 :
2022-10-03 13:05:57 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:05:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:05:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:05:57 [INFO ]  	   step  1 (lr=0.378288)                   80.70%                   0.7094
2022-10-03 13:05:57 [INFO ]  
2022-10-03 13:05:57 [INFO ]  Epoch:  120	Loss: 0.6663	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:05:59 [INFO ]  Epoch:  121	Loss: 0.6156	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:06:01 [INFO ]  Epoch:  122	Loss: 0.6796	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:06:03 [INFO ]  Epoch:  123	Loss: 0.6461	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:06:05 [INFO ]  Epoch:  124	Loss: 0.6041	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:06:07 [INFO ]  Epoch:  125	Loss: 0.5908	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:06:09 [INFO ]  Epoch:  126	Loss: 0.6258	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:06:11 [INFO ]  Epoch:  127	Loss: 0.6274	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:06:13 [INFO ]  Epoch:  128	Loss: 0.6551	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:06:14 [INFO ]  Epoch:  129	Loss: 0.6176	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:06:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 13:06:23 [INFO ]  
2022-10-03 13:06:23 [INFO ]  Begin of epoch 130 :
2022-10-03 13:06:26 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:06:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:06:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:06:26 [INFO ]  	   step  1 (lr=0.379606)                   79.89%                   0.7545
2022-10-03 13:06:26 [INFO ]  
2022-10-03 13:06:27 [INFO ]  Epoch:  130	Loss: 0.7054	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:06:28 [INFO ]  Epoch:  131	Loss: 0.6404	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:06:30 [INFO ]  Epoch:  132	Loss: 0.6336	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:06:32 [INFO ]  Epoch:  133	Loss: 0.7375	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:06:34 [INFO ]  Epoch:  134	Loss: 0.5875	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:06:36 [INFO ]  Epoch:  135	Loss: 0.5928	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:06:37 [INFO ]  Epoch:  136	Loss: 0.5887	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:06:39 [INFO ]  Epoch:  137	Loss: 0.7204	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:06:41 [INFO ]  Epoch:  138	Loss: 0.6751	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:06:43 [INFO ]  Epoch:  139	Loss: 0.6193	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:06:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 13:06:52 [INFO ]  
2022-10-03 13:06:52 [INFO ]  Begin of epoch 140 :
2022-10-03 13:06:56 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:06:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:06:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:06:56 [INFO ]  	   step  1 (lr=0.382092)                   80.64%                   0.7136
2022-10-03 13:06:56 [INFO ]  
2022-10-03 13:06:56 [INFO ]  Epoch:  140	Loss: 0.5731	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 13:06:57 [INFO ]  Epoch:  141	Loss: 0.6457	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:06:59 [INFO ]  Epoch:  142	Loss: 0.6457	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:07:01 [INFO ]  Epoch:  143	Loss: 0.6372	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:03 [INFO ]  Epoch:  144	Loss: 0.6543	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:05 [INFO ]  Epoch:  145	Loss: 0.6934	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:07:07 [INFO ]  Epoch:  146	Loss: 0.6226	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:10 [INFO ]  Epoch:  147	Loss: 0.5668	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:07:12 [INFO ]  Epoch:  148	Loss: 0.6847	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:07:14 [INFO ]  Epoch:  149	Loss: 0.7128	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:07:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 13:07:23 [INFO ]  
2022-10-03 13:07:23 [INFO ]  Begin of epoch 150 :
2022-10-03 13:07:26 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:07:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:07:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:07:26 [INFO ]  	   step  1 (lr=0.378726)                   81.12%                   0.7023
2022-10-03 13:07:26 [INFO ]  
2022-10-03 13:07:26 [INFO ]  Epoch:  150	Loss: 0.5780	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:07:28 [INFO ]  Epoch:  151	Loss: 0.6750	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:30 [INFO ]  Epoch:  152	Loss: 0.6003	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:07:32 [INFO ]  Epoch:  153	Loss: 0.5717	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:07:34 [INFO ]  Epoch:  154	Loss: 0.6564	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:07:36 [INFO ]  Epoch:  155	Loss: 0.6178	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:07:38 [INFO ]  Epoch:  156	Loss: 0.6908	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:07:39 [INFO ]  Epoch:  157	Loss: 0.6575	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:41 [INFO ]  Epoch:  158	Loss: 0.5753	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:07:43 [INFO ]  Epoch:  159	Loss: 0.6524	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:07:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 13:07:52 [INFO ]  
2022-10-03 13:07:52 [INFO ]  Begin of epoch 160 :
2022-10-03 13:07:55 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:07:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:07:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:07:55 [INFO ]  	   step  1 (lr=0.378982)                   81.22%                   0.6936
2022-10-03 13:07:55 [INFO ]  
2022-10-03 13:07:55 [INFO ]  Epoch:  160	Loss: 0.6448	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 13:07:57 [INFO ]  Epoch:  161	Loss: 0.5873	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:07:59 [INFO ]  Epoch:  162	Loss: 0.6589	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:08:01 [INFO ]  Epoch:  163	Loss: 0.6185	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 13:08:03 [INFO ]  Epoch:  164	Loss: 0.6208	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:08:05 [INFO ]  Epoch:  165	Loss: 0.5486	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:08:07 [INFO ]  Epoch:  166	Loss: 0.6542	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:08:09 [INFO ]  Epoch:  167	Loss: 0.6058	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:08:11 [INFO ]  Epoch:  168	Loss: 0.6477	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:08:13 [INFO ]  Epoch:  169	Loss: 0.6033	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:08:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 13:08:21 [INFO ]  
2022-10-03 13:08:21 [INFO ]  Begin of epoch 170 :
2022-10-03 13:08:25 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:08:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:08:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:08:25 [INFO ]  	   step  1 (lr=0.379514)                   81.22%                   0.6942
2022-10-03 13:08:25 [INFO ]  
2022-10-03 13:08:25 [INFO ]  Epoch:  170	Loss: 0.6742	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:08:26 [INFO ]  Epoch:  171	Loss: 0.6420	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:08:28 [INFO ]  Epoch:  172	Loss: 0.6392	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:08:30 [INFO ]  Epoch:  173	Loss: 0.6120	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:08:32 [INFO ]  Epoch:  174	Loss: 0.6594	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:08:34 [INFO ]  Epoch:  175	Loss: 0.5818	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:08:36 [INFO ]  Epoch:  176	Loss: 0.6400	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:08:38 [INFO ]  Epoch:  177	Loss: 0.7048	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:08:40 [INFO ]  Epoch:  178	Loss: 0.6091	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:08:42 [INFO ]  Epoch:  179	Loss: 0.6677	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:08:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 13:08:50 [INFO ]  
2022-10-03 13:08:50 [INFO ]  Begin of epoch 180 :
2022-10-03 13:08:54 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:08:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:08:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:08:54 [INFO ]  	   step  1 (lr=0.379420)                   81.32%                   0.6956
2022-10-03 13:08:54 [INFO ]  
2022-10-03 13:08:54 [INFO ]  Epoch:  180	Loss: 0.6087	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:08:55 [INFO ]  Epoch:  181	Loss: 0.6633	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:08:57 [INFO ]  Epoch:  182	Loss: 0.6829	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:08:59 [INFO ]  Epoch:  183	Loss: 0.6767	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:01 [INFO ]  Epoch:  184	Loss: 0.5981	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:03 [INFO ]  Epoch:  185	Loss: 0.5912	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:09:05 [INFO ]  Epoch:  186	Loss: 0.6490	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:09:07 [INFO ]  Epoch:  187	Loss: 0.6394	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:09:09 [INFO ]  Epoch:  188	Loss: 0.6673	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:09:10 [INFO ]  Epoch:  189	Loss: 0.7565	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:09:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 13:09:19 [INFO ]  
2022-10-03 13:09:19 [INFO ]  Begin of epoch 190 :
2022-10-03 13:09:23 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:09:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:09:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:09:23 [INFO ]  	   step  1 (lr=0.378725)                   80.25%                   0.7333
2022-10-03 13:09:23 [INFO ]  
2022-10-03 13:09:23 [INFO ]  Epoch:  190	Loss: 0.6636	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:09:24 [INFO ]  Epoch:  191	Loss: 0.6421	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:26 [INFO ]  Epoch:  192	Loss: 0.6448	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:28 [INFO ]  Epoch:  193	Loss: 0.6449	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:09:30 [INFO ]  Epoch:  194	Loss: 0.6012	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:09:32 [INFO ]  Epoch:  195	Loss: 0.6202	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:34 [INFO ]  Epoch:  196	Loss: 0.6268	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:09:36 [INFO ]  Epoch:  197	Loss: 0.6010	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:09:38 [INFO ]  Epoch:  198	Loss: 0.5763	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:09:40 [INFO ]  Epoch:  199	Loss: 0.6208	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:09:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 13:09:48 [INFO ]  
2022-10-03 13:09:48 [INFO ]  Final evaluation for SVHN :
2022-10-03 13:09:51 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:09:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:09:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:09:51 [INFO ]  	   step  1 (lr=0.378958)                   80.87%                   0.7084
2022-10-03 13:09:51 [INFO ]  
2022-10-03 13:09:51 [INFO ]  
2022-10-03 13:09:51 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 13:09:55 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:09:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:09:55 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 13:09:55 [INFO ]  	   step  1 (lr=0.378958)                   18.92%                   5.0020
2022-10-03 13:09:55 [INFO ]  
2022-10-03 13:14:31 [INFO ]  ======================================== 2022-10-03 13:14:31 ========================================
2022-10-03 13:14:31 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:14:31 [INFO ]  Options: 
2022-10-03 13:14:31 [INFO ]  	base_dir: null
2022-10-03 13:14:31 [INFO ]  	batch_size: 1024
2022-10-03 13:14:31 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:14:31 [INFO ]  	dataset: SVHN
2022-10-03 13:14:31 [INFO ]  	dataset_labels:
2022-10-03 13:14:31 [INFO ]  	- 0
2022-10-03 13:14:31 [INFO ]  	- 1
2022-10-03 13:14:31 [INFO ]  	- 2
2022-10-03 13:14:31 [INFO ]  	- 3
2022-10-03 13:14:31 [INFO ]  	- 4
2022-10-03 13:14:31 [INFO ]  	- 5
2022-10-03 13:14:31 [INFO ]  	- 6
2022-10-03 13:14:31 [INFO ]  	- 7
2022-10-03 13:14:31 [INFO ]  	- 8
2022-10-03 13:14:31 [INFO ]  	- 9
2022-10-03 13:14:31 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:14:31 [INFO ]  	- !!python/tuple
2022-10-03 13:14:31 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:14:31 [INFO ]  	    - 0.44398033618927
2022-10-03 13:14:31 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:14:31 [INFO ]  	- !!python/tuple
2022-10-03 13:14:31 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:14:31 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:14:31 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:14:31 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:14:31 [INFO ]  	decay_epochs: 50
2022-10-03 13:14:31 [INFO ]  	decay_factor: 0.1
2022-10-03 13:14:31 [INFO ]  	device_id: 0
2022-10-03 13:14:31 [INFO ]  	distill_epochs: 1
2022-10-03 13:14:31 [INFO ]  	distill_lr: 0.02
2022-10-03 13:14:31 [INFO ]  	distill_steps: 1
2022-10-03 13:14:31 [INFO ]  	epochs: 200
2022-10-03 13:14:31 [INFO ]  	expand_cls: false
2022-10-03 13:14:31 [INFO ]  	forgetting_dataset: null
2022-10-03 13:14:31 [INFO ]  	init: xavier
2022-10-03 13:14:31 [INFO ]  	init_param: 1.0
2022-10-03 13:14:31 [INFO ]  	input_size: 32
2022-10-03 13:14:31 [INFO ]  	ipc: 1
2022-10-03 13:14:31 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:14:31 [INFO ]  	log_interval: 100
2022-10-03 13:14:31 [INFO ]  	log_level: INFO
2022-10-03 13:14:31 [INFO ]  	lr: 0.01
2022-10-03 13:14:31 [INFO ]  	mode: distill_adapt
2022-10-03 13:14:31 [INFO ]  	nc: 3
2022-10-03 13:14:31 [INFO ]  	num_classes: 10
2022-10-03 13:14:31 [INFO ]  	num_workers: 8
2022-10-03 13:14:31 [INFO ]  	phase: train
2022-10-03 13:14:31 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:14:31 [INFO ]  	start_time: '2022-10-03 13:14:31'
2022-10-03 13:14:31 [INFO ]  	test_batch_size: 1024
2022-10-03 13:14:31 [INFO ]  	
2022-10-03 13:14:33 [INFO ]  train dataset size:	73257
2022-10-03 13:14:33 [INFO ]  test dataset size: 	26032
2022-10-03 13:14:33 [INFO ]  datasets built!
2022-10-03 13:14:33 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:14:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:14:36 [INFO ]  
2022-10-03 13:14:36 [INFO ]  Begin of epoch 0 :
2022-10-03 13:14:40 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:14:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:14:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:14:40 [INFO ]  	   step  1 (lr=0.020000)                    6.87%                   8.4601
2022-10-03 13:14:40 [INFO ]  
2022-10-03 13:14:40 [INFO ]  Epoch:    0	Loss: 8.8051	Data Time: 0.47s	Train Time: 0.03s
2022-10-03 13:14:41 [INFO ]  Epoch:    1	Loss: 3.1878	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:14:43 [INFO ]  Epoch:    2	Loss: 2.9164	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:14:45 [INFO ]  Epoch:    3	Loss: 2.5384	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:14:47 [INFO ]  Epoch:    4	Loss: 2.3725	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:14:49 [INFO ]  Epoch:    5	Loss: 2.2692	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:14:51 [INFO ]  Epoch:    6	Loss: 2.2130	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:14:53 [INFO ]  Epoch:    7	Loss: 2.2122	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:15:02 [INFO ]  ======================================== 2022-10-03 13:15:02 ========================================
2022-10-03 13:15:02 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:15:02 [INFO ]  Options: 
2022-10-03 13:15:02 [INFO ]  	base_dir: null
2022-10-03 13:15:02 [INFO ]  	batch_size: 1024
2022-10-03 13:15:02 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:15:02 [INFO ]  	dataset: SVHN
2022-10-03 13:15:02 [INFO ]  	dataset_labels:
2022-10-03 13:15:02 [INFO ]  	- 0
2022-10-03 13:15:02 [INFO ]  	- 1
2022-10-03 13:15:02 [INFO ]  	- 2
2022-10-03 13:15:02 [INFO ]  	- 3
2022-10-03 13:15:02 [INFO ]  	- 4
2022-10-03 13:15:02 [INFO ]  	- 5
2022-10-03 13:15:02 [INFO ]  	- 6
2022-10-03 13:15:02 [INFO ]  	- 7
2022-10-03 13:15:02 [INFO ]  	- 8
2022-10-03 13:15:02 [INFO ]  	- 9
2022-10-03 13:15:02 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:15:02 [INFO ]  	- !!python/tuple
2022-10-03 13:15:02 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:15:02 [INFO ]  	    - 0.44398033618927
2022-10-03 13:15:02 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:15:02 [INFO ]  	- !!python/tuple
2022-10-03 13:15:02 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:15:02 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:15:02 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:15:02 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:15:02 [INFO ]  	decay_epochs: 50
2022-10-03 13:15:02 [INFO ]  	decay_factor: 0.1
2022-10-03 13:15:02 [INFO ]  	device_id: 0
2022-10-03 13:15:02 [INFO ]  	distill_epochs: 1
2022-10-03 13:15:02 [INFO ]  	distill_lr: 0.02
2022-10-03 13:15:02 [INFO ]  	distill_steps: 1
2022-10-03 13:15:02 [INFO ]  	epochs: 200
2022-10-03 13:15:02 [INFO ]  	expand_cls: false
2022-10-03 13:15:02 [INFO ]  	forgetting_dataset: null
2022-10-03 13:15:02 [INFO ]  	init: xavier
2022-10-03 13:15:02 [INFO ]  	init_param: 1.0
2022-10-03 13:15:02 [INFO ]  	input_size: 32
2022-10-03 13:15:02 [INFO ]  	ipc: 1
2022-10-03 13:15:02 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:15:02 [INFO ]  	log_interval: 100
2022-10-03 13:15:02 [INFO ]  	log_level: INFO
2022-10-03 13:15:02 [INFO ]  	lr: 0.01
2022-10-03 13:15:02 [INFO ]  	mode: distill_adapt
2022-10-03 13:15:02 [INFO ]  	nc: 3
2022-10-03 13:15:02 [INFO ]  	num_classes: 10
2022-10-03 13:15:02 [INFO ]  	num_workers: 8
2022-10-03 13:15:02 [INFO ]  	phase: train
2022-10-03 13:15:02 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:15:02 [INFO ]  	start_time: '2022-10-03 13:15:02'
2022-10-03 13:15:02 [INFO ]  	test_batch_size: 1024
2022-10-03 13:15:02 [INFO ]  	
2022-10-03 13:15:05 [INFO ]  train dataset size:	73257
2022-10-03 13:15:05 [INFO ]  test dataset size: 	26032
2022-10-03 13:15:05 [INFO ]  datasets built!
2022-10-03 13:15:05 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:15:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:15:08 [INFO ]  
2022-10-03 13:15:08 [INFO ]  Begin of epoch 0 :
2022-10-03 13:15:11 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:15:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:15:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:15:11 [INFO ]  	   step  1 (lr=0.020000)                    6.72%                   9.7228
2022-10-03 13:15:11 [INFO ]  
2022-10-03 13:15:11 [INFO ]  Epoch:    0	Loss: 10.2272	Data Time: 0.39s	Train Time: 0.03s
2022-10-03 13:15:13 [INFO ]  Epoch:    1	Loss: 3.2575	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:15:14 [INFO ]  Epoch:    2	Loss: 2.7246	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:16 [INFO ]  Epoch:    3	Loss: 2.4455	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:15:18 [INFO ]  Epoch:    4	Loss: 2.3093	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:15:20 [INFO ]  Epoch:    5	Loss: 2.2430	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:22 [INFO ]  Epoch:    6	Loss: 2.2192	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:24 [INFO ]  Epoch:    7	Loss: 2.1982	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:26 [INFO ]  Epoch:    8	Loss: 2.1726	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:15:28 [INFO ]  Epoch:    9	Loss: 2.1313	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:15:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 13:15:31 [INFO ]  
2022-10-03 13:15:31 [INFO ]  Begin of epoch 10 :
2022-10-03 13:15:34 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:15:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:15:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:15:34 [INFO ]  	   step  1 (lr=0.045917)                   28.81%                   2.1345
2022-10-03 13:15:34 [INFO ]  
2022-10-03 13:15:34 [INFO ]  Epoch:   10	Loss: 2.1358	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:36 [INFO ]  Epoch:   11	Loss: 2.1952	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:15:37 [INFO ]  Epoch:   12	Loss: 2.0975	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:15:39 [INFO ]  Epoch:   13	Loss: 2.0706	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:15:41 [INFO ]  Epoch:   14	Loss: 2.0174	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:43 [INFO ]  Epoch:   15	Loss: 2.0748	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:15:45 [INFO ]  Epoch:   16	Loss: 2.0251	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:15:46 [INFO ]  Epoch:   17	Loss: 2.0541	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:15:48 [INFO ]  Epoch:   18	Loss: 1.8280	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:15:50 [INFO ]  Epoch:   19	Loss: 1.8083	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:15:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 13:15:53 [INFO ]  
2022-10-03 13:15:53 [INFO ]  Begin of epoch 20 :
2022-10-03 13:15:56 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:15:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:15:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:15:56 [INFO ]  	   step  1 (lr=0.112158)                   23.49%                   2.3911
2022-10-03 13:15:56 [INFO ]  
2022-10-03 13:15:56 [INFO ]  Epoch:   20	Loss: 2.5277	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:15:58 [INFO ]  Epoch:   21	Loss: 1.7114	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:00 [INFO ]  Epoch:   22	Loss: 1.6114	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:16:02 [INFO ]  Epoch:   23	Loss: 2.2048	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:16:04 [INFO ]  Epoch:   24	Loss: 2.1056	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:06 [INFO ]  Epoch:   25	Loss: 1.9110	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:07 [INFO ]  Epoch:   26	Loss: 1.6975	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:16:09 [INFO ]  Epoch:   27	Loss: 1.6199	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:11 [INFO ]  Epoch:   28	Loss: 1.6157	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:13 [INFO ]  Epoch:   29	Loss: 1.6517	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 13:16:16 [INFO ]  
2022-10-03 13:16:16 [INFO ]  Begin of epoch 30 :
2022-10-03 13:16:19 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:16:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:16:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:16:19 [INFO ]  	   step  1 (lr=0.125906)                   47.08%                   1.6375
2022-10-03 13:16:19 [INFO ]  
2022-10-03 13:16:19 [INFO ]  Epoch:   30	Loss: 1.5678	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:16:21 [INFO ]  Epoch:   31	Loss: 1.5979	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:16:23 [INFO ]  Epoch:   32	Loss: 1.5376	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:24 [INFO ]  Epoch:   33	Loss: 1.4711	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:16:26 [INFO ]  Epoch:   34	Loss: 1.5451	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:28 [INFO ]  Epoch:   35	Loss: 1.5119	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:16:30 [INFO ]  Epoch:   36	Loss: 1.7401	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:16:32 [INFO ]  Epoch:   37	Loss: 1.5163	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:34 [INFO ]  Epoch:   38	Loss: 1.4267	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:16:36 [INFO ]  Epoch:   39	Loss: 1.4982	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 13:16:39 [INFO ]  
2022-10-03 13:16:39 [INFO ]  Begin of epoch 40 :
2022-10-03 13:16:42 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:16:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:16:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:16:42 [INFO ]  	   step  1 (lr=0.164413)                   55.00%                   1.4379
2022-10-03 13:16:42 [INFO ]  
2022-10-03 13:16:42 [INFO ]  Epoch:   40	Loss: 1.4229	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:44 [INFO ]  Epoch:   41	Loss: 1.3139	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:16:46 [INFO ]  Epoch:   42	Loss: 1.3830	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:48 [INFO ]  Epoch:   43	Loss: 1.6146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:50 [INFO ]  Epoch:   44	Loss: 1.4333	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:16:51 [INFO ]  Epoch:   45	Loss: 1.5219	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:16:53 [INFO ]  Epoch:   46	Loss: 1.3222	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:16:55 [INFO ]  Epoch:   47	Loss: 1.3918	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:16:57 [INFO ]  Epoch:   48	Loss: 1.6436	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:16:59 [INFO ]  Epoch:   49	Loss: 1.5990	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:17:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 13:17:02 [INFO ]  
2022-10-03 13:17:02 [INFO ]  Begin of epoch 50 :
2022-10-03 13:17:05 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:17:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:17:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:17:05 [INFO ]  	   step  1 (lr=0.176156)                   56.84%                   1.3982
2022-10-03 13:17:05 [INFO ]  
2022-10-03 13:17:05 [INFO ]  Epoch:   50	Loss: 1.4534	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:07 [INFO ]  Epoch:   51	Loss: 1.4208	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:17:09 [INFO ]  Epoch:   52	Loss: 1.3029	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:17:11 [INFO ]  Epoch:   53	Loss: 1.2965	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:12 [INFO ]  Epoch:   54	Loss: 1.3471	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:14 [INFO ]  Epoch:   55	Loss: 1.4151	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:16 [INFO ]  Epoch:   56	Loss: 1.3340	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:17:18 [INFO ]  Epoch:   57	Loss: 1.2749	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:17:20 [INFO ]  Epoch:   58	Loss: 1.2814	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:17:22 [INFO ]  Epoch:   59	Loss: 1.2625	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:17:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 13:17:25 [INFO ]  
2022-10-03 13:17:25 [INFO ]  Begin of epoch 60 :
2022-10-03 13:17:28 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:17:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:17:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:17:28 [INFO ]  	   step  1 (lr=0.184290)                   57.85%                   1.3601
2022-10-03 13:17:28 [INFO ]  
2022-10-03 13:17:28 [INFO ]  Epoch:   60	Loss: 1.3057	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:17:30 [INFO ]  Epoch:   61	Loss: 1.2495	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:17:31 [INFO ]  Epoch:   62	Loss: 1.1948	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:33 [INFO ]  Epoch:   63	Loss: 1.3117	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:17:35 [INFO ]  Epoch:   64	Loss: 1.2602	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:17:37 [INFO ]  Epoch:   65	Loss: 1.2436	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:17:39 [INFO ]  Epoch:   66	Loss: 1.1579	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:17:40 [INFO ]  Epoch:   67	Loss: 1.2377	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:17:42 [INFO ]  Epoch:   68	Loss: 1.1938	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:17:44 [INFO ]  Epoch:   69	Loss: 1.3180	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:17:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 13:17:47 [INFO ]  
2022-10-03 13:17:47 [INFO ]  Begin of epoch 70 :
2022-10-03 13:17:51 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:17:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:17:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:17:51 [INFO ]  	   step  1 (lr=0.190093)                   62.95%                   1.2532
2022-10-03 13:17:51 [INFO ]  
2022-10-03 13:17:51 [INFO ]  Epoch:   70	Loss: 1.2363	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 13:17:52 [INFO ]  Epoch:   71	Loss: 1.1775	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:17:54 [INFO ]  Epoch:   72	Loss: 1.2068	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:17:56 [INFO ]  Epoch:   73	Loss: 1.3087	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:17:58 [INFO ]  Epoch:   74	Loss: 1.2098	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:00 [INFO ]  Epoch:   75	Loss: 1.2837	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:18:02 [INFO ]  Epoch:   76	Loss: 1.5539	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:04 [INFO ]  Epoch:   77	Loss: 1.2572	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:06 [INFO ]  Epoch:   78	Loss: 1.2059	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:08 [INFO ]  Epoch:   79	Loss: 1.1969	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 13:18:11 [INFO ]  
2022-10-03 13:18:11 [INFO ]  Begin of epoch 80 :
2022-10-03 13:18:15 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:18:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:18:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:18:15 [INFO ]  	   step  1 (lr=0.199833)                   63.77%                   1.2237
2022-10-03 13:18:15 [INFO ]  
2022-10-03 13:18:15 [INFO ]  Epoch:   80	Loss: 1.1468	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:18:17 [INFO ]  Epoch:   81	Loss: 1.2088	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:18:18 [INFO ]  Epoch:   82	Loss: 1.5123	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:18:20 [INFO ]  Epoch:   83	Loss: 1.1479	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:22 [INFO ]  Epoch:   84	Loss: 1.2348	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:24 [INFO ]  Epoch:   85	Loss: 1.2552	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:26 [INFO ]  Epoch:   86	Loss: 1.3399	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:18:27 [INFO ]  Epoch:   87	Loss: 1.2869	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:18:29 [INFO ]  Epoch:   88	Loss: 1.2909	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:18:31 [INFO ]  Epoch:   89	Loss: 1.1516	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:18:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 13:18:34 [INFO ]  
2022-10-03 13:18:34 [INFO ]  Begin of epoch 90 :
2022-10-03 13:18:37 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:18:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:18:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:18:37 [INFO ]  	   step  1 (lr=0.197733)                   60.23%                   1.3159
2022-10-03 13:18:37 [INFO ]  
2022-10-03 13:18:37 [INFO ]  Epoch:   90	Loss: 1.2854	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:39 [INFO ]  Epoch:   91	Loss: 1.1324	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:18:41 [INFO ]  Epoch:   92	Loss: 1.2664	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:43 [INFO ]  Epoch:   93	Loss: 1.1816	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:45 [INFO ]  Epoch:   94	Loss: 1.1820	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:18:47 [INFO ]  Epoch:   95	Loss: 1.2123	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:49 [INFO ]  Epoch:   96	Loss: 1.2279	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:18:50 [INFO ]  Epoch:   97	Loss: 1.2013	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:18:52 [INFO ]  Epoch:   98	Loss: 1.1558	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:18:54 [INFO ]  Epoch:   99	Loss: 1.2356	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:18:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 13:18:57 [INFO ]  
2022-10-03 13:18:57 [INFO ]  Begin of epoch 100 :
2022-10-03 13:19:00 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:19:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:19:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:19:00 [INFO ]  	   step  1 (lr=0.199004)                   63.24%                   1.2422
2022-10-03 13:19:00 [INFO ]  
2022-10-03 13:19:00 [INFO ]  Epoch:  100	Loss: 1.1669	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:19:02 [INFO ]  Epoch:  101	Loss: 1.1803	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:04 [INFO ]  Epoch:  102	Loss: 1.1171	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:19:06 [INFO ]  Epoch:  103	Loss: 1.2229	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:19:07 [INFO ]  Epoch:  104	Loss: 1.1796	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:19:09 [INFO ]  Epoch:  105	Loss: 1.1745	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:19:11 [INFO ]  Epoch:  106	Loss: 1.1589	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:19:13 [INFO ]  Epoch:  107	Loss: 1.1240	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:15 [INFO ]  Epoch:  108	Loss: 1.1866	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:19:17 [INFO ]  Epoch:  109	Loss: 1.1511	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 13:19:20 [INFO ]  
2022-10-03 13:19:20 [INFO ]  Begin of epoch 110 :
2022-10-03 13:19:23 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:19:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:19:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:19:23 [INFO ]  	   step  1 (lr=0.202346)                   64.12%                   1.2200
2022-10-03 13:19:23 [INFO ]  
2022-10-03 13:19:23 [INFO ]  Epoch:  110	Loss: 1.1878	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:25 [INFO ]  Epoch:  111	Loss: 1.1460	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:19:27 [INFO ]  Epoch:  112	Loss: 1.1094	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:29 [INFO ]  Epoch:  113	Loss: 1.2567	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:19:31 [INFO ]  Epoch:  114	Loss: 1.2423	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:19:33 [INFO ]  Epoch:  115	Loss: 1.2994	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:19:35 [INFO ]  Epoch:  116	Loss: 1.2125	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:19:37 [INFO ]  Epoch:  117	Loss: 1.1716	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:19:39 [INFO ]  Epoch:  118	Loss: 1.3052	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:19:41 [INFO ]  Epoch:  119	Loss: 1.3209	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:19:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 13:19:44 [INFO ]  
2022-10-03 13:19:44 [INFO ]  Begin of epoch 120 :
2022-10-03 13:19:47 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:19:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:19:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:19:47 [INFO ]  	   step  1 (lr=0.200738)                   63.78%                   1.2387
2022-10-03 13:19:47 [INFO ]  
2022-10-03 13:19:47 [INFO ]  Epoch:  120	Loss: 1.1780	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:19:49 [INFO ]  Epoch:  121	Loss: 1.1811	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:51 [INFO ]  Epoch:  122	Loss: 1.2298	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:19:53 [INFO ]  Epoch:  123	Loss: 1.2578	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:19:54 [INFO ]  Epoch:  124	Loss: 1.1974	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:19:56 [INFO ]  Epoch:  125	Loss: 1.1658	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:19:58 [INFO ]  Epoch:  126	Loss: 1.2594	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:00 [INFO ]  Epoch:  127	Loss: 1.2520	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:20:02 [INFO ]  Epoch:  128	Loss: 1.2400	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:20:03 [INFO ]  Epoch:  129	Loss: 1.2445	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:20:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 13:20:07 [INFO ]  
2022-10-03 13:20:07 [INFO ]  Begin of epoch 130 :
2022-10-03 13:20:10 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:20:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:20:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:20:10 [INFO ]  	   step  1 (lr=0.200046)                   62.82%                   1.2402
2022-10-03 13:20:10 [INFO ]  
2022-10-03 13:20:10 [INFO ]  Epoch:  130	Loss: 1.1750	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:12 [INFO ]  Epoch:  131	Loss: 1.2085	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:20:14 [INFO ]  Epoch:  132	Loss: 1.1929	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:20:15 [INFO ]  Epoch:  133	Loss: 1.1368	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:20:18 [INFO ]  Epoch:  134	Loss: 1.1367	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 13:20:19 [INFO ]  Epoch:  135	Loss: 1.2025	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:20:21 [INFO ]  Epoch:  136	Loss: 1.2239	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:23 [INFO ]  Epoch:  137	Loss: 1.1854	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:20:25 [INFO ]  Epoch:  138	Loss: 1.2017	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:27 [INFO ]  Epoch:  139	Loss: 1.2950	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:20:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 13:20:30 [INFO ]  
2022-10-03 13:20:30 [INFO ]  Begin of epoch 140 :
2022-10-03 13:20:33 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:20:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:20:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:20:33 [INFO ]  	   step  1 (lr=0.200724)                   62.11%                   1.2732
2022-10-03 13:20:33 [INFO ]  
2022-10-03 13:20:33 [INFO ]  Epoch:  140	Loss: 1.2033	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:20:35 [INFO ]  Epoch:  141	Loss: 1.2828	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:37 [INFO ]  Epoch:  142	Loss: 1.2520	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:20:39 [INFO ]  Epoch:  143	Loss: 1.1639	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:41 [INFO ]  Epoch:  144	Loss: 1.1680	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:20:42 [INFO ]  Epoch:  145	Loss: 1.1434	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:20:44 [INFO ]  Epoch:  146	Loss: 1.2002	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:20:46 [INFO ]  Epoch:  147	Loss: 1.2050	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:20:48 [INFO ]  Epoch:  148	Loss: 1.1249	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:20:50 [INFO ]  Epoch:  149	Loss: 1.1506	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:20:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 13:20:53 [INFO ]  
2022-10-03 13:20:53 [INFO ]  Begin of epoch 150 :
2022-10-03 13:20:56 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:20:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:20:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:20:56 [INFO ]  	   step  1 (lr=0.198733)                   64.46%                   1.2083
2022-10-03 13:20:56 [INFO ]  
2022-10-03 13:20:56 [INFO ]  Epoch:  150	Loss: 1.1895	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:20:58 [INFO ]  Epoch:  151	Loss: 1.1285	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:21:00 [INFO ]  Epoch:  152	Loss: 1.1155	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:21:02 [INFO ]  Epoch:  153	Loss: 1.1770	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:21:04 [INFO ]  Epoch:  154	Loss: 1.1384	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:21:05 [INFO ]  Epoch:  155	Loss: 1.0523	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:07 [INFO ]  Epoch:  156	Loss: 1.0911	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:21:09 [INFO ]  Epoch:  157	Loss: 1.1676	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:11 [INFO ]  Epoch:  158	Loss: 1.1570	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:13 [INFO ]  Epoch:  159	Loss: 1.1839	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:21:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 13:21:16 [INFO ]  
2022-10-03 13:21:16 [INFO ]  Begin of epoch 160 :
2022-10-03 13:21:19 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:21:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:21:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:21:19 [INFO ]  	   step  1 (lr=0.199121)                   64.77%                   1.1950
2022-10-03 13:21:19 [INFO ]  
2022-10-03 13:21:19 [INFO ]  Epoch:  160	Loss: 1.1479	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:21:21 [INFO ]  Epoch:  161	Loss: 1.1919	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:21:23 [INFO ]  Epoch:  162	Loss: 1.2351	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:25 [INFO ]  Epoch:  163	Loss: 1.1537	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:21:27 [INFO ]  Epoch:  164	Loss: 1.1808	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:28 [INFO ]  Epoch:  165	Loss: 1.1414	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:21:30 [INFO ]  Epoch:  166	Loss: 1.0898	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:21:32 [INFO ]  Epoch:  167	Loss: 1.1617	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:21:34 [INFO ]  Epoch:  168	Loss: 1.2030	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:21:35 [INFO ]  Epoch:  169	Loss: 1.2392	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 13:21:39 [INFO ]  
2022-10-03 13:21:39 [INFO ]  Begin of epoch 170 :
2022-10-03 13:21:42 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:21:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:21:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:21:42 [INFO ]  	   step  1 (lr=0.199058)                   64.31%                   1.2052
2022-10-03 13:21:42 [INFO ]  
2022-10-03 13:21:42 [INFO ]  Epoch:  170	Loss: 1.1913	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:21:43 [INFO ]  Epoch:  171	Loss: 1.2246	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:45 [INFO ]  Epoch:  172	Loss: 1.2366	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:21:47 [INFO ]  Epoch:  173	Loss: 1.1770	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:21:49 [INFO ]  Epoch:  174	Loss: 1.1762	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:21:51 [INFO ]  Epoch:  175	Loss: 1.2393	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:21:52 [INFO ]  Epoch:  176	Loss: 1.0925	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:54 [INFO ]  Epoch:  177	Loss: 1.1834	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:21:56 [INFO ]  Epoch:  178	Loss: 1.2391	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:21:58 [INFO ]  Epoch:  179	Loss: 1.1307	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 13:22:01 [INFO ]  
2022-10-03 13:22:01 [INFO ]  Begin of epoch 180 :
2022-10-03 13:22:05 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:22:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:22:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:22:05 [INFO ]  	   step  1 (lr=0.198925)                   64.45%                   1.2008
2022-10-03 13:22:05 [INFO ]  
2022-10-03 13:22:05 [INFO ]  Epoch:  180	Loss: 1.2404	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:22:07 [INFO ]  Epoch:  181	Loss: 1.0957	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:22:09 [INFO ]  Epoch:  182	Loss: 1.1454	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:22:11 [INFO ]  Epoch:  183	Loss: 1.2234	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:13 [INFO ]  Epoch:  184	Loss: 1.1923	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:14 [INFO ]  Epoch:  185	Loss: 1.1650	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:16 [INFO ]  Epoch:  186	Loss: 1.2070	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:22:18 [INFO ]  Epoch:  187	Loss: 1.1325	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:22:20 [INFO ]  Epoch:  188	Loss: 1.1705	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:22 [INFO ]  Epoch:  189	Loss: 1.1532	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 13:22:25 [INFO ]  
2022-10-03 13:22:25 [INFO ]  Begin of epoch 190 :
2022-10-03 13:22:28 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:22:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:22:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:22:28 [INFO ]  	   step  1 (lr=0.198724)                   64.67%                   1.2004
2022-10-03 13:22:28 [INFO ]  
2022-10-03 13:22:29 [INFO ]  Epoch:  190	Loss: 1.2153	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:22:30 [INFO ]  Epoch:  191	Loss: 1.1322	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:22:32 [INFO ]  Epoch:  192	Loss: 1.1415	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:22:34 [INFO ]  Epoch:  193	Loss: 1.1378	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:36 [INFO ]  Epoch:  194	Loss: 1.1148	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:22:38 [INFO ]  Epoch:  195	Loss: 1.1988	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:40 [INFO ]  Epoch:  196	Loss: 1.1404	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:42 [INFO ]  Epoch:  197	Loss: 1.1586	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:22:43 [INFO ]  Epoch:  198	Loss: 1.1413	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:22:45 [INFO ]  Epoch:  199	Loss: 1.1561	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:22:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 13:22:48 [INFO ]  
2022-10-03 13:22:48 [INFO ]  Final evaluation for SVHN :
2022-10-03 13:22:51 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:22:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:22:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:22:51 [INFO ]  	   step  1 (lr=0.198531)                   64.96%                   1.1962
2022-10-03 13:22:51 [INFO ]  
2022-10-03 13:22:51 [INFO ]  
2022-10-03 13:22:51 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 13:22:54 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:22:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:22:54 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 13:22:54 [INFO ]  	   step  1 (lr=0.198531)                   21.12%                   4.9502
2022-10-03 13:22:54 [INFO ]  
2022-10-03 13:22:54 [INFO ]  CPU Time: 274.815795019 seconds
2022-10-03 13:25:53 [INFO ]  ======================================== 2022-10-03 13:25:53 ========================================
2022-10-03 13:25:53 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:25:53 [INFO ]  Options: 
2022-10-03 13:25:53 [INFO ]  	base_dir: null
2022-10-03 13:25:53 [INFO ]  	batch_size: 1024
2022-10-03 13:25:53 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:25:53 [INFO ]  	dataset: SVHN
2022-10-03 13:25:53 [INFO ]  	dataset_labels:
2022-10-03 13:25:53 [INFO ]  	- 0
2022-10-03 13:25:53 [INFO ]  	- 1
2022-10-03 13:25:53 [INFO ]  	- 2
2022-10-03 13:25:53 [INFO ]  	- 3
2022-10-03 13:25:53 [INFO ]  	- 4
2022-10-03 13:25:53 [INFO ]  	- 5
2022-10-03 13:25:53 [INFO ]  	- 6
2022-10-03 13:25:53 [INFO ]  	- 7
2022-10-03 13:25:53 [INFO ]  	- 8
2022-10-03 13:25:53 [INFO ]  	- 9
2022-10-03 13:25:53 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:25:53 [INFO ]  	- !!python/tuple
2022-10-03 13:25:53 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:25:53 [INFO ]  	    - 0.44398033618927
2022-10-03 13:25:53 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:25:53 [INFO ]  	- !!python/tuple
2022-10-03 13:25:53 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:25:53 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:25:53 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:25:53 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:25:53 [INFO ]  	decay_epochs: 50
2022-10-03 13:25:53 [INFO ]  	decay_factor: 0.1
2022-10-03 13:25:53 [INFO ]  	device_id: 0
2022-10-03 13:25:53 [INFO ]  	distill_epochs: 1
2022-10-03 13:25:53 [INFO ]  	distill_lr: 0.02
2022-10-03 13:25:53 [INFO ]  	distill_steps: 1
2022-10-03 13:25:53 [INFO ]  	epochs: 200
2022-10-03 13:25:53 [INFO ]  	expand_cls: false
2022-10-03 13:25:53 [INFO ]  	forgetting_dataset: null
2022-10-03 13:25:53 [INFO ]  	init: xavier
2022-10-03 13:25:53 [INFO ]  	init_param: 1.0
2022-10-03 13:25:53 [INFO ]  	input_size: 32
2022-10-03 13:25:53 [INFO ]  	ipc: 1
2022-10-03 13:25:53 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:25:53 [INFO ]  	log_interval: 100
2022-10-03 13:25:53 [INFO ]  	log_level: INFO
2022-10-03 13:25:53 [INFO ]  	lr: 0.01
2022-10-03 13:25:53 [INFO ]  	mode: distill_adapt
2022-10-03 13:25:53 [INFO ]  	nc: 3
2022-10-03 13:25:53 [INFO ]  	num_classes: 10
2022-10-03 13:25:53 [INFO ]  	num_workers: 8
2022-10-03 13:25:53 [INFO ]  	phase: train
2022-10-03 13:25:53 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:25:53 [INFO ]  	start_time: '2022-10-03 13:25:53'
2022-10-03 13:25:53 [INFO ]  	test_batch_size: 1024
2022-10-03 13:25:53 [INFO ]  	
2022-10-03 13:25:55 [INFO ]  train dataset size:	73257
2022-10-03 13:25:55 [INFO ]  test dataset size: 	26032
2022-10-03 13:25:55 [INFO ]  datasets built!
2022-10-03 13:25:55 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:26:07 [INFO ]  ======================================== 2022-10-03 13:26:07 ========================================
2022-10-03 13:26:07 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:26:07 [INFO ]  Options: 
2022-10-03 13:26:07 [INFO ]  	base_dir: null
2022-10-03 13:26:07 [INFO ]  	batch_size: 1024
2022-10-03 13:26:07 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:26:07 [INFO ]  	dataset: SVHN
2022-10-03 13:26:07 [INFO ]  	dataset_labels:
2022-10-03 13:26:07 [INFO ]  	- 0
2022-10-03 13:26:07 [INFO ]  	- 1
2022-10-03 13:26:07 [INFO ]  	- 2
2022-10-03 13:26:07 [INFO ]  	- 3
2022-10-03 13:26:07 [INFO ]  	- 4
2022-10-03 13:26:07 [INFO ]  	- 5
2022-10-03 13:26:07 [INFO ]  	- 6
2022-10-03 13:26:07 [INFO ]  	- 7
2022-10-03 13:26:07 [INFO ]  	- 8
2022-10-03 13:26:07 [INFO ]  	- 9
2022-10-03 13:26:07 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:26:07 [INFO ]  	- !!python/tuple
2022-10-03 13:26:07 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:26:07 [INFO ]  	    - 0.44398033618927
2022-10-03 13:26:07 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:26:07 [INFO ]  	- !!python/tuple
2022-10-03 13:26:07 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:26:07 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:26:07 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:26:07 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:26:07 [INFO ]  	decay_epochs: 50
2022-10-03 13:26:07 [INFO ]  	decay_factor: 0.1
2022-10-03 13:26:07 [INFO ]  	device_id: 0
2022-10-03 13:26:07 [INFO ]  	distill_epochs: 1
2022-10-03 13:26:07 [INFO ]  	distill_lr: 0.02
2022-10-03 13:26:07 [INFO ]  	distill_steps: 1
2022-10-03 13:26:07 [INFO ]  	epochs: 200
2022-10-03 13:26:07 [INFO ]  	expand_cls: false
2022-10-03 13:26:07 [INFO ]  	forgetting_dataset: null
2022-10-03 13:26:07 [INFO ]  	init: xavier
2022-10-03 13:26:07 [INFO ]  	init_param: 1.0
2022-10-03 13:26:07 [INFO ]  	input_size: 32
2022-10-03 13:26:07 [INFO ]  	ipc: 1
2022-10-03 13:26:07 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:26:07 [INFO ]  	log_interval: 100
2022-10-03 13:26:07 [INFO ]  	log_level: INFO
2022-10-03 13:26:07 [INFO ]  	lr: 0.01
2022-10-03 13:26:07 [INFO ]  	mode: distill_adapt
2022-10-03 13:26:07 [INFO ]  	nc: 3
2022-10-03 13:26:07 [INFO ]  	num_classes: 10
2022-10-03 13:26:07 [INFO ]  	num_workers: 8
2022-10-03 13:26:07 [INFO ]  	phase: train
2022-10-03 13:26:07 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:26:07 [INFO ]  	start_time: '2022-10-03 13:26:07'
2022-10-03 13:26:07 [INFO ]  	test_batch_size: 1024
2022-10-03 13:26:07 [INFO ]  	
2022-10-03 13:26:09 [INFO ]  train dataset size:	73257
2022-10-03 13:26:09 [INFO ]  test dataset size: 	26032
2022-10-03 13:26:09 [INFO ]  datasets built!
2022-10-03 13:26:09 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:26:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:26:12 [INFO ]  
2022-10-03 13:26:12 [INFO ]  Begin of epoch 0 :
2022-10-03 13:26:15 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:26:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:26:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:26:15 [INFO ]  	   step  1 (lr=0.020000)                   17.77%                   8.9762
2022-10-03 13:26:15 [INFO ]  
2022-10-03 13:26:15 [INFO ]  Epoch:    0	Loss: 9.5639	Data Time: 0.44s	Train Time: 0.03s
2022-10-03 13:26:17 [INFO ]  Epoch:    1	Loss: 3.2542	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:26:18 [INFO ]  Epoch:    2	Loss: 2.5441	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:26:20 [INFO ]  Epoch:    3	Loss: 2.2793	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:26:22 [INFO ]  Epoch:    4	Loss: 2.2503	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:26:24 [INFO ]  Epoch:    5	Loss: 2.2232	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:26:26 [INFO ]  Epoch:    6	Loss: 2.1865	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:26:28 [INFO ]  Epoch:    7	Loss: 2.1408	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:26:30 [INFO ]  Epoch:    8	Loss: 2.1415	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:26:32 [INFO ]  Epoch:    9	Loss: 2.0813	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:26:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 13:26:35 [INFO ]  
2022-10-03 13:26:35 [INFO ]  Begin of epoch 10 :
2022-10-03 13:26:38 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:26:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:26:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:26:38 [INFO ]  	   step  1 (lr=0.050425)                   32.79%                   2.0476
2022-10-03 13:26:38 [INFO ]  
2022-10-03 13:26:38 [INFO ]  Epoch:   10	Loss: 2.0442	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:26:40 [INFO ]  Epoch:   11	Loss: 2.0486	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:26:42 [INFO ]  Epoch:   12	Loss: 2.2159	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:26:44 [INFO ]  Epoch:   13	Loss: 1.9935	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:26:46 [INFO ]  Epoch:   14	Loss: 1.8565	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:26:48 [INFO ]  Epoch:   15	Loss: 1.8878	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:26:49 [INFO ]  Epoch:   16	Loss: 1.7957	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:26:51 [INFO ]  Epoch:   17	Loss: 1.6890	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:26:53 [INFO ]  Epoch:   18	Loss: 1.6756	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:26:55 [INFO ]  Epoch:   19	Loss: 1.7194	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:26:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 13:26:58 [INFO ]  
2022-10-03 13:26:58 [INFO ]  Begin of epoch 20 :
2022-10-03 13:27:02 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:27:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:27:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:27:02 [INFO ]  	   step  1 (lr=0.107521)                   41.66%                   1.8265
2022-10-03 13:27:02 [INFO ]  
2022-10-03 13:27:02 [INFO ]  Epoch:   20	Loss: 1.7091	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 13:27:03 [INFO ]  Epoch:   21	Loss: 1.6088	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:05 [INFO ]  Epoch:   22	Loss: 1.5011	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:27:07 [INFO ]  Epoch:   23	Loss: 1.5615	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:27:09 [INFO ]  Epoch:   24	Loss: 1.4127	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:27:11 [INFO ]  Epoch:   25	Loss: 1.4555	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:27:12 [INFO ]  Epoch:   26	Loss: 1.4551	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:27:14 [INFO ]  Epoch:   27	Loss: 1.2991	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:16 [INFO ]  Epoch:   28	Loss: 1.2426	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:27:18 [INFO ]  Epoch:   29	Loss: 1.3001	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:27:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 13:27:21 [INFO ]  
2022-10-03 13:27:21 [INFO ]  Begin of epoch 30 :
2022-10-03 13:27:24 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:27:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:27:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:27:24 [INFO ]  	   step  1 (lr=0.170390)                   59.11%                   1.3186
2022-10-03 13:27:24 [INFO ]  
2022-10-03 13:27:24 [INFO ]  Epoch:   30	Loss: 1.2597	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:27:26 [INFO ]  Epoch:   31	Loss: 1.3366	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:28 [INFO ]  Epoch:   32	Loss: 1.3134	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:27:30 [INFO ]  Epoch:   33	Loss: 1.3427	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:27:32 [INFO ]  Epoch:   34	Loss: 1.3337	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:27:34 [INFO ]  Epoch:   35	Loss: 1.2356	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:27:36 [INFO ]  Epoch:   36	Loss: 1.3990	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 13:27:37 [INFO ]  Epoch:   37	Loss: 1.2135	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:39 [INFO ]  Epoch:   38	Loss: 1.1385	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:41 [INFO ]  Epoch:   39	Loss: 1.3627	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:27:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 13:27:44 [INFO ]  
2022-10-03 13:27:44 [INFO ]  Begin of epoch 40 :
2022-10-03 13:27:47 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:27:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:27:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:27:47 [INFO ]  	   step  1 (lr=0.204672)                   48.01%                   1.9456
2022-10-03 13:27:47 [INFO ]  
2022-10-03 13:27:47 [INFO ]  Epoch:   40	Loss: 1.8754	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:49 [INFO ]  Epoch:   41	Loss: 1.0989	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:27:51 [INFO ]  Epoch:   42	Loss: 1.5809	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:27:53 [INFO ]  Epoch:   43	Loss: 1.4671	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:27:54 [INFO ]  Epoch:   44	Loss: 1.4588	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:27:56 [INFO ]  Epoch:   45	Loss: 1.1768	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:27:58 [INFO ]  Epoch:   46	Loss: 1.0987	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:28:00 [INFO ]  Epoch:   47	Loss: 1.1756	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:28:02 [INFO ]  Epoch:   48	Loss: 1.3829	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:28:04 [INFO ]  Epoch:   49	Loss: 1.0759	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:28:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 13:28:07 [INFO ]  
2022-10-03 13:28:07 [INFO ]  Begin of epoch 50 :
2022-10-03 13:28:11 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:28:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:28:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:28:11 [INFO ]  	   step  1 (lr=0.205189)                   67.37%                   1.1223
2022-10-03 13:28:11 [INFO ]  
2022-10-03 13:28:11 [INFO ]  Epoch:   50	Loss: 1.0685	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:28:12 [INFO ]  Epoch:   51	Loss: 1.0293	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:28:14 [INFO ]  Epoch:   52	Loss: 1.5429	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:16 [INFO ]  Epoch:   53	Loss: 1.1361	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:17 [INFO ]  Epoch:   54	Loss: 1.1199	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:19 [INFO ]  Epoch:   55	Loss: 1.2116	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:21 [INFO ]  Epoch:   56	Loss: 1.1330	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:28:23 [INFO ]  Epoch:   57	Loss: 1.1287	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:25 [INFO ]  Epoch:   58	Loss: 1.2659	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:28:26 [INFO ]  Epoch:   59	Loss: 1.1858	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 13:28:29 [INFO ]  
2022-10-03 13:28:29 [INFO ]  Begin of epoch 60 :
2022-10-03 13:28:33 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:28:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:28:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:28:33 [INFO ]  	   step  1 (lr=0.214244)                   65.85%                   1.1500
2022-10-03 13:28:33 [INFO ]  
2022-10-03 13:28:33 [INFO ]  Epoch:   60	Loss: 1.0821	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:28:34 [INFO ]  Epoch:   61	Loss: 1.1850	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:28:36 [INFO ]  Epoch:   62	Loss: 1.0335	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:38 [INFO ]  Epoch:   63	Loss: 1.0903	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:40 [INFO ]  Epoch:   64	Loss: 1.1088	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:42 [INFO ]  Epoch:   65	Loss: 1.0817	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:28:43 [INFO ]  Epoch:   66	Loss: 1.1712	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:28:45 [INFO ]  Epoch:   67	Loss: 1.0369	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:47 [INFO ]  Epoch:   68	Loss: 1.3038	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:49 [INFO ]  Epoch:   69	Loss: 1.1970	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:28:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 13:28:52 [INFO ]  
2022-10-03 13:28:52 [INFO ]  Begin of epoch 70 :
2022-10-03 13:28:55 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:28:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:28:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:28:55 [INFO ]  	   step  1 (lr=0.213902)                   60.38%                   1.2796
2022-10-03 13:28:55 [INFO ]  
2022-10-03 13:28:55 [INFO ]  Epoch:   70	Loss: 1.1488	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:28:57 [INFO ]  Epoch:   71	Loss: 1.1901	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:28:59 [INFO ]  Epoch:   72	Loss: 1.0271	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:01 [INFO ]  Epoch:   73	Loss: 1.0126	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:03 [INFO ]  Epoch:   74	Loss: 1.1030	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:29:04 [INFO ]  Epoch:   75	Loss: 1.0440	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:29:07 [INFO ]  Epoch:   76	Loss: 1.0721	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:29:08 [INFO ]  Epoch:   77	Loss: 1.0847	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:29:10 [INFO ]  Epoch:   78	Loss: 1.5046	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:29:12 [INFO ]  Epoch:   79	Loss: 1.1061	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 13:29:16 [INFO ]  
2022-10-03 13:29:16 [INFO ]  Begin of epoch 80 :
2022-10-03 13:29:19 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:29:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:29:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:29:19 [INFO ]  	   step  1 (lr=0.231135)                   60.68%                   1.3268
2022-10-03 13:29:19 [INFO ]  
2022-10-03 13:29:19 [INFO ]  Epoch:   80	Loss: 1.1604	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:21 [INFO ]  Epoch:   81	Loss: 1.0209	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:29:23 [INFO ]  Epoch:   82	Loss: 0.9571	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:29:25 [INFO ]  Epoch:   83	Loss: 1.1044	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:27 [INFO ]  Epoch:   84	Loss: 1.3434	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:29:28 [INFO ]  Epoch:   85	Loss: 1.2042	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:30 [INFO ]  Epoch:   86	Loss: 1.0762	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:32 [INFO ]  Epoch:   87	Loss: 1.0453	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:34 [INFO ]  Epoch:   88	Loss: 1.0943	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:29:36 [INFO ]  Epoch:   89	Loss: 1.0848	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 13:29:39 [INFO ]  
2022-10-03 13:29:39 [INFO ]  Begin of epoch 90 :
2022-10-03 13:29:42 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:29:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:29:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:29:42 [INFO ]  	   step  1 (lr=0.221173)                   61.94%                   1.2998
2022-10-03 13:29:42 [INFO ]  
2022-10-03 13:29:42 [INFO ]  Epoch:   90	Loss: 1.1357	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:44 [INFO ]  Epoch:   91	Loss: 1.0520	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:29:46 [INFO ]  Epoch:   92	Loss: 0.9965	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:47 [INFO ]  Epoch:   93	Loss: 1.2995	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:29:49 [INFO ]  Epoch:   94	Loss: 1.0141	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:29:51 [INFO ]  Epoch:   95	Loss: 1.0045	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:53 [INFO ]  Epoch:   96	Loss: 0.9873	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:29:55 [INFO ]  Epoch:   97	Loss: 1.1645	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:29:56 [INFO ]  Epoch:   98	Loss: 0.9803	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:29:58 [INFO ]  Epoch:   99	Loss: 1.1653	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:30:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 13:30:01 [INFO ]  
2022-10-03 13:30:01 [INFO ]  Begin of epoch 100 :
2022-10-03 13:30:05 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:30:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:30:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:30:05 [INFO ]  	   step  1 (lr=0.224621)                   68.59%                   1.0660
2022-10-03 13:30:05 [INFO ]  
2022-10-03 13:30:05 [INFO ]  Epoch:  100	Loss: 0.9862	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:06 [INFO ]  Epoch:  101	Loss: 1.0047	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:30:08 [INFO ]  Epoch:  102	Loss: 1.0157	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:30:10 [INFO ]  Epoch:  103	Loss: 1.0057	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:30:12 [INFO ]  Epoch:  104	Loss: 1.3124	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:14 [INFO ]  Epoch:  105	Loss: 1.0471	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:30:16 [INFO ]  Epoch:  106	Loss: 1.0661	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:30:17 [INFO ]  Epoch:  107	Loss: 1.0087	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:30:19 [INFO ]  Epoch:  108	Loss: 1.0197	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:30:21 [INFO ]  Epoch:  109	Loss: 3.8733	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 13:30:24 [INFO ]  
2022-10-03 13:30:24 [INFO ]  Begin of epoch 110 :
2022-10-03 13:30:28 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:30:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:30:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:30:28 [INFO ]  	   step  1 (lr=0.227804)                   68.43%                   1.0725
2022-10-03 13:30:28 [INFO ]  
2022-10-03 13:30:28 [INFO ]  Epoch:  110	Loss: 1.0125	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:30:30 [INFO ]  Epoch:  111	Loss: 1.1003	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:30:32 [INFO ]  Epoch:  112	Loss: 1.0405	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:30:34 [INFO ]  Epoch:  113	Loss: 1.0731	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:30:36 [INFO ]  Epoch:  114	Loss: 1.3707	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:30:38 [INFO ]  Epoch:  115	Loss: 1.0175	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:30:39 [INFO ]  Epoch:  116	Loss: 0.9970	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:30:42 [INFO ]  Epoch:  117	Loss: 0.9575	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:30:43 [INFO ]  Epoch:  118	Loss: 0.9657	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:45 [INFO ]  Epoch:  119	Loss: 1.0102	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:30:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 13:30:49 [INFO ]  
2022-10-03 13:30:49 [INFO ]  Begin of epoch 120 :
2022-10-03 13:30:52 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:30:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:30:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:30:52 [INFO ]  	   step  1 (lr=0.227983)                   69.77%                   1.0533
2022-10-03 13:30:52 [INFO ]  
2022-10-03 13:30:52 [INFO ]  Epoch:  120	Loss: 1.0491	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:30:54 [INFO ]  Epoch:  121	Loss: 1.0076	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:30:56 [INFO ]  Epoch:  122	Loss: 1.0468	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:58 [INFO ]  Epoch:  123	Loss: 0.9762	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:30:59 [INFO ]  Epoch:  124	Loss: 1.0159	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:01 [INFO ]  Epoch:  125	Loss: 1.2916	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:31:03 [INFO ]  Epoch:  126	Loss: 1.0024	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:05 [INFO ]  Epoch:  127	Loss: 1.0532	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:07 [INFO ]  Epoch:  128	Loss: 0.9822	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:09 [INFO ]  Epoch:  129	Loss: 0.9906	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:31:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 13:31:12 [INFO ]  
2022-10-03 13:31:12 [INFO ]  Begin of epoch 130 :
2022-10-03 13:31:15 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:31:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:31:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:31:15 [INFO ]  	   step  1 (lr=0.229215)                   69.39%                   1.0558
2022-10-03 13:31:15 [INFO ]  
2022-10-03 13:31:15 [INFO ]  Epoch:  130	Loss: 1.0291	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:31:17 [INFO ]  Epoch:  131	Loss: 0.9647	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:19 [INFO ]  Epoch:  132	Loss: 1.0508	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:21 [INFO ]  Epoch:  133	Loss: 0.9472	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:22 [INFO ]  Epoch:  134	Loss: 0.9490	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:24 [INFO ]  Epoch:  135	Loss: 1.0100	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:31:26 [INFO ]  Epoch:  136	Loss: 1.0239	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:31:28 [INFO ]  Epoch:  137	Loss: 1.1030	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:31:30 [INFO ]  Epoch:  138	Loss: 1.0149	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:32 [INFO ]  Epoch:  139	Loss: 1.0161	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 13:31:35 [INFO ]  
2022-10-03 13:31:35 [INFO ]  Begin of epoch 140 :
2022-10-03 13:31:38 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:31:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:31:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:31:38 [INFO ]  	   step  1 (lr=0.230157)                   69.48%                   1.0557
2022-10-03 13:31:38 [INFO ]  
2022-10-03 13:31:38 [INFO ]  Epoch:  140	Loss: 0.9878	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:31:40 [INFO ]  Epoch:  141	Loss: 1.2307	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:31:42 [INFO ]  Epoch:  142	Loss: 1.0049	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:31:44 [INFO ]  Epoch:  143	Loss: 0.9417	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:46 [INFO ]  Epoch:  144	Loss: 1.0857	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:48 [INFO ]  Epoch:  145	Loss: 1.0493	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:31:49 [INFO ]  Epoch:  146	Loss: 1.0604	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:31:51 [INFO ]  Epoch:  147	Loss: 1.0324	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:31:53 [INFO ]  Epoch:  148	Loss: 1.0000	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:31:55 [INFO ]  Epoch:  149	Loss: 1.0103	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:31:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 13:31:58 [INFO ]  
2022-10-03 13:31:58 [INFO ]  Begin of epoch 150 :
2022-10-03 13:32:01 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:32:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:32:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:32:01 [INFO ]  	   step  1 (lr=0.231168)                   70.04%                   1.0361
2022-10-03 13:32:01 [INFO ]  
2022-10-03 13:32:01 [INFO ]  Epoch:  150	Loss: 1.0478	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:03 [INFO ]  Epoch:  151	Loss: 1.2569	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:32:05 [INFO ]  Epoch:  152	Loss: 1.0115	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:32:07 [INFO ]  Epoch:  153	Loss: 1.0164	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:32:09 [INFO ]  Epoch:  154	Loss: 1.0334	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:11 [INFO ]  Epoch:  155	Loss: 1.0653	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:32:12 [INFO ]  Epoch:  156	Loss: 1.0215	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:14 [INFO ]  Epoch:  157	Loss: 0.9702	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:16 [INFO ]  Epoch:  158	Loss: 1.0161	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:32:18 [INFO ]  Epoch:  159	Loss: 0.9665	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 13:32:21 [INFO ]  
2022-10-03 13:32:21 [INFO ]  Begin of epoch 160 :
2022-10-03 13:32:25 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:32:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:32:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:32:25 [INFO ]  	   step  1 (lr=0.231216)                   69.75%                   1.0424
2022-10-03 13:32:25 [INFO ]  
2022-10-03 13:32:25 [INFO ]  Epoch:  160	Loss: 0.9889	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:32:26 [INFO ]  Epoch:  161	Loss: 0.9895	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:32:28 [INFO ]  Epoch:  162	Loss: 1.0159	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:30 [INFO ]  Epoch:  163	Loss: 1.0211	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:32 [INFO ]  Epoch:  164	Loss: 1.0172	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:34 [INFO ]  Epoch:  165	Loss: 1.0146	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:35 [INFO ]  Epoch:  166	Loss: 1.0320	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:37 [INFO ]  Epoch:  167	Loss: 0.9802	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:39 [INFO ]  Epoch:  168	Loss: 1.0145	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:32:41 [INFO ]  Epoch:  169	Loss: 1.0450	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:32:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 13:32:44 [INFO ]  
2022-10-03 13:32:44 [INFO ]  Begin of epoch 170 :
2022-10-03 13:32:47 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:32:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:32:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:32:47 [INFO ]  	   step  1 (lr=0.231201)                   69.31%                   1.0492
2022-10-03 13:32:47 [INFO ]  
2022-10-03 13:32:47 [INFO ]  Epoch:  170	Loss: 1.0163	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:32:49 [INFO ]  Epoch:  171	Loss: 1.0254	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:32:51 [INFO ]  Epoch:  172	Loss: 1.2291	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:52 [INFO ]  Epoch:  173	Loss: 1.1801	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:54 [INFO ]  Epoch:  174	Loss: 1.0058	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:32:56 [INFO ]  Epoch:  175	Loss: 0.9581	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:32:58 [INFO ]  Epoch:  176	Loss: 0.9370	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:33:00 [INFO ]  Epoch:  177	Loss: 0.9619	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:33:01 [INFO ]  Epoch:  178	Loss: 0.8919	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:33:03 [INFO ]  Epoch:  179	Loss: 1.0013	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:33:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 13:33:06 [INFO ]  
2022-10-03 13:33:06 [INFO ]  Begin of epoch 180 :
2022-10-03 13:33:10 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:33:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:33:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:33:10 [INFO ]  	   step  1 (lr=0.231560)                   69.78%                   1.0381
2022-10-03 13:33:10 [INFO ]  
2022-10-03 13:33:10 [INFO ]  Epoch:  180	Loss: 1.0237	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:33:11 [INFO ]  Epoch:  181	Loss: 1.0093	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:33:13 [INFO ]  Epoch:  182	Loss: 1.1309	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:33:15 [INFO ]  Epoch:  183	Loss: 1.0476	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:33:17 [INFO ]  Epoch:  184	Loss: 1.0727	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:33:19 [INFO ]  Epoch:  185	Loss: 1.0090	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:33:21 [INFO ]  Epoch:  186	Loss: 0.8899	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:33:23 [INFO ]  Epoch:  187	Loss: 0.9738	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:33:25 [INFO ]  Epoch:  188	Loss: 1.2922	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:33:27 [INFO ]  Epoch:  189	Loss: 1.0136	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:33:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 13:33:30 [INFO ]  
2022-10-03 13:33:30 [INFO ]  Begin of epoch 190 :
2022-10-03 13:33:33 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:33:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:33:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:33:33 [INFO ]  	   step  1 (lr=0.231630)                   69.75%                   1.0422
2022-10-03 13:33:33 [INFO ]  
2022-10-03 13:33:33 [INFO ]  Epoch:  190	Loss: 0.9462	Data Time: 0.22s	Train Time: 0.00s
2022-10-03 13:33:35 [INFO ]  Epoch:  191	Loss: 0.9959	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:33:37 [INFO ]  Epoch:  192	Loss: 1.0196	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:33:39 [INFO ]  Epoch:  193	Loss: 1.0246	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:33:41 [INFO ]  Epoch:  194	Loss: 0.9845	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:33:43 [INFO ]  Epoch:  195	Loss: 0.9334	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:33:45 [INFO ]  Epoch:  196	Loss: 0.9017	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:33:46 [INFO ]  Epoch:  197	Loss: 1.0047	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:33:48 [INFO ]  Epoch:  198	Loss: 0.8992	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:33:50 [INFO ]  Epoch:  199	Loss: 0.9687	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:33:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 13:33:53 [INFO ]  
2022-10-03 13:33:53 [INFO ]  Final evaluation for SVHN :
2022-10-03 13:33:56 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:33:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:33:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:33:56 [INFO ]  	   step  1 (lr=0.231432)                   69.49%                   1.0511
2022-10-03 13:33:56 [INFO ]  
2022-10-03 13:33:56 [INFO ]  
2022-10-03 13:33:56 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 13:33:59 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:33:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:33:59 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 13:33:59 [INFO ]  	   step  1 (lr=0.231432)                   15.07%                   5.1007
2022-10-03 13:33:59 [INFO ]  
2022-10-03 13:33:59 [INFO ]  CPU Time: 4.56 minutes
2022-10-03 13:36:30 [INFO ]  ======================================== 2022-10-03 13:36:30 ========================================
2022-10-03 13:36:30 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:36:30 [INFO ]  Options: 
2022-10-03 13:36:30 [INFO ]  	base_dir: null
2022-10-03 13:36:30 [INFO ]  	batch_size: 1024
2022-10-03 13:36:30 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:36:30 [INFO ]  	dataset: SVHN
2022-10-03 13:36:30 [INFO ]  	dataset_labels:
2022-10-03 13:36:30 [INFO ]  	- 0
2022-10-03 13:36:30 [INFO ]  	- 1
2022-10-03 13:36:30 [INFO ]  	- 2
2022-10-03 13:36:30 [INFO ]  	- 3
2022-10-03 13:36:30 [INFO ]  	- 4
2022-10-03 13:36:30 [INFO ]  	- 5
2022-10-03 13:36:30 [INFO ]  	- 6
2022-10-03 13:36:30 [INFO ]  	- 7
2022-10-03 13:36:30 [INFO ]  	- 8
2022-10-03 13:36:30 [INFO ]  	- 9
2022-10-03 13:36:30 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:36:30 [INFO ]  	- !!python/tuple
2022-10-03 13:36:30 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:36:30 [INFO ]  	    - 0.44398033618927
2022-10-03 13:36:30 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:36:30 [INFO ]  	- !!python/tuple
2022-10-03 13:36:30 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:36:30 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:36:30 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:36:30 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:36:30 [INFO ]  	decay_epochs: 50
2022-10-03 13:36:30 [INFO ]  	decay_factor: 0.1
2022-10-03 13:36:30 [INFO ]  	device_id: 0
2022-10-03 13:36:30 [INFO ]  	distill_epochs: 1
2022-10-03 13:36:30 [INFO ]  	distill_lr: 0.02
2022-10-03 13:36:30 [INFO ]  	distill_steps: 1
2022-10-03 13:36:30 [INFO ]  	epochs: 200
2022-10-03 13:36:30 [INFO ]  	expand_cls: false
2022-10-03 13:36:30 [INFO ]  	forgetting_dataset: null
2022-10-03 13:36:30 [INFO ]  	init: xavier
2022-10-03 13:36:30 [INFO ]  	init_param: 1.0
2022-10-03 13:36:30 [INFO ]  	input_size: 32
2022-10-03 13:36:30 [INFO ]  	ipc: 2
2022-10-03 13:36:30 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:36:30 [INFO ]  	log_interval: 100
2022-10-03 13:36:30 [INFO ]  	log_level: INFO
2022-10-03 13:36:30 [INFO ]  	lr: 0.01
2022-10-03 13:36:30 [INFO ]  	mode: distill_adapt
2022-10-03 13:36:30 [INFO ]  	nc: 3
2022-10-03 13:36:30 [INFO ]  	num_classes: 10
2022-10-03 13:36:30 [INFO ]  	num_workers: 8
2022-10-03 13:36:30 [INFO ]  	phase: train
2022-10-03 13:36:30 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:36:30 [INFO ]  	start_time: '2022-10-03 13:36:30'
2022-10-03 13:36:30 [INFO ]  	test_batch_size: 1024
2022-10-03 13:36:30 [INFO ]  	
2022-10-03 13:36:32 [INFO ]  train dataset size:	73257
2022-10-03 13:36:32 [INFO ]  test dataset size: 	26032
2022-10-03 13:36:32 [INFO ]  datasets built!
2022-10-03 13:36:32 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:36:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:36:36 [INFO ]  
2022-10-03 13:36:36 [INFO ]  Begin of epoch 0 :
2022-10-03 13:36:39 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:36:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:36:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:36:39 [INFO ]  	   step  1 (lr=0.020000)                    7.30%                   8.0813
2022-10-03 13:36:39 [INFO ]  
2022-10-03 13:36:39 [INFO ]  Epoch:    0	Loss: 7.6813	Data Time: 0.37s	Train Time: 0.03s
2022-10-03 13:36:41 [INFO ]  Epoch:    1	Loss: 3.1297	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:36:43 [INFO ]  Epoch:    2	Loss: 2.6010	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:36:45 [INFO ]  Epoch:    3	Loss: 2.3234	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:36:47 [INFO ]  Epoch:    4	Loss: 2.2398	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:36:48 [INFO ]  Epoch:    5	Loss: 2.2079	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:36:50 [INFO ]  Epoch:    6	Loss: 2.1717	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:36:52 [INFO ]  Epoch:    7	Loss: 2.1923	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:36:54 [INFO ]  Epoch:    8	Loss: 2.1575	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:36:56 [INFO ]  Epoch:    9	Loss: 2.1341	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:36:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 13:36:59 [INFO ]  
2022-10-03 13:36:59 [INFO ]  Begin of epoch 10 :
2022-10-03 13:37:03 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:37:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:37:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:37:03 [INFO ]  	   step  1 (lr=0.050121)                   32.10%                   2.0775
2022-10-03 13:37:03 [INFO ]  
2022-10-03 13:37:03 [INFO ]  Epoch:   10	Loss: 2.0753	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:37:04 [INFO ]  Epoch:   11	Loss: 2.0411	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:37:06 [INFO ]  Epoch:   12	Loss: 1.9239	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:08 [INFO ]  Epoch:   13	Loss: 1.8810	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:37:10 [INFO ]  Epoch:   14	Loss: 1.8202	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:37:11 [INFO ]  Epoch:   15	Loss: 1.6865	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:37:13 [INFO ]  Epoch:   16	Loss: 1.6235	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:15 [INFO ]  Epoch:   17	Loss: 1.5709	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:17 [INFO ]  Epoch:   18	Loss: 1.4781	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:37:19 [INFO ]  Epoch:   19	Loss: 1.5053	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 13:37:23 [INFO ]  
2022-10-03 13:37:23 [INFO ]  Begin of epoch 20 :
2022-10-03 13:37:26 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:37:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:37:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:37:26 [INFO ]  	   step  1 (lr=0.168034)                   54.99%                   1.4516
2022-10-03 13:37:26 [INFO ]  
2022-10-03 13:37:26 [INFO ]  Epoch:   20	Loss: 1.3440	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:28 [INFO ]  Epoch:   21	Loss: 1.3339	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:37:29 [INFO ]  Epoch:   22	Loss: 1.1806	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:37:31 [INFO ]  Epoch:   23	Loss: 1.6777	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:37:33 [INFO ]  Epoch:   24	Loss: 1.2670	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:37:35 [INFO ]  Epoch:   25	Loss: 1.3131	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:37:36 [INFO ]  Epoch:   26	Loss: 1.5999	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:38 [INFO ]  Epoch:   27	Loss: 1.2026	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:37:40 [INFO ]  Epoch:   28	Loss: 1.2964	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:42 [INFO ]  Epoch:   29	Loss: 1.6064	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:37:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 13:37:46 [INFO ]  
2022-10-03 13:37:46 [INFO ]  Begin of epoch 30 :
2022-10-03 13:37:49 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:37:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:37:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:37:49 [INFO ]  	   step  1 (lr=0.201471)                   61.26%                   1.2628
2022-10-03 13:37:49 [INFO ]  
2022-10-03 13:37:49 [INFO ]  Epoch:   30	Loss: 1.2141	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:37:50 [INFO ]  Epoch:   31	Loss: 1.1409	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:52 [INFO ]  Epoch:   32	Loss: 1.0489	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:37:54 [INFO ]  Epoch:   33	Loss: 1.0290	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:37:56 [INFO ]  Epoch:   34	Loss: 1.0695	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:37:58 [INFO ]  Epoch:   35	Loss: 1.0770	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:00 [INFO ]  Epoch:   36	Loss: 1.0227	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:02 [INFO ]  Epoch:   37	Loss: 1.5254	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:38:04 [INFO ]  Epoch:   38	Loss: 1.0903	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:38:05 [INFO ]  Epoch:   39	Loss: 0.9504	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 13:38:09 [INFO ]  
2022-10-03 13:38:09 [INFO ]  Begin of epoch 40 :
2022-10-03 13:38:12 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:38:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:38:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:38:12 [INFO ]  	   step  1 (lr=0.229009)                   66.56%                   1.1291
2022-10-03 13:38:12 [INFO ]  
2022-10-03 13:38:12 [INFO ]  Epoch:   40	Loss: 1.1262	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:38:14 [INFO ]  Epoch:   41	Loss: 1.0788	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:38:16 [INFO ]  Epoch:   42	Loss: 1.0291	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:38:18 [INFO ]  Epoch:   43	Loss: 0.8794	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:19 [INFO ]  Epoch:   44	Loss: 0.8596	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:38:21 [INFO ]  Epoch:   45	Loss: 0.8988	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:23 [INFO ]  Epoch:   46	Loss: 0.9951	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:25 [INFO ]  Epoch:   47	Loss: 1.0099	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:27 [INFO ]  Epoch:   48	Loss: 1.0530	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:38:29 [INFO ]  Epoch:   49	Loss: 0.8430	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:38:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 13:38:33 [INFO ]  
2022-10-03 13:38:33 [INFO ]  Begin of epoch 50 :
2022-10-03 13:38:36 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:38:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:38:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:38:36 [INFO ]  	   step  1 (lr=0.260180)                   74.55%                   0.9027
2022-10-03 13:38:36 [INFO ]  
2022-10-03 13:38:36 [INFO ]  Epoch:   50	Loss: 0.9028	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:37 [INFO ]  Epoch:   51	Loss: 0.8161	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:39 [INFO ]  Epoch:   52	Loss: 0.8586	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:38:41 [INFO ]  Epoch:   53	Loss: 0.8577	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:43 [INFO ]  Epoch:   54	Loss: 1.0192	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:45 [INFO ]  Epoch:   55	Loss: 0.9171	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:38:46 [INFO ]  Epoch:   56	Loss: 0.8048	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:48 [INFO ]  Epoch:   57	Loss: 0.8357	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:38:50 [INFO ]  Epoch:   58	Loss: 0.8739	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:52 [INFO ]  Epoch:   59	Loss: 0.8722	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:38:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 13:38:56 [INFO ]  
2022-10-03 13:38:56 [INFO ]  Begin of epoch 60 :
2022-10-03 13:38:59 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:38:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:38:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:38:59 [INFO ]  	   step  1 (lr=0.267954)                   75.59%                   0.8658
2022-10-03 13:38:59 [INFO ]  
2022-10-03 13:38:59 [INFO ]  Epoch:   60	Loss: 0.8269	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:00 [INFO ]  Epoch:   61	Loss: 0.7326	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:39:02 [INFO ]  Epoch:   62	Loss: 0.8765	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:04 [INFO ]  Epoch:   63	Loss: 0.7579	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:39:06 [INFO ]  Epoch:   64	Loss: 0.8706	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:39:08 [INFO ]  Epoch:   65	Loss: 0.7633	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:10 [INFO ]  Epoch:   66	Loss: 0.8664	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:12 [INFO ]  Epoch:   67	Loss: 0.7767	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:39:14 [INFO ]  Epoch:   68	Loss: 0.7751	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:39:16 [INFO ]  Epoch:   69	Loss: 0.7630	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:39:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 13:39:19 [INFO ]  
2022-10-03 13:39:19 [INFO ]  Begin of epoch 70 :
2022-10-03 13:39:23 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:39:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:39:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:39:23 [INFO ]  	   step  1 (lr=0.277579)                   75.41%                   0.8746
2022-10-03 13:39:23 [INFO ]  
2022-10-03 13:39:23 [INFO ]  Epoch:   70	Loss: 0.8103	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:24 [INFO ]  Epoch:   71	Loss: 0.8014	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:39:26 [INFO ]  Epoch:   72	Loss: 0.7928	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:39:28 [INFO ]  Epoch:   73	Loss: 0.8893	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:39:30 [INFO ]  Epoch:   74	Loss: 0.8012	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:39:32 [INFO ]  Epoch:   75	Loss: 0.9547	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:34 [INFO ]  Epoch:   76	Loss: 0.7069	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:36 [INFO ]  Epoch:   77	Loss: 0.9128	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:39:38 [INFO ]  Epoch:   78	Loss: 0.7723	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:40 [INFO ]  Epoch:   79	Loss: 1.0182	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:39:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 13:39:44 [INFO ]  
2022-10-03 13:39:44 [INFO ]  Begin of epoch 80 :
2022-10-03 13:39:47 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:39:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:39:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:39:47 [INFO ]  	   step  1 (lr=0.270039)                   75.52%                   0.8717
2022-10-03 13:39:47 [INFO ]  
2022-10-03 13:39:47 [INFO ]  Epoch:   80	Loss: 0.8085	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 13:39:49 [INFO ]  Epoch:   81	Loss: 0.8075	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:39:51 [INFO ]  Epoch:   82	Loss: 0.7347	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:39:53 [INFO ]  Epoch:   83	Loss: 0.8466	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:39:55 [INFO ]  Epoch:   84	Loss: 0.8453	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:39:57 [INFO ]  Epoch:   85	Loss: 0.9516	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:39:59 [INFO ]  Epoch:   86	Loss: 0.8012	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:40:01 [INFO ]  Epoch:   87	Loss: 0.8919	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:03 [INFO ]  Epoch:   88	Loss: 0.7987	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:04 [INFO ]  Epoch:   89	Loss: 0.8467	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:40:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 13:40:08 [INFO ]  
2022-10-03 13:40:08 [INFO ]  Begin of epoch 90 :
2022-10-03 13:40:12 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:40:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:40:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:40:12 [INFO ]  	   step  1 (lr=0.286765)                   76.67%                   0.8347
2022-10-03 13:40:12 [INFO ]  
2022-10-03 13:40:12 [INFO ]  Epoch:   90	Loss: 0.8045	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:40:13 [INFO ]  Epoch:   91	Loss: 0.7245	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:15 [INFO ]  Epoch:   92	Loss: 0.7812	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:17 [INFO ]  Epoch:   93	Loss: 0.7796	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:40:19 [INFO ]  Epoch:   94	Loss: 0.7515	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:40:21 [INFO ]  Epoch:   95	Loss: 0.7733	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:40:23 [INFO ]  Epoch:   96	Loss: 0.8473	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:40:25 [INFO ]  Epoch:   97	Loss: 0.7807	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:27 [INFO ]  Epoch:   98	Loss: 0.7969	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:29 [INFO ]  Epoch:   99	Loss: 0.8137	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:40:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 13:40:33 [INFO ]  
2022-10-03 13:40:33 [INFO ]  Begin of epoch 100 :
2022-10-03 13:40:36 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:40:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:40:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:40:36 [INFO ]  	   step  1 (lr=0.295841)                   77.19%                   0.8226
2022-10-03 13:40:36 [INFO ]  
2022-10-03 13:40:36 [INFO ]  Epoch:  100	Loss: 0.8049	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:40:38 [INFO ]  Epoch:  101	Loss: 0.7850	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:40:40 [INFO ]  Epoch:  102	Loss: 0.6832	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:42 [INFO ]  Epoch:  103	Loss: 0.8347	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:40:44 [INFO ]  Epoch:  104	Loss: 0.7098	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:40:45 [INFO ]  Epoch:  105	Loss: 0.7005	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:40:47 [INFO ]  Epoch:  106	Loss: 0.7685	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:40:49 [INFO ]  Epoch:  107	Loss: 0.8184	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:51 [INFO ]  Epoch:  108	Loss: 0.7115	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:53 [INFO ]  Epoch:  109	Loss: 0.7370	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:40:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 13:40:57 [INFO ]  
2022-10-03 13:40:57 [INFO ]  Begin of epoch 110 :
2022-10-03 13:41:00 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:41:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:41:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:41:00 [INFO ]  	   step  1 (lr=0.294813)                   76.88%                   0.8300
2022-10-03 13:41:00 [INFO ]  
2022-10-03 13:41:00 [INFO ]  Epoch:  110	Loss: 0.7046	Data Time: 0.15s	Train Time: 0.00s
2022-10-03 13:41:02 [INFO ]  Epoch:  111	Loss: 0.7815	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:41:04 [INFO ]  Epoch:  112	Loss: 0.7750	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:41:06 [INFO ]  Epoch:  113	Loss: 0.7623	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:41:07 [INFO ]  Epoch:  114	Loss: 0.7940	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:41:09 [INFO ]  Epoch:  115	Loss: 0.8341	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:41:11 [INFO ]  Epoch:  116	Loss: 0.8523	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:41:13 [INFO ]  Epoch:  117	Loss: 0.7665	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:15 [INFO ]  Epoch:  118	Loss: 0.7777	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:41:16 [INFO ]  Epoch:  119	Loss: 0.7716	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:41:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 13:41:20 [INFO ]  
2022-10-03 13:41:20 [INFO ]  Begin of epoch 120 :
2022-10-03 13:41:24 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:41:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:41:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:41:24 [INFO ]  	   step  1 (lr=0.296955)                   77.12%                   0.8091
2022-10-03 13:41:24 [INFO ]  
2022-10-03 13:41:24 [INFO ]  Epoch:  120	Loss: 0.8425	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 13:41:25 [INFO ]  Epoch:  121	Loss: 0.7503	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:41:27 [INFO ]  Epoch:  122	Loss: 0.7812	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:41:29 [INFO ]  Epoch:  123	Loss: 0.7686	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:31 [INFO ]  Epoch:  124	Loss: 0.7427	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:41:33 [INFO ]  Epoch:  125	Loss: 0.7710	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:41:34 [INFO ]  Epoch:  126	Loss: 0.7672	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:41:36 [INFO ]  Epoch:  127	Loss: 0.7294	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:38 [INFO ]  Epoch:  128	Loss: 0.8354	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:41:40 [INFO ]  Epoch:  129	Loss: 0.8260	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 13:41:44 [INFO ]  
2022-10-03 13:41:44 [INFO ]  Begin of epoch 130 :
2022-10-03 13:41:47 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:41:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:41:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:41:47 [INFO ]  	   step  1 (lr=0.298481)                   76.14%                   0.8465
2022-10-03 13:41:47 [INFO ]  
2022-10-03 13:41:47 [INFO ]  Epoch:  130	Loss: 0.7378	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 13:41:49 [INFO ]  Epoch:  131	Loss: 0.7124	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:41:51 [INFO ]  Epoch:  132	Loss: 0.8073	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:53 [INFO ]  Epoch:  133	Loss: 0.7076	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:41:54 [INFO ]  Epoch:  134	Loss: 0.7066	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:41:56 [INFO ]  Epoch:  135	Loss: 0.8356	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:41:58 [INFO ]  Epoch:  136	Loss: 0.8293	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:42:00 [INFO ]  Epoch:  137	Loss: 0.8258	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:02 [INFO ]  Epoch:  138	Loss: 0.8237	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 13:42:04 [INFO ]  Epoch:  139	Loss: 0.7698	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:42:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 13:42:07 [INFO ]  
2022-10-03 13:42:07 [INFO ]  Begin of epoch 140 :
2022-10-03 13:42:11 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:42:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:42:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:42:11 [INFO ]  	   step  1 (lr=0.297768)                   77.14%                   0.8143
2022-10-03 13:42:11 [INFO ]  
2022-10-03 13:42:11 [INFO ]  Epoch:  140	Loss: 0.7621	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:42:12 [INFO ]  Epoch:  141	Loss: 0.7964	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:14 [INFO ]  Epoch:  142	Loss: 0.8184	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:16 [INFO ]  Epoch:  143	Loss: 0.7049	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:42:18 [INFO ]  Epoch:  144	Loss: 0.7231	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:42:20 [INFO ]  Epoch:  145	Loss: 0.8128	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:42:22 [INFO ]  Epoch:  146	Loss: 0.7290	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:42:24 [INFO ]  Epoch:  147	Loss: 0.7685	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:42:26 [INFO ]  Epoch:  148	Loss: 0.8376	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:42:28 [INFO ]  Epoch:  149	Loss: 0.7393	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 13:42:32 [INFO ]  
2022-10-03 13:42:32 [INFO ]  Begin of epoch 150 :
2022-10-03 13:42:35 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:42:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:42:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:42:35 [INFO ]  	   step  1 (lr=0.299814)                   76.91%                   0.8264
2022-10-03 13:42:35 [INFO ]  
2022-10-03 13:42:35 [INFO ]  Epoch:  150	Loss: 0.7407	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:42:37 [INFO ]  Epoch:  151	Loss: 0.8253	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:38 [INFO ]  Epoch:  152	Loss: 0.7168	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:42:40 [INFO ]  Epoch:  153	Loss: 0.7700	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:42:42 [INFO ]  Epoch:  154	Loss: 0.8200	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:42:44 [INFO ]  Epoch:  155	Loss: 0.7613	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:46 [INFO ]  Epoch:  156	Loss: 0.7092	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:48 [INFO ]  Epoch:  157	Loss: 0.7802	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:42:50 [INFO ]  Epoch:  158	Loss: 0.7434	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:42:51 [INFO ]  Epoch:  159	Loss: 0.7523	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:42:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 13:42:55 [INFO ]  
2022-10-03 13:42:55 [INFO ]  Begin of epoch 160 :
2022-10-03 13:42:59 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:42:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:42:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:42:59 [INFO ]  	   step  1 (lr=0.300112)                   76.66%                   0.8348
2022-10-03 13:42:59 [INFO ]  
2022-10-03 13:42:59 [INFO ]  Epoch:  160	Loss: 0.7376	Data Time: 0.20s	Train Time: 0.00s
2022-10-03 13:43:00 [INFO ]  Epoch:  161	Loss: 0.7483	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:02 [INFO ]  Epoch:  162	Loss: 0.7704	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:43:04 [INFO ]  Epoch:  163	Loss: 0.6971	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:43:06 [INFO ]  Epoch:  164	Loss: 0.7877	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:08 [INFO ]  Epoch:  165	Loss: 0.7365	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:43:10 [INFO ]  Epoch:  166	Loss: 0.8001	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:43:11 [INFO ]  Epoch:  167	Loss: 0.7714	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:13 [INFO ]  Epoch:  168	Loss: 0.7845	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:43:15 [INFO ]  Epoch:  169	Loss: 0.7109	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 13:43:19 [INFO ]  
2022-10-03 13:43:19 [INFO ]  Begin of epoch 170 :
2022-10-03 13:43:22 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:43:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:43:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:43:22 [INFO ]  	   step  1 (lr=0.300889)                   75.98%                   0.8520
2022-10-03 13:43:22 [INFO ]  
2022-10-03 13:43:22 [INFO ]  Epoch:  170	Loss: 0.7705	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:43:24 [INFO ]  Epoch:  171	Loss: 0.7811	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:43:26 [INFO ]  Epoch:  172	Loss: 0.7290	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:43:28 [INFO ]  Epoch:  173	Loss: 0.7826	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:29 [INFO ]  Epoch:  174	Loss: 0.8158	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:43:31 [INFO ]  Epoch:  175	Loss: 0.7747	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:43:33 [INFO ]  Epoch:  176	Loss: 0.7650	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:43:35 [INFO ]  Epoch:  177	Loss: 0.8270	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:43:37 [INFO ]  Epoch:  178	Loss: 0.7302	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:43:39 [INFO ]  Epoch:  179	Loss: 0.7706	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:43:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 13:43:43 [INFO ]  
2022-10-03 13:43:43 [INFO ]  Begin of epoch 180 :
2022-10-03 13:43:47 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:43:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:43:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:43:47 [INFO ]  	   step  1 (lr=0.300683)                   76.59%                   0.8268
2022-10-03 13:43:47 [INFO ]  
2022-10-03 13:43:47 [INFO ]  Epoch:  180	Loss: 0.7048	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 13:43:48 [INFO ]  Epoch:  181	Loss: 0.8021	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:43:50 [INFO ]  Epoch:  182	Loss: 0.7582	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:43:52 [INFO ]  Epoch:  183	Loss: 0.7220	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:43:54 [INFO ]  Epoch:  184	Loss: 0.7652	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:43:56 [INFO ]  Epoch:  185	Loss: 0.8433	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:43:58 [INFO ]  Epoch:  186	Loss: 0.8582	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:44:00 [INFO ]  Epoch:  187	Loss: 0.7865	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:44:02 [INFO ]  Epoch:  188	Loss: 0.7251	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:44:04 [INFO ]  Epoch:  189	Loss: 0.8420	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:44:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 13:44:08 [INFO ]  
2022-10-03 13:44:08 [INFO ]  Begin of epoch 190 :
2022-10-03 13:44:11 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:44:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:44:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:44:11 [INFO ]  	   step  1 (lr=0.301143)                   76.60%                   0.8225
2022-10-03 13:44:11 [INFO ]  
2022-10-03 13:44:11 [INFO ]  Epoch:  190	Loss: 0.7193	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 13:44:13 [INFO ]  Epoch:  191	Loss: 0.7818	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:44:15 [INFO ]  Epoch:  192	Loss: 0.8636	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:44:17 [INFO ]  Epoch:  193	Loss: 0.8209	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:44:19 [INFO ]  Epoch:  194	Loss: 0.7286	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:44:21 [INFO ]  Epoch:  195	Loss: 0.7302	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:44:23 [INFO ]  Epoch:  196	Loss: 0.7965	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:44:25 [INFO ]  Epoch:  197	Loss: 0.8611	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:44:26 [INFO ]  Epoch:  198	Loss: 0.7486	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:44:28 [INFO ]  Epoch:  199	Loss: 0.8188	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:44:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 13:44:32 [INFO ]  
2022-10-03 13:44:32 [INFO ]  Final evaluation for SVHN :
2022-10-03 13:44:35 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:44:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:44:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:44:35 [INFO ]  	   step  1 (lr=0.300958)                   75.63%                   0.8455
2022-10-03 13:44:35 [INFO ]  
2022-10-03 13:44:35 [INFO ]  
2022-10-03 13:44:35 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 13:44:38 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:44:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:44:38 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 13:44:38 [INFO ]  	   step  1 (lr=0.300958)                   16.44%                   4.6519
2022-10-03 13:44:38 [INFO ]  
2022-10-03 13:44:38 [INFO ]  CPU Time: 4.94 minutes
2022-10-03 13:47:21 [INFO ]  ======================================== 2022-10-03 13:47:21 ========================================
2022-10-03 13:47:21 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 13:47:21 [INFO ]  Options: 
2022-10-03 13:47:21 [INFO ]  	base_dir: null
2022-10-03 13:47:21 [INFO ]  	batch_size: 1024
2022-10-03 13:47:21 [INFO ]  	checkpoint_interval: 10
2022-10-03 13:47:21 [INFO ]  	dataset: SVHN
2022-10-03 13:47:21 [INFO ]  	dataset_labels:
2022-10-03 13:47:21 [INFO ]  	- 0
2022-10-03 13:47:21 [INFO ]  	- 1
2022-10-03 13:47:21 [INFO ]  	- 2
2022-10-03 13:47:21 [INFO ]  	- 3
2022-10-03 13:47:21 [INFO ]  	- 4
2022-10-03 13:47:21 [INFO ]  	- 5
2022-10-03 13:47:21 [INFO ]  	- 6
2022-10-03 13:47:21 [INFO ]  	- 7
2022-10-03 13:47:21 [INFO ]  	- 8
2022-10-03 13:47:21 [INFO ]  	- 9
2022-10-03 13:47:21 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 13:47:21 [INFO ]  	- !!python/tuple
2022-10-03 13:47:21 [INFO ]  	    - 0.4379104971885681
2022-10-03 13:47:21 [INFO ]  	    - 0.44398033618927
2022-10-03 13:47:21 [INFO ]  	    - 0.4729299545288086
2022-10-03 13:47:21 [INFO ]  	- !!python/tuple
2022-10-03 13:47:21 [INFO ]  	    - 0.19803012907505035
2022-10-03 13:47:21 [INFO ]  	    - 0.2010156363248825
2022-10-03 13:47:21 [INFO ]  	    - 0.19703614711761475
2022-10-03 13:47:21 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 13:47:21 [INFO ]  	decay_epochs: 50
2022-10-03 13:47:21 [INFO ]  	decay_factor: 0.1
2022-10-03 13:47:21 [INFO ]  	device_id: 0
2022-10-03 13:47:21 [INFO ]  	distill_epochs: 1
2022-10-03 13:47:21 [INFO ]  	distill_lr: 0.02
2022-10-03 13:47:21 [INFO ]  	distill_steps: 1
2022-10-03 13:47:21 [INFO ]  	epochs: 200
2022-10-03 13:47:21 [INFO ]  	expand_cls: false
2022-10-03 13:47:21 [INFO ]  	forgetting_dataset: null
2022-10-03 13:47:21 [INFO ]  	init: xavier
2022-10-03 13:47:21 [INFO ]  	init_param: 1.0
2022-10-03 13:47:21 [INFO ]  	input_size: 32
2022-10-03 13:47:21 [INFO ]  	ipc: 5
2022-10-03 13:47:21 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 13:47:21 [INFO ]  	log_interval: 100
2022-10-03 13:47:21 [INFO ]  	log_level: INFO
2022-10-03 13:47:21 [INFO ]  	lr: 0.01
2022-10-03 13:47:21 [INFO ]  	mode: distill_adapt
2022-10-03 13:47:21 [INFO ]  	nc: 3
2022-10-03 13:47:21 [INFO ]  	num_classes: 10
2022-10-03 13:47:21 [INFO ]  	num_workers: 8
2022-10-03 13:47:21 [INFO ]  	phase: train
2022-10-03 13:47:21 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 13:47:21 [INFO ]  	start_time: '2022-10-03 13:47:21'
2022-10-03 13:47:21 [INFO ]  	test_batch_size: 1024
2022-10-03 13:47:21 [INFO ]  	
2022-10-03 13:47:23 [INFO ]  train dataset size:	73257
2022-10-03 13:47:23 [INFO ]  test dataset size: 	26032
2022-10-03 13:47:23 [INFO ]  datasets built!
2022-10-03 13:47:23 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 13:47:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 13:47:29 [INFO ]  
2022-10-03 13:47:29 [INFO ]  Begin of epoch 0 :
2022-10-03 13:47:32 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:47:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:47:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:47:32 [INFO ]  	   step  1 (lr=0.020000)                    6.91%                   8.6568
2022-10-03 13:47:32 [INFO ]  
2022-10-03 13:47:32 [INFO ]  Epoch:    0	Loss: 8.3606	Data Time: 0.43s	Train Time: 0.04s
2022-10-03 13:47:34 [INFO ]  Epoch:    1	Loss: 3.0386	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 13:47:36 [INFO ]  Epoch:    2	Loss: 2.5220	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:47:38 [INFO ]  Epoch:    3	Loss: 2.3132	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:47:40 [INFO ]  Epoch:    4	Loss: 2.2211	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:47:42 [INFO ]  Epoch:    5	Loss: 2.1780	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:47:44 [INFO ]  Epoch:    6	Loss: 2.1514	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:47:46 [INFO ]  Epoch:    7	Loss: 2.1290	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:47:48 [INFO ]  Epoch:    8	Loss: 2.0662	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:47:50 [INFO ]  Epoch:    9	Loss: 1.9691	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:47:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 13:47:55 [INFO ]  
2022-10-03 13:47:55 [INFO ]  Begin of epoch 10 :
2022-10-03 13:47:59 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:47:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:47:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:47:59 [INFO ]  	   step  1 (lr=0.071394)                   40.12%                   1.8635
2022-10-03 13:47:59 [INFO ]  
2022-10-03 13:47:59 [INFO ]  Epoch:   10	Loss: 1.8291	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:48:01 [INFO ]  Epoch:   11	Loss: 1.7586	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:48:02 [INFO ]  Epoch:   12	Loss: 1.7167	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:48:04 [INFO ]  Epoch:   13	Loss: 1.7496	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:48:06 [INFO ]  Epoch:   14	Loss: 1.4756	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:48:08 [INFO ]  Epoch:   15	Loss: 1.4319	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:48:10 [INFO ]  Epoch:   16	Loss: 1.3693	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:12 [INFO ]  Epoch:   17	Loss: 1.5126	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:13 [INFO ]  Epoch:   18	Loss: 1.3168	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:16 [INFO ]  Epoch:   19	Loss: 1.2325	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 13:48:21 [INFO ]  
2022-10-03 13:48:21 [INFO ]  Begin of epoch 20 :
2022-10-03 13:48:25 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:48:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:48:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:48:25 [INFO ]  	   step  1 (lr=0.181289)                   61.99%                   1.2806
2022-10-03 13:48:25 [INFO ]  
2022-10-03 13:48:25 [INFO ]  Epoch:   20	Loss: 1.1261	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:26 [INFO ]  Epoch:   21	Loss: 1.1827	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:48:28 [INFO ]  Epoch:   22	Loss: 1.2161	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:30 [INFO ]  Epoch:   23	Loss: 1.1898	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:48:32 [INFO ]  Epoch:   24	Loss: 1.0855	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:48:34 [INFO ]  Epoch:   25	Loss: 1.0980	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:48:36 [INFO ]  Epoch:   26	Loss: 1.0442	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:38 [INFO ]  Epoch:   27	Loss: 1.0032	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:48:40 [INFO ]  Epoch:   28	Loss: 1.0560	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:48:42 [INFO ]  Epoch:   29	Loss: 0.9831	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:48:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 13:48:48 [INFO ]  
2022-10-03 13:48:48 [INFO ]  Begin of epoch 30 :
2022-10-03 13:48:51 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:48:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:48:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:48:51 [INFO ]  	   step  1 (lr=0.240971)                   70.34%                   1.0440
2022-10-03 13:48:51 [INFO ]  
2022-10-03 13:48:51 [INFO ]  Epoch:   30	Loss: 1.0434	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:48:53 [INFO ]  Epoch:   31	Loss: 1.0751	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:48:55 [INFO ]  Epoch:   32	Loss: 1.0398	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:48:57 [INFO ]  Epoch:   33	Loss: 1.0715	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:48:58 [INFO ]  Epoch:   34	Loss: 0.9034	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:49:00 [INFO ]  Epoch:   35	Loss: 0.9219	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:02 [INFO ]  Epoch:   36	Loss: 0.8348	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:04 [INFO ]  Epoch:   37	Loss: 0.9702	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:49:06 [INFO ]  Epoch:   38	Loss: 0.8495	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:49:08 [INFO ]  Epoch:   39	Loss: 0.8432	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 13:49:14 [INFO ]  
2022-10-03 13:49:14 [INFO ]  Begin of epoch 40 :
2022-10-03 13:49:17 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:49:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:49:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:49:17 [INFO ]  	   step  1 (lr=0.278139)                   71.77%                   0.9987
2022-10-03 13:49:17 [INFO ]  
2022-10-03 13:49:17 [INFO ]  Epoch:   40	Loss: 0.8843	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:49:19 [INFO ]  Epoch:   41	Loss: 1.0444	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:49:21 [INFO ]  Epoch:   42	Loss: 0.8831	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:49:23 [INFO ]  Epoch:   43	Loss: 0.9032	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:49:25 [INFO ]  Epoch:   44	Loss: 0.8728	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:49:27 [INFO ]  Epoch:   45	Loss: 0.7851	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:29 [INFO ]  Epoch:   46	Loss: 0.8321	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:31 [INFO ]  Epoch:   47	Loss: 0.7698	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:32 [INFO ]  Epoch:   48	Loss: 0.9464	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:34 [INFO ]  Epoch:   49	Loss: 0.9450	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:49:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 13:49:40 [INFO ]  
2022-10-03 13:49:40 [INFO ]  Begin of epoch 50 :
2022-10-03 13:49:43 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:49:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:49:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:49:43 [INFO ]  	   step  1 (lr=0.301386)                   77.78%                   0.8052
2022-10-03 13:49:43 [INFO ]  
2022-10-03 13:49:43 [INFO ]  Epoch:   50	Loss: 0.8242	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:45 [INFO ]  Epoch:   51	Loss: 0.7524	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:47 [INFO ]  Epoch:   52	Loss: 0.7789	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:49:49 [INFO ]  Epoch:   53	Loss: 0.7363	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:51 [INFO ]  Epoch:   54	Loss: 0.6993	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:49:53 [INFO ]  Epoch:   55	Loss: 0.7813	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:49:55 [INFO ]  Epoch:   56	Loss: 0.8182	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:49:57 [INFO ]  Epoch:   57	Loss: 0.7501	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:49:58 [INFO ]  Epoch:   58	Loss: 0.7346	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:50:00 [INFO ]  Epoch:   59	Loss: 0.7545	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:50:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 13:50:06 [INFO ]  
2022-10-03 13:50:06 [INFO ]  Begin of epoch 60 :
2022-10-03 13:50:10 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:50:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:50:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:50:10 [INFO ]  	   step  1 (lr=0.307857)                   77.92%                   0.8069
2022-10-03 13:50:10 [INFO ]  
2022-10-03 13:50:10 [INFO ]  Epoch:   60	Loss: 0.7767	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:50:12 [INFO ]  Epoch:   61	Loss: 0.7441	Data Time: 0.34s	Train Time: 0.01s
2022-10-03 13:50:14 [INFO ]  Epoch:   62	Loss: 0.7114	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 13:50:15 [INFO ]  Epoch:   63	Loss: 0.7728	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 13:50:17 [INFO ]  Epoch:   64	Loss: 0.7398	Data Time: 0.30s	Train Time: 0.01s
2022-10-03 13:50:19 [INFO ]  Epoch:   65	Loss: 0.6996	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 13:50:21 [INFO ]  Epoch:   66	Loss: 0.7669	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 13:50:23 [INFO ]  Epoch:   67	Loss: 0.7405	Data Time: 0.34s	Train Time: 0.01s
2022-10-03 13:50:25 [INFO ]  Epoch:   68	Loss: 0.7983	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 13:50:27 [INFO ]  Epoch:   69	Loss: 0.7765	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 13:50:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 13:50:33 [INFO ]  
2022-10-03 13:50:33 [INFO ]  Begin of epoch 70 :
2022-10-03 13:50:37 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:50:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:50:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:50:37 [INFO ]  	   step  1 (lr=0.316288)                   78.51%                   0.7702
2022-10-03 13:50:37 [INFO ]  
2022-10-03 13:50:37 [INFO ]  Epoch:   70	Loss: 0.7499	Data Time: 0.32s	Train Time: 0.01s
2022-10-03 13:50:38 [INFO ]  Epoch:   71	Loss: 0.6896	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:50:40 [INFO ]  Epoch:   72	Loss: 0.7583	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:50:42 [INFO ]  Epoch:   73	Loss: 0.7547	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:50:44 [INFO ]  Epoch:   74	Loss: 0.7392	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:50:45 [INFO ]  Epoch:   75	Loss: 0.7647	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:50:47 [INFO ]  Epoch:   76	Loss: 0.7605	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:50:49 [INFO ]  Epoch:   77	Loss: 0.7705	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:50:51 [INFO ]  Epoch:   78	Loss: 0.7206	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:50:53 [INFO ]  Epoch:   79	Loss: 0.7427	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:50:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 13:50:59 [INFO ]  
2022-10-03 13:50:59 [INFO ]  Begin of epoch 80 :
2022-10-03 13:51:02 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:51:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:51:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:51:02 [INFO ]  	   step  1 (lr=0.324172)                   78.10%                   0.7939
2022-10-03 13:51:02 [INFO ]  
2022-10-03 13:51:02 [INFO ]  Epoch:   80	Loss: 0.7276	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:51:04 [INFO ]  Epoch:   81	Loss: 0.6751	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:51:06 [INFO ]  Epoch:   82	Loss: 0.7459	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:51:07 [INFO ]  Epoch:   83	Loss: 0.7573	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:51:09 [INFO ]  Epoch:   84	Loss: 0.7285	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:51:11 [INFO ]  Epoch:   85	Loss: 0.7283	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:51:13 [INFO ]  Epoch:   86	Loss: 0.7721	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:51:15 [INFO ]  Epoch:   87	Loss: 0.6855	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:51:17 [INFO ]  Epoch:   88	Loss: 0.7113	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:51:18 [INFO ]  Epoch:   89	Loss: 0.6893	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:51:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 13:51:24 [INFO ]  
2022-10-03 13:51:24 [INFO ]  Begin of epoch 90 :
2022-10-03 13:51:27 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:51:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:51:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:51:27 [INFO ]  	   step  1 (lr=0.334504)                   79.17%                   0.7603
2022-10-03 13:51:27 [INFO ]  
2022-10-03 13:51:28 [INFO ]  Epoch:   90	Loss: 0.7563	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:51:29 [INFO ]  Epoch:   91	Loss: 0.7454	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:51:31 [INFO ]  Epoch:   92	Loss: 0.7561	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:51:33 [INFO ]  Epoch:   93	Loss: 0.6310	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:51:35 [INFO ]  Epoch:   94	Loss: 0.7404	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:51:37 [INFO ]  Epoch:   95	Loss: 0.7354	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 13:51:39 [INFO ]  Epoch:   96	Loss: 0.6825	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:51:41 [INFO ]  Epoch:   97	Loss: 0.7145	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:51:43 [INFO ]  Epoch:   98	Loss: 0.7124	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:51:44 [INFO ]  Epoch:   99	Loss: 0.6931	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:51:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 13:51:50 [INFO ]  
2022-10-03 13:51:50 [INFO ]  Begin of epoch 100 :
2022-10-03 13:51:54 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:51:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:51:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:51:54 [INFO ]  	   step  1 (lr=0.335241)                   79.26%                   0.7508
2022-10-03 13:51:54 [INFO ]  
2022-10-03 13:51:54 [INFO ]  Epoch:  100	Loss: 0.6978	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:51:55 [INFO ]  Epoch:  101	Loss: 0.6894	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:51:57 [INFO ]  Epoch:  102	Loss: 0.7257	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:51:59 [INFO ]  Epoch:  103	Loss: 0.6295	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:52:01 [INFO ]  Epoch:  104	Loss: 0.6860	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:52:03 [INFO ]  Epoch:  105	Loss: 0.7122	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:52:05 [INFO ]  Epoch:  106	Loss: 0.6590	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:52:07 [INFO ]  Epoch:  107	Loss: 0.6293	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:52:09 [INFO ]  Epoch:  108	Loss: 0.7326	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:52:11 [INFO ]  Epoch:  109	Loss: 0.7169	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:52:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 13:52:16 [INFO ]  
2022-10-03 13:52:16 [INFO ]  Begin of epoch 110 :
2022-10-03 13:52:20 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:52:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:52:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:52:20 [INFO ]  	   step  1 (lr=0.338866)                   79.28%                   0.7581
2022-10-03 13:52:20 [INFO ]  
2022-10-03 13:52:20 [INFO ]  Epoch:  110	Loss: 0.7041	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 13:52:21 [INFO ]  Epoch:  111	Loss: 0.7647	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:52:23 [INFO ]  Epoch:  112	Loss: 0.8713	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:52:25 [INFO ]  Epoch:  113	Loss: 0.6611	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:52:27 [INFO ]  Epoch:  114	Loss: 0.6998	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:52:29 [INFO ]  Epoch:  115	Loss: 0.6970	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:52:31 [INFO ]  Epoch:  116	Loss: 0.7349	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:52:33 [INFO ]  Epoch:  117	Loss: 0.7668	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:52:35 [INFO ]  Epoch:  118	Loss: 0.7878	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:52:37 [INFO ]  Epoch:  119	Loss: 0.6861	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:52:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 13:52:43 [INFO ]  
2022-10-03 13:52:43 [INFO ]  Begin of epoch 120 :
2022-10-03 13:52:46 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:52:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:52:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:52:46 [INFO ]  	   step  1 (lr=0.339716)                   79.12%                   0.7577
2022-10-03 13:52:46 [INFO ]  
2022-10-03 13:52:46 [INFO ]  Epoch:  120	Loss: 0.7287	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:52:48 [INFO ]  Epoch:  121	Loss: 0.6983	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:52:50 [INFO ]  Epoch:  122	Loss: 0.8066	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:52:52 [INFO ]  Epoch:  123	Loss: 0.7110	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:52:54 [INFO ]  Epoch:  124	Loss: 0.8974	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:52:56 [INFO ]  Epoch:  125	Loss: 0.6460	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:52:57 [INFO ]  Epoch:  126	Loss: 0.7164	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:52:59 [INFO ]  Epoch:  127	Loss: 0.6953	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:53:01 [INFO ]  Epoch:  128	Loss: 0.8467	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:53:03 [INFO ]  Epoch:  129	Loss: 0.7187	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:53:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 13:53:09 [INFO ]  
2022-10-03 13:53:09 [INFO ]  Begin of epoch 130 :
2022-10-03 13:53:12 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:53:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:53:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:53:12 [INFO ]  	   step  1 (lr=0.341662)                   79.34%                   0.7582
2022-10-03 13:53:12 [INFO ]  
2022-10-03 13:53:12 [INFO ]  Epoch:  130	Loss: 0.7166	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 13:53:14 [INFO ]  Epoch:  131	Loss: 0.7050	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:53:16 [INFO ]  Epoch:  132	Loss: 0.6535	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:53:17 [INFO ]  Epoch:  133	Loss: 0.6609	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:53:19 [INFO ]  Epoch:  134	Loss: 0.7253	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:53:21 [INFO ]  Epoch:  135	Loss: 0.6605	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:53:23 [INFO ]  Epoch:  136	Loss: 0.6880	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:53:25 [INFO ]  Epoch:  137	Loss: 0.7010	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:53:27 [INFO ]  Epoch:  138	Loss: 0.6369	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:53:29 [INFO ]  Epoch:  139	Loss: 0.7037	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:53:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 13:53:35 [INFO ]  
2022-10-03 13:53:35 [INFO ]  Begin of epoch 140 :
2022-10-03 13:53:38 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:53:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:53:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:53:38 [INFO ]  	   step  1 (lr=0.342546)                   79.56%                   0.7530
2022-10-03 13:53:38 [INFO ]  
2022-10-03 13:53:38 [INFO ]  Epoch:  140	Loss: 0.6163	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 13:53:40 [INFO ]  Epoch:  141	Loss: 0.7316	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 13:53:42 [INFO ]  Epoch:  142	Loss: 0.7054	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:53:43 [INFO ]  Epoch:  143	Loss: 0.7470	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:53:45 [INFO ]  Epoch:  144	Loss: 0.6232	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:53:47 [INFO ]  Epoch:  145	Loss: 0.6952	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:53:49 [INFO ]  Epoch:  146	Loss: 0.7750	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:53:51 [INFO ]  Epoch:  147	Loss: 0.7089	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 13:53:53 [INFO ]  Epoch:  148	Loss: 0.6537	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:53:54 [INFO ]  Epoch:  149	Loss: 0.6197	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:54:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 13:54:00 [INFO ]  
2022-10-03 13:54:00 [INFO ]  Begin of epoch 150 :
2022-10-03 13:54:03 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:54:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:54:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:54:03 [INFO ]  	   step  1 (lr=0.341151)                   79.26%                   0.7569
2022-10-03 13:54:03 [INFO ]  
2022-10-03 13:54:03 [INFO ]  Epoch:  150	Loss: 0.7225	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:05 [INFO ]  Epoch:  151	Loss: 0.6341	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:54:07 [INFO ]  Epoch:  152	Loss: 0.6195	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:09 [INFO ]  Epoch:  153	Loss: 0.7003	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 13:54:11 [INFO ]  Epoch:  154	Loss: 0.5974	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 13:54:13 [INFO ]  Epoch:  155	Loss: 0.6672	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:54:14 [INFO ]  Epoch:  156	Loss: 0.6381	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:54:16 [INFO ]  Epoch:  157	Loss: 0.7426	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:54:18 [INFO ]  Epoch:  158	Loss: 0.6910	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:54:20 [INFO ]  Epoch:  159	Loss: 0.6909	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:54:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 13:54:26 [INFO ]  
2022-10-03 13:54:26 [INFO ]  Begin of epoch 160 :
2022-10-03 13:54:29 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:54:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:54:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:54:29 [INFO ]  	   step  1 (lr=0.341750)                   79.05%                   0.7568
2022-10-03 13:54:29 [INFO ]  
2022-10-03 13:54:29 [INFO ]  Epoch:  160	Loss: 0.6804	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 13:54:31 [INFO ]  Epoch:  161	Loss: 0.6664	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:32 [INFO ]  Epoch:  162	Loss: 0.6691	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:54:34 [INFO ]  Epoch:  163	Loss: 0.6996	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:54:36 [INFO ]  Epoch:  164	Loss: 0.8201	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:54:38 [INFO ]  Epoch:  165	Loss: 0.7317	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:54:40 [INFO ]  Epoch:  166	Loss: 0.6826	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:42 [INFO ]  Epoch:  167	Loss: 0.7328	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:44 [INFO ]  Epoch:  168	Loss: 0.7632	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:54:46 [INFO ]  Epoch:  169	Loss: 0.7555	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 13:54:52 [INFO ]  
2022-10-03 13:54:52 [INFO ]  Begin of epoch 170 :
2022-10-03 13:54:55 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:54:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:54:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:54:55 [INFO ]  	   step  1 (lr=0.341628)                   79.38%                   0.7537
2022-10-03 13:54:55 [INFO ]  
2022-10-03 13:54:55 [INFO ]  Epoch:  170	Loss: 0.7156	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:54:57 [INFO ]  Epoch:  171	Loss: 0.7355	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 13:54:59 [INFO ]  Epoch:  172	Loss: 0.7407	Data Time: 0.36s	Train Time: 0.01s
2022-10-03 13:55:01 [INFO ]  Epoch:  173	Loss: 0.6568	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 13:55:03 [INFO ]  Epoch:  174	Loss: 0.7250	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 13:55:05 [INFO ]  Epoch:  175	Loss: 0.6848	Data Time: 0.28s	Train Time: 0.01s
2022-10-03 13:55:07 [INFO ]  Epoch:  176	Loss: 0.7026	Data Time: 0.34s	Train Time: 0.01s
2022-10-03 13:55:09 [INFO ]  Epoch:  177	Loss: 0.6723	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 13:55:11 [INFO ]  Epoch:  178	Loss: 0.7003	Data Time: 0.31s	Train Time: 0.01s
2022-10-03 13:55:13 [INFO ]  Epoch:  179	Loss: 0.6158	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 13:55:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 13:55:19 [INFO ]  
2022-10-03 13:55:19 [INFO ]  Begin of epoch 180 :
2022-10-03 13:55:22 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:55:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:55:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:55:22 [INFO ]  	   step  1 (lr=0.342291)                   79.59%                   0.7537
2022-10-03 13:55:22 [INFO ]  
2022-10-03 13:55:22 [INFO ]  Epoch:  180	Loss: 0.8046	Data Time: 0.35s	Train Time: 0.01s
2022-10-03 13:55:24 [INFO ]  Epoch:  181	Loss: 0.7347	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:26 [INFO ]  Epoch:  182	Loss: 0.6601	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:55:27 [INFO ]  Epoch:  183	Loss: 0.6505	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:29 [INFO ]  Epoch:  184	Loss: 0.6729	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:31 [INFO ]  Epoch:  185	Loss: 0.6733	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:55:33 [INFO ]  Epoch:  186	Loss: 0.7275	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:35 [INFO ]  Epoch:  187	Loss: 0.6173	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:37 [INFO ]  Epoch:  188	Loss: 0.7947	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:39 [INFO ]  Epoch:  189	Loss: 0.6966	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 13:55:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 13:55:45 [INFO ]  
2022-10-03 13:55:45 [INFO ]  Begin of epoch 190 :
2022-10-03 13:55:48 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:55:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:55:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:55:48 [INFO ]  	   step  1 (lr=0.342558)                   79.54%                   0.7542
2022-10-03 13:55:48 [INFO ]  
2022-10-03 13:55:48 [INFO ]  Epoch:  190	Loss: 0.6601	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 13:55:50 [INFO ]  Epoch:  191	Loss: 0.7465	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 13:55:51 [INFO ]  Epoch:  192	Loss: 0.7093	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 13:55:53 [INFO ]  Epoch:  193	Loss: 0.6506	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:55:55 [INFO ]  Epoch:  194	Loss: 0.7021	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 13:55:57 [INFO ]  Epoch:  195	Loss: 0.6430	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:55:59 [INFO ]  Epoch:  196	Loss: 0.6860	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:56:01 [INFO ]  Epoch:  197	Loss: 0.6782	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 13:56:02 [INFO ]  Epoch:  198	Loss: 0.6196	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:56:04 [INFO ]  Epoch:  199	Loss: 0.6837	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 13:56:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 13:56:10 [INFO ]  
2022-10-03 13:56:10 [INFO ]  Final evaluation for SVHN :
2022-10-03 13:56:13 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:56:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:56:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 13:56:13 [INFO ]  	   step  1 (lr=0.343046)                   79.57%                   0.7486
2022-10-03 13:56:13 [INFO ]  
2022-10-03 13:56:13 [INFO ]  
2022-10-03 13:56:13 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 13:56:16 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 13:56:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 13:56:16 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 13:56:16 [INFO ]  	   step  1 (lr=0.343046)                   17.71%                   4.8373
2022-10-03 13:56:16 [INFO ]  
2022-10-03 13:56:16 [INFO ]  CPU Time: 5.65 minutes
2022-10-03 14:02:52 [INFO ]  ======================================== 2022-10-03 14:02:52 ========================================
2022-10-03 14:02:52 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 14:02:52 [INFO ]  Options: 
2022-10-03 14:02:52 [INFO ]  	base_dir: null
2022-10-03 14:02:52 [INFO ]  	batch_size: 1024
2022-10-03 14:02:52 [INFO ]  	checkpoint_interval: 10
2022-10-03 14:02:52 [INFO ]  	dataset: SVHN
2022-10-03 14:02:52 [INFO ]  	dataset_labels:
2022-10-03 14:02:52 [INFO ]  	- 0
2022-10-03 14:02:52 [INFO ]  	- 1
2022-10-03 14:02:52 [INFO ]  	- 2
2022-10-03 14:02:52 [INFO ]  	- 3
2022-10-03 14:02:52 [INFO ]  	- 4
2022-10-03 14:02:52 [INFO ]  	- 5
2022-10-03 14:02:52 [INFO ]  	- 6
2022-10-03 14:02:52 [INFO ]  	- 7
2022-10-03 14:02:52 [INFO ]  	- 8
2022-10-03 14:02:52 [INFO ]  	- 9
2022-10-03 14:02:52 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 14:02:52 [INFO ]  	- !!python/tuple
2022-10-03 14:02:52 [INFO ]  	    - 0.4379104971885681
2022-10-03 14:02:52 [INFO ]  	    - 0.44398033618927
2022-10-03 14:02:52 [INFO ]  	    - 0.4729299545288086
2022-10-03 14:02:52 [INFO ]  	- !!python/tuple
2022-10-03 14:02:52 [INFO ]  	    - 0.19803012907505035
2022-10-03 14:02:52 [INFO ]  	    - 0.2010156363248825
2022-10-03 14:02:52 [INFO ]  	    - 0.19703614711761475
2022-10-03 14:02:52 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 14:02:52 [INFO ]  	decay_epochs: 50
2022-10-03 14:02:52 [INFO ]  	decay_factor: 0.1
2022-10-03 14:02:52 [INFO ]  	device_id: 0
2022-10-03 14:02:52 [INFO ]  	distill_epochs: 1
2022-10-03 14:02:52 [INFO ]  	distill_lr: 0.02
2022-10-03 14:02:52 [INFO ]  	distill_steps: 1
2022-10-03 14:02:52 [INFO ]  	epochs: 200
2022-10-03 14:02:52 [INFO ]  	expand_cls: false
2022-10-03 14:02:52 [INFO ]  	forgetting_dataset: null
2022-10-03 14:02:52 [INFO ]  	init: xavier
2022-10-03 14:02:52 [INFO ]  	init_param: 1.0
2022-10-03 14:02:52 [INFO ]  	input_size: 32
2022-10-03 14:02:52 [INFO ]  	ipc: 10
2022-10-03 14:02:52 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 14:02:52 [INFO ]  	log_interval: 100
2022-10-03 14:02:52 [INFO ]  	log_level: INFO
2022-10-03 14:02:52 [INFO ]  	lr: 0.01
2022-10-03 14:02:52 [INFO ]  	mode: distill_adapt
2022-10-03 14:02:52 [INFO ]  	nc: 3
2022-10-03 14:02:52 [INFO ]  	num_classes: 10
2022-10-03 14:02:52 [INFO ]  	num_workers: 8
2022-10-03 14:02:52 [INFO ]  	phase: train
2022-10-03 14:02:52 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 14:02:52 [INFO ]  	start_time: '2022-10-03 14:02:52'
2022-10-03 14:02:52 [INFO ]  	test_batch_size: 1024
2022-10-03 14:02:52 [INFO ]  	
2022-10-03 14:02:54 [INFO ]  train dataset size:	73257
2022-10-03 14:02:54 [INFO ]  test dataset size: 	26032
2022-10-03 14:02:54 [INFO ]  datasets built!
2022-10-03 14:02:54 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 14:03:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 14:03:02 [INFO ]  
2022-10-03 14:03:02 [INFO ]  Begin of epoch 0 :
2022-10-03 14:03:06 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:03:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:03:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:03:06 [INFO ]  	   step  1 (lr=0.020000)                    6.95%                   9.0561
2022-10-03 14:03:06 [INFO ]  
2022-10-03 14:03:06 [INFO ]  Epoch:    0	Loss: 8.4600	Data Time: 0.46s	Train Time: 0.04s
2022-10-03 14:03:08 [INFO ]  Epoch:    1	Loss: 2.9077	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 14:03:09 [INFO ]  Epoch:    2	Loss: 2.5181	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:11 [INFO ]  Epoch:    3	Loss: 2.3246	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:03:13 [INFO ]  Epoch:    4	Loss: 2.2139	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:15 [INFO ]  Epoch:    5	Loss: 2.1900	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:17 [INFO ]  Epoch:    6	Loss: 2.1323	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:18 [INFO ]  Epoch:    7	Loss: 2.1279	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:03:20 [INFO ]  Epoch:    8	Loss: 2.1226	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:03:22 [INFO ]  Epoch:    9	Loss: 2.0215	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 14:03:31 [INFO ]  
2022-10-03 14:03:31 [INFO ]  Begin of epoch 10 :
2022-10-03 14:03:34 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:03:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:03:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:03:34 [INFO ]  	   step  1 (lr=0.067306)                   37.45%                   1.9418
2022-10-03 14:03:34 [INFO ]  
2022-10-03 14:03:34 [INFO ]  Epoch:   10	Loss: 1.8946	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 14:03:36 [INFO ]  Epoch:   11	Loss: 1.7922	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:03:38 [INFO ]  Epoch:   12	Loss: 1.7159	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:03:39 [INFO ]  Epoch:   13	Loss: 1.4818	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:03:41 [INFO ]  Epoch:   14	Loss: 1.5396	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:03:43 [INFO ]  Epoch:   15	Loss: 1.2878	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:45 [INFO ]  Epoch:   16	Loss: 1.3039	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:47 [INFO ]  Epoch:   17	Loss: 1.3578	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:03:48 [INFO ]  Epoch:   18	Loss: 1.1751	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:50 [INFO ]  Epoch:   19	Loss: 1.2289	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:03:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 14:03:59 [INFO ]  
2022-10-03 14:03:59 [INFO ]  Begin of epoch 20 :
2022-10-03 14:04:02 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:04:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:04:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:04:02 [INFO ]  	   step  1 (lr=0.214993)                   66.79%                   1.1446
2022-10-03 14:04:02 [INFO ]  
2022-10-03 14:04:02 [INFO ]  Epoch:   20	Loss: 1.1156	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:04 [INFO ]  Epoch:   21	Loss: 1.1022	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:04:06 [INFO ]  Epoch:   22	Loss: 1.1953	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:04:08 [INFO ]  Epoch:   23	Loss: 1.0151	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:10 [INFO ]  Epoch:   24	Loss: 1.0843	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:11 [INFO ]  Epoch:   25	Loss: 1.0058	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:13 [INFO ]  Epoch:   26	Loss: 1.0302	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:15 [INFO ]  Epoch:   27	Loss: 1.0786	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:04:17 [INFO ]  Epoch:   28	Loss: 0.9558	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:04:19 [INFO ]  Epoch:   29	Loss: 0.9524	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:04:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 14:04:27 [INFO ]  
2022-10-03 14:04:27 [INFO ]  Begin of epoch 30 :
2022-10-03 14:04:31 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:04:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:04:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:04:31 [INFO ]  	   step  1 (lr=0.287248)                   72.65%                   0.9922
2022-10-03 14:04:31 [INFO ]  
2022-10-03 14:04:31 [INFO ]  Epoch:   30	Loss: 0.9598	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 14:04:32 [INFO ]  Epoch:   31	Loss: 0.9633	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:34 [INFO ]  Epoch:   32	Loss: 0.9539	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:04:36 [INFO ]  Epoch:   33	Loss: 0.8587	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:04:38 [INFO ]  Epoch:   34	Loss: 0.8453	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:04:40 [INFO ]  Epoch:   35	Loss: 0.8752	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:04:42 [INFO ]  Epoch:   36	Loss: 0.8875	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:04:43 [INFO ]  Epoch:   37	Loss: 0.8852	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:04:46 [INFO ]  Epoch:   38	Loss: 0.9503	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:04:47 [INFO ]  Epoch:   39	Loss: 0.8099	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:04:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 14:04:56 [INFO ]  
2022-10-03 14:04:56 [INFO ]  Begin of epoch 40 :
2022-10-03 14:05:00 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:05:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:05:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:05:00 [INFO ]  	   step  1 (lr=0.313467)                   75.02%                   0.9066
2022-10-03 14:05:00 [INFO ]  
2022-10-03 14:05:00 [INFO ]  Epoch:   40	Loss: 0.8813	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:05:01 [INFO ]  Epoch:   41	Loss: 0.7994	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:03 [INFO ]  Epoch:   42	Loss: 0.8430	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:05:05 [INFO ]  Epoch:   43	Loss: 0.7882	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:05:07 [INFO ]  Epoch:   44	Loss: 0.7780	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:09 [INFO ]  Epoch:   45	Loss: 0.8234	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:05:11 [INFO ]  Epoch:   46	Loss: 1.0238	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:13 [INFO ]  Epoch:   47	Loss: 0.7424	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:05:14 [INFO ]  Epoch:   48	Loss: 0.8434	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:05:16 [INFO ]  Epoch:   49	Loss: 0.7749	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:05:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 14:05:25 [INFO ]  
2022-10-03 14:05:25 [INFO ]  Begin of epoch 50 :
2022-10-03 14:05:28 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:05:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:05:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:05:28 [INFO ]  	   step  1 (lr=0.329960)                   78.18%                   0.7942
2022-10-03 14:05:28 [INFO ]  
2022-10-03 14:05:28 [INFO ]  Epoch:   50	Loss: 0.8010	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 14:05:30 [INFO ]  Epoch:   51	Loss: 0.6377	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:05:32 [INFO ]  Epoch:   52	Loss: 0.6804	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:05:34 [INFO ]  Epoch:   53	Loss: 0.6496	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:05:36 [INFO ]  Epoch:   54	Loss: 0.7182	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:38 [INFO ]  Epoch:   55	Loss: 0.6784	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:05:39 [INFO ]  Epoch:   56	Loss: 0.7083	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:41 [INFO ]  Epoch:   57	Loss: 0.6849	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:05:43 [INFO ]  Epoch:   58	Loss: 0.6738	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:05:45 [INFO ]  Epoch:   59	Loss: 0.7127	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:05:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 14:05:54 [INFO ]  
2022-10-03 14:05:54 [INFO ]  Begin of epoch 60 :
2022-10-03 14:05:57 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:05:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:05:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:05:57 [INFO ]  	   step  1 (lr=0.341451)                   77.45%                   0.8174
2022-10-03 14:05:57 [INFO ]  
2022-10-03 14:05:57 [INFO ]  Epoch:   60	Loss: 0.6909	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:05:59 [INFO ]  Epoch:   61	Loss: 0.7481	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:06:01 [INFO ]  Epoch:   62	Loss: 0.6560	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:06:03 [INFO ]  Epoch:   63	Loss: 0.7085	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:06:04 [INFO ]  Epoch:   64	Loss: 0.7297	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:06:07 [INFO ]  Epoch:   65	Loss: 0.6855	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 14:06:09 [INFO ]  Epoch:   66	Loss: 0.6551	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:06:11 [INFO ]  Epoch:   67	Loss: 0.7207	Data Time: 0.29s	Train Time: 0.01s
2022-10-03 14:06:14 [INFO ]  Epoch:   68	Loss: 0.7329	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:06:16 [INFO ]  Epoch:   69	Loss: 0.6335	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 14:06:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 14:06:25 [INFO ]  
2022-10-03 14:06:25 [INFO ]  Begin of epoch 70 :
2022-10-03 14:06:29 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:06:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:06:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:06:29 [INFO ]  	   step  1 (lr=0.347396)                   78.28%                   0.7914
2022-10-03 14:06:29 [INFO ]  
2022-10-03 14:06:29 [INFO ]  Epoch:   70	Loss: 0.6748	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:06:31 [INFO ]  Epoch:   71	Loss: 0.7279	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:06:33 [INFO ]  Epoch:   72	Loss: 0.6830	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:06:35 [INFO ]  Epoch:   73	Loss: 0.6591	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:06:37 [INFO ]  Epoch:   74	Loss: 0.6587	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:06:39 [INFO ]  Epoch:   75	Loss: 0.6490	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:06:41 [INFO ]  Epoch:   76	Loss: 0.7458	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:06:43 [INFO ]  Epoch:   77	Loss: 0.6645	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:06:44 [INFO ]  Epoch:   78	Loss: 0.6644	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:06:46 [INFO ]  Epoch:   79	Loss: 0.7646	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:06:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 14:06:55 [INFO ]  
2022-10-03 14:06:55 [INFO ]  Begin of epoch 80 :
2022-10-03 14:06:58 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:06:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:06:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:06:58 [INFO ]  	   step  1 (lr=0.350916)                   78.77%                   0.7710
2022-10-03 14:06:58 [INFO ]  
2022-10-03 14:06:58 [INFO ]  Epoch:   80	Loss: 0.5988	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:07:00 [INFO ]  Epoch:   81	Loss: 0.7553	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:07:02 [INFO ]  Epoch:   82	Loss: 0.6941	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:07:04 [INFO ]  Epoch:   83	Loss: 0.6585	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:06 [INFO ]  Epoch:   84	Loss: 0.6560	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:07:08 [INFO ]  Epoch:   85	Loss: 0.7041	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:07:11 [INFO ]  Epoch:   86	Loss: 0.6968	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:12 [INFO ]  Epoch:   87	Loss: 0.6165	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:14 [INFO ]  Epoch:   88	Loss: 0.6854	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:07:17 [INFO ]  Epoch:   89	Loss: 0.6711	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:07:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 14:07:26 [INFO ]  
2022-10-03 14:07:26 [INFO ]  Begin of epoch 90 :
2022-10-03 14:07:29 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:07:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:07:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:07:29 [INFO ]  	   step  1 (lr=0.360480)                   78.21%                   0.7920
2022-10-03 14:07:29 [INFO ]  
2022-10-03 14:07:29 [INFO ]  Epoch:   90	Loss: 0.6950	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:31 [INFO ]  Epoch:   91	Loss: 0.6640	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:07:33 [INFO ]  Epoch:   92	Loss: 0.7140	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:07:35 [INFO ]  Epoch:   93	Loss: 0.6763	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:37 [INFO ]  Epoch:   94	Loss: 0.6907	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:39 [INFO ]  Epoch:   95	Loss: 0.6853	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:07:41 [INFO ]  Epoch:   96	Loss: 0.6670	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:43 [INFO ]  Epoch:   97	Loss: 0.6967	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:07:44 [INFO ]  Epoch:   98	Loss: 0.6674	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:07:46 [INFO ]  Epoch:   99	Loss: 0.7063	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:07:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 14:07:55 [INFO ]  
2022-10-03 14:07:55 [INFO ]  Begin of epoch 100 :
2022-10-03 14:07:59 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:07:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:07:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:07:59 [INFO ]  	   step  1 (lr=0.369114)                   78.53%                   0.7816
2022-10-03 14:07:59 [INFO ]  
2022-10-03 14:07:59 [INFO ]  Epoch:  100	Loss: 0.6511	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:08:01 [INFO ]  Epoch:  101	Loss: 0.7429	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:08:02 [INFO ]  Epoch:  102	Loss: 0.6966	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:08:05 [INFO ]  Epoch:  103	Loss: 0.6374	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:08:06 [INFO ]  Epoch:  104	Loss: 0.6611	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:08:08 [INFO ]  Epoch:  105	Loss: 0.6899	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:10 [INFO ]  Epoch:  106	Loss: 0.6903	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:08:12 [INFO ]  Epoch:  107	Loss: 0.6713	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:14 [INFO ]  Epoch:  108	Loss: 0.6677	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:16 [INFO ]  Epoch:  109	Loss: 0.6288	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 14:08:24 [INFO ]  
2022-10-03 14:08:24 [INFO ]  Begin of epoch 110 :
2022-10-03 14:08:28 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:08:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:08:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:08:28 [INFO ]  	   step  1 (lr=0.372707)                   79.19%                   0.7539
2022-10-03 14:08:28 [INFO ]  
2022-10-03 14:08:28 [INFO ]  Epoch:  110	Loss: 0.7405	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 14:08:30 [INFO ]  Epoch:  111	Loss: 0.6280	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:32 [INFO ]  Epoch:  112	Loss: 0.6420	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:34 [INFO ]  Epoch:  113	Loss: 0.7200	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:08:36 [INFO ]  Epoch:  114	Loss: 0.6629	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:08:38 [INFO ]  Epoch:  115	Loss: 0.6441	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:40 [INFO ]  Epoch:  116	Loss: 0.6586	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:08:42 [INFO ]  Epoch:  117	Loss: 0.6404	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:44 [INFO ]  Epoch:  118	Loss: 0.6098	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:08:46 [INFO ]  Epoch:  119	Loss: 0.6241	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:08:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 14:08:55 [INFO ]  
2022-10-03 14:08:55 [INFO ]  Begin of epoch 120 :
2022-10-03 14:08:59 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:08:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:08:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:08:59 [INFO ]  	   step  1 (lr=0.372842)                   79.70%                   0.7457
2022-10-03 14:08:59 [INFO ]  
2022-10-03 14:08:59 [INFO ]  Epoch:  120	Loss: 0.6683	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:09:00 [INFO ]  Epoch:  121	Loss: 0.7033	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:09:02 [INFO ]  Epoch:  122	Loss: 0.6285	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:04 [INFO ]  Epoch:  123	Loss: 0.6172	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:06 [INFO ]  Epoch:  124	Loss: 0.6313	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:08 [INFO ]  Epoch:  125	Loss: 0.6443	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:09 [INFO ]  Epoch:  126	Loss: 0.6661	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:11 [INFO ]  Epoch:  127	Loss: 0.6567	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:09:13 [INFO ]  Epoch:  128	Loss: 0.7129	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:15 [INFO ]  Epoch:  129	Loss: 0.6518	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 14:09:24 [INFO ]  
2022-10-03 14:09:24 [INFO ]  Begin of epoch 130 :
2022-10-03 14:09:27 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:09:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:09:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:09:27 [INFO ]  	   step  1 (lr=0.374392)                   79.33%                   0.7574
2022-10-03 14:09:27 [INFO ]  
2022-10-03 14:09:27 [INFO ]  Epoch:  130	Loss: 0.7016	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:29 [INFO ]  Epoch:  131	Loss: 0.6068	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:09:31 [INFO ]  Epoch:  132	Loss: 0.6834	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:33 [INFO ]  Epoch:  133	Loss: 0.6510	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:09:35 [INFO ]  Epoch:  134	Loss: 0.6988	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:09:37 [INFO ]  Epoch:  135	Loss: 0.6298	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:09:38 [INFO ]  Epoch:  136	Loss: 0.7339	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 14:09:40 [INFO ]  Epoch:  137	Loss: 0.6898	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:09:42 [INFO ]  Epoch:  138	Loss: 0.6318	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:09:44 [INFO ]  Epoch:  139	Loss: 0.6217	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:09:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 14:09:53 [INFO ]  
2022-10-03 14:09:53 [INFO ]  Begin of epoch 140 :
2022-10-03 14:09:56 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:09:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:09:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:09:56 [INFO ]  	   step  1 (lr=0.376129)                   80.06%                   0.7335
2022-10-03 14:09:56 [INFO ]  
2022-10-03 14:09:56 [INFO ]  Epoch:  140	Loss: 0.6048	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:09:58 [INFO ]  Epoch:  141	Loss: 0.6986	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:10:00 [INFO ]  Epoch:  142	Loss: 0.6383	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:10:02 [INFO ]  Epoch:  143	Loss: 0.6364	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:10:04 [INFO ]  Epoch:  144	Loss: 0.6024	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 14:10:06 [INFO ]  Epoch:  145	Loss: 0.6793	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:10:08 [INFO ]  Epoch:  146	Loss: 0.7007	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:10:10 [INFO ]  Epoch:  147	Loss: 0.6636	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 14:10:11 [INFO ]  Epoch:  148	Loss: 0.7147	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:10:13 [INFO ]  Epoch:  149	Loss: 0.6186	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:10:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 14:10:22 [INFO ]  
2022-10-03 14:10:22 [INFO ]  Begin of epoch 150 :
2022-10-03 14:10:25 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:10:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:10:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:10:25 [INFO ]  	   step  1 (lr=0.377661)                   80.13%                   0.7408
2022-10-03 14:10:25 [INFO ]  
2022-10-03 14:10:25 [INFO ]  Epoch:  150	Loss: 0.6781	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 14:10:27 [INFO ]  Epoch:  151	Loss: 0.6479	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:10:29 [INFO ]  Epoch:  152	Loss: 0.7066	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:10:31 [INFO ]  Epoch:  153	Loss: 0.7485	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:10:33 [INFO ]  Epoch:  154	Loss: 0.6322	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:10:34 [INFO ]  Epoch:  155	Loss: 0.7024	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:10:36 [INFO ]  Epoch:  156	Loss: 0.7445	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:10:38 [INFO ]  Epoch:  157	Loss: 0.6158	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 14:10:40 [INFO ]  Epoch:  158	Loss: 0.6416	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:10:42 [INFO ]  Epoch:  159	Loss: 0.6383	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:10:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 14:10:51 [INFO ]  
2022-10-03 14:10:51 [INFO ]  Begin of epoch 160 :
2022-10-03 14:10:54 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:10:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:10:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:10:54 [INFO ]  	   step  1 (lr=0.378245)                   79.45%                   0.7620
2022-10-03 14:10:54 [INFO ]  
2022-10-03 14:10:54 [INFO ]  Epoch:  160	Loss: 0.7151	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:10:56 [INFO ]  Epoch:  161	Loss: 0.6464	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:10:58 [INFO ]  Epoch:  162	Loss: 0.6305	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:00 [INFO ]  Epoch:  163	Loss: 0.6674	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:11:02 [INFO ]  Epoch:  164	Loss: 0.6881	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:11:04 [INFO ]  Epoch:  165	Loss: 0.5930	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:11:05 [INFO ]  Epoch:  166	Loss: 0.6621	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 14:11:07 [INFO ]  Epoch:  167	Loss: 0.6188	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:11:09 [INFO ]  Epoch:  168	Loss: 0.6366	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 14:11:11 [INFO ]  Epoch:  169	Loss: 0.6275	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:11:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 14:11:20 [INFO ]  
2022-10-03 14:11:20 [INFO ]  Begin of epoch 170 :
2022-10-03 14:11:23 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:11:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:11:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:11:23 [INFO ]  	   step  1 (lr=0.377674)                   79.47%                   0.7516
2022-10-03 14:11:23 [INFO ]  
2022-10-03 14:11:23 [INFO ]  Epoch:  170	Loss: 0.7384	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:11:25 [INFO ]  Epoch:  171	Loss: 0.5942	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:11:27 [INFO ]  Epoch:  172	Loss: 0.6330	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:28 [INFO ]  Epoch:  173	Loss: 0.6090	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:30 [INFO ]  Epoch:  174	Loss: 0.6542	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:11:32 [INFO ]  Epoch:  175	Loss: 0.6516	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:11:34 [INFO ]  Epoch:  176	Loss: 0.7191	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:11:36 [INFO ]  Epoch:  177	Loss: 0.5231	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:11:38 [INFO ]  Epoch:  178	Loss: 0.6341	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 14:11:40 [INFO ]  Epoch:  179	Loss: 0.6798	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 14:11:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 14:11:49 [INFO ]  
2022-10-03 14:11:49 [INFO ]  Begin of epoch 180 :
2022-10-03 14:11:52 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:11:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:11:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:11:52 [INFO ]  	   step  1 (lr=0.377311)                   79.76%                   0.7518
2022-10-03 14:11:52 [INFO ]  
2022-10-03 14:11:52 [INFO ]  Epoch:  180	Loss: 0.6996	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:54 [INFO ]  Epoch:  181	Loss: 0.6231	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:55 [INFO ]  Epoch:  182	Loss: 0.6185	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:11:57 [INFO ]  Epoch:  183	Loss: 0.6519	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:11:59 [INFO ]  Epoch:  184	Loss: 0.7177	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:12:01 [INFO ]  Epoch:  185	Loss: 0.6593	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:12:03 [INFO ]  Epoch:  186	Loss: 0.7084	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:12:05 [INFO ]  Epoch:  187	Loss: 0.7360	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:12:07 [INFO ]  Epoch:  188	Loss: 0.7348	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:12:09 [INFO ]  Epoch:  189	Loss: 0.6107	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:12:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 14:12:18 [INFO ]  
2022-10-03 14:12:18 [INFO ]  Begin of epoch 190 :
2022-10-03 14:12:22 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:12:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:12:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:12:22 [INFO ]  	   step  1 (lr=0.377678)                   79.18%                   0.7604
2022-10-03 14:12:22 [INFO ]  
2022-10-03 14:12:22 [INFO ]  Epoch:  190	Loss: 0.5719	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:12:24 [INFO ]  Epoch:  191	Loss: 0.6734	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 14:12:26 [INFO ]  Epoch:  192	Loss: 0.6517	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 14:12:27 [INFO ]  Epoch:  193	Loss: 0.7067	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:12:30 [INFO ]  Epoch:  194	Loss: 0.7222	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 14:12:31 [INFO ]  Epoch:  195	Loss: 0.6853	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:12:33 [INFO ]  Epoch:  196	Loss: 0.6765	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 14:12:35 [INFO ]  Epoch:  197	Loss: 0.6544	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 14:12:37 [INFO ]  Epoch:  198	Loss: 0.6893	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 14:12:39 [INFO ]  Epoch:  199	Loss: 0.6934	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 14:12:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 14:12:47 [INFO ]  
2022-10-03 14:12:47 [INFO ]  Final evaluation for SVHN :
2022-10-03 14:12:51 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:12:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:12:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 14:12:51 [INFO ]  	   step  1 (lr=0.377996)                   78.76%                   0.7741
2022-10-03 14:12:51 [INFO ]  
2022-10-03 14:12:51 [INFO ]  
2022-10-03 14:12:51 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 14:12:54 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 14:12:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 14:12:54 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 14:12:54 [INFO ]  	   step  1 (lr=0.377996)                   15.55%                   5.4994
2022-10-03 14:12:54 [INFO ]  
2022-10-03 14:12:54 [INFO ]  CPU Time: 6.77 minutes
2022-10-03 15:11:15 [INFO ]  ======================================== 2022-10-03 15:11:15 ========================================
2022-10-03 15:11:15 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 15:11:15 [INFO ]  Options: 
2022-10-03 15:11:15 [INFO ]  	base_dir: null
2022-10-03 15:11:15 [INFO ]  	batch_size: 1024
2022-10-03 15:11:15 [INFO ]  	checkpoint_interval: 10
2022-10-03 15:11:15 [INFO ]  	dataset: SVHN
2022-10-03 15:11:15 [INFO ]  	dataset_labels:
2022-10-03 15:11:15 [INFO ]  	- 0
2022-10-03 15:11:15 [INFO ]  	- 1
2022-10-03 15:11:15 [INFO ]  	- 2
2022-10-03 15:11:15 [INFO ]  	- 3
2022-10-03 15:11:15 [INFO ]  	- 4
2022-10-03 15:11:15 [INFO ]  	- 5
2022-10-03 15:11:15 [INFO ]  	- 6
2022-10-03 15:11:15 [INFO ]  	- 7
2022-10-03 15:11:15 [INFO ]  	- 8
2022-10-03 15:11:15 [INFO ]  	- 9
2022-10-03 15:11:15 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 15:11:15 [INFO ]  	- !!python/tuple
2022-10-03 15:11:15 [INFO ]  	    - 0.4379104971885681
2022-10-03 15:11:15 [INFO ]  	    - 0.44398033618927
2022-10-03 15:11:15 [INFO ]  	    - 0.4729299545288086
2022-10-03 15:11:15 [INFO ]  	- !!python/tuple
2022-10-03 15:11:15 [INFO ]  	    - 0.19803012907505035
2022-10-03 15:11:15 [INFO ]  	    - 0.2010156363248825
2022-10-03 15:11:15 [INFO ]  	    - 0.19703614711761475
2022-10-03 15:11:15 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 15:11:15 [INFO ]  	decay_epochs: 50
2022-10-03 15:11:15 [INFO ]  	decay_factor: 0.1
2022-10-03 15:11:15 [INFO ]  	device_id: 0
2022-10-03 15:11:15 [INFO ]  	distill_epochs: 1
2022-10-03 15:11:15 [INFO ]  	distill_lr: 0.02
2022-10-03 15:11:15 [INFO ]  	distill_steps: 1
2022-10-03 15:11:15 [INFO ]  	epochs: 200
2022-10-03 15:11:15 [INFO ]  	expand_cls: false
2022-10-03 15:11:15 [INFO ]  	forgetting_dataset: null
2022-10-03 15:11:15 [INFO ]  	init: xavier
2022-10-03 15:11:15 [INFO ]  	init_param: 1.0
2022-10-03 15:11:15 [INFO ]  	input_size: 32
2022-10-03 15:11:15 [INFO ]  	ipc: 10
2022-10-03 15:11:15 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 15:11:15 [INFO ]  	log_interval: 100
2022-10-03 15:11:15 [INFO ]  	log_level: INFO
2022-10-03 15:11:15 [INFO ]  	lr: 0.01
2022-10-03 15:11:15 [INFO ]  	mode: distill_adapt
2022-10-03 15:11:15 [INFO ]  	nc: 3
2022-10-03 15:11:15 [INFO ]  	num_classes: 10
2022-10-03 15:11:15 [INFO ]  	num_workers: 8
2022-10-03 15:11:15 [INFO ]  	phase: train
2022-10-03 15:11:15 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 15:11:15 [INFO ]  	start_time: '2022-10-03 15:11:15'
2022-10-03 15:11:15 [INFO ]  	test_batch_size: 1024
2022-10-03 15:11:15 [INFO ]  	
2022-10-03 15:11:17 [INFO ]  train dataset size:	73257
2022-10-03 15:11:17 [INFO ]  test dataset size: 	26032
2022-10-03 15:11:17 [INFO ]  datasets built!
2022-10-03 15:11:17 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 15:11:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 15:11:25 [INFO ]  
2022-10-03 15:11:25 [INFO ]  Begin of epoch 0 :
2022-10-03 15:11:29 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:11:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:11:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:11:29 [INFO ]  	   step  1 (lr=0.020000)                    7.03%                   8.5896
2022-10-03 15:11:29 [INFO ]  
2022-10-03 15:11:29 [INFO ]  Epoch:    0	Loss: 8.4731	Data Time: 0.46s	Train Time: 0.04s
2022-10-03 15:11:30 [INFO ]  Epoch:    1	Loss: 3.0955	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 15:11:32 [INFO ]  Epoch:    2	Loss: 2.4620	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:11:34 [INFO ]  Epoch:    3	Loss: 2.2993	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:11:36 [INFO ]  Epoch:    4	Loss: 2.2081	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:11:38 [INFO ]  Epoch:    5	Loss: 2.1800	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:11:39 [INFO ]  Epoch:    6	Loss: 2.1569	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:11:42 [INFO ]  Epoch:    7	Loss: 2.0976	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:11:43 [INFO ]  Epoch:    8	Loss: 2.0660	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:11:45 [INFO ]  Epoch:    9	Loss: 1.9544	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:11:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 15:11:54 [INFO ]  
2022-10-03 15:11:54 [INFO ]  Begin of epoch 10 :
2022-10-03 15:11:57 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:11:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:11:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:11:57 [INFO ]  	   step  1 (lr=0.071064)                   36.96%                   1.9342
2022-10-03 15:11:57 [INFO ]  
2022-10-03 15:11:57 [INFO ]  Epoch:   10	Loss: 1.8996	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:11:58 [INFO ]  Epoch:   11	Loss: 1.7324	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:12:00 [INFO ]  Epoch:   12	Loss: 1.6331	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:02 [INFO ]  Epoch:   13	Loss: 1.4933	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:04 [INFO ]  Epoch:   14	Loss: 1.6355	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:12:06 [INFO ]  Epoch:   15	Loss: 1.4163	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:12:08 [INFO ]  Epoch:   16	Loss: 1.2442	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:12:09 [INFO ]  Epoch:   17	Loss: 1.2530	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:12:11 [INFO ]  Epoch:   18	Loss: 1.0723	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:12:13 [INFO ]  Epoch:   19	Loss: 1.1516	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 15:12:21 [INFO ]  
2022-10-03 15:12:21 [INFO ]  Begin of epoch 20 :
2022-10-03 15:12:25 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:12:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:12:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:12:25 [INFO ]  	   step  1 (lr=0.214549)                   64.50%                   1.2063
2022-10-03 15:12:25 [INFO ]  
2022-10-03 15:12:25 [INFO ]  Epoch:   20	Loss: 1.1335	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:12:27 [INFO ]  Epoch:   21	Loss: 1.1643	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 15:12:28 [INFO ]  Epoch:   22	Loss: 1.0541	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:12:30 [INFO ]  Epoch:   23	Loss: 1.0940	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:12:32 [INFO ]  Epoch:   24	Loss: 1.1390	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:34 [INFO ]  Epoch:   25	Loss: 1.0064	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:12:36 [INFO ]  Epoch:   26	Loss: 1.0556	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:12:38 [INFO ]  Epoch:   27	Loss: 1.0272	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:40 [INFO ]  Epoch:   28	Loss: 0.9827	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:12:41 [INFO ]  Epoch:   29	Loss: 0.9751	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:12:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 15:12:50 [INFO ]  
2022-10-03 15:12:50 [INFO ]  Begin of epoch 30 :
2022-10-03 15:12:54 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:12:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:12:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:12:54 [INFO ]  	   step  1 (lr=0.273679)                   69.16%                   1.1041
2022-10-03 15:12:54 [INFO ]  
2022-10-03 15:12:54 [INFO ]  Epoch:   30	Loss: 1.0323	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:12:55 [INFO ]  Epoch:   31	Loss: 0.9614	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:12:57 [INFO ]  Epoch:   32	Loss: 0.8917	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:12:59 [INFO ]  Epoch:   33	Loss: 0.9000	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:13:00 [INFO ]  Epoch:   34	Loss: 0.9514	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:13:02 [INFO ]  Epoch:   35	Loss: 0.8960	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:04 [INFO ]  Epoch:   36	Loss: 0.8992	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:13:06 [INFO ]  Epoch:   37	Loss: 0.8784	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:13:08 [INFO ]  Epoch:   38	Loss: 0.8510	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:13:10 [INFO ]  Epoch:   39	Loss: 0.8797	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 15:13:18 [INFO ]  
2022-10-03 15:13:18 [INFO ]  Begin of epoch 40 :
2022-10-03 15:13:21 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:13:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:13:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:13:21 [INFO ]  	   step  1 (lr=0.314454)                   75.29%                   0.8823
2022-10-03 15:13:21 [INFO ]  
2022-10-03 15:13:21 [INFO ]  Epoch:   40	Loss: 0.8852	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 15:13:23 [INFO ]  Epoch:   41	Loss: 0.8167	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:13:25 [INFO ]  Epoch:   42	Loss: 0.8043	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:13:27 [INFO ]  Epoch:   43	Loss: 0.7869	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:13:29 [INFO ]  Epoch:   44	Loss: 0.7882	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:13:31 [INFO ]  Epoch:   45	Loss: 0.7572	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:32 [INFO ]  Epoch:   46	Loss: 0.7862	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:13:34 [INFO ]  Epoch:   47	Loss: 0.8283	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:13:36 [INFO ]  Epoch:   48	Loss: 0.7483	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:13:38 [INFO ]  Epoch:   49	Loss: 0.7712	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:13:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 15:13:46 [INFO ]  
2022-10-03 15:13:46 [INFO ]  Begin of epoch 50 :
2022-10-03 15:13:50 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:13:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:13:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:13:50 [INFO ]  	   step  1 (lr=0.336908)                   78.25%                   0.7937
2022-10-03 15:13:50 [INFO ]  
2022-10-03 15:13:50 [INFO ]  Epoch:   50	Loss: 0.7296	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:13:51 [INFO ]  Epoch:   51	Loss: 0.7336	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:53 [INFO ]  Epoch:   52	Loss: 0.7280	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:55 [INFO ]  Epoch:   53	Loss: 0.7913	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:57 [INFO ]  Epoch:   54	Loss: 0.7109	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:13:59 [INFO ]  Epoch:   55	Loss: 0.7441	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:14:01 [INFO ]  Epoch:   56	Loss: 0.7624	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:14:03 [INFO ]  Epoch:   57	Loss: 0.6955	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:14:05 [INFO ]  Epoch:   58	Loss: 0.7403	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:14:07 [INFO ]  Epoch:   59	Loss: 0.8056	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:14:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 15:14:15 [INFO ]  
2022-10-03 15:14:15 [INFO ]  Begin of epoch 60 :
2022-10-03 15:14:19 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:14:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:14:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:14:19 [INFO ]  	   step  1 (lr=0.345065)                   77.96%                   0.8102
2022-10-03 15:14:19 [INFO ]  
2022-10-03 15:14:19 [INFO ]  Epoch:   60	Loss: 0.7352	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 15:14:20 [INFO ]  Epoch:   61	Loss: 0.6551	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:14:22 [INFO ]  Epoch:   62	Loss: 0.6514	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:14:24 [INFO ]  Epoch:   63	Loss: 0.7149	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:14:26 [INFO ]  Epoch:   64	Loss: 0.7009	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:14:28 [INFO ]  Epoch:   65	Loss: 0.6397	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:14:30 [INFO ]  Epoch:   66	Loss: 0.7044	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:14:32 [INFO ]  Epoch:   67	Loss: 0.7043	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:14:34 [INFO ]  Epoch:   68	Loss: 0.6963	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:14:35 [INFO ]  Epoch:   69	Loss: 0.6705	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:14:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 15:14:44 [INFO ]  
2022-10-03 15:14:44 [INFO ]  Begin of epoch 70 :
2022-10-03 15:14:47 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:14:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:14:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:14:47 [INFO ]  	   step  1 (lr=0.361028)                   78.88%                   0.7765
2022-10-03 15:14:47 [INFO ]  
2022-10-03 15:14:47 [INFO ]  Epoch:   70	Loss: 0.7389	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:14:49 [INFO ]  Epoch:   71	Loss: 0.7045	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:14:51 [INFO ]  Epoch:   72	Loss: 0.6720	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:14:53 [INFO ]  Epoch:   73	Loss: 0.7739	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:14:55 [INFO ]  Epoch:   74	Loss: 0.7006	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:14:57 [INFO ]  Epoch:   75	Loss: 0.6453	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:14:58 [INFO ]  Epoch:   76	Loss: 0.7033	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:15:00 [INFO ]  Epoch:   77	Loss: 0.6905	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:02 [INFO ]  Epoch:   78	Loss: 0.6001	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:15:04 [INFO ]  Epoch:   79	Loss: 0.7682	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:15:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 15:15:13 [INFO ]  
2022-10-03 15:15:13 [INFO ]  Begin of epoch 80 :
2022-10-03 15:15:16 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:15:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:15:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:15:16 [INFO ]  	   step  1 (lr=0.369692)                   78.07%                   0.7937
2022-10-03 15:15:16 [INFO ]  
2022-10-03 15:15:16 [INFO ]  Epoch:   80	Loss: 0.7292	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 15:15:18 [INFO ]  Epoch:   81	Loss: 0.6676	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:15:20 [INFO ]  Epoch:   82	Loss: 0.7256	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:15:22 [INFO ]  Epoch:   83	Loss: 0.6595	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:15:24 [INFO ]  Epoch:   84	Loss: 0.7496	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:26 [INFO ]  Epoch:   85	Loss: 0.7432	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:15:27 [INFO ]  Epoch:   86	Loss: 0.6726	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:15:29 [INFO ]  Epoch:   87	Loss: 0.6540	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:15:31 [INFO ]  Epoch:   88	Loss: 0.6516	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:33 [INFO ]  Epoch:   89	Loss: 0.6903	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 15:15:41 [INFO ]  
2022-10-03 15:15:41 [INFO ]  Begin of epoch 90 :
2022-10-03 15:15:45 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:15:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:15:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:15:45 [INFO ]  	   step  1 (lr=0.380174)                   78.97%                   0.7702
2022-10-03 15:15:45 [INFO ]  
2022-10-03 15:15:45 [INFO ]  Epoch:   90	Loss: 0.7056	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:47 [INFO ]  Epoch:   91	Loss: 0.7154	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:48 [INFO ]  Epoch:   92	Loss: 0.7040	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:15:50 [INFO ]  Epoch:   93	Loss: 0.6747	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:15:52 [INFO ]  Epoch:   94	Loss: 0.6554	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:15:54 [INFO ]  Epoch:   95	Loss: 0.6969	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:15:55 [INFO ]  Epoch:   96	Loss: 0.6230	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:57 [INFO ]  Epoch:   97	Loss: 0.6549	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:15:59 [INFO ]  Epoch:   98	Loss: 0.7592	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:01 [INFO ]  Epoch:   99	Loss: 0.6446	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 15:16:10 [INFO ]  
2022-10-03 15:16:10 [INFO ]  Begin of epoch 100 :
2022-10-03 15:16:13 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:16:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:16:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:16:13 [INFO ]  	   step  1 (lr=0.385387)                   79.61%                   0.7516
2022-10-03 15:16:13 [INFO ]  
2022-10-03 15:16:13 [INFO ]  Epoch:  100	Loss: 0.6958	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:16:15 [INFO ]  Epoch:  101	Loss: 0.7358	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:16:17 [INFO ]  Epoch:  102	Loss: 0.6041	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:16:19 [INFO ]  Epoch:  103	Loss: 0.6782	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:16:21 [INFO ]  Epoch:  104	Loss: 0.7400	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:16:22 [INFO ]  Epoch:  105	Loss: 0.6893	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:24 [INFO ]  Epoch:  106	Loss: 0.6339	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:16:26 [INFO ]  Epoch:  107	Loss: 0.6542	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:28 [INFO ]  Epoch:  108	Loss: 0.7212	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:16:30 [INFO ]  Epoch:  109	Loss: 0.7402	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 15:16:39 [INFO ]  
2022-10-03 15:16:39 [INFO ]  Begin of epoch 110 :
2022-10-03 15:16:42 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:16:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:16:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:16:42 [INFO ]  	   step  1 (lr=0.388543)                   79.76%                   0.7509
2022-10-03 15:16:42 [INFO ]  
2022-10-03 15:16:42 [INFO ]  Epoch:  110	Loss: 0.6011	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 15:16:44 [INFO ]  Epoch:  111	Loss: 0.6610	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:16:46 [INFO ]  Epoch:  112	Loss: 0.7914	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:16:48 [INFO ]  Epoch:  113	Loss: 0.6642	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:49 [INFO ]  Epoch:  114	Loss: 0.6220	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:16:51 [INFO ]  Epoch:  115	Loss: 0.6179	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:53 [INFO ]  Epoch:  116	Loss: 0.6309	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:16:55 [INFO ]  Epoch:  117	Loss: 0.6629	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:16:57 [INFO ]  Epoch:  118	Loss: 0.6419	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:16:59 [INFO ]  Epoch:  119	Loss: 0.7417	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 15:17:08 [INFO ]  
2022-10-03 15:17:08 [INFO ]  Begin of epoch 120 :
2022-10-03 15:17:11 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:17:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:17:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:17:11 [INFO ]  	   step  1 (lr=0.392616)                   79.86%                   0.7436
2022-10-03 15:17:11 [INFO ]  
2022-10-03 15:17:11 [INFO ]  Epoch:  120	Loss: 0.7240	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:17:13 [INFO ]  Epoch:  121	Loss: 0.6613	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:15 [INFO ]  Epoch:  122	Loss: 0.6044	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:17 [INFO ]  Epoch:  123	Loss: 0.7107	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:17:19 [INFO ]  Epoch:  124	Loss: 0.7536	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:17:21 [INFO ]  Epoch:  125	Loss: 0.6698	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:17:22 [INFO ]  Epoch:  126	Loss: 0.6394	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:24 [INFO ]  Epoch:  127	Loss: 0.6727	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:17:26 [INFO ]  Epoch:  128	Loss: 0.6934	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 15:17:28 [INFO ]  Epoch:  129	Loss: 0.6368	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:17:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 15:17:37 [INFO ]  
2022-10-03 15:17:37 [INFO ]  Begin of epoch 130 :
2022-10-03 15:17:40 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:17:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:17:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:17:40 [INFO ]  	   step  1 (lr=0.393146)                   79.78%                   0.7443
2022-10-03 15:17:40 [INFO ]  
2022-10-03 15:17:40 [INFO ]  Epoch:  130	Loss: 0.6457	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:42 [INFO ]  Epoch:  131	Loss: 0.6311	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 15:17:44 [INFO ]  Epoch:  132	Loss: 0.6192	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:17:46 [INFO ]  Epoch:  133	Loss: 0.6324	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:17:48 [INFO ]  Epoch:  134	Loss: 0.6185	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:17:49 [INFO ]  Epoch:  135	Loss: 0.6299	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:17:51 [INFO ]  Epoch:  136	Loss: 0.6910	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:17:53 [INFO ]  Epoch:  137	Loss: 0.6513	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:17:55 [INFO ]  Epoch:  138	Loss: 0.6257	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:17:57 [INFO ]  Epoch:  139	Loss: 0.6862	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:18:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 15:18:06 [INFO ]  
2022-10-03 15:18:06 [INFO ]  Begin of epoch 140 :
2022-10-03 15:18:09 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:18:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:18:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:18:09 [INFO ]  	   step  1 (lr=0.393796)                   79.61%                   0.7514
2022-10-03 15:18:09 [INFO ]  
2022-10-03 15:18:09 [INFO ]  Epoch:  140	Loss: 0.6819	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:18:11 [INFO ]  Epoch:  141	Loss: 0.6546	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:18:13 [INFO ]  Epoch:  142	Loss: 0.6847	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:14 [INFO ]  Epoch:  143	Loss: 0.6810	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:18:16 [INFO ]  Epoch:  144	Loss: 0.5979	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:18 [INFO ]  Epoch:  145	Loss: 0.7058	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:18:20 [INFO ]  Epoch:  146	Loss: 0.6591	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:22 [INFO ]  Epoch:  147	Loss: 0.6495	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:24 [INFO ]  Epoch:  148	Loss: 0.7078	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:18:26 [INFO ]  Epoch:  149	Loss: 0.6588	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 15:18:34 [INFO ]  
2022-10-03 15:18:34 [INFO ]  Begin of epoch 150 :
2022-10-03 15:18:38 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:18:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:18:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:18:38 [INFO ]  	   step  1 (lr=0.396794)                   79.62%                   0.7460
2022-10-03 15:18:38 [INFO ]  
2022-10-03 15:18:38 [INFO ]  Epoch:  150	Loss: 0.6591	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:18:39 [INFO ]  Epoch:  151	Loss: 0.6643	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:18:42 [INFO ]  Epoch:  152	Loss: 0.6141	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:18:43 [INFO ]  Epoch:  153	Loss: 0.6249	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:45 [INFO ]  Epoch:  154	Loss: 0.6108	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:18:47 [INFO ]  Epoch:  155	Loss: 0.6141	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:18:49 [INFO ]  Epoch:  156	Loss: 0.6397	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:18:51 [INFO ]  Epoch:  157	Loss: 0.6303	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:18:53 [INFO ]  Epoch:  158	Loss: 0.6202	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:18:55 [INFO ]  Epoch:  159	Loss: 0.6219	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:19:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 15:19:04 [INFO ]  
2022-10-03 15:19:04 [INFO ]  Begin of epoch 160 :
2022-10-03 15:19:07 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:19:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:19:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:19:07 [INFO ]  	   step  1 (lr=0.396754)                   79.87%                   0.7397
2022-10-03 15:19:07 [INFO ]  
2022-10-03 15:19:07 [INFO ]  Epoch:  160	Loss: 0.6526	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:19:09 [INFO ]  Epoch:  161	Loss: 0.6551	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:19:11 [INFO ]  Epoch:  162	Loss: 0.6846	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:19:13 [INFO ]  Epoch:  163	Loss: 0.6235	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:19:15 [INFO ]  Epoch:  164	Loss: 0.6104	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 15:19:16 [INFO ]  Epoch:  165	Loss: 0.7727	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:19:18 [INFO ]  Epoch:  166	Loss: 0.7345	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:19:20 [INFO ]  Epoch:  167	Loss: 0.6265	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:19:22 [INFO ]  Epoch:  168	Loss: 0.7098	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 15:19:24 [INFO ]  Epoch:  169	Loss: 0.6729	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:19:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 15:19:33 [INFO ]  
2022-10-03 15:19:33 [INFO ]  Begin of epoch 170 :
2022-10-03 15:19:36 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:19:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:19:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:19:36 [INFO ]  	   step  1 (lr=0.395758)                   80.09%                   0.7367
2022-10-03 15:19:36 [INFO ]  
2022-10-03 15:19:36 [INFO ]  Epoch:  170	Loss: 0.6120	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:19:38 [INFO ]  Epoch:  171	Loss: 0.6938	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:19:40 [INFO ]  Epoch:  172	Loss: 0.6270	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:19:42 [INFO ]  Epoch:  173	Loss: 0.6567	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:19:44 [INFO ]  Epoch:  174	Loss: 0.7271	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:19:45 [INFO ]  Epoch:  175	Loss: 0.6151	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:19:47 [INFO ]  Epoch:  176	Loss: 0.6562	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:19:49 [INFO ]  Epoch:  177	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:19:51 [INFO ]  Epoch:  178	Loss: 0.6920	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:19:53 [INFO ]  Epoch:  179	Loss: 0.7094	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:20:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 15:20:02 [INFO ]  
2022-10-03 15:20:02 [INFO ]  Begin of epoch 180 :
2022-10-03 15:20:05 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:20:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:20:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:20:05 [INFO ]  	   step  1 (lr=0.396162)                   79.32%                   0.7560
2022-10-03 15:20:05 [INFO ]  
2022-10-03 15:20:05 [INFO ]  Epoch:  180	Loss: 0.6241	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:07 [INFO ]  Epoch:  181	Loss: 0.6024	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:09 [INFO ]  Epoch:  182	Loss: 0.6121	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:20:11 [INFO ]  Epoch:  183	Loss: 0.6472	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:13 [INFO ]  Epoch:  184	Loss: 0.6920	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:15 [INFO ]  Epoch:  185	Loss: 0.6268	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:20:17 [INFO ]  Epoch:  186	Loss: 0.7343	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:19 [INFO ]  Epoch:  187	Loss: 0.6472	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:20:21 [INFO ]  Epoch:  188	Loss: 0.6218	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:23 [INFO ]  Epoch:  189	Loss: 0.7186	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:20:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 15:20:31 [INFO ]  
2022-10-03 15:20:31 [INFO ]  Begin of epoch 190 :
2022-10-03 15:20:35 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:20:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:20:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:20:35 [INFO ]  	   step  1 (lr=0.396914)                   79.40%                   0.7488
2022-10-03 15:20:35 [INFO ]  
2022-10-03 15:20:35 [INFO ]  Epoch:  190	Loss: 0.6726	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:20:37 [INFO ]  Epoch:  191	Loss: 0.7052	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:20:38 [INFO ]  Epoch:  192	Loss: 0.6203	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:20:40 [INFO ]  Epoch:  193	Loss: 0.6488	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:20:42 [INFO ]  Epoch:  194	Loss: 0.6233	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:20:44 [INFO ]  Epoch:  195	Loss: 0.6440	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:20:46 [INFO ]  Epoch:  196	Loss: 0.6944	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:20:48 [INFO ]  Epoch:  197	Loss: 0.6993	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:20:50 [INFO ]  Epoch:  198	Loss: 0.6366	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:20:52 [INFO ]  Epoch:  199	Loss: 0.6739	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:21:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 15:21:00 [INFO ]  
2022-10-03 15:21:00 [INFO ]  Final evaluation for SVHN :
2022-10-03 15:21:03 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:21:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:21:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:21:03 [INFO ]  	   step  1 (lr=0.397848)                   79.55%                   0.7473
2022-10-03 15:21:03 [INFO ]  
2022-10-03 15:21:03 [INFO ]  
2022-10-03 15:21:03 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 15:21:06 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:21:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:21:06 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 15:21:06 [INFO ]  	   step  1 (lr=0.397848)                   17.38%                   5.3820
2022-10-03 15:21:06 [INFO ]  
2022-10-03 15:21:06 [INFO ]  CPU Time: 6.73 minutes
2022-10-03 15:54:36 [INFO ]  ======================================== 2022-10-03 15:54:36 ========================================
2022-10-03 15:54:36 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 15:54:36 [INFO ]  Options: 
2022-10-03 15:54:36 [INFO ]  	base_dir: null
2022-10-03 15:54:36 [INFO ]  	batch_size: 1024
2022-10-03 15:54:36 [INFO ]  	checkpoint_interval: 10
2022-10-03 15:54:36 [INFO ]  	dataset: SVHN
2022-10-03 15:54:36 [INFO ]  	dataset_labels:
2022-10-03 15:54:36 [INFO ]  	- 0
2022-10-03 15:54:36 [INFO ]  	- 1
2022-10-03 15:54:36 [INFO ]  	- 2
2022-10-03 15:54:36 [INFO ]  	- 3
2022-10-03 15:54:36 [INFO ]  	- 4
2022-10-03 15:54:36 [INFO ]  	- 5
2022-10-03 15:54:36 [INFO ]  	- 6
2022-10-03 15:54:36 [INFO ]  	- 7
2022-10-03 15:54:36 [INFO ]  	- 8
2022-10-03 15:54:36 [INFO ]  	- 9
2022-10-03 15:54:36 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 15:54:36 [INFO ]  	- !!python/tuple
2022-10-03 15:54:36 [INFO ]  	    - 0.4379104971885681
2022-10-03 15:54:36 [INFO ]  	    - 0.44398033618927
2022-10-03 15:54:36 [INFO ]  	    - 0.4729299545288086
2022-10-03 15:54:36 [INFO ]  	- !!python/tuple
2022-10-03 15:54:36 [INFO ]  	    - 0.19803012907505035
2022-10-03 15:54:36 [INFO ]  	    - 0.2010156363248825
2022-10-03 15:54:36 [INFO ]  	    - 0.19703614711761475
2022-10-03 15:54:36 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 15:54:36 [INFO ]  	decay_epochs: 50
2022-10-03 15:54:36 [INFO ]  	decay_factor: 0.1
2022-10-03 15:54:36 [INFO ]  	device_id: 0
2022-10-03 15:54:36 [INFO ]  	distill_epochs: 1
2022-10-03 15:54:36 [INFO ]  	distill_lr: 0.02
2022-10-03 15:54:36 [INFO ]  	distill_steps: 1
2022-10-03 15:54:36 [INFO ]  	epochs: 200
2022-10-03 15:54:36 [INFO ]  	expand_cls: false
2022-10-03 15:54:36 [INFO ]  	forgetting_dataset: null
2022-10-03 15:54:36 [INFO ]  	init: xavier
2022-10-03 15:54:36 [INFO ]  	init_param: 1.0
2022-10-03 15:54:36 [INFO ]  	input_size: 32
2022-10-03 15:54:36 [INFO ]  	ipc: 15
2022-10-03 15:54:36 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 15:54:36 [INFO ]  	log_interval: 100
2022-10-03 15:54:36 [INFO ]  	log_level: INFO
2022-10-03 15:54:36 [INFO ]  	lr: 0.01
2022-10-03 15:54:36 [INFO ]  	mode: distill_adapt
2022-10-03 15:54:36 [INFO ]  	nc: 3
2022-10-03 15:54:36 [INFO ]  	num_classes: 10
2022-10-03 15:54:36 [INFO ]  	num_workers: 8
2022-10-03 15:54:36 [INFO ]  	phase: train
2022-10-03 15:54:36 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 15:54:36 [INFO ]  	start_time: '2022-10-03 15:54:36'
2022-10-03 15:54:36 [INFO ]  	test_batch_size: 1024
2022-10-03 15:54:36 [INFO ]  	
2022-10-03 15:54:38 [INFO ]  train dataset size:	73257
2022-10-03 15:54:38 [INFO ]  test dataset size: 	26032
2022-10-03 15:54:38 [INFO ]  datasets built!
2022-10-03 15:54:38 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 15:54:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 15:54:50 [INFO ]  
2022-10-03 15:54:50 [INFO ]  Begin of epoch 0 :
2022-10-03 15:54:53 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:54:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:54:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:54:53 [INFO ]  	   step  1 (lr=0.020000)                    7.08%                   9.0992
2022-10-03 15:54:53 [INFO ]  
2022-10-03 15:54:53 [INFO ]  Epoch:    0	Loss: 9.3350	Data Time: 0.37s	Train Time: 0.04s
2022-10-03 15:54:55 [INFO ]  Epoch:    1	Loss: 3.0685	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 15:54:57 [INFO ]  Epoch:    2	Loss: 2.5628	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:54:58 [INFO ]  Epoch:    3	Loss: 2.2997	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:55:00 [INFO ]  Epoch:    4	Loss: 2.2271	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:55:02 [INFO ]  Epoch:    5	Loss: 2.2044	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:55:04 [INFO ]  Epoch:    6	Loss: 2.1536	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:55:06 [INFO ]  Epoch:    7	Loss: 2.1208	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:55:08 [INFO ]  Epoch:    8	Loss: 2.1098	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:55:09 [INFO ]  Epoch:    9	Loss: 2.0163	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:55:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 15:55:21 [INFO ]  
2022-10-03 15:55:21 [INFO ]  Begin of epoch 10 :
2022-10-03 15:55:24 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:55:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:55:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:55:24 [INFO ]  	   step  1 (lr=0.063178)                   38.01%                   1.9492
2022-10-03 15:55:24 [INFO ]  
2022-10-03 15:55:24 [INFO ]  Epoch:   10	Loss: 1.9543	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 15:55:26 [INFO ]  Epoch:   11	Loss: 1.8023	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:55:28 [INFO ]  Epoch:   12	Loss: 1.6840	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:55:30 [INFO ]  Epoch:   13	Loss: 1.7030	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:55:32 [INFO ]  Epoch:   14	Loss: 1.4641	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:55:34 [INFO ]  Epoch:   15	Loss: 1.3753	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:55:36 [INFO ]  Epoch:   16	Loss: 1.4176	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:55:38 [INFO ]  Epoch:   17	Loss: 1.2769	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:55:40 [INFO ]  Epoch:   18	Loss: 1.1510	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:55:42 [INFO ]  Epoch:   19	Loss: 1.3555	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:55:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 15:55:53 [INFO ]  
2022-10-03 15:55:53 [INFO ]  Begin of epoch 20 :
2022-10-03 15:55:57 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:55:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:55:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:55:57 [INFO ]  	   step  1 (lr=0.221429)                   66.00%                   1.1662
2022-10-03 15:55:57 [INFO ]  
2022-10-03 15:55:57 [INFO ]  Epoch:   20	Loss: 1.1211	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:55:58 [INFO ]  Epoch:   21	Loss: 1.1443	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:56:00 [INFO ]  Epoch:   22	Loss: 1.1463	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:56:02 [INFO ]  Epoch:   23	Loss: 0.9919	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:56:04 [INFO ]  Epoch:   24	Loss: 0.9400	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:56:06 [INFO ]  Epoch:   25	Loss: 0.9966	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:56:08 [INFO ]  Epoch:   26	Loss: 0.9910	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:56:09 [INFO ]  Epoch:   27	Loss: 0.9787	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:56:11 [INFO ]  Epoch:   28	Loss: 0.9404	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:56:13 [INFO ]  Epoch:   29	Loss: 0.9464	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:56:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 15:56:25 [INFO ]  
2022-10-03 15:56:25 [INFO ]  Begin of epoch 30 :
2022-10-03 15:56:28 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:56:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:56:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:56:28 [INFO ]  	   step  1 (lr=0.287902)                   73.05%                   0.9611
2022-10-03 15:56:28 [INFO ]  
2022-10-03 15:56:28 [INFO ]  Epoch:   30	Loss: 0.9221	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:56:30 [INFO ]  Epoch:   31	Loss: 0.9040	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:56:32 [INFO ]  Epoch:   32	Loss: 0.8756	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:56:34 [INFO ]  Epoch:   33	Loss: 0.9020	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:56:35 [INFO ]  Epoch:   34	Loss: 1.0071	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:56:37 [INFO ]  Epoch:   35	Loss: 0.8157	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:56:39 [INFO ]  Epoch:   36	Loss: 0.7719	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:56:41 [INFO ]  Epoch:   37	Loss: 0.8365	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:56:43 [INFO ]  Epoch:   38	Loss: 0.8761	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:56:45 [INFO ]  Epoch:   39	Loss: 0.7820	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:56:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 15:56:57 [INFO ]  
2022-10-03 15:56:57 [INFO ]  Begin of epoch 40 :
2022-10-03 15:57:00 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:57:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:57:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:57:00 [INFO ]  	   step  1 (lr=0.323228)                   68.29%                   1.0910
2022-10-03 15:57:00 [INFO ]  
2022-10-03 15:57:00 [INFO ]  Epoch:   40	Loss: 1.0106	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:57:02 [INFO ]  Epoch:   41	Loss: 0.9093	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:04 [INFO ]  Epoch:   42	Loss: 0.7691	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:57:06 [INFO ]  Epoch:   43	Loss: 0.8828	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:07 [INFO ]  Epoch:   44	Loss: 1.2109	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:57:09 [INFO ]  Epoch:   45	Loss: 0.6925	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:57:11 [INFO ]  Epoch:   46	Loss: 0.7003	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:13 [INFO ]  Epoch:   47	Loss: 0.7594	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:15 [INFO ]  Epoch:   48	Loss: 0.7407	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:17 [INFO ]  Epoch:   49	Loss: 0.6889	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 15:57:29 [INFO ]  
2022-10-03 15:57:29 [INFO ]  Begin of epoch 50 :
2022-10-03 15:57:32 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:57:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:57:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:57:32 [INFO ]  	   step  1 (lr=0.350718)                   79.53%                   0.7612
2022-10-03 15:57:32 [INFO ]  
2022-10-03 15:57:32 [INFO ]  Epoch:   50	Loss: 0.7344	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 15:57:34 [INFO ]  Epoch:   51	Loss: 0.6450	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:57:36 [INFO ]  Epoch:   52	Loss: 0.6398	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:37 [INFO ]  Epoch:   53	Loss: 0.7194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:57:39 [INFO ]  Epoch:   54	Loss: 0.7095	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:41 [INFO ]  Epoch:   55	Loss: 0.6572	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:57:43 [INFO ]  Epoch:   56	Loss: 0.7071	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:57:45 [INFO ]  Epoch:   57	Loss: 0.6842	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:57:47 [INFO ]  Epoch:   58	Loss: 0.6484	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:57:49 [INFO ]  Epoch:   59	Loss: 0.6719	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 15:58:01 [INFO ]  
2022-10-03 15:58:01 [INFO ]  Begin of epoch 60 :
2022-10-03 15:58:04 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:58:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:58:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:58:04 [INFO ]  	   step  1 (lr=0.364650)                   79.19%                   0.7590
2022-10-03 15:58:04 [INFO ]  
2022-10-03 15:58:04 [INFO ]  Epoch:   60	Loss: 0.7100	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 15:58:06 [INFO ]  Epoch:   61	Loss: 0.6938	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:08 [INFO ]  Epoch:   62	Loss: 0.6574	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:58:09 [INFO ]  Epoch:   63	Loss: 0.6774	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 15:58:11 [INFO ]  Epoch:   64	Loss: 0.6755	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:58:13 [INFO ]  Epoch:   65	Loss: 0.6763	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:58:15 [INFO ]  Epoch:   66	Loss: 0.7301	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:17 [INFO ]  Epoch:   67	Loss: 0.7164	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 15:58:19 [INFO ]  Epoch:   68	Loss: 0.7183	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:21 [INFO ]  Epoch:   69	Loss: 0.7466	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:58:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 15:58:32 [INFO ]  
2022-10-03 15:58:32 [INFO ]  Begin of epoch 70 :
2022-10-03 15:58:36 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:58:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:58:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:58:36 [INFO ]  	   step  1 (lr=0.376527)                   80.19%                   0.7404
2022-10-03 15:58:36 [INFO ]  
2022-10-03 15:58:36 [INFO ]  Epoch:   70	Loss: 0.6829	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:58:38 [INFO ]  Epoch:   71	Loss: 0.6688	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:58:39 [INFO ]  Epoch:   72	Loss: 0.7194	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:58:41 [INFO ]  Epoch:   73	Loss: 0.6850	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:58:43 [INFO ]  Epoch:   74	Loss: 0.7224	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:58:45 [INFO ]  Epoch:   75	Loss: 0.6837	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:47 [INFO ]  Epoch:   76	Loss: 0.7078	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:58:49 [INFO ]  Epoch:   77	Loss: 0.6655	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 15:58:51 [INFO ]  Epoch:   78	Loss: 0.7260	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:58:53 [INFO ]  Epoch:   79	Loss: 0.7183	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:59:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 15:59:05 [INFO ]  
2022-10-03 15:59:05 [INFO ]  Begin of epoch 80 :
2022-10-03 15:59:08 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:59:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:59:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:59:08 [INFO ]  	   step  1 (lr=0.381596)                   79.83%                   0.7405
2022-10-03 15:59:08 [INFO ]  
2022-10-03 15:59:08 [INFO ]  Epoch:   80	Loss: 0.6036	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 15:59:10 [INFO ]  Epoch:   81	Loss: 0.6732	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:12 [INFO ]  Epoch:   82	Loss: 0.7018	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:59:14 [INFO ]  Epoch:   83	Loss: 0.6195	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:59:16 [INFO ]  Epoch:   84	Loss: 0.6202	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:59:17 [INFO ]  Epoch:   85	Loss: 0.7084	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:19 [INFO ]  Epoch:   86	Loss: 0.6342	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:59:21 [INFO ]  Epoch:   87	Loss: 0.6541	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:59:23 [INFO ]  Epoch:   88	Loss: 0.6700	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 15:59:25 [INFO ]  Epoch:   89	Loss: 0.6206	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 15:59:36 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 15:59:36 [INFO ]  
2022-10-03 15:59:36 [INFO ]  Begin of epoch 90 :
2022-10-03 15:59:40 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 15:59:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 15:59:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 15:59:40 [INFO ]  	   step  1 (lr=0.395014)                   80.26%                   0.7328
2022-10-03 15:59:40 [INFO ]  
2022-10-03 15:59:40 [INFO ]  Epoch:   90	Loss: 0.7051	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:42 [INFO ]  Epoch:   91	Loss: 0.6602	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:59:44 [INFO ]  Epoch:   92	Loss: 0.6407	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:45 [INFO ]  Epoch:   93	Loss: 0.6641	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:47 [INFO ]  Epoch:   94	Loss: 0.6652	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 15:59:49 [INFO ]  Epoch:   95	Loss: 0.6161	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 15:59:51 [INFO ]  Epoch:   96	Loss: 0.7363	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 15:59:53 [INFO ]  Epoch:   97	Loss: 0.6113	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 15:59:55 [INFO ]  Epoch:   98	Loss: 0.6224	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 15:59:57 [INFO ]  Epoch:   99	Loss: 0.6185	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:00:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 16:00:09 [INFO ]  
2022-10-03 16:00:09 [INFO ]  Begin of epoch 100 :
2022-10-03 16:00:12 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:00:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:00:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:00:12 [INFO ]  	   step  1 (lr=0.401947)                   80.00%                   0.7353
2022-10-03 16:00:12 [INFO ]  
2022-10-03 16:00:12 [INFO ]  Epoch:  100	Loss: 0.6721	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:00:14 [INFO ]  Epoch:  101	Loss: 0.6985	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:00:16 [INFO ]  Epoch:  102	Loss: 0.6142	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:00:18 [INFO ]  Epoch:  103	Loss: 0.6355	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:00:20 [INFO ]  Epoch:  104	Loss: 0.6493	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:00:22 [INFO ]  Epoch:  105	Loss: 0.6520	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:00:24 [INFO ]  Epoch:  106	Loss: 0.6282	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:00:25 [INFO ]  Epoch:  107	Loss: 0.5844	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:00:27 [INFO ]  Epoch:  108	Loss: 0.6419	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 16:00:29 [INFO ]  Epoch:  109	Loss: 0.6159	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:00:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 16:00:41 [INFO ]  
2022-10-03 16:00:41 [INFO ]  Begin of epoch 110 :
2022-10-03 16:00:45 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:00:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:00:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:00:45 [INFO ]  	   step  1 (lr=0.403788)                   80.95%                   0.7033
2022-10-03 16:00:45 [INFO ]  
2022-10-03 16:00:45 [INFO ]  Epoch:  110	Loss: 0.6578	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 16:00:46 [INFO ]  Epoch:  111	Loss: 0.7053	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 16:00:48 [INFO ]  Epoch:  112	Loss: 0.6534	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:00:50 [INFO ]  Epoch:  113	Loss: 0.6290	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 16:00:52 [INFO ]  Epoch:  114	Loss: 0.6458	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:00:54 [INFO ]  Epoch:  115	Loss: 0.6153	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:00:56 [INFO ]  Epoch:  116	Loss: 0.6276	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:00:58 [INFO ]  Epoch:  117	Loss: 0.7028	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:00 [INFO ]  Epoch:  118	Loss: 0.6647	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:01:02 [INFO ]  Epoch:  119	Loss: 0.6606	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 16:01:14 [INFO ]  
2022-10-03 16:01:14 [INFO ]  Begin of epoch 120 :
2022-10-03 16:01:17 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:01:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:01:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:01:17 [INFO ]  	   step  1 (lr=0.404040)                   80.75%                   0.7109
2022-10-03 16:01:17 [INFO ]  
2022-10-03 16:01:17 [INFO ]  Epoch:  120	Loss: 0.6662	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:19 [INFO ]  Epoch:  121	Loss: 0.6821	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:21 [INFO ]  Epoch:  122	Loss: 0.6737	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:22 [INFO ]  Epoch:  123	Loss: 0.6305	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:25 [INFO ]  Epoch:  124	Loss: 0.7158	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:27 [INFO ]  Epoch:  125	Loss: 0.6663	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:29 [INFO ]  Epoch:  126	Loss: 0.6318	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:31 [INFO ]  Epoch:  127	Loss: 0.5630	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:33 [INFO ]  Epoch:  128	Loss: 0.5758	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:34 [INFO ]  Epoch:  129	Loss: 0.6671	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 16:01:46 [INFO ]  
2022-10-03 16:01:46 [INFO ]  Begin of epoch 130 :
2022-10-03 16:01:50 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:01:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:01:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:01:50 [INFO ]  	   step  1 (lr=0.405808)                   79.99%                   0.7383
2022-10-03 16:01:50 [INFO ]  
2022-10-03 16:01:50 [INFO ]  Epoch:  130	Loss: 0.7410	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:01:51 [INFO ]  Epoch:  131	Loss: 0.6562	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 16:01:53 [INFO ]  Epoch:  132	Loss: 0.6520	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 16:01:55 [INFO ]  Epoch:  133	Loss: 0.5997	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:01:57 [INFO ]  Epoch:  134	Loss: 0.5847	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:01:59 [INFO ]  Epoch:  135	Loss: 0.6631	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:02:01 [INFO ]  Epoch:  136	Loss: 0.6621	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:02:03 [INFO ]  Epoch:  137	Loss: 0.6943	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:02:04 [INFO ]  Epoch:  138	Loss: 0.6724	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:02:06 [INFO ]  Epoch:  139	Loss: 0.5975	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:02:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 16:02:18 [INFO ]  
2022-10-03 16:02:18 [INFO ]  Begin of epoch 140 :
2022-10-03 16:02:21 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:02:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:02:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:02:21 [INFO ]  	   step  1 (lr=0.403930)                   80.77%                   0.7178
2022-10-03 16:02:21 [INFO ]  
2022-10-03 16:02:21 [INFO ]  Epoch:  140	Loss: 0.6208	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 16:02:23 [INFO ]  Epoch:  141	Loss: 0.6100	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 16:02:25 [INFO ]  Epoch:  142	Loss: 0.6274	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:02:27 [INFO ]  Epoch:  143	Loss: 0.6171	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:02:29 [INFO ]  Epoch:  144	Loss: 0.6747	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 16:02:31 [INFO ]  Epoch:  145	Loss: 0.6518	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:02:32 [INFO ]  Epoch:  146	Loss: 0.6161	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:02:34 [INFO ]  Epoch:  147	Loss: 0.5965	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:02:36 [INFO ]  Epoch:  148	Loss: 0.6667	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:02:38 [INFO ]  Epoch:  149	Loss: 0.6121	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:02:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 16:02:50 [INFO ]  
2022-10-03 16:02:50 [INFO ]  Begin of epoch 150 :
2022-10-03 16:02:53 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:02:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:02:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:02:53 [INFO ]  	   step  1 (lr=0.407085)                   80.84%                   0.7036
2022-10-03 16:02:53 [INFO ]  
2022-10-03 16:02:53 [INFO ]  Epoch:  150	Loss: 0.5692	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:02:55 [INFO ]  Epoch:  151	Loss: 0.5564	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:02:57 [INFO ]  Epoch:  152	Loss: 0.6402	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 16:02:59 [INFO ]  Epoch:  153	Loss: 0.6336	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:03:01 [INFO ]  Epoch:  154	Loss: 0.6434	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:03:03 [INFO ]  Epoch:  155	Loss: 0.6433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:03:05 [INFO ]  Epoch:  156	Loss: 0.5910	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 16:03:07 [INFO ]  Epoch:  157	Loss: 0.6198	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:03:09 [INFO ]  Epoch:  158	Loss: 0.6012	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:03:11 [INFO ]  Epoch:  159	Loss: 0.6218	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:03:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 16:03:23 [INFO ]  
2022-10-03 16:03:23 [INFO ]  Begin of epoch 160 :
2022-10-03 16:03:26 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:03:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:03:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:03:26 [INFO ]  	   step  1 (lr=0.406949)                   81.05%                   0.7029
2022-10-03 16:03:26 [INFO ]  
2022-10-03 16:03:26 [INFO ]  Epoch:  160	Loss: 0.6237	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 16:03:28 [INFO ]  Epoch:  161	Loss: 0.6994	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:03:30 [INFO ]  Epoch:  162	Loss: 0.5772	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:03:32 [INFO ]  Epoch:  163	Loss: 0.6579	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 16:03:34 [INFO ]  Epoch:  164	Loss: 0.6444	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 16:03:36 [INFO ]  Epoch:  165	Loss: 0.6798	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:03:38 [INFO ]  Epoch:  166	Loss: 0.6945	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 16:03:40 [INFO ]  Epoch:  167	Loss: 0.6482	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:03:41 [INFO ]  Epoch:  168	Loss: 0.6750	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 16:03:43 [INFO ]  Epoch:  169	Loss: 0.6399	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 16:03:55 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 16:03:55 [INFO ]  
2022-10-03 16:03:55 [INFO ]  Begin of epoch 170 :
2022-10-03 16:03:59 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:03:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:03:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:03:59 [INFO ]  	   step  1 (lr=0.405402)                   81.18%                   0.7063
2022-10-03 16:03:59 [INFO ]  
2022-10-03 16:03:59 [INFO ]  Epoch:  170	Loss: 0.6103	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:01 [INFO ]  Epoch:  171	Loss: 0.6069	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 16:04:03 [INFO ]  Epoch:  172	Loss: 0.6425	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:04 [INFO ]  Epoch:  173	Loss: 0.5681	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:06 [INFO ]  Epoch:  174	Loss: 0.6819	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:08 [INFO ]  Epoch:  175	Loss: 0.6205	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:04:10 [INFO ]  Epoch:  176	Loss: 0.7488	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 16:04:12 [INFO ]  Epoch:  177	Loss: 0.6230	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 16:04:14 [INFO ]  Epoch:  178	Loss: 0.6232	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 16:04:16 [INFO ]  Epoch:  179	Loss: 0.6487	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 16:04:28 [INFO ]  
2022-10-03 16:04:28 [INFO ]  Begin of epoch 180 :
2022-10-03 16:04:31 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:04:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:04:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:04:31 [INFO ]  	   step  1 (lr=0.406367)                   80.64%                   0.7074
2022-10-03 16:04:31 [INFO ]  
2022-10-03 16:04:31 [INFO ]  Epoch:  180	Loss: 0.6039	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 16:04:33 [INFO ]  Epoch:  181	Loss: 0.6441	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 16:04:35 [INFO ]  Epoch:  182	Loss: 0.6168	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 16:04:37 [INFO ]  Epoch:  183	Loss: 0.6427	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 16:04:39 [INFO ]  Epoch:  184	Loss: 0.6452	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:04:41 [INFO ]  Epoch:  185	Loss: 0.6619	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 16:04:43 [INFO ]  Epoch:  186	Loss: 0.6796	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 16:04:45 [INFO ]  Epoch:  187	Loss: 0.6240	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 16:04:47 [INFO ]  Epoch:  188	Loss: 0.5889	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 16:04:48 [INFO ]  Epoch:  189	Loss: 0.6007	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:05:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 16:05:00 [INFO ]  
2022-10-03 16:05:00 [INFO ]  Begin of epoch 190 :
2022-10-03 16:05:04 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:05:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:05:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:05:04 [INFO ]  	   step  1 (lr=0.405999)                   81.18%                   0.7053
2022-10-03 16:05:04 [INFO ]  
2022-10-03 16:05:04 [INFO ]  Epoch:  190	Loss: 0.5789	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:05:06 [INFO ]  Epoch:  191	Loss: 0.6581	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 16:05:08 [INFO ]  Epoch:  192	Loss: 0.6571	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:05:10 [INFO ]  Epoch:  193	Loss: 0.6349	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:05:11 [INFO ]  Epoch:  194	Loss: 0.5832	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:05:13 [INFO ]  Epoch:  195	Loss: 0.5946	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 16:05:15 [INFO ]  Epoch:  196	Loss: 0.6309	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 16:05:17 [INFO ]  Epoch:  197	Loss: 0.6915	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 16:05:19 [INFO ]  Epoch:  198	Loss: 0.6559	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 16:05:21 [INFO ]  Epoch:  199	Loss: 0.6398	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 16:05:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 16:05:33 [INFO ]  
2022-10-03 16:05:33 [INFO ]  Final evaluation for SVHN :
2022-10-03 16:05:36 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:05:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:05:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 16:05:36 [INFO ]  	   step  1 (lr=0.405814)                   81.19%                   0.7031
2022-10-03 16:05:36 [INFO ]  
2022-10-03 16:05:36 [INFO ]  
2022-10-03 16:05:36 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 16:05:39 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 16:05:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 16:05:39 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 16:05:39 [INFO ]  	   step  1 (lr=0.405814)                   18.24%                   5.4138
2022-10-03 16:05:39 [INFO ]  
2022-10-03 16:05:39 [INFO ]  CPU Time: 7.92 minutes
2022-10-03 17:11:06 [INFO ]  ======================================== 2022-10-03 17:11:06 ========================================
2022-10-03 17:11:06 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 17:11:06 [INFO ]  Options: 
2022-10-03 17:11:06 [INFO ]  	base_dir: null
2022-10-03 17:11:06 [INFO ]  	batch_size: 1024
2022-10-03 17:11:06 [INFO ]  	checkpoint_interval: 10
2022-10-03 17:11:06 [INFO ]  	dataset: SVHN
2022-10-03 17:11:06 [INFO ]  	dataset_labels:
2022-10-03 17:11:06 [INFO ]  	- 0
2022-10-03 17:11:06 [INFO ]  	- 1
2022-10-03 17:11:06 [INFO ]  	- 2
2022-10-03 17:11:06 [INFO ]  	- 3
2022-10-03 17:11:06 [INFO ]  	- 4
2022-10-03 17:11:06 [INFO ]  	- 5
2022-10-03 17:11:06 [INFO ]  	- 6
2022-10-03 17:11:06 [INFO ]  	- 7
2022-10-03 17:11:06 [INFO ]  	- 8
2022-10-03 17:11:06 [INFO ]  	- 9
2022-10-03 17:11:06 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 17:11:06 [INFO ]  	- !!python/tuple
2022-10-03 17:11:06 [INFO ]  	    - 0.4379104971885681
2022-10-03 17:11:06 [INFO ]  	    - 0.44398033618927
2022-10-03 17:11:06 [INFO ]  	    - 0.4729299545288086
2022-10-03 17:11:06 [INFO ]  	- !!python/tuple
2022-10-03 17:11:06 [INFO ]  	    - 0.19803012907505035
2022-10-03 17:11:06 [INFO ]  	    - 0.2010156363248825
2022-10-03 17:11:06 [INFO ]  	    - 0.19703614711761475
2022-10-03 17:11:06 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 17:11:06 [INFO ]  	decay_epochs: 50
2022-10-03 17:11:06 [INFO ]  	decay_factor: 0.1
2022-10-03 17:11:06 [INFO ]  	device_id: 0
2022-10-03 17:11:06 [INFO ]  	distill_epochs: 1
2022-10-03 17:11:06 [INFO ]  	distill_lr: 0.02
2022-10-03 17:11:06 [INFO ]  	distill_steps: 1
2022-10-03 17:11:06 [INFO ]  	epochs: 200
2022-10-03 17:11:06 [INFO ]  	expand_cls: false
2022-10-03 17:11:06 [INFO ]  	forgetting_dataset: null
2022-10-03 17:11:06 [INFO ]  	init: xavier
2022-10-03 17:11:06 [INFO ]  	init_param: 1.0
2022-10-03 17:11:06 [INFO ]  	input_size: 32
2022-10-03 17:11:06 [INFO ]  	ipc: 15
2022-10-03 17:11:06 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 17:11:06 [INFO ]  	log_interval: 100
2022-10-03 17:11:06 [INFO ]  	log_level: INFO
2022-10-03 17:11:06 [INFO ]  	lr: 0.01
2022-10-03 17:11:06 [INFO ]  	mode: distill_adapt
2022-10-03 17:11:06 [INFO ]  	nc: 3
2022-10-03 17:11:06 [INFO ]  	num_classes: 10
2022-10-03 17:11:06 [INFO ]  	num_workers: 8
2022-10-03 17:11:06 [INFO ]  	phase: train
2022-10-03 17:11:06 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 17:11:06 [INFO ]  	start_time: '2022-10-03 17:11:06'
2022-10-03 17:11:06 [INFO ]  	test_batch_size: 1024
2022-10-03 17:11:06 [INFO ]  	
2022-10-03 17:11:08 [INFO ]  train dataset size:	73257
2022-10-03 17:11:08 [INFO ]  test dataset size: 	26032
2022-10-03 17:11:08 [INFO ]  datasets built!
2022-10-03 17:11:08 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 17:11:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 17:11:20 [INFO ]  
2022-10-03 17:11:20 [INFO ]  Begin of epoch 0 :
2022-10-03 17:11:23 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:11:23 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:11:23 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:11:23 [INFO ]  	   step  1 (lr=0.020000)                    7.24%                   8.5801
2022-10-03 17:11:23 [INFO ]  
2022-10-03 17:11:23 [INFO ]  Epoch:    0	Loss: 8.1443	Data Time: 0.39s	Train Time: 0.04s
2022-10-03 17:11:25 [INFO ]  Epoch:    1	Loss: 2.8919	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:11:27 [INFO ]  Epoch:    2	Loss: 2.4372	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:11:28 [INFO ]  Epoch:    3	Loss: 2.2656	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:11:30 [INFO ]  Epoch:    4	Loss: 2.2123	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:11:32 [INFO ]  Epoch:    5	Loss: 2.2218	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:11:34 [INFO ]  Epoch:    6	Loss: 2.1645	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:11:36 [INFO ]  Epoch:    7	Loss: 2.1237	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:11:38 [INFO ]  Epoch:    8	Loss: 2.0578	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:11:40 [INFO ]  Epoch:    9	Loss: 2.0147	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:11:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 17:11:51 [INFO ]  
2022-10-03 17:11:51 [INFO ]  Begin of epoch 10 :
2022-10-03 17:11:55 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:11:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:11:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:11:55 [INFO ]  	   step  1 (lr=0.079077)                   41.30%                   1.8325
2022-10-03 17:11:55 [INFO ]  
2022-10-03 17:11:55 [INFO ]  Epoch:   10	Loss: 1.8777	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:11:56 [INFO ]  Epoch:   11	Loss: 1.6450	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:11:58 [INFO ]  Epoch:   12	Loss: 1.4947	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:00 [INFO ]  Epoch:   13	Loss: 1.4093	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:12:02 [INFO ]  Epoch:   14	Loss: 1.3249	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:12:04 [INFO ]  Epoch:   15	Loss: 1.2971	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:06 [INFO ]  Epoch:   16	Loss: 1.2894	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:12:08 [INFO ]  Epoch:   17	Loss: 1.1944	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:10 [INFO ]  Epoch:   18	Loss: 1.1549	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:12 [INFO ]  Epoch:   19	Loss: 1.0423	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 17:12:23 [INFO ]  
2022-10-03 17:12:23 [INFO ]  Begin of epoch 20 :
2022-10-03 17:12:27 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:12:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:12:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:12:27 [INFO ]  	   step  1 (lr=0.231621)                   60.96%                   1.3278
2022-10-03 17:12:27 [INFO ]  
2022-10-03 17:12:27 [INFO ]  Epoch:   20	Loss: 1.2922	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 17:12:28 [INFO ]  Epoch:   21	Loss: 1.0876	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:12:31 [INFO ]  Epoch:   22	Loss: 0.9681	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:33 [INFO ]  Epoch:   23	Loss: 1.1750	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:12:34 [INFO ]  Epoch:   24	Loss: 0.9541	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:12:36 [INFO ]  Epoch:   25	Loss: 0.9624	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:12:38 [INFO ]  Epoch:   26	Loss: 0.9328	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:40 [INFO ]  Epoch:   27	Loss: 0.8942	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:42 [INFO ]  Epoch:   28	Loss: 0.9666	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:12:44 [INFO ]  Epoch:   29	Loss: 0.9299	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:12:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 17:12:56 [INFO ]  
2022-10-03 17:12:56 [INFO ]  Begin of epoch 30 :
2022-10-03 17:12:59 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:12:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:12:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:12:59 [INFO ]  	   step  1 (lr=0.296167)                   74.29%                   0.9142
2022-10-03 17:12:59 [INFO ]  
2022-10-03 17:12:59 [INFO ]  Epoch:   30	Loss: 0.8458	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 17:13:01 [INFO ]  Epoch:   31	Loss: 0.7627	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:13:03 [INFO ]  Epoch:   32	Loss: 0.9726	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:13:05 [INFO ]  Epoch:   33	Loss: 0.8726	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:13:07 [INFO ]  Epoch:   34	Loss: 0.8374	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:13:09 [INFO ]  Epoch:   35	Loss: 0.7914	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:13:11 [INFO ]  Epoch:   36	Loss: 0.7549	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:13:13 [INFO ]  Epoch:   37	Loss: 0.7890	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:13:15 [INFO ]  Epoch:   38	Loss: 0.7735	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:13:17 [INFO ]  Epoch:   39	Loss: 0.9327	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:13:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 17:13:29 [INFO ]  
2022-10-03 17:13:29 [INFO ]  Begin of epoch 40 :
2022-10-03 17:13:32 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:13:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:13:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:13:32 [INFO ]  	   step  1 (lr=0.332017)                   75.03%                   0.8831
2022-10-03 17:13:32 [INFO ]  
2022-10-03 17:13:32 [INFO ]  Epoch:   40	Loss: 0.7440	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:13:34 [INFO ]  Epoch:   41	Loss: 0.9504	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:13:35 [INFO ]  Epoch:   42	Loss: 0.7749	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:13:37 [INFO ]  Epoch:   43	Loss: 0.7275	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:13:39 [INFO ]  Epoch:   44	Loss: 0.7607	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:13:41 [INFO ]  Epoch:   45	Loss: 0.8211	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:13:43 [INFO ]  Epoch:   46	Loss: 0.6824	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:13:45 [INFO ]  Epoch:   47	Loss: 0.7762	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:13:47 [INFO ]  Epoch:   48	Loss: 0.8205	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:13:48 [INFO ]  Epoch:   49	Loss: 0.6882	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:14:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 17:14:00 [INFO ]  
2022-10-03 17:14:00 [INFO ]  Begin of epoch 50 :
2022-10-03 17:14:04 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:14:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:14:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:14:04 [INFO ]  	   step  1 (lr=0.342249)                   80.54%                   0.7262
2022-10-03 17:14:04 [INFO ]  
2022-10-03 17:14:04 [INFO ]  Epoch:   50	Loss: 0.6809	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:14:05 [INFO ]  Epoch:   51	Loss: 0.6195	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:14:08 [INFO ]  Epoch:   52	Loss: 0.6781	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:14:09 [INFO ]  Epoch:   53	Loss: 0.7333	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:14:11 [INFO ]  Epoch:   54	Loss: 0.6222	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:14:13 [INFO ]  Epoch:   55	Loss: 0.6421	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:14:15 [INFO ]  Epoch:   56	Loss: 0.6728	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:14:17 [INFO ]  Epoch:   57	Loss: 0.6500	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:14:19 [INFO ]  Epoch:   58	Loss: 0.6823	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:14:20 [INFO ]  Epoch:   59	Loss: 0.6661	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:14:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 17:14:32 [INFO ]  
2022-10-03 17:14:32 [INFO ]  Begin of epoch 60 :
2022-10-03 17:14:36 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:14:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:14:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:14:36 [INFO ]  	   step  1 (lr=0.354964)                   79.72%                   0.7433
2022-10-03 17:14:36 [INFO ]  
2022-10-03 17:14:36 [INFO ]  Epoch:   60	Loss: 0.6485	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:14:37 [INFO ]  Epoch:   61	Loss: 0.6428	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:14:39 [INFO ]  Epoch:   62	Loss: 0.6960	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:14:41 [INFO ]  Epoch:   63	Loss: 0.6596	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:14:43 [INFO ]  Epoch:   64	Loss: 0.6402	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:14:45 [INFO ]  Epoch:   65	Loss: 0.7433	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:14:47 [INFO ]  Epoch:   66	Loss: 0.6515	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:14:49 [INFO ]  Epoch:   67	Loss: 0.6761	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:14:51 [INFO ]  Epoch:   68	Loss: 0.6273	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:14:53 [INFO ]  Epoch:   69	Loss: 0.6507	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:15:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 17:15:05 [INFO ]  
2022-10-03 17:15:05 [INFO ]  Begin of epoch 70 :
2022-10-03 17:15:08 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:15:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:15:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:15:08 [INFO ]  	   step  1 (lr=0.364153)                   79.38%                   0.7579
2022-10-03 17:15:08 [INFO ]  
2022-10-03 17:15:09 [INFO ]  Epoch:   70	Loss: 0.6766	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:15:10 [INFO ]  Epoch:   71	Loss: 0.6495	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:15:12 [INFO ]  Epoch:   72	Loss: 0.7162	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:15:14 [INFO ]  Epoch:   73	Loss: 0.6888	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:15:16 [INFO ]  Epoch:   74	Loss: 0.6677	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:15:18 [INFO ]  Epoch:   75	Loss: 0.6194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:15:20 [INFO ]  Epoch:   76	Loss: 0.6544	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:15:22 [INFO ]  Epoch:   77	Loss: 0.6252	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 17:15:23 [INFO ]  Epoch:   78	Loss: 0.6074	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:15:26 [INFO ]  Epoch:   79	Loss: 0.7033	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:15:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 17:15:37 [INFO ]  
2022-10-03 17:15:37 [INFO ]  Begin of epoch 80 :
2022-10-03 17:15:41 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:15:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:15:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:15:41 [INFO ]  	   step  1 (lr=0.372169)                   80.61%                   0.7056
2022-10-03 17:15:41 [INFO ]  
2022-10-03 17:15:41 [INFO ]  Epoch:   80	Loss: 0.6152	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:15:42 [INFO ]  Epoch:   81	Loss: 0.5612	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:15:44 [INFO ]  Epoch:   82	Loss: 0.6781	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:15:46 [INFO ]  Epoch:   83	Loss: 0.6697	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:15:48 [INFO ]  Epoch:   84	Loss: 0.6657	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:15:50 [INFO ]  Epoch:   85	Loss: 0.6299	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:15:52 [INFO ]  Epoch:   86	Loss: 0.6378	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:15:54 [INFO ]  Epoch:   87	Loss: 0.6383	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:15:56 [INFO ]  Epoch:   88	Loss: 0.6069	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:15:57 [INFO ]  Epoch:   89	Loss: 0.6574	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:16:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 17:16:09 [INFO ]  
2022-10-03 17:16:09 [INFO ]  Begin of epoch 90 :
2022-10-03 17:16:13 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:16:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:16:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:16:13 [INFO ]  	   step  1 (lr=0.373902)                   80.28%                   0.7229
2022-10-03 17:16:13 [INFO ]  
2022-10-03 17:16:13 [INFO ]  Epoch:   90	Loss: 0.6907	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:14 [INFO ]  Epoch:   91	Loss: 0.5899	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:16 [INFO ]  Epoch:   92	Loss: 0.6577	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:16:18 [INFO ]  Epoch:   93	Loss: 0.6145	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:16:20 [INFO ]  Epoch:   94	Loss: 0.6979	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:16:22 [INFO ]  Epoch:   95	Loss: 0.5763	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:16:24 [INFO ]  Epoch:   96	Loss: 0.6979	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:25 [INFO ]  Epoch:   97	Loss: 0.6271	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:16:27 [INFO ]  Epoch:   98	Loss: 0.6281	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:16:29 [INFO ]  Epoch:   99	Loss: 0.6510	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:16:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 17:16:41 [INFO ]  
2022-10-03 17:16:41 [INFO ]  Begin of epoch 100 :
2022-10-03 17:16:44 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:16:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:16:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:16:44 [INFO ]  	   step  1 (lr=0.385863)                   81.58%                   0.6866
2022-10-03 17:16:44 [INFO ]  
2022-10-03 17:16:44 [INFO ]  Epoch:  100	Loss: 0.6437	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:16:46 [INFO ]  Epoch:  101	Loss: 0.5748	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:16:48 [INFO ]  Epoch:  102	Loss: 0.5914	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:16:50 [INFO ]  Epoch:  103	Loss: 0.5819	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:52 [INFO ]  Epoch:  104	Loss: 0.5495	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:16:53 [INFO ]  Epoch:  105	Loss: 0.6205	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:55 [INFO ]  Epoch:  106	Loss: 0.6625	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:16:57 [INFO ]  Epoch:  107	Loss: 0.5966	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:16:59 [INFO ]  Epoch:  108	Loss: 0.6958	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:17:01 [INFO ]  Epoch:  109	Loss: 0.6089	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:17:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 17:17:13 [INFO ]  
2022-10-03 17:17:13 [INFO ]  Begin of epoch 110 :
2022-10-03 17:17:17 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:17:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:17:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:17:17 [INFO ]  	   step  1 (lr=0.389663)                   80.96%                   0.6988
2022-10-03 17:17:17 [INFO ]  
2022-10-03 17:17:17 [INFO ]  Epoch:  110	Loss: 0.6754	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:17:18 [INFO ]  Epoch:  111	Loss: 0.6062	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:17:20 [INFO ]  Epoch:  112	Loss: 0.5991	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:17:22 [INFO ]  Epoch:  113	Loss: 0.6158	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:17:24 [INFO ]  Epoch:  114	Loss: 0.5935	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:17:26 [INFO ]  Epoch:  115	Loss: 0.6093	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:17:28 [INFO ]  Epoch:  116	Loss: 0.6248	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:17:30 [INFO ]  Epoch:  117	Loss: 0.6498	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:17:32 [INFO ]  Epoch:  118	Loss: 0.6748	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:17:33 [INFO ]  Epoch:  119	Loss: 0.7161	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:17:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 17:17:45 [INFO ]  
2022-10-03 17:17:45 [INFO ]  Begin of epoch 120 :
2022-10-03 17:17:49 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:17:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:17:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:17:49 [INFO ]  	   step  1 (lr=0.388148)                   81.41%                   0.6902
2022-10-03 17:17:49 [INFO ]  
2022-10-03 17:17:49 [INFO ]  Epoch:  120	Loss: 0.6516	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:17:51 [INFO ]  Epoch:  121	Loss: 0.6428	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:17:53 [INFO ]  Epoch:  122	Loss: 0.5976	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:17:55 [INFO ]  Epoch:  123	Loss: 0.6137	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:17:56 [INFO ]  Epoch:  124	Loss: 0.6006	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:17:59 [INFO ]  Epoch:  125	Loss: 0.5877	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:18:00 [INFO ]  Epoch:  126	Loss: 0.6196	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:18:02 [INFO ]  Epoch:  127	Loss: 0.5926	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:18:04 [INFO ]  Epoch:  128	Loss: 0.6116	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:18:06 [INFO ]  Epoch:  129	Loss: 0.6234	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:18:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 17:18:18 [INFO ]  
2022-10-03 17:18:18 [INFO ]  Begin of epoch 130 :
2022-10-03 17:18:21 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:18:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:18:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:18:21 [INFO ]  	   step  1 (lr=0.390408)                   81.61%                   0.6873
2022-10-03 17:18:21 [INFO ]  
2022-10-03 17:18:21 [INFO ]  Epoch:  130	Loss: 0.6979	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:18:23 [INFO ]  Epoch:  131	Loss: 0.5910	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:18:25 [INFO ]  Epoch:  132	Loss: 0.6194	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:18:27 [INFO ]  Epoch:  133	Loss: 0.6094	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:18:29 [INFO ]  Epoch:  134	Loss: 0.5391	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:18:31 [INFO ]  Epoch:  135	Loss: 0.5652	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:18:33 [INFO ]  Epoch:  136	Loss: 0.5767	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:18:35 [INFO ]  Epoch:  137	Loss: 0.7019	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:18:37 [INFO ]  Epoch:  138	Loss: 0.6337	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:18:39 [INFO ]  Epoch:  139	Loss: 0.6858	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:18:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 17:18:50 [INFO ]  
2022-10-03 17:18:50 [INFO ]  Begin of epoch 140 :
2022-10-03 17:18:54 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:18:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:18:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:18:54 [INFO ]  	   step  1 (lr=0.393098)                   81.66%                   0.6892
2022-10-03 17:18:54 [INFO ]  
2022-10-03 17:18:54 [INFO ]  Epoch:  140	Loss: 0.6920	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:18:56 [INFO ]  Epoch:  141	Loss: 0.6071	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:18:58 [INFO ]  Epoch:  142	Loss: 0.5580	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:18:59 [INFO ]  Epoch:  143	Loss: 0.6280	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:19:01 [INFO ]  Epoch:  144	Loss: 0.6044	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:19:03 [INFO ]  Epoch:  145	Loss: 0.6202	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:19:05 [INFO ]  Epoch:  146	Loss: 0.6283	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:07 [INFO ]  Epoch:  147	Loss: 0.5847	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:09 [INFO ]  Epoch:  148	Loss: 0.6209	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:19:11 [INFO ]  Epoch:  149	Loss: 0.6245	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 17:19:23 [INFO ]  
2022-10-03 17:19:23 [INFO ]  Begin of epoch 150 :
2022-10-03 17:19:27 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:19:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:19:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:19:27 [INFO ]  	   step  1 (lr=0.393369)                   81.18%                   0.6976
2022-10-03 17:19:27 [INFO ]  
2022-10-03 17:19:27 [INFO ]  Epoch:  150	Loss: 0.6302	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:28 [INFO ]  Epoch:  151	Loss: 0.5892	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:19:30 [INFO ]  Epoch:  152	Loss: 0.6453	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:19:32 [INFO ]  Epoch:  153	Loss: 0.6650	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:19:34 [INFO ]  Epoch:  154	Loss: 0.6076	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:36 [INFO ]  Epoch:  155	Loss: 0.6243	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:19:38 [INFO ]  Epoch:  156	Loss: 0.5769	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:19:40 [INFO ]  Epoch:  157	Loss: 0.5686	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:19:42 [INFO ]  Epoch:  158	Loss: 0.6328	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:19:44 [INFO ]  Epoch:  159	Loss: 0.6128	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:19:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 17:19:56 [INFO ]  
2022-10-03 17:19:56 [INFO ]  Begin of epoch 160 :
2022-10-03 17:19:59 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:19:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:19:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:19:59 [INFO ]  	   step  1 (lr=0.393025)                   81.28%                   0.6958
2022-10-03 17:19:59 [INFO ]  
2022-10-03 17:19:59 [INFO ]  Epoch:  160	Loss: 0.6259	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:20:01 [INFO ]  Epoch:  161	Loss: 0.6122	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:20:02 [INFO ]  Epoch:  162	Loss: 0.6082	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:04 [INFO ]  Epoch:  163	Loss: 0.6473	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:07 [INFO ]  Epoch:  164	Loss: 0.6469	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:09 [INFO ]  Epoch:  165	Loss: 0.6169	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:10 [INFO ]  Epoch:  166	Loss: 0.6353	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:12 [INFO ]  Epoch:  167	Loss: 0.6360	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:14 [INFO ]  Epoch:  168	Loss: 0.5729	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:20:16 [INFO ]  Epoch:  169	Loss: 0.6602	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:20:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 17:20:28 [INFO ]  
2022-10-03 17:20:28 [INFO ]  Begin of epoch 170 :
2022-10-03 17:20:32 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:20:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:20:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:20:32 [INFO ]  	   step  1 (lr=0.392438)                   81.66%                   0.6844
2022-10-03 17:20:32 [INFO ]  
2022-10-03 17:20:32 [INFO ]  Epoch:  170	Loss: 0.6893	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 17:20:33 [INFO ]  Epoch:  171	Loss: 0.5734	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:35 [INFO ]  Epoch:  172	Loss: 0.6183	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:37 [INFO ]  Epoch:  173	Loss: 0.6244	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:20:39 [INFO ]  Epoch:  174	Loss: 0.6340	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:41 [INFO ]  Epoch:  175	Loss: 0.6970	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:20:43 [INFO ]  Epoch:  176	Loss: 0.6253	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:20:45 [INFO ]  Epoch:  177	Loss: 0.6405	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:20:47 [INFO ]  Epoch:  178	Loss: 0.6151	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:20:49 [INFO ]  Epoch:  179	Loss: 0.6265	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:21:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 17:21:01 [INFO ]  
2022-10-03 17:21:01 [INFO ]  Begin of epoch 180 :
2022-10-03 17:21:04 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:21:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:21:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:21:04 [INFO ]  	   step  1 (lr=0.392784)                   81.33%                   0.6942
2022-10-03 17:21:04 [INFO ]  
2022-10-03 17:21:04 [INFO ]  Epoch:  180	Loss: 0.5812	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:21:06 [INFO ]  Epoch:  181	Loss: 0.6117	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:21:08 [INFO ]  Epoch:  182	Loss: 0.6491	Data Time: 0.27s	Train Time: 0.01s
2022-10-03 17:21:11 [INFO ]  Epoch:  183	Loss: 0.6012	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:21:13 [INFO ]  Epoch:  184	Loss: 0.5765	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:21:15 [INFO ]  Epoch:  185	Loss: 0.6481	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:21:18 [INFO ]  Epoch:  186	Loss: 0.7228	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:21:20 [INFO ]  Epoch:  187	Loss: 0.6169	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:21:22 [INFO ]  Epoch:  188	Loss: 0.6511	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:21:24 [INFO ]  Epoch:  189	Loss: 0.5351	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:21:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 17:21:37 [INFO ]  
2022-10-03 17:21:37 [INFO ]  Begin of epoch 190 :
2022-10-03 17:21:40 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:21:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:21:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:21:40 [INFO ]  	   step  1 (lr=0.393151)                   81.54%                   0.6848
2022-10-03 17:21:40 [INFO ]  
2022-10-03 17:21:40 [INFO ]  Epoch:  190	Loss: 0.5353	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:21:42 [INFO ]  Epoch:  191	Loss: 0.5999	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:21:44 [INFO ]  Epoch:  192	Loss: 0.6063	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:21:46 [INFO ]  Epoch:  193	Loss: 0.6054	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:21:48 [INFO ]  Epoch:  194	Loss: 0.6591	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:21:50 [INFO ]  Epoch:  195	Loss: 0.5833	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:21:52 [INFO ]  Epoch:  196	Loss: 0.6327	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:21:54 [INFO ]  Epoch:  197	Loss: 0.5762	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:21:55 [INFO ]  Epoch:  198	Loss: 0.6215	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:21:57 [INFO ]  Epoch:  199	Loss: 0.6265	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:22:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 17:22:09 [INFO ]  
2022-10-03 17:22:09 [INFO ]  Final evaluation for SVHN :
2022-10-03 17:22:12 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:22:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:22:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:22:12 [INFO ]  	   step  1 (lr=0.393028)                   81.49%                   0.6846
2022-10-03 17:22:12 [INFO ]  
2022-10-03 17:22:12 [INFO ]  
2022-10-03 17:22:12 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 17:22:15 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:22:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:22:15 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 17:22:15 [INFO ]  	   step  1 (lr=0.393028)                   15.50%                   5.5570
2022-10-03 17:22:15 [INFO ]  
2022-10-03 17:22:15 [INFO ]  CPU Time: 7.88 minutes
2022-10-03 17:26:20 [INFO ]  ======================================== 2022-10-03 17:26:20 ========================================
2022-10-03 17:26:20 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 17:26:20 [INFO ]  Options: 
2022-10-03 17:26:20 [INFO ]  	base_dir: null
2022-10-03 17:26:20 [INFO ]  	batch_size: 1024
2022-10-03 17:26:20 [INFO ]  	checkpoint_interval: 10
2022-10-03 17:26:20 [INFO ]  	dataset: SVHN
2022-10-03 17:26:20 [INFO ]  	dataset_labels:
2022-10-03 17:26:20 [INFO ]  	- 0
2022-10-03 17:26:20 [INFO ]  	- 1
2022-10-03 17:26:20 [INFO ]  	- 2
2022-10-03 17:26:20 [INFO ]  	- 3
2022-10-03 17:26:20 [INFO ]  	- 4
2022-10-03 17:26:20 [INFO ]  	- 5
2022-10-03 17:26:20 [INFO ]  	- 6
2022-10-03 17:26:20 [INFO ]  	- 7
2022-10-03 17:26:20 [INFO ]  	- 8
2022-10-03 17:26:20 [INFO ]  	- 9
2022-10-03 17:26:20 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 17:26:20 [INFO ]  	- !!python/tuple
2022-10-03 17:26:20 [INFO ]  	    - 0.4379104971885681
2022-10-03 17:26:20 [INFO ]  	    - 0.44398033618927
2022-10-03 17:26:20 [INFO ]  	    - 0.4729299545288086
2022-10-03 17:26:20 [INFO ]  	- !!python/tuple
2022-10-03 17:26:20 [INFO ]  	    - 0.19803012907505035
2022-10-03 17:26:20 [INFO ]  	    - 0.2010156363248825
2022-10-03 17:26:20 [INFO ]  	    - 0.19703614711761475
2022-10-03 17:26:20 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 17:26:20 [INFO ]  	decay_epochs: 50
2022-10-03 17:26:20 [INFO ]  	decay_factor: 0.1
2022-10-03 17:26:20 [INFO ]  	device_id: 0
2022-10-03 17:26:20 [INFO ]  	distill_epochs: 1
2022-10-03 17:26:20 [INFO ]  	distill_lr: 0.02
2022-10-03 17:26:20 [INFO ]  	distill_steps: 1
2022-10-03 17:26:20 [INFO ]  	epochs: 200
2022-10-03 17:26:20 [INFO ]  	expand_cls: false
2022-10-03 17:26:20 [INFO ]  	forgetting_dataset: null
2022-10-03 17:26:20 [INFO ]  	init: xavier
2022-10-03 17:26:20 [INFO ]  	init_param: 1.0
2022-10-03 17:26:20 [INFO ]  	input_size: 32
2022-10-03 17:26:20 [INFO ]  	ipc: 15
2022-10-03 17:26:20 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 17:26:20 [INFO ]  	log_interval: 100
2022-10-03 17:26:20 [INFO ]  	log_level: INFO
2022-10-03 17:26:20 [INFO ]  	lr: 0.01
2022-10-03 17:26:20 [INFO ]  	mode: distill_adapt
2022-10-03 17:26:20 [INFO ]  	nc: 3
2022-10-03 17:26:20 [INFO ]  	num_classes: 10
2022-10-03 17:26:20 [INFO ]  	num_workers: 8
2022-10-03 17:26:20 [INFO ]  	phase: train
2022-10-03 17:26:20 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 17:26:20 [INFO ]  	start_time: '2022-10-03 17:26:20'
2022-10-03 17:26:20 [INFO ]  	test_batch_size: 1024
2022-10-03 17:26:20 [INFO ]  	
2022-10-03 17:26:22 [INFO ]  train dataset size:	73257
2022-10-03 17:26:22 [INFO ]  test dataset size: 	26032
2022-10-03 17:26:22 [INFO ]  datasets built!
2022-10-03 17:26:22 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 17:26:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 17:26:33 [INFO ]  
2022-10-03 17:26:33 [INFO ]  Begin of epoch 0 :
2022-10-03 17:26:37 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:26:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:26:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:26:37 [INFO ]  	   step  1 (lr=0.020000)                    7.39%                   8.5480
2022-10-03 17:26:37 [INFO ]  
2022-10-03 17:26:37 [INFO ]  Epoch:    0	Loss: 8.3473	Data Time: 0.37s	Train Time: 0.04s
2022-10-03 17:26:38 [INFO ]  Epoch:    1	Loss: 2.9175	Data Time: 0.14s	Train Time: 0.01s
2022-10-03 17:26:40 [INFO ]  Epoch:    2	Loss: 2.4491	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:26:42 [INFO ]  Epoch:    3	Loss: 2.2562	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:26:44 [INFO ]  Epoch:    4	Loss: 2.2249	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:26:46 [INFO ]  Epoch:    5	Loss: 2.1745	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:26:48 [INFO ]  Epoch:    6	Loss: 2.1668	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:26:50 [INFO ]  Epoch:    7	Loss: 2.0733	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:26:52 [INFO ]  Epoch:    8	Loss: 2.0213	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:26:53 [INFO ]  Epoch:    9	Loss: 1.9118	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:27:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 17:27:05 [INFO ]  
2022-10-03 17:27:05 [INFO ]  Begin of epoch 10 :
2022-10-03 17:27:08 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:27:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:27:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:27:08 [INFO ]  	   step  1 (lr=0.082188)                   41.13%                   1.8401
2022-10-03 17:27:08 [INFO ]  
2022-10-03 17:27:08 [INFO ]  Epoch:   10	Loss: 1.7931	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 17:27:10 [INFO ]  Epoch:   11	Loss: 1.6728	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:27:12 [INFO ]  Epoch:   12	Loss: 1.4447	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:14 [INFO ]  Epoch:   13	Loss: 1.3929	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:27:16 [INFO ]  Epoch:   14	Loss: 1.4322	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:18 [INFO ]  Epoch:   15	Loss: 1.2481	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:27:20 [INFO ]  Epoch:   16	Loss: 1.2507	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:22 [INFO ]  Epoch:   17	Loss: 1.2234	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:27:23 [INFO ]  Epoch:   18	Loss: 1.3867	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:27:25 [INFO ]  Epoch:   19	Loss: 1.0349	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:27:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 17:27:37 [INFO ]  
2022-10-03 17:27:37 [INFO ]  Begin of epoch 20 :
2022-10-03 17:27:40 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:27:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:27:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:27:40 [INFO ]  	   step  1 (lr=0.242678)                   63.99%                   1.2449
2022-10-03 17:27:40 [INFO ]  
2022-10-03 17:27:40 [INFO ]  Epoch:   20	Loss: 1.0834	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:27:42 [INFO ]  Epoch:   21	Loss: 1.1094	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:44 [INFO ]  Epoch:   22	Loss: 1.0846	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:46 [INFO ]  Epoch:   23	Loss: 1.0130	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:47 [INFO ]  Epoch:   24	Loss: 0.9534	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:49 [INFO ]  Epoch:   25	Loss: 0.8869	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:27:51 [INFO ]  Epoch:   26	Loss: 0.9666	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:27:53 [INFO ]  Epoch:   27	Loss: 0.8954	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:54 [INFO ]  Epoch:   28	Loss: 1.0728	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:27:56 [INFO ]  Epoch:   29	Loss: 0.8821	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:28:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 17:28:08 [INFO ]  
2022-10-03 17:28:08 [INFO ]  Begin of epoch 30 :
2022-10-03 17:28:12 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:28:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:28:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:28:12 [INFO ]  	   step  1 (lr=0.311205)                   73.32%                   0.9543
2022-10-03 17:28:12 [INFO ]  
2022-10-03 17:28:12 [INFO ]  Epoch:   30	Loss: 0.9410	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:28:14 [INFO ]  Epoch:   31	Loss: 0.8401	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:28:15 [INFO ]  Epoch:   32	Loss: 0.8374	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:28:17 [INFO ]  Epoch:   33	Loss: 0.9706	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:28:19 [INFO ]  Epoch:   34	Loss: 0.8588	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:28:21 [INFO ]  Epoch:   35	Loss: 0.7891	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:28:23 [INFO ]  Epoch:   36	Loss: 0.8441	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:28:24 [INFO ]  Epoch:   37	Loss: 0.8717	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:28:26 [INFO ]  Epoch:   38	Loss: 0.7380	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:28:28 [INFO ]  Epoch:   39	Loss: 0.7407	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:28:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 17:28:40 [INFO ]  
2022-10-03 17:28:40 [INFO ]  Begin of epoch 40 :
2022-10-03 17:28:43 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:28:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:28:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:28:43 [INFO ]  	   step  1 (lr=0.353027)                   76.26%                   0.8684
2022-10-03 17:28:43 [INFO ]  
2022-10-03 17:28:43 [INFO ]  Epoch:   40	Loss: 0.8492	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:28:45 [INFO ]  Epoch:   41	Loss: 0.7065	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:28:47 [INFO ]  Epoch:   42	Loss: 0.7286	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:28:49 [INFO ]  Epoch:   43	Loss: 0.6830	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:28:50 [INFO ]  Epoch:   44	Loss: 0.7486	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:28:52 [INFO ]  Epoch:   45	Loss: 0.7004	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:28:54 [INFO ]  Epoch:   46	Loss: 0.7843	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:28:56 [INFO ]  Epoch:   47	Loss: 0.6887	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:28:58 [INFO ]  Epoch:   48	Loss: 0.6955	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:29:00 [INFO ]  Epoch:   49	Loss: 0.7747	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:29:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 17:29:12 [INFO ]  
2022-10-03 17:29:12 [INFO ]  Begin of epoch 50 :
2022-10-03 17:29:16 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:29:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:29:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:29:16 [INFO ]  	   step  1 (lr=0.370902)                   80.09%                   0.7203
2022-10-03 17:29:16 [INFO ]  
2022-10-03 17:29:16 [INFO ]  Epoch:   50	Loss: 0.6200	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 17:29:18 [INFO ]  Epoch:   51	Loss: 0.6578	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:20 [INFO ]  Epoch:   52	Loss: 0.6533	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:21 [INFO ]  Epoch:   53	Loss: 0.6690	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:29:24 [INFO ]  Epoch:   54	Loss: 0.6300	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:29:26 [INFO ]  Epoch:   55	Loss: 0.6468	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:29:28 [INFO ]  Epoch:   56	Loss: 0.6515	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:29:29 [INFO ]  Epoch:   57	Loss: 0.6677	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:31 [INFO ]  Epoch:   58	Loss: 0.6481	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:33 [INFO ]  Epoch:   59	Loss: 0.6060	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:29:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 17:29:45 [INFO ]  
2022-10-03 17:29:45 [INFO ]  Begin of epoch 60 :
2022-10-03 17:29:49 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:29:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:29:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:29:49 [INFO ]  	   step  1 (lr=0.380581)                   80.24%                   0.7252
2022-10-03 17:29:49 [INFO ]  
2022-10-03 17:29:49 [INFO ]  Epoch:   60	Loss: 0.6567	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 17:29:50 [INFO ]  Epoch:   61	Loss: 0.6793	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:29:52 [INFO ]  Epoch:   62	Loss: 0.7486	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:29:54 [INFO ]  Epoch:   63	Loss: 0.6809	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:56 [INFO ]  Epoch:   64	Loss: 0.6126	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:29:58 [INFO ]  Epoch:   65	Loss: 0.5726	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:30:00 [INFO ]  Epoch:   66	Loss: 0.6166	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:30:02 [INFO ]  Epoch:   67	Loss: 0.6438	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:30:04 [INFO ]  Epoch:   68	Loss: 0.6686	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:30:06 [INFO ]  Epoch:   69	Loss: 0.6740	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:30:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 17:30:18 [INFO ]  
2022-10-03 17:30:18 [INFO ]  Begin of epoch 70 :
2022-10-03 17:30:21 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:30:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:30:21 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:30:21 [INFO ]  	   step  1 (lr=0.388789)                   81.02%                   0.7117
2022-10-03 17:30:21 [INFO ]  
2022-10-03 17:30:21 [INFO ]  Epoch:   70	Loss: 0.6961	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:30:23 [INFO ]  Epoch:   71	Loss: 0.6459	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:30:25 [INFO ]  Epoch:   72	Loss: 0.7098	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:30:27 [INFO ]  Epoch:   73	Loss: 0.6477	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:30:29 [INFO ]  Epoch:   74	Loss: 0.6384	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:30:31 [INFO ]  Epoch:   75	Loss: 0.6177	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:30:33 [INFO ]  Epoch:   76	Loss: 0.6181	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:30:34 [INFO ]  Epoch:   77	Loss: 0.5507	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:30:36 [INFO ]  Epoch:   78	Loss: 0.6298	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:30:38 [INFO ]  Epoch:   79	Loss: 0.6148	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:30:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 17:30:50 [INFO ]  
2022-10-03 17:30:50 [INFO ]  Begin of epoch 80 :
2022-10-03 17:30:53 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:30:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:30:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:30:53 [INFO ]  	   step  1 (lr=0.396480)                   80.49%                   0.7165
2022-10-03 17:30:53 [INFO ]  
2022-10-03 17:30:53 [INFO ]  Epoch:   80	Loss: 0.5827	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:30:55 [INFO ]  Epoch:   81	Loss: 0.6523	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:30:57 [INFO ]  Epoch:   82	Loss: 0.6248	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:30:59 [INFO ]  Epoch:   83	Loss: 0.6320	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:31:01 [INFO ]  Epoch:   84	Loss: 0.6433	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:31:03 [INFO ]  Epoch:   85	Loss: 0.6179	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:31:05 [INFO ]  Epoch:   86	Loss: 0.6421	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:31:07 [INFO ]  Epoch:   87	Loss: 0.5532	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:31:09 [INFO ]  Epoch:   88	Loss: 0.6435	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:31:11 [INFO ]  Epoch:   89	Loss: 0.6482	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:31:23 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 17:31:23 [INFO ]  
2022-10-03 17:31:23 [INFO ]  Begin of epoch 90 :
2022-10-03 17:31:26 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:31:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:31:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:31:26 [INFO ]  	   step  1 (lr=0.404235)                   81.26%                   0.6980
2022-10-03 17:31:26 [INFO ]  
2022-10-03 17:31:26 [INFO ]  Epoch:   90	Loss: 0.6260	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 17:31:28 [INFO ]  Epoch:   91	Loss: 0.6162	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:31:30 [INFO ]  Epoch:   92	Loss: 0.6058	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:31:32 [INFO ]  Epoch:   93	Loss: 0.6005	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:31:34 [INFO ]  Epoch:   94	Loss: 0.6837	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:31:36 [INFO ]  Epoch:   95	Loss: 0.5770	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:31:37 [INFO ]  Epoch:   96	Loss: 0.5923	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:31:39 [INFO ]  Epoch:   97	Loss: 0.5806	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:31:41 [INFO ]  Epoch:   98	Loss: 0.7050	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:31:43 [INFO ]  Epoch:   99	Loss: 0.5243	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:31:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 17:31:56 [INFO ]  
2022-10-03 17:31:56 [INFO ]  Begin of epoch 100 :
2022-10-03 17:31:59 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:31:59 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:31:59 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:31:59 [INFO ]  	   step  1 (lr=0.412105)                   81.85%                   0.6724
2022-10-03 17:31:59 [INFO ]  
2022-10-03 17:31:59 [INFO ]  Epoch:  100	Loss: 0.5515	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:32:01 [INFO ]  Epoch:  101	Loss: 0.5428	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:03 [INFO ]  Epoch:  102	Loss: 0.5541	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:32:05 [INFO ]  Epoch:  103	Loss: 0.6181	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:07 [INFO ]  Epoch:  104	Loss: 0.6116	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:09 [INFO ]  Epoch:  105	Loss: 0.5617	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:32:11 [INFO ]  Epoch:  106	Loss: 0.5618	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:32:12 [INFO ]  Epoch:  107	Loss: 0.5047	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:32:14 [INFO ]  Epoch:  108	Loss: 0.5460	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:32:16 [INFO ]  Epoch:  109	Loss: 0.6514	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 17:32:28 [INFO ]  
2022-10-03 17:32:28 [INFO ]  Begin of epoch 110 :
2022-10-03 17:32:32 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:32:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:32:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:32:32 [INFO ]  	   step  1 (lr=0.415390)                   81.38%                   0.6895
2022-10-03 17:32:32 [INFO ]  
2022-10-03 17:32:32 [INFO ]  Epoch:  110	Loss: 0.5627	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:32:33 [INFO ]  Epoch:  111	Loss: 0.6033	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:35 [INFO ]  Epoch:  112	Loss: 0.6778	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:37 [INFO ]  Epoch:  113	Loss: 0.6639	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:39 [INFO ]  Epoch:  114	Loss: 0.6512	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:32:41 [INFO ]  Epoch:  115	Loss: 0.5512	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:32:43 [INFO ]  Epoch:  116	Loss: 0.6482	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:32:45 [INFO ]  Epoch:  117	Loss: 0.6419	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:32:47 [INFO ]  Epoch:  118	Loss: 0.5927	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:32:49 [INFO ]  Epoch:  119	Loss: 0.6005	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 17:33:00 [INFO ]  
2022-10-03 17:33:00 [INFO ]  Begin of epoch 120 :
2022-10-03 17:33:04 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:33:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:33:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:33:04 [INFO ]  	   step  1 (lr=0.415260)                   81.61%                   0.6735
2022-10-03 17:33:04 [INFO ]  
2022-10-03 17:33:04 [INFO ]  Epoch:  120	Loss: 0.5251	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:06 [INFO ]  Epoch:  121	Loss: 0.6211	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:08 [INFO ]  Epoch:  122	Loss: 0.6954	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:33:10 [INFO ]  Epoch:  123	Loss: 0.5915	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:33:12 [INFO ]  Epoch:  124	Loss: 0.7166	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:14 [INFO ]  Epoch:  125	Loss: 0.5481	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:15 [INFO ]  Epoch:  126	Loss: 0.6203	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:17 [INFO ]  Epoch:  127	Loss: 0.6177	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:33:19 [INFO ]  Epoch:  128	Loss: 0.5640	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:33:22 [INFO ]  Epoch:  129	Loss: 0.6433	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 17:33:33 [INFO ]  
2022-10-03 17:33:33 [INFO ]  Begin of epoch 130 :
2022-10-03 17:33:37 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:33:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:33:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:33:37 [INFO ]  	   step  1 (lr=0.416338)                   81.59%                   0.6800
2022-10-03 17:33:37 [INFO ]  
2022-10-03 17:33:37 [INFO ]  Epoch:  130	Loss: 0.7332	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:33:39 [INFO ]  Epoch:  131	Loss: 0.6495	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:33:41 [INFO ]  Epoch:  132	Loss: 0.6351	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:33:43 [INFO ]  Epoch:  133	Loss: 0.5340	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:45 [INFO ]  Epoch:  134	Loss: 0.5627	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:47 [INFO ]  Epoch:  135	Loss: 0.6408	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:33:49 [INFO ]  Epoch:  136	Loss: 0.5557	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:33:51 [INFO ]  Epoch:  137	Loss: 0.5807	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:33:53 [INFO ]  Epoch:  138	Loss: 0.6230	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:33:55 [INFO ]  Epoch:  139	Loss: 0.6238	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:34:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 17:34:07 [INFO ]  
2022-10-03 17:34:07 [INFO ]  Begin of epoch 140 :
2022-10-03 17:34:10 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:34:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:34:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:34:10 [INFO ]  	   step  1 (lr=0.416780)                   80.74%                   0.7076
2022-10-03 17:34:10 [INFO ]  
2022-10-03 17:34:10 [INFO ]  Epoch:  140	Loss: 0.6259	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:34:12 [INFO ]  Epoch:  141	Loss: 0.6382	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:34:14 [INFO ]  Epoch:  142	Loss: 0.6253	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:34:16 [INFO ]  Epoch:  143	Loss: 0.6348	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:34:18 [INFO ]  Epoch:  144	Loss: 0.5640	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:34:20 [INFO ]  Epoch:  145	Loss: 0.5956	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:34:21 [INFO ]  Epoch:  146	Loss: 0.5499	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:34:23 [INFO ]  Epoch:  147	Loss: 0.6595	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:34:25 [INFO ]  Epoch:  148	Loss: 0.6290	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:34:27 [INFO ]  Epoch:  149	Loss: 0.5165	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:34:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 17:34:39 [INFO ]  
2022-10-03 17:34:39 [INFO ]  Begin of epoch 150 :
2022-10-03 17:34:43 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:34:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:34:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:34:43 [INFO ]  	   step  1 (lr=0.415440)                   81.55%                   0.6827
2022-10-03 17:34:43 [INFO ]  
2022-10-03 17:34:43 [INFO ]  Epoch:  150	Loss: 0.6365	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:34:44 [INFO ]  Epoch:  151	Loss: 0.5583	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:34:46 [INFO ]  Epoch:  152	Loss: 0.6001	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:34:48 [INFO ]  Epoch:  153	Loss: 0.5787	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:34:50 [INFO ]  Epoch:  154	Loss: 0.5720	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:34:52 [INFO ]  Epoch:  155	Loss: 0.5674	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:34:54 [INFO ]  Epoch:  156	Loss: 0.6358	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:34:56 [INFO ]  Epoch:  157	Loss: 0.5736	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:34:58 [INFO ]  Epoch:  158	Loss: 0.6941	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:35:00 [INFO ]  Epoch:  159	Loss: 0.6093	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:35:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 17:35:12 [INFO ]  
2022-10-03 17:35:12 [INFO ]  Begin of epoch 160 :
2022-10-03 17:35:15 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:35:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:35:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:35:15 [INFO ]  	   step  1 (lr=0.416618)                   81.54%                   0.6838
2022-10-03 17:35:15 [INFO ]  
2022-10-03 17:35:15 [INFO ]  Epoch:  160	Loss: 0.5770	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:35:17 [INFO ]  Epoch:  161	Loss: 0.5784	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:35:19 [INFO ]  Epoch:  162	Loss: 0.5870	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:35:21 [INFO ]  Epoch:  163	Loss: 0.5771	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:35:23 [INFO ]  Epoch:  164	Loss: 0.5890	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:35:25 [INFO ]  Epoch:  165	Loss: 0.5879	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:35:27 [INFO ]  Epoch:  166	Loss: 0.6575	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:35:29 [INFO ]  Epoch:  167	Loss: 0.6542	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:35:30 [INFO ]  Epoch:  168	Loss: 0.5991	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:35:33 [INFO ]  Epoch:  169	Loss: 0.6099	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:35:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 17:35:44 [INFO ]  
2022-10-03 17:35:44 [INFO ]  Begin of epoch 170 :
2022-10-03 17:35:48 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:35:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:35:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:35:48 [INFO ]  	   step  1 (lr=0.417768)                   81.63%                   0.6830
2022-10-03 17:35:48 [INFO ]  
2022-10-03 17:35:48 [INFO ]  Epoch:  170	Loss: 0.5655	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:35:49 [INFO ]  Epoch:  171	Loss: 0.7039	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:35:51 [INFO ]  Epoch:  172	Loss: 0.6432	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:35:53 [INFO ]  Epoch:  173	Loss: 0.6223	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:35:55 [INFO ]  Epoch:  174	Loss: 0.5500	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:35:57 [INFO ]  Epoch:  175	Loss: 0.5554	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:35:59 [INFO ]  Epoch:  176	Loss: 0.5736	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:36:01 [INFO ]  Epoch:  177	Loss: 0.5960	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:36:03 [INFO ]  Epoch:  178	Loss: 0.5835	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:36:05 [INFO ]  Epoch:  179	Loss: 0.5908	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:36:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 17:36:17 [INFO ]  
2022-10-03 17:36:17 [INFO ]  Begin of epoch 180 :
2022-10-03 17:36:20 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:36:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:36:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:36:20 [INFO ]  	   step  1 (lr=0.417747)                   81.02%                   0.6984
2022-10-03 17:36:20 [INFO ]  
2022-10-03 17:36:20 [INFO ]  Epoch:  180	Loss: 0.6421	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:36:22 [INFO ]  Epoch:  181	Loss: 0.6431	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:36:24 [INFO ]  Epoch:  182	Loss: 0.6090	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:36:26 [INFO ]  Epoch:  183	Loss: 0.6105	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:36:27 [INFO ]  Epoch:  184	Loss: 0.6785	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:36:29 [INFO ]  Epoch:  185	Loss: 0.5664	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:36:31 [INFO ]  Epoch:  186	Loss: 0.5942	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:36:33 [INFO ]  Epoch:  187	Loss: 0.5469	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:36:35 [INFO ]  Epoch:  188	Loss: 0.5291	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:36:37 [INFO ]  Epoch:  189	Loss: 0.6236	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:36:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 17:36:49 [INFO ]  
2022-10-03 17:36:49 [INFO ]  Begin of epoch 190 :
2022-10-03 17:36:52 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:36:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:36:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:36:52 [INFO ]  	   step  1 (lr=0.418501)                   81.59%                   0.6880
2022-10-03 17:36:52 [INFO ]  
2022-10-03 17:36:52 [INFO ]  Epoch:  190	Loss: 0.6159	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:36:54 [INFO ]  Epoch:  191	Loss: 0.6495	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:36:56 [INFO ]  Epoch:  192	Loss: 0.5914	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:36:58 [INFO ]  Epoch:  193	Loss: 0.6386	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:37:00 [INFO ]  Epoch:  194	Loss: 0.5298	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:37:02 [INFO ]  Epoch:  195	Loss: 0.5707	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:37:04 [INFO ]  Epoch:  196	Loss: 0.5722	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:37:06 [INFO ]  Epoch:  197	Loss: 0.5876	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:37:08 [INFO ]  Epoch:  198	Loss: 0.5657	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:37:10 [INFO ]  Epoch:  199	Loss: 0.5999	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:37:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 17:37:21 [INFO ]  
2022-10-03 17:37:21 [INFO ]  Final evaluation for SVHN :
2022-10-03 17:37:25 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:37:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:37:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:37:25 [INFO ]  	   step  1 (lr=0.418869)                   81.45%                   0.6859
2022-10-03 17:37:25 [INFO ]  
2022-10-03 17:37:25 [INFO ]  
2022-10-03 17:37:25 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 17:37:28 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:37:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:37:28 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 17:37:28 [INFO ]  	   step  1 (lr=0.418869)                   14.97%                   5.6294
2022-10-03 17:37:28 [INFO ]  
2022-10-03 17:37:28 [INFO ]  CPU Time: 7.95 minutes
2022-10-03 17:37:55 [INFO ]  ======================================== 2022-10-03 17:37:55 ========================================
2022-10-03 17:37:55 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 17:37:55 [INFO ]  Options: 
2022-10-03 17:37:55 [INFO ]  	base_dir: null
2022-10-03 17:37:55 [INFO ]  	batch_size: 1024
2022-10-03 17:37:55 [INFO ]  	checkpoint_interval: 10
2022-10-03 17:37:55 [INFO ]  	dataset: SVHN
2022-10-03 17:37:55 [INFO ]  	dataset_labels:
2022-10-03 17:37:55 [INFO ]  	- 0
2022-10-03 17:37:55 [INFO ]  	- 1
2022-10-03 17:37:55 [INFO ]  	- 2
2022-10-03 17:37:55 [INFO ]  	- 3
2022-10-03 17:37:55 [INFO ]  	- 4
2022-10-03 17:37:55 [INFO ]  	- 5
2022-10-03 17:37:55 [INFO ]  	- 6
2022-10-03 17:37:55 [INFO ]  	- 7
2022-10-03 17:37:55 [INFO ]  	- 8
2022-10-03 17:37:55 [INFO ]  	- 9
2022-10-03 17:37:55 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 17:37:55 [INFO ]  	- !!python/tuple
2022-10-03 17:37:55 [INFO ]  	    - 0.4379104971885681
2022-10-03 17:37:55 [INFO ]  	    - 0.44398033618927
2022-10-03 17:37:55 [INFO ]  	    - 0.4729299545288086
2022-10-03 17:37:55 [INFO ]  	- !!python/tuple
2022-10-03 17:37:55 [INFO ]  	    - 0.19803012907505035
2022-10-03 17:37:55 [INFO ]  	    - 0.2010156363248825
2022-10-03 17:37:55 [INFO ]  	    - 0.19703614711761475
2022-10-03 17:37:55 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 17:37:55 [INFO ]  	decay_epochs: 50
2022-10-03 17:37:55 [INFO ]  	decay_factor: 0.1
2022-10-03 17:37:55 [INFO ]  	device_id: 0
2022-10-03 17:37:55 [INFO ]  	distill_epochs: 1
2022-10-03 17:37:55 [INFO ]  	distill_lr: 0.02
2022-10-03 17:37:55 [INFO ]  	distill_steps: 1
2022-10-03 17:37:55 [INFO ]  	epochs: 200
2022-10-03 17:37:55 [INFO ]  	expand_cls: false
2022-10-03 17:37:55 [INFO ]  	forgetting_dataset: null
2022-10-03 17:37:55 [INFO ]  	init: xavier
2022-10-03 17:37:55 [INFO ]  	init_param: 1.0
2022-10-03 17:37:55 [INFO ]  	input_size: 32
2022-10-03 17:37:55 [INFO ]  	ipc: 15
2022-10-03 17:37:55 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 17:37:55 [INFO ]  	log_interval: 100
2022-10-03 17:37:55 [INFO ]  	log_level: INFO
2022-10-03 17:37:55 [INFO ]  	lr: 0.01
2022-10-03 17:37:55 [INFO ]  	mode: distill_adapt
2022-10-03 17:37:55 [INFO ]  	nc: 3
2022-10-03 17:37:55 [INFO ]  	num_classes: 10
2022-10-03 17:37:55 [INFO ]  	num_workers: 8
2022-10-03 17:37:55 [INFO ]  	phase: train
2022-10-03 17:37:55 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 17:37:55 [INFO ]  	start_time: '2022-10-03 17:37:55'
2022-10-03 17:37:55 [INFO ]  	test_batch_size: 1024
2022-10-03 17:37:55 [INFO ]  	
2022-10-03 17:37:57 [INFO ]  train dataset size:	73257
2022-10-03 17:37:57 [INFO ]  test dataset size: 	26032
2022-10-03 17:37:57 [INFO ]  datasets built!
2022-10-03 17:37:57 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 17:38:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 17:38:09 [INFO ]  
2022-10-03 17:38:09 [INFO ]  Begin of epoch 0 :
2022-10-03 17:38:12 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:38:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:38:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:38:12 [INFO ]  	   step  1 (lr=0.020000)                    7.36%                   8.6340
2022-10-03 17:38:12 [INFO ]  
2022-10-03 17:38:12 [INFO ]  Epoch:    0	Loss: 8.3463	Data Time: 0.38s	Train Time: 0.04s
2022-10-03 17:38:14 [INFO ]  Epoch:    1	Loss: 3.0702	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:38:16 [INFO ]  Epoch:    2	Loss: 2.4549	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:38:18 [INFO ]  Epoch:    3	Loss: 2.2744	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:38:20 [INFO ]  Epoch:    4	Loss: 2.2336	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:38:22 [INFO ]  Epoch:    5	Loss: 2.1765	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:38:23 [INFO ]  Epoch:    6	Loss: 2.1431	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:38:25 [INFO ]  Epoch:    7	Loss: 2.0884	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:38:27 [INFO ]  Epoch:    8	Loss: 2.0736	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:38:29 [INFO ]  Epoch:    9	Loss: 1.9083	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:38:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 17:38:41 [INFO ]  
2022-10-03 17:38:41 [INFO ]  Begin of epoch 10 :
2022-10-03 17:38:45 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:38:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:38:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:38:45 [INFO ]  	   step  1 (lr=0.081280)                   41.91%                   1.8012
2022-10-03 17:38:45 [INFO ]  
2022-10-03 17:38:45 [INFO ]  Epoch:   10	Loss: 1.8129	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:38:46 [INFO ]  Epoch:   11	Loss: 1.6975	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:38:48 [INFO ]  Epoch:   12	Loss: 1.5851	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:38:50 [INFO ]  Epoch:   13	Loss: 1.4408	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:38:52 [INFO ]  Epoch:   14	Loss: 1.3135	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:38:54 [INFO ]  Epoch:   15	Loss: 1.2227	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:38:56 [INFO ]  Epoch:   16	Loss: 1.2652	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:38:58 [INFO ]  Epoch:   17	Loss: 1.2014	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:38:59 [INFO ]  Epoch:   18	Loss: 1.2553	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:39:01 [INFO ]  Epoch:   19	Loss: 1.0112	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:39:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 17:39:13 [INFO ]  
2022-10-03 17:39:13 [INFO ]  Begin of epoch 20 :
2022-10-03 17:39:16 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:39:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:39:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:39:16 [INFO ]  	   step  1 (lr=0.238523)                   66.08%                   1.1398
2022-10-03 17:39:16 [INFO ]  
2022-10-03 17:39:16 [INFO ]  Epoch:   20	Loss: 1.0306	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:39:18 [INFO ]  Epoch:   21	Loss: 1.0730	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:39:20 [INFO ]  Epoch:   22	Loss: 1.1591	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:39:22 [INFO ]  Epoch:   23	Loss: 0.9909	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:39:24 [INFO ]  Epoch:   24	Loss: 0.8944	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:39:26 [INFO ]  Epoch:   25	Loss: 0.9755	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:39:28 [INFO ]  Epoch:   26	Loss: 1.1113	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:39:30 [INFO ]  Epoch:   27	Loss: 0.8016	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:39:32 [INFO ]  Epoch:   28	Loss: 0.9802	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:39:34 [INFO ]  Epoch:   29	Loss: 0.8533	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:39:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 17:39:46 [INFO ]  
2022-10-03 17:39:46 [INFO ]  Begin of epoch 30 :
2022-10-03 17:39:49 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:39:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:39:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:39:49 [INFO ]  	   step  1 (lr=0.300465)                   71.95%                   0.9994
2022-10-03 17:39:49 [INFO ]  
2022-10-03 17:39:49 [INFO ]  Epoch:   30	Loss: 0.9883	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:39:51 [INFO ]  Epoch:   31	Loss: 0.8452	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:39:53 [INFO ]  Epoch:   32	Loss: 0.8604	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:39:55 [INFO ]  Epoch:   33	Loss: 0.7057	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:39:57 [INFO ]  Epoch:   34	Loss: 0.9123	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:39:59 [INFO ]  Epoch:   35	Loss: 0.8343	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:40:01 [INFO ]  Epoch:   36	Loss: 0.9850	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:40:03 [INFO ]  Epoch:   37	Loss: 0.8790	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:40:05 [INFO ]  Epoch:   38	Loss: 0.9305	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:40:07 [INFO ]  Epoch:   39	Loss: 0.8622	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:40:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 17:40:19 [INFO ]  
2022-10-03 17:40:19 [INFO ]  Begin of epoch 40 :
2022-10-03 17:40:22 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:40:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:40:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:40:22 [INFO ]  	   step  1 (lr=0.326340)                   75.13%                   0.9035
2022-10-03 17:40:22 [INFO ]  
2022-10-03 17:40:22 [INFO ]  Epoch:   40	Loss: 0.8039	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:40:24 [INFO ]  Epoch:   41	Loss: 0.8173	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:40:26 [INFO ]  Epoch:   42	Loss: 0.9440	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:40:28 [INFO ]  Epoch:   43	Loss: 0.8166	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:40:30 [INFO ]  Epoch:   44	Loss: 0.9306	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:40:32 [INFO ]  Epoch:   45	Loss: 0.7819	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:40:34 [INFO ]  Epoch:   46	Loss: 0.7477	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:40:36 [INFO ]  Epoch:   47	Loss: 0.7996	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:40:37 [INFO ]  Epoch:   48	Loss: 0.8289	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:40:39 [INFO ]  Epoch:   49	Loss: 0.7957	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:40:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 17:40:51 [INFO ]  
2022-10-03 17:40:51 [INFO ]  Begin of epoch 50 :
2022-10-03 17:40:55 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:40:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:40:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:40:55 [INFO ]  	   step  1 (lr=0.341101)                   78.31%                   0.7918
2022-10-03 17:40:55 [INFO ]  
2022-10-03 17:40:55 [INFO ]  Epoch:   50	Loss: 0.7601	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:40:56 [INFO ]  Epoch:   51	Loss: 0.7192	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:40:58 [INFO ]  Epoch:   52	Loss: 0.6862	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:41:00 [INFO ]  Epoch:   53	Loss: 0.7372	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:41:02 [INFO ]  Epoch:   54	Loss: 0.7080	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:41:04 [INFO ]  Epoch:   55	Loss: 0.6710	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:41:06 [INFO ]  Epoch:   56	Loss: 0.7153	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:41:08 [INFO ]  Epoch:   57	Loss: 0.7192	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:41:10 [INFO ]  Epoch:   58	Loss: 0.7232	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:41:12 [INFO ]  Epoch:   59	Loss: 0.6882	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:41:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 17:41:24 [INFO ]  
2022-10-03 17:41:24 [INFO ]  Begin of epoch 60 :
2022-10-03 17:41:28 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:41:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:41:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:41:28 [INFO ]  	   step  1 (lr=0.350780)                   79.55%                   0.7605
2022-10-03 17:41:28 [INFO ]  
2022-10-03 17:41:28 [INFO ]  Epoch:   60	Loss: 0.6881	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:41:30 [INFO ]  Epoch:   61	Loss: 0.6628	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:41:31 [INFO ]  Epoch:   62	Loss: 0.6790	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:41:33 [INFO ]  Epoch:   63	Loss: 0.7301	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:41:35 [INFO ]  Epoch:   64	Loss: 0.7314	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:41:37 [INFO ]  Epoch:   65	Loss: 0.6966	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:41:39 [INFO ]  Epoch:   66	Loss: 0.6884	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:41:41 [INFO ]  Epoch:   67	Loss: 0.7881	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:41:43 [INFO ]  Epoch:   68	Loss: 0.7006	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:41:45 [INFO ]  Epoch:   69	Loss: 0.7203	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:41:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 17:41:57 [INFO ]  
2022-10-03 17:41:57 [INFO ]  Begin of epoch 70 :
2022-10-03 17:42:00 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:42:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:42:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:42:00 [INFO ]  	   step  1 (lr=0.362512)                   79.92%                   0.7499
2022-10-03 17:42:00 [INFO ]  
2022-10-03 17:42:00 [INFO ]  Epoch:   70	Loss: 0.6424	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 17:42:02 [INFO ]  Epoch:   71	Loss: 0.6740	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:42:04 [INFO ]  Epoch:   72	Loss: 0.5970	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:42:06 [INFO ]  Epoch:   73	Loss: 0.7395	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:42:08 [INFO ]  Epoch:   74	Loss: 0.6332	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:42:10 [INFO ]  Epoch:   75	Loss: 0.6375	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:12 [INFO ]  Epoch:   76	Loss: 0.7000	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:13 [INFO ]  Epoch:   77	Loss: 0.6142	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:42:15 [INFO ]  Epoch:   78	Loss: 0.6571	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:42:17 [INFO ]  Epoch:   79	Loss: 0.7363	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:42:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 17:42:30 [INFO ]  
2022-10-03 17:42:30 [INFO ]  Begin of epoch 80 :
2022-10-03 17:42:33 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:42:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:42:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:42:33 [INFO ]  	   step  1 (lr=0.368356)                   79.38%                   0.7646
2022-10-03 17:42:33 [INFO ]  
2022-10-03 17:42:33 [INFO ]  Epoch:   80	Loss: 0.6507	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:35 [INFO ]  Epoch:   81	Loss: 0.6331	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:42:37 [INFO ]  Epoch:   82	Loss: 0.7076	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:42:39 [INFO ]  Epoch:   83	Loss: 0.6673	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:42:41 [INFO ]  Epoch:   84	Loss: 0.6749	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:43 [INFO ]  Epoch:   85	Loss: 0.6584	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:45 [INFO ]  Epoch:   86	Loss: 0.7166	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:47 [INFO ]  Epoch:   87	Loss: 0.6540	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:42:49 [INFO ]  Epoch:   88	Loss: 0.6425	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:42:51 [INFO ]  Epoch:   89	Loss: 0.6622	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:43:03 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 17:43:03 [INFO ]  
2022-10-03 17:43:03 [INFO ]  Begin of epoch 90 :
2022-10-03 17:43:06 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:43:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:43:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:43:06 [INFO ]  	   step  1 (lr=0.377635)                   77.71%                   0.8194
2022-10-03 17:43:06 [INFO ]  
2022-10-03 17:43:06 [INFO ]  Epoch:   90	Loss: 0.7482	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:43:08 [INFO ]  Epoch:   91	Loss: 0.6839	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:43:10 [INFO ]  Epoch:   92	Loss: 0.6936	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:43:12 [INFO ]  Epoch:   93	Loss: 0.6144	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:43:14 [INFO ]  Epoch:   94	Loss: 0.7057	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:43:16 [INFO ]  Epoch:   95	Loss: 0.6683	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:43:17 [INFO ]  Epoch:   96	Loss: 0.6821	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:43:19 [INFO ]  Epoch:   97	Loss: 0.7083	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:43:21 [INFO ]  Epoch:   98	Loss: 0.6711	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:43:23 [INFO ]  Epoch:   99	Loss: 0.7591	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:43:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 17:43:35 [INFO ]  
2022-10-03 17:43:35 [INFO ]  Begin of epoch 100 :
2022-10-03 17:43:39 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:43:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:43:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:43:39 [INFO ]  	   step  1 (lr=0.385378)                   80.66%                   0.7235
2022-10-03 17:43:39 [INFO ]  
2022-10-03 17:43:39 [INFO ]  Epoch:  100	Loss: 0.6277	Data Time: 0.19s	Train Time: 0.00s
2022-10-03 17:43:40 [INFO ]  Epoch:  101	Loss: 0.6883	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:43:42 [INFO ]  Epoch:  102	Loss: 0.6132	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:43:44 [INFO ]  Epoch:  103	Loss: 0.6642	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:43:46 [INFO ]  Epoch:  104	Loss: 0.7444	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:43:48 [INFO ]  Epoch:  105	Loss: 0.6514	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:43:50 [INFO ]  Epoch:  106	Loss: 0.7075	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:43:52 [INFO ]  Epoch:  107	Loss: 0.5723	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:43:54 [INFO ]  Epoch:  108	Loss: 0.6809	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:43:56 [INFO ]  Epoch:  109	Loss: 0.6379	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:44:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 17:44:08 [INFO ]  
2022-10-03 17:44:08 [INFO ]  Begin of epoch 110 :
2022-10-03 17:44:11 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:44:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:44:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:44:11 [INFO ]  	   step  1 (lr=0.386995)                   80.76%                   0.7201
2022-10-03 17:44:11 [INFO ]  
2022-10-03 17:44:11 [INFO ]  Epoch:  110	Loss: 0.6375	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:44:13 [INFO ]  Epoch:  111	Loss: 0.6470	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:44:15 [INFO ]  Epoch:  112	Loss: 0.6362	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:44:17 [INFO ]  Epoch:  113	Loss: 0.6749	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:44:19 [INFO ]  Epoch:  114	Loss: 0.7011	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:44:21 [INFO ]  Epoch:  115	Loss: 0.5411	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:44:23 [INFO ]  Epoch:  116	Loss: 0.6822	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:44:25 [INFO ]  Epoch:  117	Loss: 0.6399	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:44:26 [INFO ]  Epoch:  118	Loss: 0.5578	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:44:28 [INFO ]  Epoch:  119	Loss: 0.6261	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:44:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 17:44:40 [INFO ]  
2022-10-03 17:44:40 [INFO ]  Begin of epoch 120 :
2022-10-03 17:44:44 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:44:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:44:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:44:44 [INFO ]  	   step  1 (lr=0.386003)                   80.28%                   0.7383
2022-10-03 17:44:44 [INFO ]  
2022-10-03 17:44:44 [INFO ]  Epoch:  120	Loss: 0.6131	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:44:45 [INFO ]  Epoch:  121	Loss: 0.7459	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:44:47 [INFO ]  Epoch:  122	Loss: 0.6783	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:44:49 [INFO ]  Epoch:  123	Loss: 0.6315	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:44:51 [INFO ]  Epoch:  124	Loss: 0.6972	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:44:53 [INFO ]  Epoch:  125	Loss: 0.7038	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:44:55 [INFO ]  Epoch:  126	Loss: 0.7440	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:44:57 [INFO ]  Epoch:  127	Loss: 0.6665	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:44:59 [INFO ]  Epoch:  128	Loss: 0.7700	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:45:02 [INFO ]  Epoch:  129	Loss: 0.6539	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:45:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 17:45:13 [INFO ]  
2022-10-03 17:45:13 [INFO ]  Begin of epoch 130 :
2022-10-03 17:45:17 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:45:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:45:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:45:17 [INFO ]  	   step  1 (lr=0.387821)                   80.64%                   0.7235
2022-10-03 17:45:17 [INFO ]  
2022-10-03 17:45:17 [INFO ]  Epoch:  130	Loss: 0.6972	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:45:19 [INFO ]  Epoch:  131	Loss: 0.6733	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:45:21 [INFO ]  Epoch:  132	Loss: 0.6692	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:45:23 [INFO ]  Epoch:  133	Loss: 0.6835	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:45:25 [INFO ]  Epoch:  134	Loss: 0.6778	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:45:27 [INFO ]  Epoch:  135	Loss: 0.6178	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:45:29 [INFO ]  Epoch:  136	Loss: 0.5816	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:45:31 [INFO ]  Epoch:  137	Loss: 0.6499	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:45:33 [INFO ]  Epoch:  138	Loss: 0.6761	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:45:35 [INFO ]  Epoch:  139	Loss: 0.6193	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:45:47 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 17:45:47 [INFO ]  
2022-10-03 17:45:47 [INFO ]  Begin of epoch 140 :
2022-10-03 17:45:51 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:45:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:45:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:45:51 [INFO ]  	   step  1 (lr=0.387403)                   80.87%                   0.7146
2022-10-03 17:45:51 [INFO ]  
2022-10-03 17:45:51 [INFO ]  Epoch:  140	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:45:52 [INFO ]  Epoch:  141	Loss: 0.6958	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:45:54 [INFO ]  Epoch:  142	Loss: 0.5854	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:45:56 [INFO ]  Epoch:  143	Loss: 0.6752	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 17:45:58 [INFO ]  Epoch:  144	Loss: 0.6165	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:00 [INFO ]  Epoch:  145	Loss: 0.6262	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:46:02 [INFO ]  Epoch:  146	Loss: 0.6351	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:46:04 [INFO ]  Epoch:  147	Loss: 0.6315	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:46:06 [INFO ]  Epoch:  148	Loss: 0.6970	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:46:08 [INFO ]  Epoch:  149	Loss: 0.5884	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:20 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 17:46:20 [INFO ]  
2022-10-03 17:46:20 [INFO ]  Begin of epoch 150 :
2022-10-03 17:46:24 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:46:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:46:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:46:24 [INFO ]  	   step  1 (lr=0.389940)                   80.69%                   0.7232
2022-10-03 17:46:24 [INFO ]  
2022-10-03 17:46:24 [INFO ]  Epoch:  150	Loss: 0.5793	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:25 [INFO ]  Epoch:  151	Loss: 0.6358	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:27 [INFO ]  Epoch:  152	Loss: 0.6696	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 17:46:29 [INFO ]  Epoch:  153	Loss: 0.6598	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:31 [INFO ]  Epoch:  154	Loss: 0.6654	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:46:33 [INFO ]  Epoch:  155	Loss: 0.7229	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:46:35 [INFO ]  Epoch:  156	Loss: 0.6123	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:46:37 [INFO ]  Epoch:  157	Loss: 0.6773	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:46:39 [INFO ]  Epoch:  158	Loss: 0.6560	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:41 [INFO ]  Epoch:  159	Loss: 0.6856	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:46:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 17:46:53 [INFO ]  
2022-10-03 17:46:53 [INFO ]  Begin of epoch 160 :
2022-10-03 17:46:56 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:46:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:46:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:46:56 [INFO ]  	   step  1 (lr=0.389832)                   80.05%                   0.7384
2022-10-03 17:46:56 [INFO ]  
2022-10-03 17:46:56 [INFO ]  Epoch:  160	Loss: 0.5862	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:46:58 [INFO ]  Epoch:  161	Loss: 0.6495	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:47:00 [INFO ]  Epoch:  162	Loss: 0.6149	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:02 [INFO ]  Epoch:  163	Loss: 0.6426	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:47:04 [INFO ]  Epoch:  164	Loss: 0.5731	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:47:06 [INFO ]  Epoch:  165	Loss: 0.6533	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:08 [INFO ]  Epoch:  166	Loss: 0.6519	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:10 [INFO ]  Epoch:  167	Loss: 0.6376	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:47:12 [INFO ]  Epoch:  168	Loss: 0.6721	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:47:13 [INFO ]  Epoch:  169	Loss: 0.5784	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:47:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 17:47:25 [INFO ]  
2022-10-03 17:47:25 [INFO ]  Begin of epoch 170 :
2022-10-03 17:47:29 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:47:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:47:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:47:29 [INFO ]  	   step  1 (lr=0.389684)                   80.37%                   0.7311
2022-10-03 17:47:29 [INFO ]  
2022-10-03 17:47:29 [INFO ]  Epoch:  170	Loss: 0.6004	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:47:31 [INFO ]  Epoch:  171	Loss: 0.6216	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:47:33 [INFO ]  Epoch:  172	Loss: 0.5887	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:35 [INFO ]  Epoch:  173	Loss: 0.6601	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:37 [INFO ]  Epoch:  174	Loss: 0.5898	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 17:47:39 [INFO ]  Epoch:  175	Loss: 0.5502	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 17:47:41 [INFO ]  Epoch:  176	Loss: 0.6806	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:47:43 [INFO ]  Epoch:  177	Loss: 0.6915	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:47:45 [INFO ]  Epoch:  178	Loss: 0.6291	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:47:47 [INFO ]  Epoch:  179	Loss: 0.6001	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:47:59 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 17:47:59 [INFO ]  
2022-10-03 17:47:59 [INFO ]  Begin of epoch 180 :
2022-10-03 17:48:02 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:48:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:48:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:48:02 [INFO ]  	   step  1 (lr=0.389726)                   80.78%                   0.7197
2022-10-03 17:48:02 [INFO ]  
2022-10-03 17:48:02 [INFO ]  Epoch:  180	Loss: 0.5850	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 17:48:04 [INFO ]  Epoch:  181	Loss: 0.5328	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 17:48:06 [INFO ]  Epoch:  182	Loss: 0.7022	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:48:08 [INFO ]  Epoch:  183	Loss: 0.6443	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:10 [INFO ]  Epoch:  184	Loss: 0.6689	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:48:12 [INFO ]  Epoch:  185	Loss: 0.6559	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:13 [INFO ]  Epoch:  186	Loss: 0.6501	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:15 [INFO ]  Epoch:  187	Loss: 0.6930	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:17 [INFO ]  Epoch:  188	Loss: 0.6678	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:19 [INFO ]  Epoch:  189	Loss: 0.5875	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:48:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 17:48:32 [INFO ]  
2022-10-03 17:48:32 [INFO ]  Begin of epoch 190 :
2022-10-03 17:48:35 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:48:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:48:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:48:35 [INFO ]  	   step  1 (lr=0.390104)                   80.26%                   0.7268
2022-10-03 17:48:35 [INFO ]  
2022-10-03 17:48:35 [INFO ]  Epoch:  190	Loss: 0.6454	Data Time: 0.17s	Train Time: 0.00s
2022-10-03 17:48:37 [INFO ]  Epoch:  191	Loss: 0.6129	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 17:48:39 [INFO ]  Epoch:  192	Loss: 0.6816	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:48:40 [INFO ]  Epoch:  193	Loss: 0.6961	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 17:48:42 [INFO ]  Epoch:  194	Loss: 0.6395	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:44 [INFO ]  Epoch:  195	Loss: 0.7234	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:46 [INFO ]  Epoch:  196	Loss: 0.5586	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 17:48:48 [INFO ]  Epoch:  197	Loss: 0.6357	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 17:48:50 [INFO ]  Epoch:  198	Loss: 0.6360	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 17:48:52 [INFO ]  Epoch:  199	Loss: 0.6479	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 17:49:03 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 17:49:03 [INFO ]  
2022-10-03 17:49:03 [INFO ]  Final evaluation for SVHN :
2022-10-03 17:49:07 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:49:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:49:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 17:49:07 [INFO ]  	   step  1 (lr=0.389928)                   80.37%                   0.7278
2022-10-03 17:49:07 [INFO ]  
2022-10-03 17:49:07 [INFO ]  
2022-10-03 17:49:07 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 17:49:10 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 17:49:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 17:49:10 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 17:49:10 [INFO ]  	   step  1 (lr=0.389928)                   17.81%                   5.3256
2022-10-03 17:49:10 [INFO ]  
2022-10-03 17:49:10 [INFO ]  CPU Time: 8.02 minutes
2022-10-03 18:19:50 [INFO ]  ======================================== 2022-10-03 18:19:50 ========================================
2022-10-03 18:19:50 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 18:19:50 [INFO ]  Options: 
2022-10-03 18:19:50 [INFO ]  	base_dir: null
2022-10-03 18:19:50 [INFO ]  	batch_size: 1024
2022-10-03 18:19:50 [INFO ]  	checkpoint_interval: 10
2022-10-03 18:19:50 [INFO ]  	dataset: SVHN
2022-10-03 18:19:50 [INFO ]  	dataset_labels:
2022-10-03 18:19:50 [INFO ]  	- 0
2022-10-03 18:19:50 [INFO ]  	- 1
2022-10-03 18:19:50 [INFO ]  	- 2
2022-10-03 18:19:50 [INFO ]  	- 3
2022-10-03 18:19:50 [INFO ]  	- 4
2022-10-03 18:19:50 [INFO ]  	- 5
2022-10-03 18:19:50 [INFO ]  	- 6
2022-10-03 18:19:50 [INFO ]  	- 7
2022-10-03 18:19:50 [INFO ]  	- 8
2022-10-03 18:19:50 [INFO ]  	- 9
2022-10-03 18:19:50 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 18:19:50 [INFO ]  	- !!python/tuple
2022-10-03 18:19:50 [INFO ]  	    - 0.4379104971885681
2022-10-03 18:19:50 [INFO ]  	    - 0.44398033618927
2022-10-03 18:19:50 [INFO ]  	    - 0.4729299545288086
2022-10-03 18:19:50 [INFO ]  	- !!python/tuple
2022-10-03 18:19:50 [INFO ]  	    - 0.19803012907505035
2022-10-03 18:19:50 [INFO ]  	    - 0.2010156363248825
2022-10-03 18:19:50 [INFO ]  	    - 0.19703614711761475
2022-10-03 18:19:50 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 18:19:50 [INFO ]  	decay_epochs: 50
2022-10-03 18:19:50 [INFO ]  	decay_factor: 0.1
2022-10-03 18:19:50 [INFO ]  	device_id: 0
2022-10-03 18:19:50 [INFO ]  	distill_epochs: 1
2022-10-03 18:19:50 [INFO ]  	distill_lr: 0.02
2022-10-03 18:19:50 [INFO ]  	distill_steps: 1
2022-10-03 18:19:50 [INFO ]  	epochs: 200
2022-10-03 18:19:50 [INFO ]  	expand_cls: false
2022-10-03 18:19:50 [INFO ]  	forgetting_dataset: null
2022-10-03 18:19:50 [INFO ]  	init: xavier
2022-10-03 18:19:50 [INFO ]  	init_param: 1.0
2022-10-03 18:19:50 [INFO ]  	input_size: 32
2022-10-03 18:19:50 [INFO ]  	ipc: 15
2022-10-03 18:19:50 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 18:19:50 [INFO ]  	log_interval: 100
2022-10-03 18:19:50 [INFO ]  	log_level: INFO
2022-10-03 18:19:50 [INFO ]  	lr: 0.01
2022-10-03 18:19:50 [INFO ]  	mode: distill_adapt
2022-10-03 18:19:50 [INFO ]  	nc: 3
2022-10-03 18:19:50 [INFO ]  	num_classes: 10
2022-10-03 18:19:50 [INFO ]  	num_workers: 8
2022-10-03 18:19:50 [INFO ]  	phase: train
2022-10-03 18:19:50 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 18:19:50 [INFO ]  	start_time: '2022-10-03 18:19:50'
2022-10-03 18:19:50 [INFO ]  	test_batch_size: 1024
2022-10-03 18:19:50 [INFO ]  	
2022-10-03 18:19:52 [INFO ]  train dataset size:	73257
2022-10-03 18:19:52 [INFO ]  test dataset size: 	26032
2022-10-03 18:19:52 [INFO ]  datasets built!
2022-10-03 18:19:52 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 18:20:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 18:20:04 [INFO ]  
2022-10-03 18:20:04 [INFO ]  Begin of epoch 0 :
2022-10-03 18:20:08 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:20:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:20:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:20:08 [INFO ]  	   step  1 (lr=0.020000)                    7.16%                   8.6714
2022-10-03 18:20:08 [INFO ]  
2022-10-03 18:20:08 [INFO ]  Epoch:    0	Loss: 7.8334	Data Time: 0.44s	Train Time: 0.04s
2022-10-03 18:20:09 [INFO ]  Epoch:    1	Loss: 2.9437	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:20:11 [INFO ]  Epoch:    2	Loss: 2.4746	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:20:13 [INFO ]  Epoch:    3	Loss: 2.2456	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:20:15 [INFO ]  Epoch:    4	Loss: 2.2194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:20:17 [INFO ]  Epoch:    5	Loss: 2.1980	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:20:19 [INFO ]  Epoch:    6	Loss: 2.1690	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:20:20 [INFO ]  Epoch:    7	Loss: 2.0847	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:20:22 [INFO ]  Epoch:    8	Loss: 2.0573	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:20:24 [INFO ]  Epoch:    9	Loss: 1.9773	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:20:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 18:20:35 [INFO ]  
2022-10-03 18:20:35 [INFO ]  Begin of epoch 10 :
2022-10-03 18:20:39 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:20:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:20:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:20:39 [INFO ]  	   step  1 (lr=0.075043)                   41.87%                   1.8547
2022-10-03 18:20:39 [INFO ]  
2022-10-03 18:20:39 [INFO ]  Epoch:   10	Loss: 1.8615	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:20:41 [INFO ]  Epoch:   11	Loss: 1.9805	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 18:20:43 [INFO ]  Epoch:   12	Loss: 1.6697	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:20:44 [INFO ]  Epoch:   13	Loss: 1.4914	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:20:46 [INFO ]  Epoch:   14	Loss: 1.4884	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:20:48 [INFO ]  Epoch:   15	Loss: 1.3768	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 18:20:50 [INFO ]  Epoch:   16	Loss: 1.3347	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:20:52 [INFO ]  Epoch:   17	Loss: 1.2377	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:20:54 [INFO ]  Epoch:   18	Loss: 1.2536	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:20:56 [INFO ]  Epoch:   19	Loss: 1.0728	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:21:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 18:21:08 [INFO ]  
2022-10-03 18:21:08 [INFO ]  Begin of epoch 20 :
2022-10-03 18:21:11 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:21:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:21:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:21:11 [INFO ]  	   step  1 (lr=0.218627)                   62.60%                   1.2677
2022-10-03 18:21:11 [INFO ]  
2022-10-03 18:21:11 [INFO ]  Epoch:   20	Loss: 1.2295	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:21:13 [INFO ]  Epoch:   21	Loss: 1.2037	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:21:15 [INFO ]  Epoch:   22	Loss: 1.0773	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:21:16 [INFO ]  Epoch:   23	Loss: 0.9360	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 18:21:18 [INFO ]  Epoch:   24	Loss: 1.0052	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:21:20 [INFO ]  Epoch:   25	Loss: 1.0155	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:21:22 [INFO ]  Epoch:   26	Loss: 0.8556	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:21:24 [INFO ]  Epoch:   27	Loss: 0.8606	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:21:26 [INFO ]  Epoch:   28	Loss: 1.0330	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:21:28 [INFO ]  Epoch:   29	Loss: 0.9998	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:21:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 18:21:39 [INFO ]  
2022-10-03 18:21:39 [INFO ]  Begin of epoch 30 :
2022-10-03 18:21:43 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:21:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:21:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:21:43 [INFO ]  	   step  1 (lr=0.278810)                   71.92%                   0.9833
2022-10-03 18:21:43 [INFO ]  
2022-10-03 18:21:43 [INFO ]  Epoch:   30	Loss: 0.9333	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:21:44 [INFO ]  Epoch:   31	Loss: 0.9186	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:21:46 [INFO ]  Epoch:   32	Loss: 0.9279	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:21:48 [INFO ]  Epoch:   33	Loss: 0.8634	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:21:50 [INFO ]  Epoch:   34	Loss: 0.8993	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:21:52 [INFO ]  Epoch:   35	Loss: 0.8152	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:21:54 [INFO ]  Epoch:   36	Loss: 0.8357	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:21:56 [INFO ]  Epoch:   37	Loss: 0.8615	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:21:58 [INFO ]  Epoch:   38	Loss: 0.8793	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:22:00 [INFO ]  Epoch:   39	Loss: 0.7842	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:22:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 18:22:12 [INFO ]  
2022-10-03 18:22:12 [INFO ]  Begin of epoch 40 :
2022-10-03 18:22:15 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:22:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:22:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:22:15 [INFO ]  	   step  1 (lr=0.326796)                   77.16%                   0.8219
2022-10-03 18:22:15 [INFO ]  
2022-10-03 18:22:15 [INFO ]  Epoch:   40	Loss: 0.8269	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:22:17 [INFO ]  Epoch:   41	Loss: 0.8609	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:22:19 [INFO ]  Epoch:   42	Loss: 0.7840	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:22:21 [INFO ]  Epoch:   43	Loss: 0.7229	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:22:22 [INFO ]  Epoch:   44	Loss: 0.7591	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:22:24 [INFO ]  Epoch:   45	Loss: 0.7889	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:22:26 [INFO ]  Epoch:   46	Loss: 0.7360	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:22:28 [INFO ]  Epoch:   47	Loss: 1.0571	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:22:30 [INFO ]  Epoch:   48	Loss: 0.9643	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:22:32 [INFO ]  Epoch:   49	Loss: 0.7592	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:22:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 18:22:44 [INFO ]  
2022-10-03 18:22:44 [INFO ]  Begin of epoch 50 :
2022-10-03 18:22:47 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:22:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:22:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:22:47 [INFO ]  	   step  1 (lr=0.346954)                   79.81%                   0.7428
2022-10-03 18:22:47 [INFO ]  
2022-10-03 18:22:47 [INFO ]  Epoch:   50	Loss: 0.7663	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 18:22:49 [INFO ]  Epoch:   51	Loss: 0.6634	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:22:51 [INFO ]  Epoch:   52	Loss: 0.6779	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:22:53 [INFO ]  Epoch:   53	Loss: 0.6772	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:22:55 [INFO ]  Epoch:   54	Loss: 0.6271	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:22:57 [INFO ]  Epoch:   55	Loss: 0.6719	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:22:59 [INFO ]  Epoch:   56	Loss: 0.6754	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:23:01 [INFO ]  Epoch:   57	Loss: 0.6193	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:03 [INFO ]  Epoch:   58	Loss: 0.6670	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:05 [INFO ]  Epoch:   59	Loss: 0.6374	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 18:23:16 [INFO ]  
2022-10-03 18:23:16 [INFO ]  Begin of epoch 60 :
2022-10-03 18:23:20 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:23:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:23:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:23:20 [INFO ]  	   step  1 (lr=0.358095)                   79.24%                   0.7623
2022-10-03 18:23:20 [INFO ]  
2022-10-03 18:23:20 [INFO ]  Epoch:   60	Loss: 0.7013	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:23:22 [INFO ]  Epoch:   61	Loss: 0.7190	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 18:23:23 [INFO ]  Epoch:   62	Loss: 0.7178	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:23:25 [INFO ]  Epoch:   63	Loss: 0.6333	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:27 [INFO ]  Epoch:   64	Loss: 0.7074	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:29 [INFO ]  Epoch:   65	Loss: 0.6959	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 18:23:31 [INFO ]  Epoch:   66	Loss: 0.6159	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:23:33 [INFO ]  Epoch:   67	Loss: 0.6687	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:35 [INFO ]  Epoch:   68	Loss: 0.6996	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:23:37 [INFO ]  Epoch:   69	Loss: 0.6130	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 18:23:49 [INFO ]  
2022-10-03 18:23:49 [INFO ]  Begin of epoch 70 :
2022-10-03 18:23:52 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:23:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:23:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:23:52 [INFO ]  	   step  1 (lr=0.368847)                   80.06%                   0.7271
2022-10-03 18:23:52 [INFO ]  
2022-10-03 18:23:52 [INFO ]  Epoch:   70	Loss: 0.7399	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 18:23:54 [INFO ]  Epoch:   71	Loss: 0.6985	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:23:56 [INFO ]  Epoch:   72	Loss: 0.6623	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:23:57 [INFO ]  Epoch:   73	Loss: 0.6803	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:23:59 [INFO ]  Epoch:   74	Loss: 0.6759	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:24:01 [INFO ]  Epoch:   75	Loss: 0.6831	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:24:03 [INFO ]  Epoch:   76	Loss: 0.6447	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:05 [INFO ]  Epoch:   77	Loss: 0.6251	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:24:07 [INFO ]  Epoch:   78	Loss: 0.6311	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:09 [INFO ]  Epoch:   79	Loss: 0.6233	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:24:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 18:24:21 [INFO ]  
2022-10-03 18:24:21 [INFO ]  Begin of epoch 80 :
2022-10-03 18:24:24 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:24:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:24:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:24:24 [INFO ]  	   step  1 (lr=0.378159)                   80.57%                   0.7122
2022-10-03 18:24:24 [INFO ]  
2022-10-03 18:24:24 [INFO ]  Epoch:   80	Loss: 0.6027	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:26 [INFO ]  Epoch:   81	Loss: 0.6639	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:24:28 [INFO ]  Epoch:   82	Loss: 0.7449	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:24:30 [INFO ]  Epoch:   83	Loss: 0.7505	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:24:32 [INFO ]  Epoch:   84	Loss: 0.6061	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:24:33 [INFO ]  Epoch:   85	Loss: 0.7246	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:35 [INFO ]  Epoch:   86	Loss: 0.7288	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:24:37 [INFO ]  Epoch:   87	Loss: 0.6705	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:39 [INFO ]  Epoch:   88	Loss: 0.6636	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:24:41 [INFO ]  Epoch:   89	Loss: 0.6479	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:24:53 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 18:24:53 [INFO ]  
2022-10-03 18:24:53 [INFO ]  Begin of epoch 90 :
2022-10-03 18:24:56 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:24:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:24:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:24:56 [INFO ]  	   step  1 (lr=0.387121)                   80.97%                   0.6997
2022-10-03 18:24:56 [INFO ]  
2022-10-03 18:24:56 [INFO ]  Epoch:   90	Loss: 0.6034	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:24:58 [INFO ]  Epoch:   91	Loss: 0.6188	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:25:00 [INFO ]  Epoch:   92	Loss: 0.6371	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:25:02 [INFO ]  Epoch:   93	Loss: 0.6871	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:25:03 [INFO ]  Epoch:   94	Loss: 0.5912	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:25:05 [INFO ]  Epoch:   95	Loss: 0.6384	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:25:07 [INFO ]  Epoch:   96	Loss: 0.6320	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:25:09 [INFO ]  Epoch:   97	Loss: 0.6827	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:25:11 [INFO ]  Epoch:   98	Loss: 0.6779	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 18:25:13 [INFO ]  Epoch:   99	Loss: 0.5672	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:25:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 18:25:25 [INFO ]  
2022-10-03 18:25:25 [INFO ]  Begin of epoch 100 :
2022-10-03 18:25:28 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:25:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:25:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:25:28 [INFO ]  	   step  1 (lr=0.388088)                   81.40%                   0.6868
2022-10-03 18:25:28 [INFO ]  
2022-10-03 18:25:28 [INFO ]  Epoch:  100	Loss: 0.5885	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 18:25:30 [INFO ]  Epoch:  101	Loss: 0.6126	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 18:25:32 [INFO ]  Epoch:  102	Loss: 0.5903	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:25:34 [INFO ]  Epoch:  103	Loss: 0.6800	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:25:35 [INFO ]  Epoch:  104	Loss: 0.6908	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 18:25:37 [INFO ]  Epoch:  105	Loss: 0.6693	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:25:39 [INFO ]  Epoch:  106	Loss: 0.5958	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:25:41 [INFO ]  Epoch:  107	Loss: 0.6937	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:25:43 [INFO ]  Epoch:  108	Loss: 0.6351	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:25:45 [INFO ]  Epoch:  109	Loss: 0.6169	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:25:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 18:25:57 [INFO ]  
2022-10-03 18:25:57 [INFO ]  Begin of epoch 110 :
2022-10-03 18:26:00 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:26:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:26:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:26:00 [INFO ]  	   step  1 (lr=0.386686)                   81.29%                   0.6907
2022-10-03 18:26:00 [INFO ]  
2022-10-03 18:26:00 [INFO ]  Epoch:  110	Loss: 0.6445	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:02 [INFO ]  Epoch:  111	Loss: 0.6553	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:26:04 [INFO ]  Epoch:  112	Loss: 0.7259	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:26:06 [INFO ]  Epoch:  113	Loss: 0.6271	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:08 [INFO ]  Epoch:  114	Loss: 0.6810	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:10 [INFO ]  Epoch:  115	Loss: 0.6339	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:26:12 [INFO ]  Epoch:  116	Loss: 0.6357	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:14 [INFO ]  Epoch:  117	Loss: 0.6707	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:26:16 [INFO ]  Epoch:  118	Loss: 0.6628	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:26:18 [INFO ]  Epoch:  119	Loss: 0.6103	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:26:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 18:26:30 [INFO ]  
2022-10-03 18:26:30 [INFO ]  Begin of epoch 120 :
2022-10-03 18:26:33 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:26:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:26:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:26:33 [INFO ]  	   step  1 (lr=0.388378)                   81.68%                   0.6810
2022-10-03 18:26:33 [INFO ]  
2022-10-03 18:26:33 [INFO ]  Epoch:  120	Loss: 0.6122	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:26:35 [INFO ]  Epoch:  121	Loss: 0.6106	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:37 [INFO ]  Epoch:  122	Loss: 0.6392	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:26:39 [INFO ]  Epoch:  123	Loss: 0.5821	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:26:40 [INFO ]  Epoch:  124	Loss: 0.6805	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:26:42 [INFO ]  Epoch:  125	Loss: 0.7095	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:26:44 [INFO ]  Epoch:  126	Loss: 0.6534	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:26:46 [INFO ]  Epoch:  127	Loss: 0.6056	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:26:48 [INFO ]  Epoch:  128	Loss: 0.5639	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:26:50 [INFO ]  Epoch:  129	Loss: 0.6695	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:27:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 18:27:02 [INFO ]  
2022-10-03 18:27:02 [INFO ]  Begin of epoch 130 :
2022-10-03 18:27:06 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:27:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:27:06 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:27:06 [INFO ]  	   step  1 (lr=0.388727)                   81.28%                   0.6919
2022-10-03 18:27:06 [INFO ]  
2022-10-03 18:27:06 [INFO ]  Epoch:  130	Loss: 0.6587	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:27:08 [INFO ]  Epoch:  131	Loss: 0.6694	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:27:09 [INFO ]  Epoch:  132	Loss: 0.6285	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:27:11 [INFO ]  Epoch:  133	Loss: 0.5733	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:27:13 [INFO ]  Epoch:  134	Loss: 0.6659	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:27:15 [INFO ]  Epoch:  135	Loss: 0.6288	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:27:17 [INFO ]  Epoch:  136	Loss: 0.6164	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:27:19 [INFO ]  Epoch:  137	Loss: 0.5987	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:27:21 [INFO ]  Epoch:  138	Loss: 0.6927	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:27:23 [INFO ]  Epoch:  139	Loss: 0.6180	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:27:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 18:27:34 [INFO ]  
2022-10-03 18:27:34 [INFO ]  Begin of epoch 140 :
2022-10-03 18:27:38 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:27:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:27:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:27:38 [INFO ]  	   step  1 (lr=0.389442)                   81.43%                   0.6844
2022-10-03 18:27:38 [INFO ]  
2022-10-03 18:27:38 [INFO ]  Epoch:  140	Loss: 0.6024	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 18:27:40 [INFO ]  Epoch:  141	Loss: 0.6656	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:27:42 [INFO ]  Epoch:  142	Loss: 0.6529	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:27:44 [INFO ]  Epoch:  143	Loss: 0.6900	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:27:46 [INFO ]  Epoch:  144	Loss: 0.6784	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:27:48 [INFO ]  Epoch:  145	Loss: 0.6469	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:27:50 [INFO ]  Epoch:  146	Loss: 0.6104	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:27:52 [INFO ]  Epoch:  147	Loss: 0.6000	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:27:54 [INFO ]  Epoch:  148	Loss: 0.6486	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:27:56 [INFO ]  Epoch:  149	Loss: 0.5992	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 18:28:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 18:28:08 [INFO ]  
2022-10-03 18:28:08 [INFO ]  Begin of epoch 150 :
2022-10-03 18:28:11 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:28:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:28:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:28:11 [INFO ]  	   step  1 (lr=0.389162)                   81.45%                   0.6861
2022-10-03 18:28:11 [INFO ]  
2022-10-03 18:28:11 [INFO ]  Epoch:  150	Loss: 0.6203	Data Time: 0.24s	Train Time: 0.00s
2022-10-03 18:28:13 [INFO ]  Epoch:  151	Loss: 0.6274	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:28:15 [INFO ]  Epoch:  152	Loss: 0.7167	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:28:17 [INFO ]  Epoch:  153	Loss: 0.6833	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:28:19 [INFO ]  Epoch:  154	Loss: 0.6047	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:28:21 [INFO ]  Epoch:  155	Loss: 0.6852	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 18:28:23 [INFO ]  Epoch:  156	Loss: 0.6104	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:28:24 [INFO ]  Epoch:  157	Loss: 0.5678	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:28:26 [INFO ]  Epoch:  158	Loss: 0.6097	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:28:28 [INFO ]  Epoch:  159	Loss: 0.6248	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:28:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 18:28:40 [INFO ]  
2022-10-03 18:28:40 [INFO ]  Begin of epoch 160 :
2022-10-03 18:28:44 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:28:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:28:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:28:44 [INFO ]  	   step  1 (lr=0.389102)                   81.02%                   0.6913
2022-10-03 18:28:44 [INFO ]  
2022-10-03 18:28:44 [INFO ]  Epoch:  160	Loss: 0.6345	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:28:46 [INFO ]  Epoch:  161	Loss: 0.6592	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:28:48 [INFO ]  Epoch:  162	Loss: 0.6953	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:28:49 [INFO ]  Epoch:  163	Loss: 0.6322	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:28:51 [INFO ]  Epoch:  164	Loss: 0.5675	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:28:53 [INFO ]  Epoch:  165	Loss: 0.6162	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:28:55 [INFO ]  Epoch:  166	Loss: 0.6684	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 18:28:57 [INFO ]  Epoch:  167	Loss: 0.6380	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:28:59 [INFO ]  Epoch:  168	Loss: 0.6872	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:29:01 [INFO ]  Epoch:  169	Loss: 0.6352	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:29:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 18:29:13 [INFO ]  
2022-10-03 18:29:13 [INFO ]  Begin of epoch 170 :
2022-10-03 18:29:16 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:29:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:29:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:29:16 [INFO ]  	   step  1 (lr=0.389350)                   81.03%                   0.6948
2022-10-03 18:29:16 [INFO ]  
2022-10-03 18:29:16 [INFO ]  Epoch:  170	Loss: 0.6747	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:18 [INFO ]  Epoch:  171	Loss: 0.5932	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:29:20 [INFO ]  Epoch:  172	Loss: 0.6998	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:22 [INFO ]  Epoch:  173	Loss: 0.6311	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 18:29:24 [INFO ]  Epoch:  174	Loss: 0.6243	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:29:26 [INFO ]  Epoch:  175	Loss: 0.6069	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 18:29:28 [INFO ]  Epoch:  176	Loss: 0.6827	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:29:30 [INFO ]  Epoch:  177	Loss: 0.5883	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:31 [INFO ]  Epoch:  178	Loss: 0.6721	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:29:33 [INFO ]  Epoch:  179	Loss: 0.6655	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 18:29:45 [INFO ]  
2022-10-03 18:29:45 [INFO ]  Begin of epoch 180 :
2022-10-03 18:29:48 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:29:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:29:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:29:48 [INFO ]  	   step  1 (lr=0.390173)                   81.52%                   0.6812
2022-10-03 18:29:48 [INFO ]  
2022-10-03 18:29:48 [INFO ]  Epoch:  180	Loss: 0.5021	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:50 [INFO ]  Epoch:  181	Loss: 0.6265	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:29:52 [INFO ]  Epoch:  182	Loss: 0.5417	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:53 [INFO ]  Epoch:  183	Loss: 0.5884	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 18:29:55 [INFO ]  Epoch:  184	Loss: 0.6865	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 18:29:57 [INFO ]  Epoch:  185	Loss: 0.5597	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:29:59 [INFO ]  Epoch:  186	Loss: 0.5784	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:30:01 [INFO ]  Epoch:  187	Loss: 0.8085	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:30:03 [INFO ]  Epoch:  188	Loss: 0.6027	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 18:30:05 [INFO ]  Epoch:  189	Loss: 0.6534	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:30:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 18:30:17 [INFO ]  
2022-10-03 18:30:17 [INFO ]  Begin of epoch 190 :
2022-10-03 18:30:20 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:30:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:30:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:30:20 [INFO ]  	   step  1 (lr=0.390796)                   81.17%                   0.6913
2022-10-03 18:30:20 [INFO ]  
2022-10-03 18:30:20 [INFO ]  Epoch:  190	Loss: 0.6956	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 18:30:22 [INFO ]  Epoch:  191	Loss: 0.6555	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 18:30:24 [INFO ]  Epoch:  192	Loss: 0.6466	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 18:30:26 [INFO ]  Epoch:  193	Loss: 0.6535	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:30:28 [INFO ]  Epoch:  194	Loss: 0.5418	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 18:30:30 [INFO ]  Epoch:  195	Loss: 0.6828	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:30:32 [INFO ]  Epoch:  196	Loss: 0.6600	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 18:30:34 [INFO ]  Epoch:  197	Loss: 0.6540	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:30:36 [INFO ]  Epoch:  198	Loss: 0.6012	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 18:30:37 [INFO ]  Epoch:  199	Loss: 0.6376	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 18:30:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 18:30:49 [INFO ]  
2022-10-03 18:30:49 [INFO ]  Final evaluation for SVHN :
2022-10-03 18:30:52 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:30:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:30:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 18:30:52 [INFO ]  	   step  1 (lr=0.390818)                   81.23%                   0.6889
2022-10-03 18:30:52 [INFO ]  
2022-10-03 18:30:52 [INFO ]  
2022-10-03 18:30:52 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 18:30:55 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 18:30:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 18:30:55 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 18:30:55 [INFO ]  	   step  1 (lr=0.390818)                   19.18%                   4.8346
2022-10-03 18:30:55 [INFO ]  
2022-10-03 18:30:55 [INFO ]  CPU Time: 7.93 minutes
2022-10-03 18:35:01 [INFO ]  ======================================== 2022-10-03 18:35:01 ========================================
2022-10-03 18:35:01 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 18:35:01 [INFO ]  Options: 
2022-10-03 18:35:01 [INFO ]  	base_dir: null
2022-10-03 18:35:01 [INFO ]  	batch_size: 1024
2022-10-03 18:35:01 [INFO ]  	checkpoint_interval: 10
2022-10-03 18:35:01 [INFO ]  	dataset: SVHN
2022-10-03 18:35:01 [INFO ]  	dataset_labels:
2022-10-03 18:35:01 [INFO ]  	- 0
2022-10-03 18:35:01 [INFO ]  	- 1
2022-10-03 18:35:01 [INFO ]  	- 2
2022-10-03 18:35:01 [INFO ]  	- 3
2022-10-03 18:35:01 [INFO ]  	- 4
2022-10-03 18:35:01 [INFO ]  	- 5
2022-10-03 18:35:01 [INFO ]  	- 6
2022-10-03 18:35:01 [INFO ]  	- 7
2022-10-03 18:35:01 [INFO ]  	- 8
2022-10-03 18:35:01 [INFO ]  	- 9
2022-10-03 18:35:01 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 18:35:01 [INFO ]  	- !!python/tuple
2022-10-03 18:35:01 [INFO ]  	    - 0.4379104971885681
2022-10-03 18:35:01 [INFO ]  	    - 0.44398033618927
2022-10-03 18:35:01 [INFO ]  	    - 0.4729299545288086
2022-10-03 18:35:01 [INFO ]  	- !!python/tuple
2022-10-03 18:35:01 [INFO ]  	    - 0.19803012907505035
2022-10-03 18:35:01 [INFO ]  	    - 0.2010156363248825
2022-10-03 18:35:01 [INFO ]  	    - 0.19703614711761475
2022-10-03 18:35:01 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 18:35:01 [INFO ]  	decay_epochs: 50
2022-10-03 18:35:01 [INFO ]  	decay_factor: 0.1
2022-10-03 18:35:01 [INFO ]  	device_id: 0
2022-10-03 18:35:01 [INFO ]  	distill_epochs: 1
2022-10-03 18:35:01 [INFO ]  	distill_lr: 0.02
2022-10-03 18:35:01 [INFO ]  	distill_steps: 1
2022-10-03 18:35:01 [INFO ]  	epochs: 200
2022-10-03 18:35:01 [INFO ]  	expand_cls: false
2022-10-03 18:35:01 [INFO ]  	forgetting_dataset: null
2022-10-03 18:35:01 [INFO ]  	init: xavier
2022-10-03 18:35:01 [INFO ]  	init_param: 1.0
2022-10-03 18:35:01 [INFO ]  	input_size: 32
2022-10-03 18:35:01 [INFO ]  	ipc: 200
2022-10-03 18:35:01 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 18:35:01 [INFO ]  	log_interval: 100
2022-10-03 18:35:01 [INFO ]  	log_level: INFO
2022-10-03 18:35:01 [INFO ]  	lr: 0.01
2022-10-03 18:35:01 [INFO ]  	mode: distill_adapt
2022-10-03 18:35:01 [INFO ]  	nc: 3
2022-10-03 18:35:01 [INFO ]  	num_classes: 10
2022-10-03 18:35:01 [INFO ]  	num_workers: 8
2022-10-03 18:35:01 [INFO ]  	phase: train
2022-10-03 18:35:01 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 18:35:01 [INFO ]  	start_time: '2022-10-03 18:35:01'
2022-10-03 18:35:01 [INFO ]  	test_batch_size: 1024
2022-10-03 18:35:01 [INFO ]  	
2022-10-03 18:35:03 [INFO ]  train dataset size:	73257
2022-10-03 18:35:03 [INFO ]  test dataset size: 	26032
2022-10-03 18:35:03 [INFO ]  datasets built!
2022-10-03 18:35:03 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 21:02:33 [INFO ]  ======================================== 2022-10-03 21:02:33 ========================================
2022-10-03 21:02:33 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 21:02:33 [INFO ]  Options: 
2022-10-03 21:02:33 [INFO ]  	base_dir: null
2022-10-03 21:02:33 [INFO ]  	batch_size: 1024
2022-10-03 21:02:33 [INFO ]  	checkpoint_interval: 10
2022-10-03 21:02:33 [INFO ]  	dataset: SVHN
2022-10-03 21:02:33 [INFO ]  	dataset_labels:
2022-10-03 21:02:33 [INFO ]  	- 0
2022-10-03 21:02:33 [INFO ]  	- 1
2022-10-03 21:02:33 [INFO ]  	- 2
2022-10-03 21:02:33 [INFO ]  	- 3
2022-10-03 21:02:33 [INFO ]  	- 4
2022-10-03 21:02:33 [INFO ]  	- 5
2022-10-03 21:02:33 [INFO ]  	- 6
2022-10-03 21:02:33 [INFO ]  	- 7
2022-10-03 21:02:33 [INFO ]  	- 8
2022-10-03 21:02:33 [INFO ]  	- 9
2022-10-03 21:02:33 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 21:02:33 [INFO ]  	- !!python/tuple
2022-10-03 21:02:33 [INFO ]  	    - 0.4379104971885681
2022-10-03 21:02:33 [INFO ]  	    - 0.44398033618927
2022-10-03 21:02:33 [INFO ]  	    - 0.4729299545288086
2022-10-03 21:02:33 [INFO ]  	- !!python/tuple
2022-10-03 21:02:33 [INFO ]  	    - 0.19803012907505035
2022-10-03 21:02:33 [INFO ]  	    - 0.2010156363248825
2022-10-03 21:02:33 [INFO ]  	    - 0.19703614711761475
2022-10-03 21:02:33 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 21:02:33 [INFO ]  	decay_epochs: 50
2022-10-03 21:02:33 [INFO ]  	decay_factor: 0.1
2022-10-03 21:02:33 [INFO ]  	device_id: 0
2022-10-03 21:02:33 [INFO ]  	distill_epochs: 1
2022-10-03 21:02:33 [INFO ]  	distill_lr: 0.02
2022-10-03 21:02:33 [INFO ]  	distill_steps: 1
2022-10-03 21:02:33 [INFO ]  	epochs: 200
2022-10-03 21:02:33 [INFO ]  	expand_cls: false
2022-10-03 21:02:33 [INFO ]  	forgetting_dataset: null
2022-10-03 21:02:33 [INFO ]  	init: xavier
2022-10-03 21:02:33 [INFO ]  	init_param: 1.0
2022-10-03 21:02:33 [INFO ]  	input_size: 32
2022-10-03 21:02:33 [INFO ]  	ipc: 150
2022-10-03 21:02:33 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 21:02:33 [INFO ]  	log_interval: 100
2022-10-03 21:02:33 [INFO ]  	log_level: INFO
2022-10-03 21:02:33 [INFO ]  	lr: 0.01
2022-10-03 21:02:33 [INFO ]  	mode: distill_adapt
2022-10-03 21:02:33 [INFO ]  	nc: 3
2022-10-03 21:02:33 [INFO ]  	num_classes: 10
2022-10-03 21:02:33 [INFO ]  	num_workers: 8
2022-10-03 21:02:33 [INFO ]  	phase: train
2022-10-03 21:02:33 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 21:02:33 [INFO ]  	start_time: '2022-10-03 21:02:33'
2022-10-03 21:02:33 [INFO ]  	test_batch_size: 1024
2022-10-03 21:02:33 [INFO ]  	
2022-10-03 21:02:35 [INFO ]  train dataset size:	73257
2022-10-03 21:02:35 [INFO ]  test dataset size: 	26032
2022-10-03 21:02:35 [INFO ]  datasets built!
2022-10-03 21:02:35 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 21:03:36 [INFO ]  ======================================== 2022-10-03 21:03:36 ========================================
2022-10-03 21:03:36 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 21:03:36 [INFO ]  Options: 
2022-10-03 21:03:36 [INFO ]  	base_dir: null
2022-10-03 21:03:36 [INFO ]  	batch_size: 1024
2022-10-03 21:03:36 [INFO ]  	checkpoint_interval: 10
2022-10-03 21:03:36 [INFO ]  	dataset: SVHN
2022-10-03 21:03:36 [INFO ]  	dataset_labels:
2022-10-03 21:03:36 [INFO ]  	- 0
2022-10-03 21:03:36 [INFO ]  	- 1
2022-10-03 21:03:36 [INFO ]  	- 2
2022-10-03 21:03:36 [INFO ]  	- 3
2022-10-03 21:03:36 [INFO ]  	- 4
2022-10-03 21:03:36 [INFO ]  	- 5
2022-10-03 21:03:36 [INFO ]  	- 6
2022-10-03 21:03:36 [INFO ]  	- 7
2022-10-03 21:03:36 [INFO ]  	- 8
2022-10-03 21:03:36 [INFO ]  	- 9
2022-10-03 21:03:36 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 21:03:36 [INFO ]  	- !!python/tuple
2022-10-03 21:03:36 [INFO ]  	    - 0.4379104971885681
2022-10-03 21:03:36 [INFO ]  	    - 0.44398033618927
2022-10-03 21:03:36 [INFO ]  	    - 0.4729299545288086
2022-10-03 21:03:36 [INFO ]  	- !!python/tuple
2022-10-03 21:03:36 [INFO ]  	    - 0.19803012907505035
2022-10-03 21:03:36 [INFO ]  	    - 0.2010156363248825
2022-10-03 21:03:36 [INFO ]  	    - 0.19703614711761475
2022-10-03 21:03:36 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 21:03:36 [INFO ]  	decay_epochs: 50
2022-10-03 21:03:36 [INFO ]  	decay_factor: 0.1
2022-10-03 21:03:36 [INFO ]  	device_id: 0
2022-10-03 21:03:36 [INFO ]  	distill_epochs: 1
2022-10-03 21:03:36 [INFO ]  	distill_lr: 0.02
2022-10-03 21:03:36 [INFO ]  	distill_steps: 1
2022-10-03 21:03:36 [INFO ]  	epochs: 200
2022-10-03 21:03:36 [INFO ]  	expand_cls: false
2022-10-03 21:03:36 [INFO ]  	forgetting_dataset: null
2022-10-03 21:03:36 [INFO ]  	init: xavier
2022-10-03 21:03:36 [INFO ]  	init_param: 1.0
2022-10-03 21:03:36 [INFO ]  	input_size: 32
2022-10-03 21:03:36 [INFO ]  	ipc: 100
2022-10-03 21:03:36 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 21:03:36 [INFO ]  	log_interval: 100
2022-10-03 21:03:36 [INFO ]  	log_level: INFO
2022-10-03 21:03:36 [INFO ]  	lr: 0.01
2022-10-03 21:03:36 [INFO ]  	mode: distill_adapt
2022-10-03 21:03:36 [INFO ]  	nc: 3
2022-10-03 21:03:36 [INFO ]  	num_classes: 10
2022-10-03 21:03:36 [INFO ]  	num_workers: 8
2022-10-03 21:03:36 [INFO ]  	phase: train
2022-10-03 21:03:36 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 21:03:36 [INFO ]  	start_time: '2022-10-03 21:03:36'
2022-10-03 21:03:36 [INFO ]  	test_batch_size: 1024
2022-10-03 21:03:36 [INFO ]  	
2022-10-03 21:03:38 [INFO ]  train dataset size:	73257
2022-10-03 21:03:38 [INFO ]  test dataset size: 	26032
2022-10-03 21:03:38 [INFO ]  datasets built!
2022-10-03 21:03:38 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 21:06:37 [INFO ]  ======================================== 2022-10-03 21:06:37 ========================================
2022-10-03 21:06:37 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-03 21:06:37 [INFO ]  Options: 
2022-10-03 21:06:37 [INFO ]  	base_dir: null
2022-10-03 21:06:37 [INFO ]  	batch_size: 1024
2022-10-03 21:06:37 [INFO ]  	checkpoint_interval: 10
2022-10-03 21:06:37 [INFO ]  	dataset: SVHN
2022-10-03 21:06:37 [INFO ]  	dataset_labels:
2022-10-03 21:06:37 [INFO ]  	- 0
2022-10-03 21:06:37 [INFO ]  	- 1
2022-10-03 21:06:37 [INFO ]  	- 2
2022-10-03 21:06:37 [INFO ]  	- 3
2022-10-03 21:06:37 [INFO ]  	- 4
2022-10-03 21:06:37 [INFO ]  	- 5
2022-10-03 21:06:37 [INFO ]  	- 6
2022-10-03 21:06:37 [INFO ]  	- 7
2022-10-03 21:06:37 [INFO ]  	- 8
2022-10-03 21:06:37 [INFO ]  	- 9
2022-10-03 21:06:37 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-03 21:06:37 [INFO ]  	- !!python/tuple
2022-10-03 21:06:37 [INFO ]  	    - 0.4379104971885681
2022-10-03 21:06:37 [INFO ]  	    - 0.44398033618927
2022-10-03 21:06:37 [INFO ]  	    - 0.4729299545288086
2022-10-03 21:06:37 [INFO ]  	- !!python/tuple
2022-10-03 21:06:37 [INFO ]  	    - 0.19803012907505035
2022-10-03 21:06:37 [INFO ]  	    - 0.2010156363248825
2022-10-03 21:06:37 [INFO ]  	    - 0.19703614711761475
2022-10-03 21:06:37 [INFO ]  	dataset_root: ./data/svhn
2022-10-03 21:06:37 [INFO ]  	decay_epochs: 50
2022-10-03 21:06:37 [INFO ]  	decay_factor: 0.1
2022-10-03 21:06:37 [INFO ]  	device_id: 0
2022-10-03 21:06:37 [INFO ]  	distill_epochs: 1
2022-10-03 21:06:37 [INFO ]  	distill_lr: 0.02
2022-10-03 21:06:37 [INFO ]  	distill_steps: 1
2022-10-03 21:06:37 [INFO ]  	epochs: 200
2022-10-03 21:06:37 [INFO ]  	expand_cls: false
2022-10-03 21:06:37 [INFO ]  	forgetting_dataset: null
2022-10-03 21:06:37 [INFO ]  	init: xavier
2022-10-03 21:06:37 [INFO ]  	init_param: 1.0
2022-10-03 21:06:37 [INFO ]  	input_size: 32
2022-10-03 21:06:37 [INFO ]  	ipc: 200
2022-10-03 21:06:37 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-03 21:06:37 [INFO ]  	log_interval: 100
2022-10-03 21:06:37 [INFO ]  	log_level: INFO
2022-10-03 21:06:37 [INFO ]  	lr: 0.01
2022-10-03 21:06:37 [INFO ]  	mode: distill_adapt
2022-10-03 21:06:37 [INFO ]  	nc: 3
2022-10-03 21:06:37 [INFO ]  	num_classes: 10
2022-10-03 21:06:37 [INFO ]  	num_workers: 8
2022-10-03 21:06:37 [INFO ]  	phase: train
2022-10-03 21:06:37 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-03 21:06:37 [INFO ]  	start_time: '2022-10-03 21:06:37'
2022-10-03 21:06:37 [INFO ]  	test_batch_size: 1024
2022-10-03 21:06:37 [INFO ]  	
2022-10-03 21:06:39 [INFO ]  train dataset size:	73257
2022-10-03 21:06:39 [INFO ]  test dataset size: 	26032
2022-10-03 21:06:39 [INFO ]  datasets built!
2022-10-03 21:06:39 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-03 21:06:41 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-03 21:06:41 [INFO ]  
2022-10-03 21:06:41 [INFO ]  Begin of epoch 0 :
2022-10-03 21:06:44 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:06:44 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:06:44 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:06:44 [INFO ]  	   step  1 (lr=0.020000)                    7.15%                   8.7340
2022-10-03 21:06:44 [INFO ]  
2022-10-03 21:06:44 [INFO ]  Epoch:    0	Loss: 9.1931	Data Time: 0.41s	Train Time: 0.13s
2022-10-03 21:06:46 [INFO ]  Epoch:    1	Loss: 2.9601	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:06:48 [INFO ]  Epoch:    2	Loss: 2.4564	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:06:50 [INFO ]  Epoch:    3	Loss: 2.2514	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:06:52 [INFO ]  Epoch:    4	Loss: 2.2261	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:06:54 [INFO ]  Epoch:    5	Loss: 2.1899	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:06:56 [INFO ]  Epoch:    6	Loss: 2.1367	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 21:06:59 [INFO ]  Epoch:    7	Loss: 2.0828	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:01 [INFO ]  Epoch:    8	Loss: 2.0004	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:07:03 [INFO ]  Epoch:    9	Loss: 1.9402	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:07:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-03 21:07:05 [INFO ]  
2022-10-03 21:07:05 [INFO ]  Begin of epoch 10 :
2022-10-03 21:07:08 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:07:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:07:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:07:08 [INFO ]  	   step  1 (lr=0.078136)                   43.70%                   1.7970
2022-10-03 21:07:08 [INFO ]  
2022-10-03 21:07:08 [INFO ]  Epoch:   10	Loss: 1.8088	Data Time: 0.21s	Train Time: 0.00s
2022-10-03 21:07:10 [INFO ]  Epoch:   11	Loss: 1.6677	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:07:13 [INFO ]  Epoch:   12	Loss: 1.5918	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:07:15 [INFO ]  Epoch:   13	Loss: 1.3806	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:07:17 [INFO ]  Epoch:   14	Loss: 1.2862	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:19 [INFO ]  Epoch:   15	Loss: 1.3703	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:21 [INFO ]  Epoch:   16	Loss: 1.1369	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:07:23 [INFO ]  Epoch:   17	Loss: 1.0728	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:07:25 [INFO ]  Epoch:   18	Loss: 1.0770	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:07:27 [INFO ]  Epoch:   19	Loss: 1.1242	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-03 21:07:30 [INFO ]  
2022-10-03 21:07:30 [INFO ]  Begin of epoch 20 :
2022-10-03 21:07:33 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:07:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:07:33 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:07:33 [INFO ]  	   step  1 (lr=0.263977)                   70.32%                   1.0350
2022-10-03 21:07:33 [INFO ]  
2022-10-03 21:07:33 [INFO ]  Epoch:   20	Loss: 0.9557	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:35 [INFO ]  Epoch:   21	Loss: 0.9262	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:37 [INFO ]  Epoch:   22	Loss: 0.9523	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:07:39 [INFO ]  Epoch:   23	Loss: 0.8814	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:41 [INFO ]  Epoch:   24	Loss: 0.8386	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:07:43 [INFO ]  Epoch:   25	Loss: 0.9689	Data Time: 0.15s	Train Time: 0.01s
2022-10-03 21:07:46 [INFO ]  Epoch:   26	Loss: 0.8156	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:07:48 [INFO ]  Epoch:   27	Loss: 0.9076	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:07:50 [INFO ]  Epoch:   28	Loss: 0.7887	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:07:52 [INFO ]  Epoch:   29	Loss: 0.8849	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:07:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-03 21:07:54 [INFO ]  
2022-10-03 21:07:54 [INFO ]  Begin of epoch 30 :
2022-10-03 21:07:57 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:07:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:07:57 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:07:57 [INFO ]  	   step  1 (lr=0.344849)                   73.25%                   0.9401
2022-10-03 21:07:57 [INFO ]  
2022-10-03 21:07:57 [INFO ]  Epoch:   30	Loss: 0.9451	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:00 [INFO ]  Epoch:   31	Loss: 0.7615	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:08:02 [INFO ]  Epoch:   32	Loss: 0.8323	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:08:04 [INFO ]  Epoch:   33	Loss: 0.7914	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:06 [INFO ]  Epoch:   34	Loss: 0.7064	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:08 [INFO ]  Epoch:   35	Loss: 0.9514	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:08:10 [INFO ]  Epoch:   36	Loss: 0.8457	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:12 [INFO ]  Epoch:   37	Loss: 0.7360	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:08:14 [INFO ]  Epoch:   38	Loss: 0.6617	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:08:17 [INFO ]  Epoch:   39	Loss: 0.8647	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:19 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0040/results.pth
2022-10-03 21:08:19 [INFO ]  
2022-10-03 21:08:19 [INFO ]  Begin of epoch 40 :
2022-10-03 21:08:22 [INFO ]  Begin of epoch 40 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:08:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:08:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:08:22 [INFO ]  	   step  1 (lr=0.374456)                   79.20%                   0.7545
2022-10-03 21:08:22 [INFO ]  
2022-10-03 21:08:22 [INFO ]  Epoch:   40	Loss: 0.7087	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:08:24 [INFO ]  Epoch:   41	Loss: 0.6711	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:08:27 [INFO ]  Epoch:   42	Loss: 0.6847	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:08:29 [INFO ]  Epoch:   43	Loss: 0.6968	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:08:31 [INFO ]  Epoch:   44	Loss: 0.7016	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:33 [INFO ]  Epoch:   45	Loss: 0.6296	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:08:35 [INFO ]  Epoch:   46	Loss: 0.6769	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:08:37 [INFO ]  Epoch:   47	Loss: 0.7210	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:39 [INFO ]  Epoch:   48	Loss: 0.6489	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:41 [INFO ]  Epoch:   49	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0050/results.pth
2022-10-03 21:08:44 [INFO ]  
2022-10-03 21:08:44 [INFO ]  Begin of epoch 50 :
2022-10-03 21:08:47 [INFO ]  Begin of epoch 50 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:08:47 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:08:47 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:08:47 [INFO ]  	   step  1 (lr=0.396022)                   81.72%                   0.6823
2022-10-03 21:08:47 [INFO ]  
2022-10-03 21:08:47 [INFO ]  Epoch:   50	Loss: 0.6449	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:49 [INFO ]  Epoch:   51	Loss: 0.6466	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:51 [INFO ]  Epoch:   52	Loss: 0.5579	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:08:53 [INFO ]  Epoch:   53	Loss: 0.5854	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:08:55 [INFO ]  Epoch:   54	Loss: 0.5677	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:08:58 [INFO ]  Epoch:   55	Loss: 0.6649	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:00 [INFO ]  Epoch:   56	Loss: 0.5643	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:02 [INFO ]  Epoch:   57	Loss: 0.6292	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:04 [INFO ]  Epoch:   58	Loss: 0.6062	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:06 [INFO ]  Epoch:   59	Loss: 0.5841	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:08 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0060/results.pth
2022-10-03 21:09:08 [INFO ]  
2022-10-03 21:09:08 [INFO ]  Begin of epoch 60 :
2022-10-03 21:09:12 [INFO ]  Begin of epoch 60 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:09:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:09:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:09:12 [INFO ]  	   step  1 (lr=0.409307)                   82.14%                   0.6675
2022-10-03 21:09:12 [INFO ]  
2022-10-03 21:09:12 [INFO ]  Epoch:   60	Loss: 0.6539	Data Time: 0.23s	Train Time: 0.00s
2022-10-03 21:09:14 [INFO ]  Epoch:   61	Loss: 0.6043	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:16 [INFO ]  Epoch:   62	Loss: 0.5573	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:18 [INFO ]  Epoch:   63	Loss: 0.5801	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:20 [INFO ]  Epoch:   64	Loss: 0.5536	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:09:22 [INFO ]  Epoch:   65	Loss: 0.6156	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:24 [INFO ]  Epoch:   66	Loss: 0.6579	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:09:27 [INFO ]  Epoch:   67	Loss: 0.6879	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:29 [INFO ]  Epoch:   68	Loss: 0.6053	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:31 [INFO ]  Epoch:   69	Loss: 0.5484	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:09:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0070/results.pth
2022-10-03 21:09:33 [INFO ]  
2022-10-03 21:09:33 [INFO ]  Begin of epoch 70 :
2022-10-03 21:09:37 [INFO ]  Begin of epoch 70 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:09:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:09:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:09:37 [INFO ]  	   step  1 (lr=0.422532)                   81.73%                   0.6768
2022-10-03 21:09:37 [INFO ]  
2022-10-03 21:09:37 [INFO ]  Epoch:   70	Loss: 0.5843	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:09:39 [INFO ]  Epoch:   71	Loss: 0.6172	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:09:41 [INFO ]  Epoch:   72	Loss: 0.6426	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:09:43 [INFO ]  Epoch:   73	Loss: 0.5045	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:09:45 [INFO ]  Epoch:   74	Loss: 0.6186	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:09:48 [INFO ]  Epoch:   75	Loss: 0.5879	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:09:50 [INFO ]  Epoch:   76	Loss: 0.5991	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:52 [INFO ]  Epoch:   77	Loss: 0.6458	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:09:54 [INFO ]  Epoch:   78	Loss: 0.5454	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:09:56 [INFO ]  Epoch:   79	Loss: 0.6350	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:09:58 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0080/results.pth
2022-10-03 21:09:58 [INFO ]  
2022-10-03 21:09:58 [INFO ]  Begin of epoch 80 :
2022-10-03 21:10:02 [INFO ]  Begin of epoch 80 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:10:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:10:02 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:10:02 [INFO ]  	   step  1 (lr=0.434369)                   82.42%                   0.6615
2022-10-03 21:10:02 [INFO ]  
2022-10-03 21:10:02 [INFO ]  Epoch:   80	Loss: 0.5258	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 21:10:04 [INFO ]  Epoch:   81	Loss: 0.5937	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:10:06 [INFO ]  Epoch:   82	Loss: 0.6295	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 21:10:08 [INFO ]  Epoch:   83	Loss: 0.6507	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:10:11 [INFO ]  Epoch:   84	Loss: 0.5472	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:10:13 [INFO ]  Epoch:   85	Loss: 0.5092	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:10:15 [INFO ]  Epoch:   86	Loss: 0.5556	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:17 [INFO ]  Epoch:   87	Loss: 0.5284	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:10:19 [INFO ]  Epoch:   88	Loss: 0.5992	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:21 [INFO ]  Epoch:   89	Loss: 0.6157	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0090/results.pth
2022-10-03 21:10:24 [INFO ]  
2022-10-03 21:10:24 [INFO ]  Begin of epoch 90 :
2022-10-03 21:10:27 [INFO ]  Begin of epoch 90 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:10:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:10:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:10:27 [INFO ]  	   step  1 (lr=0.446253)                   82.56%                   0.6533
2022-10-03 21:10:27 [INFO ]  
2022-10-03 21:10:27 [INFO ]  Epoch:   90	Loss: 0.5944	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:29 [INFO ]  Epoch:   91	Loss: 0.5563	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:10:31 [INFO ]  Epoch:   92	Loss: 0.5725	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:33 [INFO ]  Epoch:   93	Loss: 0.5169	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:36 [INFO ]  Epoch:   94	Loss: 0.5802	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:10:38 [INFO ]  Epoch:   95	Loss: 0.5774	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:10:40 [INFO ]  Epoch:   96	Loss: 0.5550	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:10:42 [INFO ]  Epoch:   97	Loss: 0.6224	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:44 [INFO ]  Epoch:   98	Loss: 0.6155	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:10:47 [INFO ]  Epoch:   99	Loss: 0.6265	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:10:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0100/results.pth
2022-10-03 21:10:49 [INFO ]  
2022-10-03 21:10:49 [INFO ]  Begin of epoch 100 :
2022-10-03 21:10:52 [INFO ]  Begin of epoch 100 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:10:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:10:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:10:52 [INFO ]  	   step  1 (lr=0.459563)                   82.78%                   0.6482
2022-10-03 21:10:52 [INFO ]  
2022-10-03 21:10:52 [INFO ]  Epoch:  100	Loss: 0.4969	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 21:10:55 [INFO ]  Epoch:  101	Loss: 0.5551	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:10:57 [INFO ]  Epoch:  102	Loss: 0.5336	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:10:59 [INFO ]  Epoch:  103	Loss: 0.5227	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:11:01 [INFO ]  Epoch:  104	Loss: 0.4850	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:03 [INFO ]  Epoch:  105	Loss: 0.5913	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:11:05 [INFO ]  Epoch:  106	Loss: 0.5944	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:08 [INFO ]  Epoch:  107	Loss: 0.6389	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:11:10 [INFO ]  Epoch:  108	Loss: 0.6155	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:12 [INFO ]  Epoch:  109	Loss: 0.6346	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0110/results.pth
2022-10-03 21:11:14 [INFO ]  
2022-10-03 21:11:14 [INFO ]  Begin of epoch 110 :
2022-10-03 21:11:18 [INFO ]  Begin of epoch 110 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:11:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:11:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:11:18 [INFO ]  	   step  1 (lr=0.461578)                   82.87%                   0.6444
2022-10-03 21:11:18 [INFO ]  
2022-10-03 21:11:18 [INFO ]  Epoch:  110	Loss: 0.5314	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:20 [INFO ]  Epoch:  111	Loss: 0.5815	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:11:22 [INFO ]  Epoch:  112	Loss: 0.5278	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:24 [INFO ]  Epoch:  113	Loss: 0.5109	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:26 [INFO ]  Epoch:  114	Loss: 0.5287	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:11:29 [INFO ]  Epoch:  115	Loss: 0.5537	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:11:31 [INFO ]  Epoch:  116	Loss: 0.5324	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:11:33 [INFO ]  Epoch:  117	Loss: 0.5359	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:11:35 [INFO ]  Epoch:  118	Loss: 0.5522	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:11:37 [INFO ]  Epoch:  119	Loss: 0.5770	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:11:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0120/results.pth
2022-10-03 21:11:40 [INFO ]  
2022-10-03 21:11:40 [INFO ]  Begin of epoch 120 :
2022-10-03 21:11:43 [INFO ]  Begin of epoch 120 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:11:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:11:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:11:43 [INFO ]  	   step  1 (lr=0.461895)                   82.87%                   0.6445
2022-10-03 21:11:43 [INFO ]  
2022-10-03 21:11:43 [INFO ]  Epoch:  120	Loss: 0.5343	Data Time: 0.16s	Train Time: 0.00s
2022-10-03 21:11:45 [INFO ]  Epoch:  121	Loss: 0.5663	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:11:47 [INFO ]  Epoch:  122	Loss: 0.5399	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:11:50 [INFO ]  Epoch:  123	Loss: 0.5412	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:11:52 [INFO ]  Epoch:  124	Loss: 0.6236	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:11:54 [INFO ]  Epoch:  125	Loss: 0.5997	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:11:56 [INFO ]  Epoch:  126	Loss: 0.5176	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:11:58 [INFO ]  Epoch:  127	Loss: 0.6137	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:12:01 [INFO ]  Epoch:  128	Loss: 0.5289	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:03 [INFO ]  Epoch:  129	Loss: 0.5993	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:12:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0130/results.pth
2022-10-03 21:12:05 [INFO ]  
2022-10-03 21:12:05 [INFO ]  Begin of epoch 130 :
2022-10-03 21:12:09 [INFO ]  Begin of epoch 130 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:12:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:12:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:12:09 [INFO ]  	   step  1 (lr=0.463825)                   82.84%                   0.6467
2022-10-03 21:12:09 [INFO ]  
2022-10-03 21:12:09 [INFO ]  Epoch:  130	Loss: 0.5922	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:12:11 [INFO ]  Epoch:  131	Loss: 0.5605	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:12:13 [INFO ]  Epoch:  132	Loss: 0.5460	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:12:15 [INFO ]  Epoch:  133	Loss: 0.5512	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:12:17 [INFO ]  Epoch:  134	Loss: 0.5403	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:19 [INFO ]  Epoch:  135	Loss: 0.6026	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:12:22 [INFO ]  Epoch:  136	Loss: 0.5239	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:24 [INFO ]  Epoch:  137	Loss: 0.5466	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 21:12:26 [INFO ]  Epoch:  138	Loss: 0.5129	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:12:28 [INFO ]  Epoch:  139	Loss: 0.5079	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0140/results.pth
2022-10-03 21:12:31 [INFO ]  
2022-10-03 21:12:31 [INFO ]  Begin of epoch 140 :
2022-10-03 21:12:34 [INFO ]  Begin of epoch 140 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:12:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:12:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:12:34 [INFO ]  	   step  1 (lr=0.465437)                   82.88%                   0.6477
2022-10-03 21:12:34 [INFO ]  
2022-10-03 21:12:34 [INFO ]  Epoch:  140	Loss: 0.5511	Data Time: 0.18s	Train Time: 0.00s
2022-10-03 21:12:36 [INFO ]  Epoch:  141	Loss: 0.5222	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:38 [INFO ]  Epoch:  142	Loss: 0.5285	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:12:41 [INFO ]  Epoch:  143	Loss: 0.5343	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:12:43 [INFO ]  Epoch:  144	Loss: 0.5426	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:12:45 [INFO ]  Epoch:  145	Loss: 0.5002	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:12:47 [INFO ]  Epoch:  146	Loss: 0.5774	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:49 [INFO ]  Epoch:  147	Loss: 0.5200	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:12:52 [INFO ]  Epoch:  148	Loss: 0.6911	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:54 [INFO ]  Epoch:  149	Loss: 0.5220	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:12:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0150/results.pth
2022-10-03 21:12:56 [INFO ]  
2022-10-03 21:12:56 [INFO ]  Begin of epoch 150 :
2022-10-03 21:13:00 [INFO ]  Begin of epoch 150 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:13:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:13:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:13:00 [INFO ]  	   step  1 (lr=0.467400)                   83.03%                   0.6434
2022-10-03 21:13:00 [INFO ]  
2022-10-03 21:13:00 [INFO ]  Epoch:  150	Loss: 0.5678	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:02 [INFO ]  Epoch:  151	Loss: 0.5555	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:13:04 [INFO ]  Epoch:  152	Loss: 0.5308	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:13:06 [INFO ]  Epoch:  153	Loss: 0.5842	Data Time: 0.26s	Train Time: 0.01s
2022-10-03 21:13:09 [INFO ]  Epoch:  154	Loss: 0.5351	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:13:11 [INFO ]  Epoch:  155	Loss: 0.5935	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:13 [INFO ]  Epoch:  156	Loss: 0.6083	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:13:15 [INFO ]  Epoch:  157	Loss: 0.4661	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:13:18 [INFO ]  Epoch:  158	Loss: 0.5019	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:13:20 [INFO ]  Epoch:  159	Loss: 0.5929	Data Time: 0.23s	Train Time: 0.01s
2022-10-03 21:13:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0160/results.pth
2022-10-03 21:13:22 [INFO ]  
2022-10-03 21:13:22 [INFO ]  Begin of epoch 160 :
2022-10-03 21:13:26 [INFO ]  Begin of epoch 160 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:13:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:13:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:13:26 [INFO ]  	   step  1 (lr=0.467638)                   82.87%                   0.6470
2022-10-03 21:13:26 [INFO ]  
2022-10-03 21:13:26 [INFO ]  Epoch:  160	Loss: 0.5437	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:13:28 [INFO ]  Epoch:  161	Loss: 0.5456	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:13:30 [INFO ]  Epoch:  162	Loss: 0.4267	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:13:32 [INFO ]  Epoch:  163	Loss: 0.4724	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:34 [INFO ]  Epoch:  164	Loss: 0.6050	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:37 [INFO ]  Epoch:  165	Loss: 0.5316	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:13:39 [INFO ]  Epoch:  166	Loss: 0.5870	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:41 [INFO ]  Epoch:  167	Loss: 0.5523	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:13:43 [INFO ]  Epoch:  168	Loss: 0.5438	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:13:45 [INFO ]  Epoch:  169	Loss: 0.5539	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0170/results.pth
2022-10-03 21:13:48 [INFO ]  
2022-10-03 21:13:48 [INFO ]  Begin of epoch 170 :
2022-10-03 21:13:51 [INFO ]  Begin of epoch 170 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:13:51 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:13:51 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:13:51 [INFO ]  	   step  1 (lr=0.467887)                   82.77%                   0.6501
2022-10-03 21:13:51 [INFO ]  
2022-10-03 21:13:51 [INFO ]  Epoch:  170	Loss: 0.5542	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:13:54 [INFO ]  Epoch:  171	Loss: 0.5770	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:13:56 [INFO ]  Epoch:  172	Loss: 0.6383	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:13:58 [INFO ]  Epoch:  173	Loss: 0.4799	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:14:00 [INFO ]  Epoch:  174	Loss: 0.5255	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:02 [INFO ]  Epoch:  175	Loss: 0.6000	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:14:05 [INFO ]  Epoch:  176	Loss: 0.4847	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:07 [INFO ]  Epoch:  177	Loss: 0.5339	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:09 [INFO ]  Epoch:  178	Loss: 0.5518	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:11 [INFO ]  Epoch:  179	Loss: 0.5795	Data Time: 0.21s	Train Time: 0.01s
2022-10-03 21:14:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0180/results.pth
2022-10-03 21:14:14 [INFO ]  
2022-10-03 21:14:14 [INFO ]  Begin of epoch 180 :
2022-10-03 21:14:17 [INFO ]  Begin of epoch 180 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:14:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:14:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:14:17 [INFO ]  	   step  1 (lr=0.468061)                   82.88%                   0.6460
2022-10-03 21:14:17 [INFO ]  
2022-10-03 21:14:17 [INFO ]  Epoch:  180	Loss: 0.6086	Data Time: 0.25s	Train Time: 0.00s
2022-10-03 21:14:19 [INFO ]  Epoch:  181	Loss: 0.5972	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:14:22 [INFO ]  Epoch:  182	Loss: 0.6270	Data Time: 0.22s	Train Time: 0.01s
2022-10-03 21:14:24 [INFO ]  Epoch:  183	Loss: 0.5508	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:14:26 [INFO ]  Epoch:  184	Loss: 0.5334	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:28 [INFO ]  Epoch:  185	Loss: 0.5234	Data Time: 0.18s	Train Time: 0.01s
2022-10-03 21:14:31 [INFO ]  Epoch:  186	Loss: 0.6307	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:14:33 [INFO ]  Epoch:  187	Loss: 0.5481	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:35 [INFO ]  Epoch:  188	Loss: 0.6166	Data Time: 0.19s	Train Time: 0.01s
2022-10-03 21:14:37 [INFO ]  Epoch:  189	Loss: 0.5403	Data Time: 0.20s	Train Time: 0.01s
2022-10-03 21:14:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0190/results.pth
2022-10-03 21:14:40 [INFO ]  
2022-10-03 21:14:40 [INFO ]  Begin of epoch 190 :
2022-10-03 21:14:43 [INFO ]  Begin of epoch 190 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:14:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:14:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:14:43 [INFO ]  	   step  1 (lr=0.468246)                   82.99%                   0.6419
2022-10-03 21:14:43 [INFO ]  
2022-10-03 21:14:43 [INFO ]  Epoch:  190	Loss: 0.6194	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:45 [INFO ]  Epoch:  191	Loss: 0.5685	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:14:47 [INFO ]  Epoch:  192	Loss: 0.5453	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:49 [INFO ]  Epoch:  193	Loss: 0.5937	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:52 [INFO ]  Epoch:  194	Loss: 0.5604	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:14:54 [INFO ]  Epoch:  195	Loss: 0.6215	Data Time: 0.17s	Train Time: 0.01s
2022-10-03 21:14:56 [INFO ]  Epoch:  196	Loss: 0.6566	Data Time: 0.25s	Train Time: 0.01s
2022-10-03 21:14:58 [INFO ]  Epoch:  197	Loss: 0.5811	Data Time: 0.16s	Train Time: 0.01s
2022-10-03 21:15:01 [INFO ]  Epoch:  198	Loss: 0.5444	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:15:03 [INFO ]  Epoch:  199	Loss: 0.6039	Data Time: 0.24s	Train Time: 0.01s
2022-10-03 21:15:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-03 21:15:05 [INFO ]  
2022-10-03 21:15:05 [INFO ]  Final evaluation for SVHN :
2022-10-03 21:15:08 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:15:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:15:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-03 21:15:08 [INFO ]  	   step  1 (lr=0.468205)                   83.02%                   0.6431
2022-10-03 21:15:08 [INFO ]  
2022-10-03 21:15:08 [INFO ]  
2022-10-03 21:15:08 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-03 21:15:11 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-03 21:15:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-03 21:15:11 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-03 21:15:11 [INFO ]  	   step  1 (lr=0.468205)                   14.43%                   5.7078
2022-10-03 21:15:11 [INFO ]  
2022-10-03 21:15:11 [INFO ]  CPU Time: 7.38 minutes
2022-10-04 08:00:45 [INFO ]  ======================================== 2022-10-04 08:00:45 ========================================
2022-10-04 08:00:45 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 08:00:45 [INFO ]  Options: 
2022-10-04 08:00:45 [INFO ]  	base_dir: null
2022-10-04 08:00:45 [INFO ]  	batch_size: 1024
2022-10-04 08:00:45 [INFO ]  	checkpoint_interval: 10
2022-10-04 08:00:45 [INFO ]  	dataset: SVHN
2022-10-04 08:00:45 [INFO ]  	dataset_labels:
2022-10-04 08:00:45 [INFO ]  	- 0
2022-10-04 08:00:45 [INFO ]  	- 1
2022-10-04 08:00:45 [INFO ]  	- 2
2022-10-04 08:00:45 [INFO ]  	- 3
2022-10-04 08:00:45 [INFO ]  	- 4
2022-10-04 08:00:45 [INFO ]  	- 5
2022-10-04 08:00:45 [INFO ]  	- 6
2022-10-04 08:00:45 [INFO ]  	- 7
2022-10-04 08:00:45 [INFO ]  	- 8
2022-10-04 08:00:45 [INFO ]  	- 9
2022-10-04 08:00:45 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 08:00:45 [INFO ]  	- !!python/tuple
2022-10-04 08:00:45 [INFO ]  	    - 0.4379104971885681
2022-10-04 08:00:45 [INFO ]  	    - 0.44398033618927
2022-10-04 08:00:45 [INFO ]  	    - 0.4729299545288086
2022-10-04 08:00:45 [INFO ]  	- !!python/tuple
2022-10-04 08:00:45 [INFO ]  	    - 0.19803012907505035
2022-10-04 08:00:45 [INFO ]  	    - 0.2010156363248825
2022-10-04 08:00:45 [INFO ]  	    - 0.19703614711761475
2022-10-04 08:00:45 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 08:00:45 [INFO ]  	decay_epochs: 50
2022-10-04 08:00:45 [INFO ]  	decay_factor: 0.1
2022-10-04 08:00:45 [INFO ]  	device_id: 0
2022-10-04 08:00:45 [INFO ]  	distill_epochs: 1
2022-10-04 08:00:45 [INFO ]  	distill_lr: 0.02
2022-10-04 08:00:45 [INFO ]  	distill_steps: 1
2022-10-04 08:00:45 [INFO ]  	epochs: 200
2022-10-04 08:00:45 [INFO ]  	expand_cls: false
2022-10-04 08:00:45 [INFO ]  	forgetting_dataset: null
2022-10-04 08:00:45 [INFO ]  	init: xavier
2022-10-04 08:00:45 [INFO ]  	init_param: 1.0
2022-10-04 08:00:45 [INFO ]  	input_size: 32
2022-10-04 08:00:45 [INFO ]  	ipc: 1
2022-10-04 08:00:45 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 08:00:45 [INFO ]  	log_interval: 100
2022-10-04 08:00:45 [INFO ]  	log_level: INFO
2022-10-04 08:00:45 [INFO ]  	lr: 0.01
2022-10-04 08:00:45 [INFO ]  	mode: distill_adapt
2022-10-04 08:00:45 [INFO ]  	nc: 3
2022-10-04 08:00:45 [INFO ]  	num_classes: 10
2022-10-04 08:00:45 [INFO ]  	num_workers: 8
2022-10-04 08:00:45 [INFO ]  	phase: train
2022-10-04 08:00:45 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 08:00:45 [INFO ]  	start_time: '2022-10-04 08:00:45'
2022-10-04 08:00:45 [INFO ]  	test_batch_size: 1024
2022-10-04 08:00:45 [INFO ]  	
2022-10-04 08:00:48 [INFO ]  train dataset size:	73257
2022-10-04 08:00:48 [INFO ]  test dataset size: 	26032
2022-10-04 08:00:48 [INFO ]  datasets built!
2022-10-04 08:00:48 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 08:00:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 08:00:49 [INFO ]  
2022-10-04 08:00:49 [INFO ]  Begin of epoch 0 :
2022-10-04 08:00:53 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:00:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:00:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:00:53 [INFO ]  	   step  1 (lr=0.020000)                    6.76%                   9.2562
2022-10-04 08:00:53 [INFO ]  
2022-10-04 08:00:53 [INFO ]  Epoch:    0	Loss: 9.1668	Data Time: 0.40s	Train Time: 0.03s
2022-10-04 08:00:54 [INFO ]  Epoch:    1	Loss: 3.4313	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 08:00:56 [INFO ]  Epoch:    2	Loss: 3.0729	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:00:58 [INFO ]  Epoch:    3	Loss: 2.4894	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:01:00 [INFO ]  Epoch:    4	Loss: 2.3375	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:01:01 [INFO ]  Epoch:    5	Loss: 2.2401	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:01:03 [INFO ]  Epoch:    6	Loss: 2.2249	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:01:05 [INFO ]  Epoch:    7	Loss: 2.3092	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 08:01:07 [INFO ]  Epoch:    8	Loss: 2.1790	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:01:08 [INFO ]  Epoch:    9	Loss: 2.2046	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:01:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0010/results.pth
2022-10-04 08:01:10 [INFO ]  
2022-10-04 08:01:10 [INFO ]  Begin of epoch 10 :
2022-10-04 08:01:13 [INFO ]  Begin of epoch 10 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:01:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:01:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:01:13 [INFO ]  	   step  1 (lr=0.053316)                   27.72%                   2.1532
2022-10-04 08:01:13 [INFO ]  
2022-10-04 08:01:13 [INFO ]  Epoch:   10	Loss: 2.1417	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:01:15 [INFO ]  Epoch:   11	Loss: 2.1403	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:01:17 [INFO ]  Epoch:   12	Loss: 2.1274	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:01:18 [INFO ]  Epoch:   13	Loss: 2.0772	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:01:20 [INFO ]  Epoch:   14	Loss: 2.0427	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:01:22 [INFO ]  Epoch:   15	Loss: 1.9562	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:24 [INFO ]  Epoch:   16	Loss: 1.8599	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:01:26 [INFO ]  Epoch:   17	Loss: 1.7732	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:01:27 [INFO ]  Epoch:   18	Loss: 1.8070	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:29 [INFO ]  Epoch:   19	Loss: 1.7135	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:01:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0020/results.pth
2022-10-04 08:01:31 [INFO ]  
2022-10-04 08:01:31 [INFO ]  Begin of epoch 20 :
2022-10-04 08:01:34 [INFO ]  Begin of epoch 20 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:01:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:01:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:01:34 [INFO ]  	   step  1 (lr=0.126537)                   49.60%                   1.5741
2022-10-04 08:01:34 [INFO ]  
2022-10-04 08:01:34 [INFO ]  Epoch:   20	Loss: 1.6049	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:01:36 [INFO ]  Epoch:   21	Loss: 1.6456	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:38 [INFO ]  Epoch:   22	Loss: 1.4908	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:01:39 [INFO ]  Epoch:   23	Loss: 1.6669	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:01:41 [INFO ]  Epoch:   24	Loss: 1.6329	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:43 [INFO ]  Epoch:   25	Loss: 1.4713	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:44 [INFO ]  Epoch:   26	Loss: 1.4275	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:01:46 [INFO ]  Epoch:   27	Loss: 1.5020	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:01:48 [INFO ]  Epoch:   28	Loss: 1.4953	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:01:50 [INFO ]  Epoch:   29	Loss: 1.7084	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0030/results.pth
2022-10-04 08:01:52 [INFO ]  
2022-10-04 08:01:52 [INFO ]  Begin of epoch 30 :
2022-10-04 08:01:55 [INFO ]  Begin of epoch 30 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:01:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:01:55 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:01:55 [INFO ]  	   step  1 (lr=0.152788)                   54.77%                   1.4409
2022-10-04 08:01:55 [INFO ]  
2022-10-04 08:01:55 [INFO ]  Epoch:   30	Loss: 1.4178	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:01:56 [INFO ]  Epoch:   31	Loss: 1.4123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:01:58 [INFO ]  Epoch:   32	Loss: 1.3294	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:02:00 [INFO ]  Epoch:   33	Loss: 1.3784	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:02:02 [INFO ]  Epoch:   34	Loss: 1.3316	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:02:04 [INFO ]  Epoch:   35	Loss: 1.3047	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:02:06 [INFO ]  Epoch:   36	Loss: 1.4319	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:02:07 [INFO ]  Epoch:   37	Loss: 1.4292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:02:09 [INFO ]  Epoch:   38	Loss: 1.3736	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:02:11 [INFO ]  Epoch:   39	Loss: 1.3190	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:08 [INFO ]  ======================================== 2022-10-04 08:04:08 ========================================
2022-10-04 08:04:08 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 08:04:08 [INFO ]  Options: 
2022-10-04 08:04:08 [INFO ]  	base_dir: null
2022-10-04 08:04:08 [INFO ]  	batch_size: 1024
2022-10-04 08:04:08 [INFO ]  	checkpoint_interval: 300
2022-10-04 08:04:08 [INFO ]  	dataset: SVHN
2022-10-04 08:04:08 [INFO ]  	dataset_labels:
2022-10-04 08:04:08 [INFO ]  	- 0
2022-10-04 08:04:08 [INFO ]  	- 1
2022-10-04 08:04:08 [INFO ]  	- 2
2022-10-04 08:04:08 [INFO ]  	- 3
2022-10-04 08:04:08 [INFO ]  	- 4
2022-10-04 08:04:08 [INFO ]  	- 5
2022-10-04 08:04:08 [INFO ]  	- 6
2022-10-04 08:04:08 [INFO ]  	- 7
2022-10-04 08:04:08 [INFO ]  	- 8
2022-10-04 08:04:08 [INFO ]  	- 9
2022-10-04 08:04:08 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 08:04:08 [INFO ]  	- !!python/tuple
2022-10-04 08:04:08 [INFO ]  	    - 0.4379104971885681
2022-10-04 08:04:08 [INFO ]  	    - 0.44398033618927
2022-10-04 08:04:08 [INFO ]  	    - 0.4729299545288086
2022-10-04 08:04:08 [INFO ]  	- !!python/tuple
2022-10-04 08:04:08 [INFO ]  	    - 0.19803012907505035
2022-10-04 08:04:08 [INFO ]  	    - 0.2010156363248825
2022-10-04 08:04:08 [INFO ]  	    - 0.19703614711761475
2022-10-04 08:04:08 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 08:04:08 [INFO ]  	decay_epochs: 50
2022-10-04 08:04:08 [INFO ]  	decay_factor: 0.1
2022-10-04 08:04:08 [INFO ]  	device_id: 0
2022-10-04 08:04:08 [INFO ]  	distill_epochs: 1
2022-10-04 08:04:08 [INFO ]  	distill_lr: 0.02
2022-10-04 08:04:08 [INFO ]  	distill_steps: 1
2022-10-04 08:04:08 [INFO ]  	epochs: 200
2022-10-04 08:04:08 [INFO ]  	expand_cls: false
2022-10-04 08:04:08 [INFO ]  	forgetting_dataset: null
2022-10-04 08:04:08 [INFO ]  	init: xavier
2022-10-04 08:04:08 [INFO ]  	init_param: 1.0
2022-10-04 08:04:08 [INFO ]  	input_size: 32
2022-10-04 08:04:08 [INFO ]  	ipc: 1
2022-10-04 08:04:08 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 08:04:08 [INFO ]  	log_interval: 100
2022-10-04 08:04:08 [INFO ]  	log_level: INFO
2022-10-04 08:04:08 [INFO ]  	lr: 0.01
2022-10-04 08:04:08 [INFO ]  	mode: distill_adapt
2022-10-04 08:04:08 [INFO ]  	nc: 3
2022-10-04 08:04:08 [INFO ]  	num_classes: 10
2022-10-04 08:04:08 [INFO ]  	num_workers: 8
2022-10-04 08:04:08 [INFO ]  	phase: train
2022-10-04 08:04:08 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 08:04:08 [INFO ]  	start_time: '2022-10-04 08:04:08'
2022-10-04 08:04:08 [INFO ]  	test_batch_size: 1024
2022-10-04 08:04:08 [INFO ]  	
2022-10-04 08:04:10 [INFO ]  train dataset size:	73257
2022-10-04 08:04:10 [INFO ]  test dataset size: 	26032
2022-10-04 08:04:10 [INFO ]  datasets built!
2022-10-04 08:04:10 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 08:04:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 08:04:12 [INFO ]  
2022-10-04 08:04:12 [INFO ]  Begin of epoch 0 :
2022-10-04 08:04:15 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:04:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:04:15 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:04:15 [INFO ]  	   step  1 (lr=0.020000)                    7.35%                   8.3401
2022-10-04 08:04:15 [INFO ]  
2022-10-04 08:04:15 [INFO ]  Epoch:    0	Loss: 7.9700	Data Time: 0.43s	Train Time: 0.03s
2022-10-04 08:04:17 [INFO ]  Epoch:    1	Loss: 3.6130	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:04:19 [INFO ]  Epoch:    2	Loss: 3.0884	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:04:20 [INFO ]  Epoch:    3	Loss: 2.6157	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:04:22 [INFO ]  Epoch:    4	Loss: 2.3967	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:24 [INFO ]  Epoch:    5	Loss: 2.2901	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:26 [INFO ]  Epoch:    6	Loss: 2.2304	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:04:27 [INFO ]  Epoch:    7	Loss: 2.1727	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:29 [INFO ]  Epoch:    8	Loss: 2.1733	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:31 [INFO ]  Epoch:    9	Loss: 2.1526	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:33 [INFO ]  Epoch:   10	Loss: 2.1218	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:35 [INFO ]  Epoch:   11	Loss: 2.1753	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:04:36 [INFO ]  Epoch:   12	Loss: 2.1243	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:04:38 [INFO ]  Epoch:   13	Loss: 2.0680	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:04:40 [INFO ]  Epoch:   14	Loss: 1.9975	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:41 [INFO ]  Epoch:   15	Loss: 1.9482	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:04:43 [INFO ]  Epoch:   16	Loss: 1.8239	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:45 [INFO ]  Epoch:   17	Loss: 1.8690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:47 [INFO ]  Epoch:   18	Loss: 1.6990	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:48 [INFO ]  Epoch:   19	Loss: 1.6464	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:04:50 [INFO ]  Epoch:   20	Loss: 1.6384	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:04:52 [INFO ]  Epoch:   21	Loss: 1.5987	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:04:54 [INFO ]  Epoch:   22	Loss: 1.5511	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:04:56 [INFO ]  Epoch:   23	Loss: 1.7586	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:04:57 [INFO ]  Epoch:   24	Loss: 1.8803	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:04:59 [INFO ]  Epoch:   25	Loss: 1.6227	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:05:01 [INFO ]  Epoch:   26	Loss: 1.9412	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:03 [INFO ]  Epoch:   27	Loss: 1.5363	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:05:05 [INFO ]  Epoch:   28	Loss: 1.5296	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:07 [INFO ]  Epoch:   29	Loss: 1.6242	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:05:08 [INFO ]  Epoch:   30	Loss: 1.4984	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:10 [INFO ]  Epoch:   31	Loss: 1.4906	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:05:12 [INFO ]  Epoch:   32	Loss: 1.4643	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:14 [INFO ]  Epoch:   33	Loss: 1.5299	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:05:16 [INFO ]  Epoch:   34	Loss: 1.5024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:17 [INFO ]  Epoch:   35	Loss: 1.4797	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:05:19 [INFO ]  Epoch:   36	Loss: 1.4050	Data Time: 0.25s	Train Time: 0.00s
2022-10-04 08:05:21 [INFO ]  Epoch:   37	Loss: 1.7495	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:05:23 [INFO ]  Epoch:   38	Loss: 1.4695	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:05:25 [INFO ]  Epoch:   39	Loss: 1.5757	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:26 [INFO ]  Epoch:   40	Loss: 1.4979	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:05:28 [INFO ]  Epoch:   41	Loss: 1.3754	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:30 [INFO ]  Epoch:   42	Loss: 1.3292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:32 [INFO ]  Epoch:   43	Loss: 1.4607	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:34 [INFO ]  Epoch:   44	Loss: 1.2721	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:05:35 [INFO ]  Epoch:   45	Loss: 1.3517	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:37 [INFO ]  Epoch:   46	Loss: 1.4433	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:05:39 [INFO ]  Epoch:   47	Loss: 1.3233	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:41 [INFO ]  Epoch:   48	Loss: 1.2285	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:05:43 [INFO ]  Epoch:   49	Loss: 1.2702	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:44 [INFO ]  Epoch:   50	Loss: 1.2603	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:05:46 [INFO ]  Epoch:   51	Loss: 1.3416	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:05:48 [INFO ]  Epoch:   52	Loss: 1.2401	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:50 [INFO ]  Epoch:   53	Loss: 1.3220	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:05:52 [INFO ]  Epoch:   54	Loss: 1.2073	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:05:54 [INFO ]  Epoch:   55	Loss: 1.1654	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:56 [INFO ]  Epoch:   56	Loss: 1.2842	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:05:57 [INFO ]  Epoch:   57	Loss: 1.1578	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:05:59 [INFO ]  Epoch:   58	Loss: 1.2414	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:06:01 [INFO ]  Epoch:   59	Loss: 1.1340	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:06:03 [INFO ]  Epoch:   60	Loss: 1.1544	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:06:05 [INFO ]  Epoch:   61	Loss: 1.2633	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:06 [INFO ]  Epoch:   62	Loss: 1.2439	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:06:08 [INFO ]  Epoch:   63	Loss: 1.1503	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:06:10 [INFO ]  Epoch:   64	Loss: 1.2656	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:06:11 [INFO ]  Epoch:   65	Loss: 1.3165	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:06:13 [INFO ]  Epoch:   66	Loss: 1.1314	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:15 [INFO ]  Epoch:   67	Loss: 1.2341	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:17 [INFO ]  Epoch:   68	Loss: 1.4724	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:19 [INFO ]  Epoch:   69	Loss: 1.2485	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:06:20 [INFO ]  Epoch:   70	Loss: 1.3772	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:06:22 [INFO ]  Epoch:   71	Loss: 1.4843	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:24 [INFO ]  Epoch:   72	Loss: 1.3072	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:06:26 [INFO ]  Epoch:   73	Loss: 1.3684	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:06:28 [INFO ]  Epoch:   74	Loss: 1.2179	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:06:30 [INFO ]  Epoch:   75	Loss: 1.2187	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:31 [INFO ]  Epoch:   76	Loss: 1.2137	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:06:33 [INFO ]  Epoch:   77	Loss: 1.2279	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:06:35 [INFO ]  Epoch:   78	Loss: 1.1857	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:06:37 [INFO ]  Epoch:   79	Loss: 1.2786	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:38 [INFO ]  Epoch:   80	Loss: 1.2571	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:06:40 [INFO ]  Epoch:   81	Loss: 1.1700	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:06:42 [INFO ]  Epoch:   82	Loss: 1.1379	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:06:44 [INFO ]  Epoch:   83	Loss: 1.2431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:46 [INFO ]  Epoch:   84	Loss: 1.2026	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:06:47 [INFO ]  Epoch:   85	Loss: 1.2559	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:06:49 [INFO ]  Epoch:   86	Loss: 1.2166	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:51 [INFO ]  Epoch:   87	Loss: 1.2118	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:53 [INFO ]  Epoch:   88	Loss: 1.3636	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:06:54 [INFO ]  Epoch:   89	Loss: 1.2487	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:06:56 [INFO ]  Epoch:   90	Loss: 1.3663	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:06:58 [INFO ]  Epoch:   91	Loss: 1.2072	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:00 [INFO ]  Epoch:   92	Loss: 1.2997	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:07:01 [INFO ]  Epoch:   93	Loss: 1.2943	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:07:03 [INFO ]  Epoch:   94	Loss: 1.2247	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:07:05 [INFO ]  Epoch:   95	Loss: 1.2662	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:07:07 [INFO ]  Epoch:   96	Loss: 1.2688	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:09 [INFO ]  Epoch:   97	Loss: 1.2079	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:07:10 [INFO ]  Epoch:   98	Loss: 2.4154	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:12 [INFO ]  Epoch:   99	Loss: 1.4271	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:14 [INFO ]  Epoch:  100	Loss: 1.2756	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:16 [INFO ]  Epoch:  101	Loss: 1.2243	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:18 [INFO ]  Epoch:  102	Loss: 1.1578	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:07:19 [INFO ]  Epoch:  103	Loss: 1.2134	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:21 [INFO ]  Epoch:  104	Loss: 1.1813	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:23 [INFO ]  Epoch:  105	Loss: 1.1735	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:25 [INFO ]  Epoch:  106	Loss: 1.2054	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:07:26 [INFO ]  Epoch:  107	Loss: 1.1775	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:28 [INFO ]  Epoch:  108	Loss: 1.1976	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:07:30 [INFO ]  Epoch:  109	Loss: 1.2175	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:32 [INFO ]  Epoch:  110	Loss: 1.3742	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:34 [INFO ]  Epoch:  111	Loss: 1.2301	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:35 [INFO ]  Epoch:  112	Loss: 1.4711	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:37 [INFO ]  Epoch:  113	Loss: 1.1796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:39 [INFO ]  Epoch:  114	Loss: 1.1355	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:41 [INFO ]  Epoch:  115	Loss: 1.2198	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:43 [INFO ]  Epoch:  116	Loss: 1.1760	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:07:45 [INFO ]  Epoch:  117	Loss: 1.2376	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:07:46 [INFO ]  Epoch:  118	Loss: 1.2296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:48 [INFO ]  Epoch:  119	Loss: 1.2120	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:50 [INFO ]  Epoch:  120	Loss: 1.1631	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:52 [INFO ]  Epoch:  121	Loss: 1.2440	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:07:54 [INFO ]  Epoch:  122	Loss: 1.2911	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:07:56 [INFO ]  Epoch:  123	Loss: 1.1503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:07:58 [INFO ]  Epoch:  124	Loss: 1.6422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:07:59 [INFO ]  Epoch:  125	Loss: 1.2673	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:01 [INFO ]  Epoch:  126	Loss: 1.2209	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:03 [INFO ]  Epoch:  127	Loss: 1.1280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:05 [INFO ]  Epoch:  128	Loss: 1.2354	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:07 [INFO ]  Epoch:  129	Loss: 1.1806	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:08 [INFO ]  Epoch:  130	Loss: 1.2314	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:10 [INFO ]  Epoch:  131	Loss: 1.1290	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:12 [INFO ]  Epoch:  132	Loss: 1.1805	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:08:14 [INFO ]  Epoch:  133	Loss: 1.1343	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:16 [INFO ]  Epoch:  134	Loss: 1.0728	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:08:18 [INFO ]  Epoch:  135	Loss: 1.1843	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:08:19 [INFO ]  Epoch:  136	Loss: 1.1565	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:21 [INFO ]  Epoch:  137	Loss: 1.1227	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:08:23 [INFO ]  Epoch:  138	Loss: 1.1757	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:24 [INFO ]  Epoch:  139	Loss: 1.2343	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:08:26 [INFO ]  Epoch:  140	Loss: 1.2887	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:28 [INFO ]  Epoch:  141	Loss: 1.2068	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:30 [INFO ]  Epoch:  142	Loss: 1.2552	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:32 [INFO ]  Epoch:  143	Loss: 1.1698	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:33 [INFO ]  Epoch:  144	Loss: 1.1668	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:35 [INFO ]  Epoch:  145	Loss: 1.1848	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:08:37 [INFO ]  Epoch:  146	Loss: 1.1930	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:08:39 [INFO ]  Epoch:  147	Loss: 1.2734	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:08:41 [INFO ]  Epoch:  148	Loss: 1.2125	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:08:42 [INFO ]  Epoch:  149	Loss: 1.3338	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:08:44 [INFO ]  Epoch:  150	Loss: 1.3399	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:08:46 [INFO ]  Epoch:  151	Loss: 1.2547	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:08:48 [INFO ]  Epoch:  152	Loss: 1.3129	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:08:50 [INFO ]  Epoch:  153	Loss: 1.1917	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:08:52 [INFO ]  Epoch:  154	Loss: 1.1688	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 08:08:53 [INFO ]  Epoch:  155	Loss: 1.2324	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:55 [INFO ]  Epoch:  156	Loss: 1.2967	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:57 [INFO ]  Epoch:  157	Loss: 1.2632	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:08:59 [INFO ]  Epoch:  158	Loss: 1.2224	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:09:01 [INFO ]  Epoch:  159	Loss: 1.2364	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:02 [INFO ]  Epoch:  160	Loss: 1.2054	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:09:04 [INFO ]  Epoch:  161	Loss: 1.1910	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:06 [INFO ]  Epoch:  162	Loss: 1.2067	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:08 [INFO ]  Epoch:  163	Loss: 1.1865	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:09:10 [INFO ]  Epoch:  164	Loss: 1.2110	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:09:11 [INFO ]  Epoch:  165	Loss: 1.2426	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:09:13 [INFO ]  Epoch:  166	Loss: 1.2988	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:15 [INFO ]  Epoch:  167	Loss: 1.2256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:17 [INFO ]  Epoch:  168	Loss: 1.2765	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:19 [INFO ]  Epoch:  169	Loss: 1.2415	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:09:20 [INFO ]  Epoch:  170	Loss: 1.2659	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:22 [INFO ]  Epoch:  171	Loss: 1.2044	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:09:24 [INFO ]  Epoch:  172	Loss: 1.1820	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:09:26 [INFO ]  Epoch:  173	Loss: 1.1795	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:28 [INFO ]  Epoch:  174	Loss: 1.1831	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:30 [INFO ]  Epoch:  175	Loss: 1.1849	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:09:32 [INFO ]  Epoch:  176	Loss: 1.1889	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:09:33 [INFO ]  Epoch:  177	Loss: 1.2285	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:35 [INFO ]  Epoch:  178	Loss: 1.2204	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:37 [INFO ]  Epoch:  179	Loss: 1.2101	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:39 [INFO ]  Epoch:  180	Loss: 1.4845	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:09:41 [INFO ]  Epoch:  181	Loss: 1.1777	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:09:43 [INFO ]  Epoch:  182	Loss: 1.2931	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:09:44 [INFO ]  Epoch:  183	Loss: 1.1649	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:46 [INFO ]  Epoch:  184	Loss: 1.2038	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:48 [INFO ]  Epoch:  185	Loss: 1.2103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:09:50 [INFO ]  Epoch:  186	Loss: 1.1499	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:09:52 [INFO ]  Epoch:  187	Loss: 1.2193	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:09:53 [INFO ]  Epoch:  188	Loss: 1.1970	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:09:55 [INFO ]  Epoch:  189	Loss: 1.2609	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:09:57 [INFO ]  Epoch:  190	Loss: 1.1864	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:09:59 [INFO ]  Epoch:  191	Loss: 1.1895	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:10:01 [INFO ]  Epoch:  192	Loss: 1.2311	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:10:02 [INFO ]  Epoch:  193	Loss: 1.2277	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:10:04 [INFO ]  Epoch:  194	Loss: 1.1998	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:10:06 [INFO ]  Epoch:  195	Loss: 1.1655	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:10:08 [INFO ]  Epoch:  196	Loss: 1.2160	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:10:10 [INFO ]  Epoch:  197	Loss: 1.2746	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:10:12 [INFO ]  Epoch:  198	Loss: 1.2029	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:10:14 [INFO ]  Epoch:  199	Loss: 1.2025	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:10:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 08:10:15 [INFO ]  
2022-10-04 08:10:15 [INFO ]  Final evaluation for SVHN :
2022-10-04 08:10:18 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:10:18 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:10:18 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:10:18 [INFO ]  	   step  1 (lr=0.199397)                   63.21%                   1.2507
2022-10-04 08:10:18 [INFO ]  
2022-10-04 08:10:18 [INFO ]  
2022-10-04 08:10:18 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 08:10:21 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:10:21 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:10:21 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 08:10:21 [INFO ]  	   step  1 (lr=0.199397)                   20.21%                   4.5681
2022-10-04 08:10:21 [INFO ]  
2022-10-04 08:10:21 [INFO ]  CPU Time: 3.34 minutes
2022-10-04 08:10:48 [INFO ]  ======================================== 2022-10-04 08:10:48 ========================================
2022-10-04 08:10:48 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 08:10:48 [INFO ]  Options: 
2022-10-04 08:10:48 [INFO ]  	base_dir: null
2022-10-04 08:10:48 [INFO ]  	batch_size: 1024
2022-10-04 08:10:48 [INFO ]  	checkpoint_interval: 300
2022-10-04 08:10:48 [INFO ]  	dataset: SVHN
2022-10-04 08:10:48 [INFO ]  	dataset_labels:
2022-10-04 08:10:48 [INFO ]  	- 0
2022-10-04 08:10:48 [INFO ]  	- 1
2022-10-04 08:10:48 [INFO ]  	- 2
2022-10-04 08:10:48 [INFO ]  	- 3
2022-10-04 08:10:48 [INFO ]  	- 4
2022-10-04 08:10:48 [INFO ]  	- 5
2022-10-04 08:10:48 [INFO ]  	- 6
2022-10-04 08:10:48 [INFO ]  	- 7
2022-10-04 08:10:48 [INFO ]  	- 8
2022-10-04 08:10:48 [INFO ]  	- 9
2022-10-04 08:10:48 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 08:10:48 [INFO ]  	- !!python/tuple
2022-10-04 08:10:48 [INFO ]  	    - 0.4379104971885681
2022-10-04 08:10:48 [INFO ]  	    - 0.44398033618927
2022-10-04 08:10:48 [INFO ]  	    - 0.4729299545288086
2022-10-04 08:10:48 [INFO ]  	- !!python/tuple
2022-10-04 08:10:48 [INFO ]  	    - 0.19803012907505035
2022-10-04 08:10:48 [INFO ]  	    - 0.2010156363248825
2022-10-04 08:10:48 [INFO ]  	    - 0.19703614711761475
2022-10-04 08:10:48 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 08:10:48 [INFO ]  	decay_epochs: 50
2022-10-04 08:10:48 [INFO ]  	decay_factor: 0.1
2022-10-04 08:10:48 [INFO ]  	device_id: 0
2022-10-04 08:10:48 [INFO ]  	distill_epochs: 1
2022-10-04 08:10:48 [INFO ]  	distill_lr: 0.02
2022-10-04 08:10:48 [INFO ]  	distill_steps: 1
2022-10-04 08:10:48 [INFO ]  	epochs: 200
2022-10-04 08:10:48 [INFO ]  	expand_cls: false
2022-10-04 08:10:48 [INFO ]  	forgetting_dataset: null
2022-10-04 08:10:48 [INFO ]  	init: xavier
2022-10-04 08:10:48 [INFO ]  	init_param: 1.0
2022-10-04 08:10:48 [INFO ]  	input_size: 32
2022-10-04 08:10:48 [INFO ]  	ipc: 2
2022-10-04 08:10:48 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 08:10:48 [INFO ]  	log_interval: 100
2022-10-04 08:10:48 [INFO ]  	log_level: INFO
2022-10-04 08:10:48 [INFO ]  	lr: 0.01
2022-10-04 08:10:48 [INFO ]  	mode: distill_adapt
2022-10-04 08:10:48 [INFO ]  	nc: 3
2022-10-04 08:10:48 [INFO ]  	num_classes: 10
2022-10-04 08:10:48 [INFO ]  	num_workers: 8
2022-10-04 08:10:48 [INFO ]  	phase: train
2022-10-04 08:10:48 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 08:10:48 [INFO ]  	start_time: '2022-10-04 08:10:48'
2022-10-04 08:10:48 [INFO ]  	test_batch_size: 1024
2022-10-04 08:10:48 [INFO ]  	
2022-10-04 08:10:51 [INFO ]  train dataset size:	73257
2022-10-04 08:10:51 [INFO ]  test dataset size: 	26032
2022-10-04 08:10:51 [INFO ]  datasets built!
2022-10-04 08:10:51 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 08:10:52 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 08:10:52 [INFO ]  
2022-10-04 08:10:52 [INFO ]  Begin of epoch 0 :
2022-10-04 08:10:56 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:10:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:10:56 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:10:56 [INFO ]  	   step  1 (lr=0.020000)                    6.92%                   9.1476
2022-10-04 08:10:56 [INFO ]  
2022-10-04 08:10:56 [INFO ]  Epoch:    0	Loss: 8.5899	Data Time: 0.42s	Train Time: 0.03s
2022-10-04 08:10:57 [INFO ]  Epoch:    1	Loss: 3.7962	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:10:59 [INFO ]  Epoch:    2	Loss: 3.1558	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:11:01 [INFO ]  Epoch:    3	Loss: 2.4081	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:11:03 [INFO ]  Epoch:    4	Loss: 2.2886	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:04 [INFO ]  Epoch:    5	Loss: 2.2232	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:06 [INFO ]  Epoch:    6	Loss: 2.2238	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:11:08 [INFO ]  Epoch:    7	Loss: 2.1838	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:10 [INFO ]  Epoch:    8	Loss: 2.1731	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:11:12 [INFO ]  Epoch:    9	Loss: 2.1538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:14 [INFO ]  Epoch:   10	Loss: 2.1220	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:11:16 [INFO ]  Epoch:   11	Loss: 2.0846	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:11:18 [INFO ]  Epoch:   12	Loss: 2.1325	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:11:20 [INFO ]  Epoch:   13	Loss: 2.0489	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:21 [INFO ]  Epoch:   14	Loss: 2.0145	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:11:23 [INFO ]  Epoch:   15	Loss: 1.9725	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:25 [INFO ]  Epoch:   16	Loss: 1.8516	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:11:27 [INFO ]  Epoch:   17	Loss: 1.7139	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:11:29 [INFO ]  Epoch:   18	Loss: 1.6568	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:31 [INFO ]  Epoch:   19	Loss: 1.5190	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:33 [INFO ]  Epoch:   20	Loss: 1.5577	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:11:35 [INFO ]  Epoch:   21	Loss: 1.6670	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:11:37 [INFO ]  Epoch:   22	Loss: 1.3355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:38 [INFO ]  Epoch:   23	Loss: 1.4336	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:11:40 [INFO ]  Epoch:   24	Loss: 1.2401	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:42 [INFO ]  Epoch:   25	Loss: 1.2856	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:44 [INFO ]  Epoch:   26	Loss: 1.2649	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:11:46 [INFO ]  Epoch:   27	Loss: 1.2892	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:48 [INFO ]  Epoch:   28	Loss: 1.2908	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:11:50 [INFO ]  Epoch:   29	Loss: 1.5300	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:11:52 [INFO ]  Epoch:   30	Loss: 1.1955	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:53 [INFO ]  Epoch:   31	Loss: 1.1656	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:11:55 [INFO ]  Epoch:   32	Loss: 1.3876	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:11:57 [INFO ]  Epoch:   33	Loss: 1.1514	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:11:59 [INFO ]  Epoch:   34	Loss: 1.0804	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:12:01 [INFO ]  Epoch:   35	Loss: 1.2065	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:12:03 [INFO ]  Epoch:   36	Loss: 1.1367	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:05 [INFO ]  Epoch:   37	Loss: 1.1740	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:12:06 [INFO ]  Epoch:   38	Loss: 1.1031	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:08 [INFO ]  Epoch:   39	Loss: 1.0990	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:10 [INFO ]  Epoch:   40	Loss: 1.0888	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:11 [INFO ]  Epoch:   41	Loss: 2.9485	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:12:13 [INFO ]  Epoch:   42	Loss: 1.0390	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:12:15 [INFO ]  Epoch:   43	Loss: 1.0241	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:17 [INFO ]  Epoch:   44	Loss: 1.0472	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:19 [INFO ]  Epoch:   45	Loss: 0.9797	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:12:21 [INFO ]  Epoch:   46	Loss: 0.9830	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:23 [INFO ]  Epoch:   47	Loss: 1.0890	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:12:25 [INFO ]  Epoch:   48	Loss: 1.2795	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:12:27 [INFO ]  Epoch:   49	Loss: 1.0378	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:12:28 [INFO ]  Epoch:   50	Loss: 1.0075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:30 [INFO ]  Epoch:   51	Loss: 0.9795	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:32 [INFO ]  Epoch:   52	Loss: 0.9245	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:34 [INFO ]  Epoch:   53	Loss: 1.0395	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 08:12:36 [INFO ]  Epoch:   54	Loss: 0.8597	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:12:38 [INFO ]  Epoch:   55	Loss: 0.9278	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:12:40 [INFO ]  Epoch:   56	Loss: 0.8444	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:12:41 [INFO ]  Epoch:   57	Loss: 0.9102	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:43 [INFO ]  Epoch:   58	Loss: 0.9657	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:12:45 [INFO ]  Epoch:   59	Loss: 0.9256	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:12:47 [INFO ]  Epoch:   60	Loss: 0.8766	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:49 [INFO ]  Epoch:   61	Loss: 0.8971	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:12:51 [INFO ]  Epoch:   62	Loss: 0.9967	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:12:52 [INFO ]  Epoch:   63	Loss: 0.9055	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:12:54 [INFO ]  Epoch:   64	Loss: 0.9292	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:12:56 [INFO ]  Epoch:   65	Loss: 0.9229	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:12:58 [INFO ]  Epoch:   66	Loss: 0.9364	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:13:00 [INFO ]  Epoch:   67	Loss: 0.9072	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:13:02 [INFO ]  Epoch:   68	Loss: 1.0587	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:04 [INFO ]  Epoch:   69	Loss: 1.0128	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:13:05 [INFO ]  Epoch:   70	Loss: 0.8893	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:07 [INFO ]  Epoch:   71	Loss: 1.0096	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:13:09 [INFO ]  Epoch:   72	Loss: 0.9981	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:11 [INFO ]  Epoch:   73	Loss: 0.9133	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:13:13 [INFO ]  Epoch:   74	Loss: 0.8919	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:15 [INFO ]  Epoch:   75	Loss: 1.0032	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:13:16 [INFO ]  Epoch:   76	Loss: 1.0017	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:18 [INFO ]  Epoch:   77	Loss: 1.1103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:20 [INFO ]  Epoch:   78	Loss: 1.0053	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:13:22 [INFO ]  Epoch:   79	Loss: 0.8791	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:13:24 [INFO ]  Epoch:   80	Loss: 0.9230	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:26 [INFO ]  Epoch:   81	Loss: 1.0895	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:13:28 [INFO ]  Epoch:   82	Loss: 0.8666	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:13:30 [INFO ]  Epoch:   83	Loss: 0.9086	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:32 [INFO ]  Epoch:   84	Loss: 0.9458	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:33 [INFO ]  Epoch:   85	Loss: 0.9037	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:13:35 [INFO ]  Epoch:   86	Loss: 0.8685	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:13:37 [INFO ]  Epoch:   87	Loss: 0.9283	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:39 [INFO ]  Epoch:   88	Loss: 0.8794	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:13:41 [INFO ]  Epoch:   89	Loss: 0.8372	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:43 [INFO ]  Epoch:   90	Loss: 0.8911	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:13:45 [INFO ]  Epoch:   91	Loss: 0.9231	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:13:46 [INFO ]  Epoch:   92	Loss: 0.9483	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:13:48 [INFO ]  Epoch:   93	Loss: 0.8754	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:13:50 [INFO ]  Epoch:   94	Loss: 0.9149	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:52 [INFO ]  Epoch:   95	Loss: 0.8423	Data Time: 0.23s	Train Time: 0.00s
2022-10-04 08:13:54 [INFO ]  Epoch:   96	Loss: 0.8585	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:13:56 [INFO ]  Epoch:   97	Loss: 0.9314	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:13:57 [INFO ]  Epoch:   98	Loss: 0.9883	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:13:59 [INFO ]  Epoch:   99	Loss: 0.8396	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:01 [INFO ]  Epoch:  100	Loss: 0.8633	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:03 [INFO ]  Epoch:  101	Loss: 0.8593	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:05 [INFO ]  Epoch:  102	Loss: 0.9653	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:14:07 [INFO ]  Epoch:  103	Loss: 0.9306	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:14:08 [INFO ]  Epoch:  104	Loss: 0.7823	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:10 [INFO ]  Epoch:  105	Loss: 0.8492	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:14:12 [INFO ]  Epoch:  106	Loss: 0.8326	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:14:14 [INFO ]  Epoch:  107	Loss: 0.8672	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:14:16 [INFO ]  Epoch:  108	Loss: 0.8794	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:14:18 [INFO ]  Epoch:  109	Loss: 0.8549	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:20 [INFO ]  Epoch:  110	Loss: 0.8797	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:22 [INFO ]  Epoch:  111	Loss: 0.8259	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:14:24 [INFO ]  Epoch:  112	Loss: 0.9144	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:26 [INFO ]  Epoch:  113	Loss: 0.8868	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:28 [INFO ]  Epoch:  114	Loss: 0.7880	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:30 [INFO ]  Epoch:  115	Loss: 0.8547	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:14:32 [INFO ]  Epoch:  116	Loss: 0.8284	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:14:33 [INFO ]  Epoch:  117	Loss: 0.7174	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:35 [INFO ]  Epoch:  118	Loss: 0.8793	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:37 [INFO ]  Epoch:  119	Loss: 0.8930	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:39 [INFO ]  Epoch:  120	Loss: 0.9077	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:41 [INFO ]  Epoch:  121	Loss: 0.8770	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:14:43 [INFO ]  Epoch:  122	Loss: 0.8942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:45 [INFO ]  Epoch:  123	Loss: 0.8597	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:46 [INFO ]  Epoch:  124	Loss: 0.8159	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:48 [INFO ]  Epoch:  125	Loss: 0.8550	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:50 [INFO ]  Epoch:  126	Loss: 0.8254	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:14:52 [INFO ]  Epoch:  127	Loss: 0.8579	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:14:53 [INFO ]  Epoch:  128	Loss: 0.8028	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:55 [INFO ]  Epoch:  129	Loss: 0.8086	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:57 [INFO ]  Epoch:  130	Loss: 0.8207	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:14:59 [INFO ]  Epoch:  131	Loss: 0.9392	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:15:00 [INFO ]  Epoch:  132	Loss: 0.9135	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:15:02 [INFO ]  Epoch:  133	Loss: 0.8210	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:04 [INFO ]  Epoch:  134	Loss: 0.8743	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:15:06 [INFO ]  Epoch:  135	Loss: 0.8106	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:08 [INFO ]  Epoch:  136	Loss: 0.8619	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:09 [INFO ]  Epoch:  137	Loss: 0.8647	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:15:11 [INFO ]  Epoch:  138	Loss: 0.8491	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:13 [INFO ]  Epoch:  139	Loss: 0.8345	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:15:15 [INFO ]  Epoch:  140	Loss: 0.8471	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:17 [INFO ]  Epoch:  141	Loss: 0.9459	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:19 [INFO ]  Epoch:  142	Loss: 0.9309	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:20 [INFO ]  Epoch:  143	Loss: 0.8242	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:22 [INFO ]  Epoch:  144	Loss: 0.8870	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:15:24 [INFO ]  Epoch:  145	Loss: 0.8261	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:15:26 [INFO ]  Epoch:  146	Loss: 0.8306	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:15:28 [INFO ]  Epoch:  147	Loss: 0.8630	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:15:30 [INFO ]  Epoch:  148	Loss: 0.8547	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:15:32 [INFO ]  Epoch:  149	Loss: 0.8046	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:33 [INFO ]  Epoch:  150	Loss: 0.8794	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:15:35 [INFO ]  Epoch:  151	Loss: 0.7798	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:37 [INFO ]  Epoch:  152	Loss: 0.9073	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:15:39 [INFO ]  Epoch:  153	Loss: 0.8510	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:15:41 [INFO ]  Epoch:  154	Loss: 0.8451	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:42 [INFO ]  Epoch:  155	Loss: 0.8674	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:15:44 [INFO ]  Epoch:  156	Loss: 0.7952	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:46 [INFO ]  Epoch:  157	Loss: 0.7702	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:48 [INFO ]  Epoch:  158	Loss: 0.7889	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:15:50 [INFO ]  Epoch:  159	Loss: 0.7798	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:15:52 [INFO ]  Epoch:  160	Loss: 0.9018	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:53 [INFO ]  Epoch:  161	Loss: 0.8735	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:55 [INFO ]  Epoch:  162	Loss: 0.8124	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:15:57 [INFO ]  Epoch:  163	Loss: 0.8770	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:15:59 [INFO ]  Epoch:  164	Loss: 0.9449	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:16:01 [INFO ]  Epoch:  165	Loss: 0.8202	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:03 [INFO ]  Epoch:  166	Loss: 0.8249	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:05 [INFO ]  Epoch:  167	Loss: 0.8436	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:06 [INFO ]  Epoch:  168	Loss: 0.8990	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:08 [INFO ]  Epoch:  169	Loss: 0.8283	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:16:10 [INFO ]  Epoch:  170	Loss: 0.8064	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:16:12 [INFO ]  Epoch:  171	Loss: 0.7947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:14 [INFO ]  Epoch:  172	Loss: 0.8735	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:16 [INFO ]  Epoch:  173	Loss: 0.8342	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:18 [INFO ]  Epoch:  174	Loss: 0.7972	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:16:19 [INFO ]  Epoch:  175	Loss: 0.8126	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:16:21 [INFO ]  Epoch:  176	Loss: 0.8719	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:23 [INFO ]  Epoch:  177	Loss: 0.8442	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:16:25 [INFO ]  Epoch:  178	Loss: 0.8564	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:27 [INFO ]  Epoch:  179	Loss: 0.8149	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:28 [INFO ]  Epoch:  180	Loss: 0.8557	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:30 [INFO ]  Epoch:  181	Loss: 0.8367	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:16:32 [INFO ]  Epoch:  182	Loss: 0.8175	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:34 [INFO ]  Epoch:  183	Loss: 0.7620	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:16:36 [INFO ]  Epoch:  184	Loss: 0.8695	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:37 [INFO ]  Epoch:  185	Loss: 0.8368	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:16:39 [INFO ]  Epoch:  186	Loss: 0.8899	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:16:41 [INFO ]  Epoch:  187	Loss: 0.9645	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:43 [INFO ]  Epoch:  188	Loss: 0.8419	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:16:44 [INFO ]  Epoch:  189	Loss: 0.8272	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:16:46 [INFO ]  Epoch:  190	Loss: 0.9332	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:48 [INFO ]  Epoch:  191	Loss: 0.8523	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:50 [INFO ]  Epoch:  192	Loss: 0.8574	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:16:52 [INFO ]  Epoch:  193	Loss: 0.8635	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:16:53 [INFO ]  Epoch:  194	Loss: 0.9130	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:16:55 [INFO ]  Epoch:  195	Loss: 0.7688	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:16:57 [INFO ]  Epoch:  196	Loss: 0.8923	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:16:59 [INFO ]  Epoch:  197	Loss: 0.9563	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:17:01 [INFO ]  Epoch:  198	Loss: 0.8578	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:17:03 [INFO ]  Epoch:  199	Loss: 0.8972	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:17:04 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 08:17:04 [INFO ]  
2022-10-04 08:17:04 [INFO ]  Final evaluation for SVHN :
2022-10-04 08:17:08 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:17:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:17:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:17:08 [INFO ]  	   step  1 (lr=0.283310)                   73.92%                   0.9227
2022-10-04 08:17:08 [INFO ]  
2022-10-04 08:17:08 [INFO ]  
2022-10-04 08:17:08 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 08:17:10 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:17:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:17:10 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 08:17:10 [INFO ]  	   step  1 (lr=0.283310)                   19.51%                   5.0364
2022-10-04 08:17:10 [INFO ]  
2022-10-04 08:17:10 [INFO ]  CPU Time: 3.40 minutes
2022-10-04 08:27:57 [INFO ]  ======================================== 2022-10-04 08:27:57 ========================================
2022-10-04 08:27:57 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 08:27:57 [INFO ]  Options: 
2022-10-04 08:27:57 [INFO ]  	base_dir: null
2022-10-04 08:27:57 [INFO ]  	batch_size: 1024
2022-10-04 08:27:57 [INFO ]  	checkpoint_interval: 300
2022-10-04 08:27:57 [INFO ]  	dataset: SVHN
2022-10-04 08:27:57 [INFO ]  	dataset_labels:
2022-10-04 08:27:57 [INFO ]  	- 0
2022-10-04 08:27:57 [INFO ]  	- 1
2022-10-04 08:27:57 [INFO ]  	- 2
2022-10-04 08:27:57 [INFO ]  	- 3
2022-10-04 08:27:57 [INFO ]  	- 4
2022-10-04 08:27:57 [INFO ]  	- 5
2022-10-04 08:27:57 [INFO ]  	- 6
2022-10-04 08:27:57 [INFO ]  	- 7
2022-10-04 08:27:57 [INFO ]  	- 8
2022-10-04 08:27:57 [INFO ]  	- 9
2022-10-04 08:27:57 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 08:27:57 [INFO ]  	- !!python/tuple
2022-10-04 08:27:57 [INFO ]  	    - 0.4379104971885681
2022-10-04 08:27:57 [INFO ]  	    - 0.44398033618927
2022-10-04 08:27:57 [INFO ]  	    - 0.4729299545288086
2022-10-04 08:27:57 [INFO ]  	- !!python/tuple
2022-10-04 08:27:57 [INFO ]  	    - 0.19803012907505035
2022-10-04 08:27:57 [INFO ]  	    - 0.2010156363248825
2022-10-04 08:27:57 [INFO ]  	    - 0.19703614711761475
2022-10-04 08:27:57 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 08:27:57 [INFO ]  	decay_epochs: 50
2022-10-04 08:27:57 [INFO ]  	decay_factor: 0.1
2022-10-04 08:27:57 [INFO ]  	device_id: 0
2022-10-04 08:27:57 [INFO ]  	distill_epochs: 1
2022-10-04 08:27:57 [INFO ]  	distill_lr: 0.02
2022-10-04 08:27:57 [INFO ]  	distill_steps: 1
2022-10-04 08:27:57 [INFO ]  	epochs: 200
2022-10-04 08:27:57 [INFO ]  	expand_cls: false
2022-10-04 08:27:57 [INFO ]  	forgetting_dataset: null
2022-10-04 08:27:57 [INFO ]  	init: xavier
2022-10-04 08:27:57 [INFO ]  	init_param: 1.0
2022-10-04 08:27:57 [INFO ]  	input_size: 32
2022-10-04 08:27:57 [INFO ]  	ipc: 5
2022-10-04 08:27:57 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 08:27:57 [INFO ]  	log_interval: 100
2022-10-04 08:27:57 [INFO ]  	log_level: INFO
2022-10-04 08:27:57 [INFO ]  	lr: 0.01
2022-10-04 08:27:57 [INFO ]  	mode: distill_adapt
2022-10-04 08:27:57 [INFO ]  	nc: 3
2022-10-04 08:27:57 [INFO ]  	num_classes: 10
2022-10-04 08:27:57 [INFO ]  	num_workers: 8
2022-10-04 08:27:57 [INFO ]  	phase: train
2022-10-04 08:27:57 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 08:27:57 [INFO ]  	start_time: '2022-10-04 08:27:57'
2022-10-04 08:27:57 [INFO ]  	test_batch_size: 1024
2022-10-04 08:27:57 [INFO ]  	
2022-10-04 08:27:59 [INFO ]  train dataset size:	73257
2022-10-04 08:27:59 [INFO ]  test dataset size: 	26032
2022-10-04 08:27:59 [INFO ]  datasets built!
2022-10-04 08:27:59 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 08:28:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 08:28:01 [INFO ]  
2022-10-04 08:28:01 [INFO ]  Begin of epoch 0 :
2022-10-04 08:28:04 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:28:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:28:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:28:04 [INFO ]  	   step  1 (lr=0.020000)                    6.91%                   8.9102
2022-10-04 08:28:04 [INFO ]  
2022-10-04 08:28:04 [INFO ]  Epoch:    0	Loss: 9.2561	Data Time: 0.35s	Train Time: 0.03s
2022-10-04 08:28:06 [INFO ]  Epoch:    1	Loss: 2.9789	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:28:08 [INFO ]  Epoch:    2	Loss: 2.4968	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:28:10 [INFO ]  Epoch:    3	Loss: 2.3032	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:28:12 [INFO ]  Epoch:    4	Loss: 2.2047	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:13 [INFO ]  Epoch:    5	Loss: 2.2024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:15 [INFO ]  Epoch:    6	Loss: 2.1386	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:17 [INFO ]  Epoch:    7	Loss: 2.1137	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:28:19 [INFO ]  Epoch:    8	Loss: 2.0860	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:21 [INFO ]  Epoch:    9	Loss: 2.0398	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:22 [INFO ]  Epoch:   10	Loss: 1.8559	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:28:24 [INFO ]  Epoch:   11	Loss: 1.8240	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:28:26 [INFO ]  Epoch:   12	Loss: 1.6875	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:28 [INFO ]  Epoch:   13	Loss: 1.5127	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:30 [INFO ]  Epoch:   14	Loss: 1.4325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:31 [INFO ]  Epoch:   15	Loss: 1.3654	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:33 [INFO ]  Epoch:   16	Loss: 1.3236	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:28:35 [INFO ]  Epoch:   17	Loss: 1.2634	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:28:37 [INFO ]  Epoch:   18	Loss: 1.1921	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:28:39 [INFO ]  Epoch:   19	Loss: 1.1115	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:41 [INFO ]  Epoch:   20	Loss: 1.1700	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:28:42 [INFO ]  Epoch:   21	Loss: 1.2200	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:44 [INFO ]  Epoch:   22	Loss: 1.0719	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:46 [INFO ]  Epoch:   23	Loss: 1.1768	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:48 [INFO ]  Epoch:   24	Loss: 0.9512	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:28:50 [INFO ]  Epoch:   25	Loss: 1.0551	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:28:52 [INFO ]  Epoch:   26	Loss: 0.9439	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:53 [INFO ]  Epoch:   27	Loss: 1.0377	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:28:55 [INFO ]  Epoch:   28	Loss: 1.0545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:57 [INFO ]  Epoch:   29	Loss: 0.9774	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:28:59 [INFO ]  Epoch:   30	Loss: 1.0527	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:01 [INFO ]  Epoch:   31	Loss: 0.9295	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:02 [INFO ]  Epoch:   32	Loss: 0.9234	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:05 [INFO ]  Epoch:   33	Loss: 1.0523	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:06 [INFO ]  Epoch:   34	Loss: 1.4047	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:29:08 [INFO ]  Epoch:   35	Loss: 0.8871	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:10 [INFO ]  Epoch:   36	Loss: 0.8735	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:12 [INFO ]  Epoch:   37	Loss: 0.8638	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:14 [INFO ]  Epoch:   38	Loss: 0.9259	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:16 [INFO ]  Epoch:   39	Loss: 0.9532	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:17 [INFO ]  Epoch:   40	Loss: 0.8371	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:29:19 [INFO ]  Epoch:   41	Loss: 1.0334	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:21 [INFO ]  Epoch:   42	Loss: 1.0196	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:29:23 [INFO ]  Epoch:   43	Loss: 0.7995	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:25 [INFO ]  Epoch:   44	Loss: 0.9048	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:29:27 [INFO ]  Epoch:   45	Loss: 0.8306	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:29:28 [INFO ]  Epoch:   46	Loss: 0.7169	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:29:30 [INFO ]  Epoch:   47	Loss: 0.8096	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:32 [INFO ]  Epoch:   48	Loss: 0.9327	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:34 [INFO ]  Epoch:   49	Loss: 0.8826	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:36 [INFO ]  Epoch:   50	Loss: 0.7453	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:29:38 [INFO ]  Epoch:   51	Loss: 0.7542	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:39 [INFO ]  Epoch:   52	Loss: 0.7915	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:41 [INFO ]  Epoch:   53	Loss: 0.7657	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:43 [INFO ]  Epoch:   54	Loss: 0.6898	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:45 [INFO ]  Epoch:   55	Loss: 0.7351	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:47 [INFO ]  Epoch:   56	Loss: 0.7076	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:48 [INFO ]  Epoch:   57	Loss: 0.6877	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:29:50 [INFO ]  Epoch:   58	Loss: 0.7924	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:52 [INFO ]  Epoch:   59	Loss: 0.8458	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:29:54 [INFO ]  Epoch:   60	Loss: 0.7542	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:29:56 [INFO ]  Epoch:   61	Loss: 0.6677	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:29:58 [INFO ]  Epoch:   62	Loss: 0.6556	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:30:00 [INFO ]  Epoch:   63	Loss: 0.7627	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:02 [INFO ]  Epoch:   64	Loss: 0.7894	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:04 [INFO ]  Epoch:   65	Loss: 0.7097	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:06 [INFO ]  Epoch:   66	Loss: 0.7083	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:30:08 [INFO ]  Epoch:   67	Loss: 0.7465	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:09 [INFO ]  Epoch:   68	Loss: 0.8826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:11 [INFO ]  Epoch:   69	Loss: 0.7086	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:13 [INFO ]  Epoch:   70	Loss: 0.7856	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:15 [INFO ]  Epoch:   71	Loss: 0.7294	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:17 [INFO ]  Epoch:   72	Loss: 0.7240	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:30:19 [INFO ]  Epoch:   73	Loss: 0.8398	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:21 [INFO ]  Epoch:   74	Loss: 0.7105	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:30:22 [INFO ]  Epoch:   75	Loss: 0.7243	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:24 [INFO ]  Epoch:   76	Loss: 0.8845	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:26 [INFO ]  Epoch:   77	Loss: 0.7431	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:30:28 [INFO ]  Epoch:   78	Loss: 0.6669	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:30 [INFO ]  Epoch:   79	Loss: 0.8033	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:31 [INFO ]  Epoch:   80	Loss: 0.7410	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:30:33 [INFO ]  Epoch:   81	Loss: 0.7076	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:30:35 [INFO ]  Epoch:   82	Loss: 0.6900	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:37 [INFO ]  Epoch:   83	Loss: 0.7431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:39 [INFO ]  Epoch:   84	Loss: 0.6699	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:41 [INFO ]  Epoch:   85	Loss: 0.6381	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:43 [INFO ]  Epoch:   86	Loss: 0.7634	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:30:45 [INFO ]  Epoch:   87	Loss: 0.8091	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:46 [INFO ]  Epoch:   88	Loss: 0.7846	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:48 [INFO ]  Epoch:   89	Loss: 0.6857	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:50 [INFO ]  Epoch:   90	Loss: 0.8449	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:52 [INFO ]  Epoch:   91	Loss: 0.7266	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:54 [INFO ]  Epoch:   92	Loss: 0.7284	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:56 [INFO ]  Epoch:   93	Loss: 0.7399	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:30:58 [INFO ]  Epoch:   94	Loss: 0.7033	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:30:59 [INFO ]  Epoch:   95	Loss: 0.7763	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:31:01 [INFO ]  Epoch:   96	Loss: 0.7836	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:31:03 [INFO ]  Epoch:   97	Loss: 0.7167	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:05 [INFO ]  Epoch:   98	Loss: 0.7036	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:07 [INFO ]  Epoch:   99	Loss: 0.6863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:09 [INFO ]  Epoch:  100	Loss: 0.6691	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:11 [INFO ]  Epoch:  101	Loss: 0.7839	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:31:12 [INFO ]  Epoch:  102	Loss: 0.6751	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:31:14 [INFO ]  Epoch:  103	Loss: 0.7336	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:16 [INFO ]  Epoch:  104	Loss: 0.6493	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:31:18 [INFO ]  Epoch:  105	Loss: 0.8306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:20 [INFO ]  Epoch:  106	Loss: 0.7680	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:31:22 [INFO ]  Epoch:  107	Loss: 0.7336	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:31:24 [INFO ]  Epoch:  108	Loss: 0.7052	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:31:26 [INFO ]  Epoch:  109	Loss: 0.8137	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:27 [INFO ]  Epoch:  110	Loss: 0.6802	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:29 [INFO ]  Epoch:  111	Loss: 0.7818	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:31:31 [INFO ]  Epoch:  112	Loss: 0.6706	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:31:33 [INFO ]  Epoch:  113	Loss: 0.7018	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:31:35 [INFO ]  Epoch:  114	Loss: 0.6831	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:31:36 [INFO ]  Epoch:  115	Loss: 0.7287	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:31:38 [INFO ]  Epoch:  116	Loss: 0.6941	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:40 [INFO ]  Epoch:  117	Loss: 0.6018	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:42 [INFO ]  Epoch:  118	Loss: 0.7588	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:44 [INFO ]  Epoch:  119	Loss: 0.7851	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:45 [INFO ]  Epoch:  120	Loss: 0.7764	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:31:48 [INFO ]  Epoch:  121	Loss: 0.7317	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:31:49 [INFO ]  Epoch:  122	Loss: 0.7716	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:31:51 [INFO ]  Epoch:  123	Loss: 0.7132	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:31:53 [INFO ]  Epoch:  124	Loss: 0.7102	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:31:55 [INFO ]  Epoch:  125	Loss: 0.7579	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:31:57 [INFO ]  Epoch:  126	Loss: 0.7094	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:31:59 [INFO ]  Epoch:  127	Loss: 0.7287	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:00 [INFO ]  Epoch:  128	Loss: 0.7261	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:02 [INFO ]  Epoch:  129	Loss: 0.6983	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:32:04 [INFO ]  Epoch:  130	Loss: 0.7505	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:06 [INFO ]  Epoch:  131	Loss: 0.8545	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:32:07 [INFO ]  Epoch:  132	Loss: 0.7980	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:32:09 [INFO ]  Epoch:  133	Loss: 0.7824	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:11 [INFO ]  Epoch:  134	Loss: 0.7498	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:32:13 [INFO ]  Epoch:  135	Loss: 0.6863	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:32:15 [INFO ]  Epoch:  136	Loss: 0.6488	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:17 [INFO ]  Epoch:  137	Loss: 0.7406	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:32:19 [INFO ]  Epoch:  138	Loss: 0.6119	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:32:20 [INFO ]  Epoch:  139	Loss: 0.7540	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:32:22 [INFO ]  Epoch:  140	Loss: 0.7833	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 08:32:24 [INFO ]  Epoch:  141	Loss: 0.7540	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:32:26 [INFO ]  Epoch:  142	Loss: 0.7035	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:32:28 [INFO ]  Epoch:  143	Loss: 0.7199	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:32:29 [INFO ]  Epoch:  144	Loss: 0.8300	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:32:31 [INFO ]  Epoch:  145	Loss: 0.7085	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:33 [INFO ]  Epoch:  146	Loss: 0.7223	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:35 [INFO ]  Epoch:  147	Loss: 0.7193	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:36 [INFO ]  Epoch:  148	Loss: 0.7130	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:32:38 [INFO ]  Epoch:  149	Loss: 0.7860	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:32:40 [INFO ]  Epoch:  150	Loss: 0.6335	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:42 [INFO ]  Epoch:  151	Loss: 0.7753	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:32:44 [INFO ]  Epoch:  152	Loss: 0.7743	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:46 [INFO ]  Epoch:  153	Loss: 0.7834	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:32:48 [INFO ]  Epoch:  154	Loss: 0.6884	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:49 [INFO ]  Epoch:  155	Loss: 0.6441	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:32:51 [INFO ]  Epoch:  156	Loss: 0.7092	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:32:53 [INFO ]  Epoch:  157	Loss: 0.6921	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:32:55 [INFO ]  Epoch:  158	Loss: 0.6907	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:32:57 [INFO ]  Epoch:  159	Loss: 0.6640	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:32:59 [INFO ]  Epoch:  160	Loss: 0.6711	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:01 [INFO ]  Epoch:  161	Loss: 0.6903	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:33:02 [INFO ]  Epoch:  162	Loss: 0.7189	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:33:04 [INFO ]  Epoch:  163	Loss: 0.8187	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:06 [INFO ]  Epoch:  164	Loss: 0.7100	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:08 [INFO ]  Epoch:  165	Loss: 0.7093	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:10 [INFO ]  Epoch:  166	Loss: 0.7387	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:12 [INFO ]  Epoch:  167	Loss: 0.7395	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:33:14 [INFO ]  Epoch:  168	Loss: 0.7012	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:33:16 [INFO ]  Epoch:  169	Loss: 0.7881	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:33:17 [INFO ]  Epoch:  170	Loss: 0.7848	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:19 [INFO ]  Epoch:  171	Loss: 0.7720	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:21 [INFO ]  Epoch:  172	Loss: 0.7853	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:23 [INFO ]  Epoch:  173	Loss: 0.7393	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:33:25 [INFO ]  Epoch:  174	Loss: 0.6951	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:33:27 [INFO ]  Epoch:  175	Loss: 0.7170	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 08:33:28 [INFO ]  Epoch:  176	Loss: 0.7256	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:33:30 [INFO ]  Epoch:  177	Loss: 0.7194	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:33:32 [INFO ]  Epoch:  178	Loss: 0.8092	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:34 [INFO ]  Epoch:  179	Loss: 0.7414	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:36 [INFO ]  Epoch:  180	Loss: 0.7624	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:33:37 [INFO ]  Epoch:  181	Loss: 0.7742	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:33:39 [INFO ]  Epoch:  182	Loss: 0.6942	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:33:41 [INFO ]  Epoch:  183	Loss: 0.7474	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 08:33:43 [INFO ]  Epoch:  184	Loss: 0.6687	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:33:45 [INFO ]  Epoch:  185	Loss: 0.7151	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:33:47 [INFO ]  Epoch:  186	Loss: 0.7651	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:33:49 [INFO ]  Epoch:  187	Loss: 0.6888	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:33:51 [INFO ]  Epoch:  188	Loss: 0.7769	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 08:33:52 [INFO ]  Epoch:  189	Loss: 0.7311	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 08:33:54 [INFO ]  Epoch:  190	Loss: 0.6615	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 08:33:56 [INFO ]  Epoch:  191	Loss: 0.7069	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:33:58 [INFO ]  Epoch:  192	Loss: 0.6403	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 08:34:00 [INFO ]  Epoch:  193	Loss: 0.6660	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:34:02 [INFO ]  Epoch:  194	Loss: 0.6970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 08:34:04 [INFO ]  Epoch:  195	Loss: 0.7287	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:34:05 [INFO ]  Epoch:  196	Loss: 0.7421	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 08:34:07 [INFO ]  Epoch:  197	Loss: 0.6916	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:34:09 [INFO ]  Epoch:  198	Loss: 0.7352	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 08:34:11 [INFO ]  Epoch:  199	Loss: 0.7386	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 08:34:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 08:34:12 [INFO ]  
2022-10-04 08:34:12 [INFO ]  Final evaluation for SVHN :
2022-10-04 08:34:16 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:34:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:34:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 08:34:16 [INFO ]  	   step  1 (lr=0.326078)                   78.72%                   0.7971
2022-10-04 08:34:16 [INFO ]  
2022-10-04 08:34:16 [INFO ]  
2022-10-04 08:34:16 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 08:34:19 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 08:34:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 08:34:19 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 08:34:19 [INFO ]  	   step  1 (lr=0.326078)                   16.66%                   5.0699
2022-10-04 08:34:19 [INFO ]  
2022-10-04 08:34:19 [INFO ]  CPU Time: 3.42 minutes
2022-10-04 09:07:41 [INFO ]  ======================================== 2022-10-04 09:07:41 ========================================
2022-10-04 09:07:41 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 09:07:41 [INFO ]  Options: 
2022-10-04 09:07:41 [INFO ]  	base_dir: null
2022-10-04 09:07:41 [INFO ]  	batch_size: 1024
2022-10-04 09:07:41 [INFO ]  	checkpoint_interval: 300
2022-10-04 09:07:41 [INFO ]  	dataset: SVHN
2022-10-04 09:07:41 [INFO ]  	dataset_labels:
2022-10-04 09:07:41 [INFO ]  	- 0
2022-10-04 09:07:41 [INFO ]  	- 1
2022-10-04 09:07:41 [INFO ]  	- 2
2022-10-04 09:07:41 [INFO ]  	- 3
2022-10-04 09:07:41 [INFO ]  	- 4
2022-10-04 09:07:41 [INFO ]  	- 5
2022-10-04 09:07:41 [INFO ]  	- 6
2022-10-04 09:07:41 [INFO ]  	- 7
2022-10-04 09:07:41 [INFO ]  	- 8
2022-10-04 09:07:41 [INFO ]  	- 9
2022-10-04 09:07:41 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 09:07:41 [INFO ]  	- !!python/tuple
2022-10-04 09:07:41 [INFO ]  	    - 0.4379104971885681
2022-10-04 09:07:41 [INFO ]  	    - 0.44398033618927
2022-10-04 09:07:41 [INFO ]  	    - 0.4729299545288086
2022-10-04 09:07:41 [INFO ]  	- !!python/tuple
2022-10-04 09:07:41 [INFO ]  	    - 0.19803012907505035
2022-10-04 09:07:41 [INFO ]  	    - 0.2010156363248825
2022-10-04 09:07:41 [INFO ]  	    - 0.19703614711761475
2022-10-04 09:07:41 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 09:07:41 [INFO ]  	decay_epochs: 50
2022-10-04 09:07:41 [INFO ]  	decay_factor: 0.1
2022-10-04 09:07:41 [INFO ]  	device_id: 0
2022-10-04 09:07:41 [INFO ]  	distill_epochs: 1
2022-10-04 09:07:41 [INFO ]  	distill_lr: 0.02
2022-10-04 09:07:41 [INFO ]  	distill_steps: 1
2022-10-04 09:07:41 [INFO ]  	epochs: 200
2022-10-04 09:07:41 [INFO ]  	expand_cls: false
2022-10-04 09:07:41 [INFO ]  	forgetting_dataset: null
2022-10-04 09:07:41 [INFO ]  	init: xavier
2022-10-04 09:07:41 [INFO ]  	init_param: 1.0
2022-10-04 09:07:41 [INFO ]  	input_size: 32
2022-10-04 09:07:41 [INFO ]  	ipc: 10
2022-10-04 09:07:41 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 09:07:41 [INFO ]  	log_interval: 100
2022-10-04 09:07:41 [INFO ]  	log_level: INFO
2022-10-04 09:07:41 [INFO ]  	lr: 0.01
2022-10-04 09:07:41 [INFO ]  	mode: distill_adapt
2022-10-04 09:07:41 [INFO ]  	nc: 3
2022-10-04 09:07:41 [INFO ]  	num_classes: 10
2022-10-04 09:07:41 [INFO ]  	num_workers: 8
2022-10-04 09:07:41 [INFO ]  	phase: train
2022-10-04 09:07:41 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 09:07:41 [INFO ]  	start_time: '2022-10-04 09:07:41'
2022-10-04 09:07:41 [INFO ]  	test_batch_size: 1024
2022-10-04 09:07:41 [INFO ]  	
2022-10-04 09:07:43 [INFO ]  train dataset size:	73257
2022-10-04 09:07:43 [INFO ]  test dataset size: 	26032
2022-10-04 09:07:43 [INFO ]  datasets built!
2022-10-04 09:07:43 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 09:07:45 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 09:07:45 [INFO ]  
2022-10-04 09:07:45 [INFO ]  Begin of epoch 0 :
2022-10-04 09:07:48 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:07:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:07:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:07:48 [INFO ]  	   step  1 (lr=0.020000)                    7.07%                   9.1864
2022-10-04 09:07:48 [INFO ]  
2022-10-04 09:07:49 [INFO ]  Epoch:    0	Loss: 9.2894	Data Time: 0.37s	Train Time: 0.04s
2022-10-04 09:07:50 [INFO ]  Epoch:    1	Loss: 3.1275	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:07:52 [INFO ]  Epoch:    2	Loss: 2.5941	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:07:54 [INFO ]  Epoch:    3	Loss: 2.3428	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:07:55 [INFO ]  Epoch:    4	Loss: 2.2421	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:07:57 [INFO ]  Epoch:    5	Loss: 2.2145	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:07:59 [INFO ]  Epoch:    6	Loss: 2.1952	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:08:01 [INFO ]  Epoch:    7	Loss: 2.1162	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:08:02 [INFO ]  Epoch:    8	Loss: 2.0968	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:05 [INFO ]  Epoch:    9	Loss: 2.0365	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:08:06 [INFO ]  Epoch:   10	Loss: 1.9328	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:08:08 [INFO ]  Epoch:   11	Loss: 1.8153	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:08:10 [INFO ]  Epoch:   12	Loss: 1.6974	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:08:12 [INFO ]  Epoch:   13	Loss: 1.5697	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:13 [INFO ]  Epoch:   14	Loss: 1.3880	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:08:15 [INFO ]  Epoch:   15	Loss: 1.3721	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:08:17 [INFO ]  Epoch:   16	Loss: 1.2809	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:08:19 [INFO ]  Epoch:   17	Loss: 1.3353	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:08:20 [INFO ]  Epoch:   18	Loss: 1.2360	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:08:22 [INFO ]  Epoch:   19	Loss: 1.1400	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 09:08:24 [INFO ]  Epoch:   20	Loss: 1.0751	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:08:26 [INFO ]  Epoch:   21	Loss: 1.1194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:08:28 [INFO ]  Epoch:   22	Loss: 1.0487	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:29 [INFO ]  Epoch:   23	Loss: 1.0532	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:08:31 [INFO ]  Epoch:   24	Loss: 1.1286	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:33 [INFO ]  Epoch:   25	Loss: 0.9919	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:08:35 [INFO ]  Epoch:   26	Loss: 0.9529	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:08:36 [INFO ]  Epoch:   27	Loss: 0.9582	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:08:38 [INFO ]  Epoch:   28	Loss: 0.9006	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:40 [INFO ]  Epoch:   29	Loss: 0.8829	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:08:42 [INFO ]  Epoch:   30	Loss: 0.8225	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:08:44 [INFO ]  Epoch:   31	Loss: 0.9161	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:08:46 [INFO ]  Epoch:   32	Loss: 0.8307	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:47 [INFO ]  Epoch:   33	Loss: 1.1757	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:49 [INFO ]  Epoch:   34	Loss: 0.9683	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:08:51 [INFO ]  Epoch:   35	Loss: 1.0378	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:08:53 [INFO ]  Epoch:   36	Loss: 0.8561	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:08:54 [INFO ]  Epoch:   37	Loss: 0.8297	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:08:56 [INFO ]  Epoch:   38	Loss: 0.7828	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:08:58 [INFO ]  Epoch:   39	Loss: 0.9120	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:09:00 [INFO ]  Epoch:   40	Loss: 0.7021	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:09:01 [INFO ]  Epoch:   41	Loss: 0.7661	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:03 [INFO ]  Epoch:   42	Loss: 0.7868	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:05 [INFO ]  Epoch:   43	Loss: 0.7573	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:09:07 [INFO ]  Epoch:   44	Loss: 0.7950	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:09 [INFO ]  Epoch:   45	Loss: 0.7077	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:10 [INFO ]  Epoch:   46	Loss: 0.7709	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:09:12 [INFO ]  Epoch:   47	Loss: 0.6379	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:09:14 [INFO ]  Epoch:   48	Loss: 0.6949	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:09:16 [INFO ]  Epoch:   49	Loss: 0.6837	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:17 [INFO ]  Epoch:   50	Loss: 0.6851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:19 [INFO ]  Epoch:   51	Loss: 0.6475	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:21 [INFO ]  Epoch:   52	Loss: 0.6379	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:23 [INFO ]  Epoch:   53	Loss: 0.6367	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:09:25 [INFO ]  Epoch:   54	Loss: 0.6714	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:09:27 [INFO ]  Epoch:   55	Loss: 0.7398	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:09:29 [INFO ]  Epoch:   56	Loss: 0.6481	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:09:30 [INFO ]  Epoch:   57	Loss: 0.6238	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:09:32 [INFO ]  Epoch:   58	Loss: 0.6995	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:09:34 [INFO ]  Epoch:   59	Loss: 0.5826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:36 [INFO ]  Epoch:   60	Loss: 0.6702	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:09:38 [INFO ]  Epoch:   61	Loss: 0.6955	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:09:40 [INFO ]  Epoch:   62	Loss: 0.6777	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:41 [INFO ]  Epoch:   63	Loss: 0.7357	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:43 [INFO ]  Epoch:   64	Loss: 0.6130	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:09:45 [INFO ]  Epoch:   65	Loss: 0.6848	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:09:47 [INFO ]  Epoch:   66	Loss: 0.6711	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:09:49 [INFO ]  Epoch:   67	Loss: 0.7069	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:09:51 [INFO ]  Epoch:   68	Loss: 0.6416	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:09:53 [INFO ]  Epoch:   69	Loss: 0.6547	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:09:54 [INFO ]  Epoch:   70	Loss: 0.6790	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:09:56 [INFO ]  Epoch:   71	Loss: 0.6301	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:09:58 [INFO ]  Epoch:   72	Loss: 0.6801	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:10:00 [INFO ]  Epoch:   73	Loss: 0.6895	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:10:02 [INFO ]  Epoch:   74	Loss: 0.7098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:03 [INFO ]  Epoch:   75	Loss: 0.6823	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:10:05 [INFO ]  Epoch:   76	Loss: 0.6128	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:10:07 [INFO ]  Epoch:   77	Loss: 0.5896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:09 [INFO ]  Epoch:   78	Loss: 0.6085	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 09:10:11 [INFO ]  Epoch:   79	Loss: 0.6358	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:10:13 [INFO ]  Epoch:   80	Loss: 0.7245	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:10:14 [INFO ]  Epoch:   81	Loss: 0.6619	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:10:16 [INFO ]  Epoch:   82	Loss: 0.6841	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:10:18 [INFO ]  Epoch:   83	Loss: 0.6243	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:10:20 [INFO ]  Epoch:   84	Loss: 0.6168	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:10:22 [INFO ]  Epoch:   85	Loss: 0.6045	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:10:23 [INFO ]  Epoch:   86	Loss: 0.6700	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:10:25 [INFO ]  Epoch:   87	Loss: 0.5515	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:10:27 [INFO ]  Epoch:   88	Loss: 0.6675	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:10:29 [INFO ]  Epoch:   89	Loss: 0.6324	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:31 [INFO ]  Epoch:   90	Loss: 0.6738	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:10:32 [INFO ]  Epoch:   91	Loss: 0.6102	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:34 [INFO ]  Epoch:   92	Loss: 0.6478	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:36 [INFO ]  Epoch:   93	Loss: 0.6307	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 09:10:38 [INFO ]  Epoch:   94	Loss: 0.7358	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:10:40 [INFO ]  Epoch:   95	Loss: 0.6894	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:10:42 [INFO ]  Epoch:   96	Loss: 0.7648	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:10:44 [INFO ]  Epoch:   97	Loss: 0.6558	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:45 [INFO ]  Epoch:   98	Loss: 0.6951	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:47 [INFO ]  Epoch:   99	Loss: 0.6659	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:10:49 [INFO ]  Epoch:  100	Loss: 0.6234	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:10:51 [INFO ]  Epoch:  101	Loss: 0.6324	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:10:53 [INFO ]  Epoch:  102	Loss: 0.6691	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:54 [INFO ]  Epoch:  103	Loss: 0.5821	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:10:56 [INFO ]  Epoch:  104	Loss: 0.6715	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:10:58 [INFO ]  Epoch:  105	Loss: 0.6836	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:11:00 [INFO ]  Epoch:  106	Loss: 0.6090	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:11:02 [INFO ]  Epoch:  107	Loss: 0.6399	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:11:04 [INFO ]  Epoch:  108	Loss: 0.6982	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:11:05 [INFO ]  Epoch:  109	Loss: 0.6149	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:11:07 [INFO ]  Epoch:  110	Loss: 0.5877	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:11:09 [INFO ]  Epoch:  111	Loss: 0.5901	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:11:11 [INFO ]  Epoch:  112	Loss: 0.5569	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:11:12 [INFO ]  Epoch:  113	Loss: 0.6955	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:11:14 [INFO ]  Epoch:  114	Loss: 0.6758	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:11:16 [INFO ]  Epoch:  115	Loss: 0.6771	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:11:18 [INFO ]  Epoch:  116	Loss: 0.5958	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:19 [INFO ]  Epoch:  117	Loss: 0.6988	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:11:21 [INFO ]  Epoch:  118	Loss: 0.6145	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:23 [INFO ]  Epoch:  119	Loss: 0.6808	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:11:25 [INFO ]  Epoch:  120	Loss: 0.6661	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:11:26 [INFO ]  Epoch:  121	Loss: 0.6321	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:11:28 [INFO ]  Epoch:  122	Loss: 0.6699	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:11:30 [INFO ]  Epoch:  123	Loss: 0.6533	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:11:32 [INFO ]  Epoch:  124	Loss: 0.6739	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:11:34 [INFO ]  Epoch:  125	Loss: 0.7180	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:11:36 [INFO ]  Epoch:  126	Loss: 0.6362	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:38 [INFO ]  Epoch:  127	Loss: 0.6127	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:11:40 [INFO ]  Epoch:  128	Loss: 0.5591	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:41 [INFO ]  Epoch:  129	Loss: 0.6096	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:11:43 [INFO ]  Epoch:  130	Loss: 0.6139	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:45 [INFO ]  Epoch:  131	Loss: 0.6590	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:47 [INFO ]  Epoch:  132	Loss: 0.5869	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:11:49 [INFO ]  Epoch:  133	Loss: 0.6318	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 09:11:50 [INFO ]  Epoch:  134	Loss: 0.6112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:52 [INFO ]  Epoch:  135	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:11:54 [INFO ]  Epoch:  136	Loss: 0.6394	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:11:56 [INFO ]  Epoch:  137	Loss: 0.6348	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:11:58 [INFO ]  Epoch:  138	Loss: 0.6581	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:12:00 [INFO ]  Epoch:  139	Loss: 0.6581	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:02 [INFO ]  Epoch:  140	Loss: 0.5849	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:12:04 [INFO ]  Epoch:  141	Loss: 0.5754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:06 [INFO ]  Epoch:  142	Loss: 0.7233	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:07 [INFO ]  Epoch:  143	Loss: 0.5906	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:12:09 [INFO ]  Epoch:  144	Loss: 0.6606	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:11 [INFO ]  Epoch:  145	Loss: 0.7059	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:12:13 [INFO ]  Epoch:  146	Loss: 0.5380	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:12:14 [INFO ]  Epoch:  147	Loss: 0.6993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:16 [INFO ]  Epoch:  148	Loss: 0.5861	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:18 [INFO ]  Epoch:  149	Loss: 0.5898	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:12:20 [INFO ]  Epoch:  150	Loss: 0.6170	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:12:22 [INFO ]  Epoch:  151	Loss: 0.6364	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:12:23 [INFO ]  Epoch:  152	Loss: 0.6003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:25 [INFO ]  Epoch:  153	Loss: 0.6584	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:12:27 [INFO ]  Epoch:  154	Loss: 0.6201	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:12:29 [INFO ]  Epoch:  155	Loss: 0.6020	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:31 [INFO ]  Epoch:  156	Loss: 0.6721	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:12:32 [INFO ]  Epoch:  157	Loss: 0.5970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:34 [INFO ]  Epoch:  158	Loss: 0.6554	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:12:36 [INFO ]  Epoch:  159	Loss: 0.5886	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:38 [INFO ]  Epoch:  160	Loss: 0.6141	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:40 [INFO ]  Epoch:  161	Loss: 0.6041	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:42 [INFO ]  Epoch:  162	Loss: 0.5845	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:12:44 [INFO ]  Epoch:  163	Loss: 0.5891	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:12:45 [INFO ]  Epoch:  164	Loss: 0.6232	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:47 [INFO ]  Epoch:  165	Loss: 0.6248	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:49 [INFO ]  Epoch:  166	Loss: 0.6255	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:12:51 [INFO ]  Epoch:  167	Loss: 0.6024	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:53 [INFO ]  Epoch:  168	Loss: 0.6241	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:12:54 [INFO ]  Epoch:  169	Loss: 0.6448	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:12:56 [INFO ]  Epoch:  170	Loss: 0.6442	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:12:58 [INFO ]  Epoch:  171	Loss: 0.5888	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:00 [INFO ]  Epoch:  172	Loss: 0.6075	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:02 [INFO ]  Epoch:  173	Loss: 0.6666	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:04 [INFO ]  Epoch:  174	Loss: 0.6046	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:06 [INFO ]  Epoch:  175	Loss: 0.6575	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:07 [INFO ]  Epoch:  176	Loss: 0.6207	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:13:09 [INFO ]  Epoch:  177	Loss: 0.6561	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:13:11 [INFO ]  Epoch:  178	Loss: 0.5725	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:13 [INFO ]  Epoch:  179	Loss: 0.6349	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:14 [INFO ]  Epoch:  180	Loss: 0.6673	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:16 [INFO ]  Epoch:  181	Loss: 0.6179	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:13:18 [INFO ]  Epoch:  182	Loss: 0.6957	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:13:20 [INFO ]  Epoch:  183	Loss: 0.6763	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:22 [INFO ]  Epoch:  184	Loss: 0.6874	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:24 [INFO ]  Epoch:  185	Loss: 0.6149	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:25 [INFO ]  Epoch:  186	Loss: 0.6473	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:27 [INFO ]  Epoch:  187	Loss: 0.6252	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:13:29 [INFO ]  Epoch:  188	Loss: 0.6958	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:13:31 [INFO ]  Epoch:  189	Loss: 0.6845	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:33 [INFO ]  Epoch:  190	Loss: 0.7246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:13:34 [INFO ]  Epoch:  191	Loss: 0.6197	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:36 [INFO ]  Epoch:  192	Loss: 0.5899	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:13:38 [INFO ]  Epoch:  193	Loss: 0.5826	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:13:40 [INFO ]  Epoch:  194	Loss: 0.6317	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:42 [INFO ]  Epoch:  195	Loss: 0.6499	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:13:43 [INFO ]  Epoch:  196	Loss: 0.5592	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:45 [INFO ]  Epoch:  197	Loss: 0.5925	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:13:47 [INFO ]  Epoch:  198	Loss: 0.6444	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:13:49 [INFO ]  Epoch:  199	Loss: 0.6022	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:13:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 09:13:50 [INFO ]  
2022-10-04 09:13:50 [INFO ]  Final evaluation for SVHN :
2022-10-04 09:13:53 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:13:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:13:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:13:53 [INFO ]  	   step  1 (lr=0.380002)                   81.39%                   0.6844
2022-10-04 09:13:53 [INFO ]  
2022-10-04 09:13:53 [INFO ]  
2022-10-04 09:13:53 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 09:13:56 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:13:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:13:56 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 09:13:56 [INFO ]  	   step  1 (lr=0.380002)                   13.71%                   5.2243
2022-10-04 09:13:56 [INFO ]  
2022-10-04 09:13:56 [INFO ]  CPU Time: 3.39 minutes
2022-10-04 09:16:29 [INFO ]  ======================================== 2022-10-04 09:16:29 ========================================
2022-10-04 09:16:29 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 09:16:29 [INFO ]  Options: 
2022-10-04 09:16:29 [INFO ]  	base_dir: null
2022-10-04 09:16:29 [INFO ]  	batch_size: 1024
2022-10-04 09:16:29 [INFO ]  	checkpoint_interval: 300
2022-10-04 09:16:29 [INFO ]  	dataset: SVHN
2022-10-04 09:16:29 [INFO ]  	dataset_labels:
2022-10-04 09:16:29 [INFO ]  	- 0
2022-10-04 09:16:29 [INFO ]  	- 1
2022-10-04 09:16:29 [INFO ]  	- 2
2022-10-04 09:16:29 [INFO ]  	- 3
2022-10-04 09:16:29 [INFO ]  	- 4
2022-10-04 09:16:29 [INFO ]  	- 5
2022-10-04 09:16:29 [INFO ]  	- 6
2022-10-04 09:16:29 [INFO ]  	- 7
2022-10-04 09:16:29 [INFO ]  	- 8
2022-10-04 09:16:29 [INFO ]  	- 9
2022-10-04 09:16:29 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 09:16:29 [INFO ]  	- !!python/tuple
2022-10-04 09:16:29 [INFO ]  	    - 0.4379104971885681
2022-10-04 09:16:29 [INFO ]  	    - 0.44398033618927
2022-10-04 09:16:29 [INFO ]  	    - 0.4729299545288086
2022-10-04 09:16:29 [INFO ]  	- !!python/tuple
2022-10-04 09:16:29 [INFO ]  	    - 0.19803012907505035
2022-10-04 09:16:29 [INFO ]  	    - 0.2010156363248825
2022-10-04 09:16:29 [INFO ]  	    - 0.19703614711761475
2022-10-04 09:16:29 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 09:16:29 [INFO ]  	decay_epochs: 50
2022-10-04 09:16:29 [INFO ]  	decay_factor: 0.1
2022-10-04 09:16:29 [INFO ]  	device_id: 0
2022-10-04 09:16:29 [INFO ]  	distill_epochs: 1
2022-10-04 09:16:29 [INFO ]  	distill_lr: 0.02
2022-10-04 09:16:29 [INFO ]  	distill_steps: 1
2022-10-04 09:16:29 [INFO ]  	epochs: 200
2022-10-04 09:16:29 [INFO ]  	expand_cls: false
2022-10-04 09:16:29 [INFO ]  	forgetting_dataset: null
2022-10-04 09:16:29 [INFO ]  	init: xavier
2022-10-04 09:16:29 [INFO ]  	init_param: 1.0
2022-10-04 09:16:29 [INFO ]  	input_size: 32
2022-10-04 09:16:29 [INFO ]  	ipc: 15
2022-10-04 09:16:29 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 09:16:29 [INFO ]  	log_interval: 100
2022-10-04 09:16:29 [INFO ]  	log_level: INFO
2022-10-04 09:16:29 [INFO ]  	lr: 0.01
2022-10-04 09:16:29 [INFO ]  	mode: distill_adapt
2022-10-04 09:16:29 [INFO ]  	nc: 3
2022-10-04 09:16:29 [INFO ]  	num_classes: 10
2022-10-04 09:16:29 [INFO ]  	num_workers: 8
2022-10-04 09:16:29 [INFO ]  	phase: train
2022-10-04 09:16:29 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 09:16:29 [INFO ]  	start_time: '2022-10-04 09:16:29'
2022-10-04 09:16:29 [INFO ]  	test_batch_size: 1024
2022-10-04 09:16:29 [INFO ]  	
2022-10-04 09:16:31 [INFO ]  train dataset size:	73257
2022-10-04 09:16:31 [INFO ]  test dataset size: 	26032
2022-10-04 09:16:31 [INFO ]  datasets built!
2022-10-04 09:16:31 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 09:16:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 09:16:33 [INFO ]  
2022-10-04 09:16:33 [INFO ]  Begin of epoch 0 :
2022-10-04 09:16:36 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:16:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:16:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:16:36 [INFO ]  	   step  1 (lr=0.020000)                    7.10%                   8.5713
2022-10-04 09:16:36 [INFO ]  
2022-10-04 09:16:36 [INFO ]  Epoch:    0	Loss: 8.9497	Data Time: 0.37s	Train Time: 0.04s
2022-10-04 09:16:38 [INFO ]  Epoch:    1	Loss: 2.8902	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:16:40 [INFO ]  Epoch:    2	Loss: 2.5376	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:16:41 [INFO ]  Epoch:    3	Loss: 2.2847	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:16:43 [INFO ]  Epoch:    4	Loss: 2.2161	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:16:45 [INFO ]  Epoch:    5	Loss: 2.1597	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:16:47 [INFO ]  Epoch:    6	Loss: 2.1439	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:16:48 [INFO ]  Epoch:    7	Loss: 2.0909	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:16:50 [INFO ]  Epoch:    8	Loss: 2.0154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:16:52 [INFO ]  Epoch:    9	Loss: 1.9678	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:16:54 [INFO ]  Epoch:   10	Loss: 1.8217	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:16:55 [INFO ]  Epoch:   11	Loss: 1.7100	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:16:57 [INFO ]  Epoch:   12	Loss: 1.5228	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:16:59 [INFO ]  Epoch:   13	Loss: 1.4674	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:17:01 [INFO ]  Epoch:   14	Loss: 1.4011	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:17:03 [INFO ]  Epoch:   15	Loss: 1.3611	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:17:04 [INFO ]  Epoch:   16	Loss: 1.1931	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:06 [INFO ]  Epoch:   17	Loss: 1.2096	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:17:08 [INFO ]  Epoch:   18	Loss: 1.2410	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:17:10 [INFO ]  Epoch:   19	Loss: 1.0283	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:12 [INFO ]  Epoch:   20	Loss: 1.0551	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:17:14 [INFO ]  Epoch:   21	Loss: 1.0375	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:17:15 [INFO ]  Epoch:   22	Loss: 0.9423	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:17:17 [INFO ]  Epoch:   23	Loss: 0.9497	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:17:19 [INFO ]  Epoch:   24	Loss: 1.1526	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:17:21 [INFO ]  Epoch:   25	Loss: 1.1351	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:23 [INFO ]  Epoch:   26	Loss: 0.9976	Data Time: 0.17s	Train Time: 0.00s
2022-10-04 09:17:24 [INFO ]  Epoch:   27	Loss: 0.9148	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:26 [INFO ]  Epoch:   28	Loss: 0.9941	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:17:28 [INFO ]  Epoch:   29	Loss: 0.9411	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:30 [INFO ]  Epoch:   30	Loss: 0.8982	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:17:32 [INFO ]  Epoch:   31	Loss: 1.0124	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:33 [INFO ]  Epoch:   32	Loss: 0.8545	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:17:35 [INFO ]  Epoch:   33	Loss: 0.8468	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:37 [INFO ]  Epoch:   34	Loss: 0.8358	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:39 [INFO ]  Epoch:   35	Loss: 0.8224	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:40 [INFO ]  Epoch:   36	Loss: 0.7918	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:17:42 [INFO ]  Epoch:   37	Loss: 0.8940	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:44 [INFO ]  Epoch:   38	Loss: 0.7273	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:46 [INFO ]  Epoch:   39	Loss: 0.8450	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:17:48 [INFO ]  Epoch:   40	Loss: 0.7560	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:50 [INFO ]  Epoch:   41	Loss: 0.7617	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:52 [INFO ]  Epoch:   42	Loss: 0.7482	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:17:53 [INFO ]  Epoch:   43	Loss: 0.7817	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:55 [INFO ]  Epoch:   44	Loss: 0.7254	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:17:57 [INFO ]  Epoch:   45	Loss: 0.7192	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:17:59 [INFO ]  Epoch:   46	Loss: 0.7744	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:01 [INFO ]  Epoch:   47	Loss: 0.9347	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:18:03 [INFO ]  Epoch:   48	Loss: 0.7436	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:18:05 [INFO ]  Epoch:   49	Loss: 0.7531	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:18:06 [INFO ]  Epoch:   50	Loss: 0.6426	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:18:08 [INFO ]  Epoch:   51	Loss: 0.6674	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:18:10 [INFO ]  Epoch:   52	Loss: 0.6960	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:12 [INFO ]  Epoch:   53	Loss: 0.7563	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:14 [INFO ]  Epoch:   54	Loss: 0.6549	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:18:15 [INFO ]  Epoch:   55	Loss: 0.7341	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:18:17 [INFO ]  Epoch:   56	Loss: 0.6254	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:19 [INFO ]  Epoch:   57	Loss: 0.6136	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:18:21 [INFO ]  Epoch:   58	Loss: 0.6649	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:23 [INFO ]  Epoch:   59	Loss: 0.6667	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:25 [INFO ]  Epoch:   60	Loss: 0.5952	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:18:26 [INFO ]  Epoch:   61	Loss: 0.6516	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:18:28 [INFO ]  Epoch:   62	Loss: 0.5849	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:30 [INFO ]  Epoch:   63	Loss: 0.5976	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:32 [INFO ]  Epoch:   64	Loss: 0.6704	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:33 [INFO ]  Epoch:   65	Loss: 0.6386	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:35 [INFO ]  Epoch:   66	Loss: 0.6164	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:37 [INFO ]  Epoch:   67	Loss: 0.6697	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:18:39 [INFO ]  Epoch:   68	Loss: 0.6870	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:41 [INFO ]  Epoch:   69	Loss: 0.6591	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:18:42 [INFO ]  Epoch:   70	Loss: 0.6428	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:18:44 [INFO ]  Epoch:   71	Loss: 0.6164	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:18:46 [INFO ]  Epoch:   72	Loss: 0.6460	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:48 [INFO ]  Epoch:   73	Loss: 0.6752	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:18:50 [INFO ]  Epoch:   74	Loss: 0.6777	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:18:51 [INFO ]  Epoch:   75	Loss: 0.5882	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:18:53 [INFO ]  Epoch:   76	Loss: 0.6256	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:18:55 [INFO ]  Epoch:   77	Loss: 0.6787	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:18:57 [INFO ]  Epoch:   78	Loss: 0.5916	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:18:59 [INFO ]  Epoch:   79	Loss: 0.7022	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:19:01 [INFO ]  Epoch:   80	Loss: 0.6458	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:19:02 [INFO ]  Epoch:   81	Loss: 0.6507	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:04 [INFO ]  Epoch:   82	Loss: 0.5707	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:06 [INFO ]  Epoch:   83	Loss: 0.6406	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:08 [INFO ]  Epoch:   84	Loss: 0.5735	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:09 [INFO ]  Epoch:   85	Loss: 0.6408	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:11 [INFO ]  Epoch:   86	Loss: 0.8223	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:13 [INFO ]  Epoch:   87	Loss: 0.6003	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:19:15 [INFO ]  Epoch:   88	Loss: 0.5957	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:19:17 [INFO ]  Epoch:   89	Loss: 0.6195	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:19 [INFO ]  Epoch:   90	Loss: 0.6872	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:19:20 [INFO ]  Epoch:   91	Loss: 0.5959	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:22 [INFO ]  Epoch:   92	Loss: 0.6294	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:19:24 [INFO ]  Epoch:   93	Loss: 0.6240	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:26 [INFO ]  Epoch:   94	Loss: 0.6367	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:28 [INFO ]  Epoch:   95	Loss: 0.6788	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:19:29 [INFO ]  Epoch:   96	Loss: 0.6179	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:31 [INFO ]  Epoch:   97	Loss: 0.6411	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:33 [INFO ]  Epoch:   98	Loss: 0.5239	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:19:35 [INFO ]  Epoch:   99	Loss: 0.6877	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:37 [INFO ]  Epoch:  100	Loss: 0.6257	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:39 [INFO ]  Epoch:  101	Loss: 0.5673	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:19:40 [INFO ]  Epoch:  102	Loss: 0.5692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:42 [INFO ]  Epoch:  103	Loss: 0.6390	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:19:44 [INFO ]  Epoch:  104	Loss: 0.6778	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:19:46 [INFO ]  Epoch:  105	Loss: 0.6375	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:48 [INFO ]  Epoch:  106	Loss: 0.5639	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:49 [INFO ]  Epoch:  107	Loss: 0.5936	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:19:51 [INFO ]  Epoch:  108	Loss: 0.6000	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:53 [INFO ]  Epoch:  109	Loss: 0.6743	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:19:55 [INFO ]  Epoch:  110	Loss: 0.6102	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:19:57 [INFO ]  Epoch:  111	Loss: 0.6646	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:19:59 [INFO ]  Epoch:  112	Loss: 0.6666	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:20:00 [INFO ]  Epoch:  113	Loss: 0.6173	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:20:02 [INFO ]  Epoch:  114	Loss: 0.6081	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:04 [INFO ]  Epoch:  115	Loss: 0.5908	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:06 [INFO ]  Epoch:  116	Loss: 0.5663	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:20:07 [INFO ]  Epoch:  117	Loss: 0.6040	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:20:09 [INFO ]  Epoch:  118	Loss: 0.5783	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:20:11 [INFO ]  Epoch:  119	Loss: 0.5847	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:13 [INFO ]  Epoch:  120	Loss: 0.5527	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:15 [INFO ]  Epoch:  121	Loss: 0.6125	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:20:17 [INFO ]  Epoch:  122	Loss: 0.5586	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:20:18 [INFO ]  Epoch:  123	Loss: 0.7278	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:20:20 [INFO ]  Epoch:  124	Loss: 0.5842	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:22 [INFO ]  Epoch:  125	Loss: 0.5259	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:20:24 [INFO ]  Epoch:  126	Loss: 0.6908	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:20:26 [INFO ]  Epoch:  127	Loss: 0.6316	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:20:28 [INFO ]  Epoch:  128	Loss: 0.5916	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:30 [INFO ]  Epoch:  129	Loss: 0.6123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:32 [INFO ]  Epoch:  130	Loss: 0.6133	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:33 [INFO ]  Epoch:  131	Loss: 0.6172	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:35 [INFO ]  Epoch:  132	Loss: 0.5905	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:20:37 [INFO ]  Epoch:  133	Loss: 0.5575	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:39 [INFO ]  Epoch:  134	Loss: 0.6724	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:41 [INFO ]  Epoch:  135	Loss: 0.5862	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 09:20:43 [INFO ]  Epoch:  136	Loss: 0.6256	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:20:44 [INFO ]  Epoch:  137	Loss: 0.6380	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:46 [INFO ]  Epoch:  138	Loss: 0.6741	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:20:48 [INFO ]  Epoch:  139	Loss: 0.5540	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:20:50 [INFO ]  Epoch:  140	Loss: 0.6126	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:20:52 [INFO ]  Epoch:  141	Loss: 0.5846	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:53 [INFO ]  Epoch:  142	Loss: 0.6412	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:20:55 [INFO ]  Epoch:  143	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:57 [INFO ]  Epoch:  144	Loss: 0.7074	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:20:59 [INFO ]  Epoch:  145	Loss: 0.6114	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:21:01 [INFO ]  Epoch:  146	Loss: 0.6594	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:21:03 [INFO ]  Epoch:  147	Loss: 0.6605	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:21:05 [INFO ]  Epoch:  148	Loss: 0.5905	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:07 [INFO ]  Epoch:  149	Loss: 0.6076	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:21:08 [INFO ]  Epoch:  150	Loss: 0.6402	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:21:10 [INFO ]  Epoch:  151	Loss: 0.6166	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:21:12 [INFO ]  Epoch:  152	Loss: 0.6177	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:21:14 [INFO ]  Epoch:  153	Loss: 0.6207	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:21:16 [INFO ]  Epoch:  154	Loss: 0.6235	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:18 [INFO ]  Epoch:  155	Loss: 0.5956	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:21:20 [INFO ]  Epoch:  156	Loss: 0.5657	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:21:22 [INFO ]  Epoch:  157	Loss: 0.6420	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:24 [INFO ]  Epoch:  158	Loss: 0.5986	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:21:26 [INFO ]  Epoch:  159	Loss: 0.6069	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:21:27 [INFO ]  Epoch:  160	Loss: 0.5980	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:29 [INFO ]  Epoch:  161	Loss: 0.5557	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:31 [INFO ]  Epoch:  162	Loss: 0.6874	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:33 [INFO ]  Epoch:  163	Loss: 0.6589	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:21:35 [INFO ]  Epoch:  164	Loss: 0.6931	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:21:36 [INFO ]  Epoch:  165	Loss: 0.5849	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:21:38 [INFO ]  Epoch:  166	Loss: 0.6573	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:21:40 [INFO ]  Epoch:  167	Loss: 0.6264	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:42 [INFO ]  Epoch:  168	Loss: 0.6400	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:21:44 [INFO ]  Epoch:  169	Loss: 0.6102	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:21:45 [INFO ]  Epoch:  170	Loss: 0.5858	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:21:47 [INFO ]  Epoch:  171	Loss: 0.7010	Data Time: 0.22s	Train Time: 0.00s
2022-10-04 09:21:49 [INFO ]  Epoch:  172	Loss: 0.6115	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:51 [INFO ]  Epoch:  173	Loss: 0.5936	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:53 [INFO ]  Epoch:  174	Loss: 0.5675	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:54 [INFO ]  Epoch:  175	Loss: 0.6692	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:21:56 [INFO ]  Epoch:  176	Loss: 0.5692	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:21:58 [INFO ]  Epoch:  177	Loss: 0.5459	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:22:00 [INFO ]  Epoch:  178	Loss: 0.5853	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:22:01 [INFO ]  Epoch:  179	Loss: 0.6503	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:03 [INFO ]  Epoch:  180	Loss: 0.6013	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:22:05 [INFO ]  Epoch:  181	Loss: 0.5473	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:22:07 [INFO ]  Epoch:  182	Loss: 0.6406	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:22:09 [INFO ]  Epoch:  183	Loss: 0.6482	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:22:11 [INFO ]  Epoch:  184	Loss: 0.5513	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:12 [INFO ]  Epoch:  185	Loss: 0.6233	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:22:14 [INFO ]  Epoch:  186	Loss: 0.6509	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:16 [INFO ]  Epoch:  187	Loss: 0.6070	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:18 [INFO ]  Epoch:  188	Loss: 0.5693	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:22:20 [INFO ]  Epoch:  189	Loss: 0.5867	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:22 [INFO ]  Epoch:  190	Loss: 0.6045	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:22:24 [INFO ]  Epoch:  191	Loss: 0.5116	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:22:26 [INFO ]  Epoch:  192	Loss: 0.5816	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:22:27 [INFO ]  Epoch:  193	Loss: 0.5172	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:29 [INFO ]  Epoch:  194	Loss: 0.5539	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:22:31 [INFO ]  Epoch:  195	Loss: 0.5781	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:33 [INFO ]  Epoch:  196	Loss: 0.6242	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:22:35 [INFO ]  Epoch:  197	Loss: 0.5512	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:22:37 [INFO ]  Epoch:  198	Loss: 0.5786	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:22:38 [INFO ]  Epoch:  199	Loss: 0.6300	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:22:40 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 09:22:40 [INFO ]  
2022-10-04 09:22:40 [INFO ]  Final evaluation for SVHN :
2022-10-04 09:22:43 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:22:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:22:43 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:22:43 [INFO ]  	   step  1 (lr=0.398312)                   81.73%                   0.6784
2022-10-04 09:22:43 [INFO ]  
2022-10-04 09:22:43 [INFO ]  
2022-10-04 09:22:43 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 09:22:46 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:22:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:22:46 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 09:22:46 [INFO ]  	   step  1 (lr=0.398312)                   16.22%                   5.2711
2022-10-04 09:22:46 [INFO ]  
2022-10-04 09:22:46 [INFO ]  CPU Time: 3.41 minutes
2022-10-04 09:46:18 [INFO ]  ======================================== 2022-10-04 09:46:18 ========================================
2022-10-04 09:46:18 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 09:46:18 [INFO ]  Options: 
2022-10-04 09:46:18 [INFO ]  	base_dir: null
2022-10-04 09:46:18 [INFO ]  	batch_size: 1024
2022-10-04 09:46:18 [INFO ]  	checkpoint_interval: 300
2022-10-04 09:46:18 [INFO ]  	dataset: SVHN
2022-10-04 09:46:18 [INFO ]  	dataset_labels:
2022-10-04 09:46:18 [INFO ]  	- 0
2022-10-04 09:46:18 [INFO ]  	- 1
2022-10-04 09:46:18 [INFO ]  	- 2
2022-10-04 09:46:18 [INFO ]  	- 3
2022-10-04 09:46:18 [INFO ]  	- 4
2022-10-04 09:46:18 [INFO ]  	- 5
2022-10-04 09:46:18 [INFO ]  	- 6
2022-10-04 09:46:18 [INFO ]  	- 7
2022-10-04 09:46:18 [INFO ]  	- 8
2022-10-04 09:46:18 [INFO ]  	- 9
2022-10-04 09:46:18 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 09:46:18 [INFO ]  	- !!python/tuple
2022-10-04 09:46:18 [INFO ]  	    - 0.4379104971885681
2022-10-04 09:46:18 [INFO ]  	    - 0.44398033618927
2022-10-04 09:46:18 [INFO ]  	    - 0.4729299545288086
2022-10-04 09:46:18 [INFO ]  	- !!python/tuple
2022-10-04 09:46:18 [INFO ]  	    - 0.19803012907505035
2022-10-04 09:46:18 [INFO ]  	    - 0.2010156363248825
2022-10-04 09:46:18 [INFO ]  	    - 0.19703614711761475
2022-10-04 09:46:18 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 09:46:18 [INFO ]  	decay_epochs: 50
2022-10-04 09:46:18 [INFO ]  	decay_factor: 0.1
2022-10-04 09:46:18 [INFO ]  	device_id: 0
2022-10-04 09:46:18 [INFO ]  	distill_epochs: 1
2022-10-04 09:46:18 [INFO ]  	distill_lr: 0.02
2022-10-04 09:46:18 [INFO ]  	distill_steps: 1
2022-10-04 09:46:18 [INFO ]  	epochs: 200
2022-10-04 09:46:18 [INFO ]  	expand_cls: false
2022-10-04 09:46:18 [INFO ]  	forgetting_dataset: null
2022-10-04 09:46:18 [INFO ]  	init: xavier
2022-10-04 09:46:18 [INFO ]  	init_param: 1.0
2022-10-04 09:46:18 [INFO ]  	input_size: 32
2022-10-04 09:46:18 [INFO ]  	ipc: 20
2022-10-04 09:46:18 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 09:46:18 [INFO ]  	log_interval: 100
2022-10-04 09:46:18 [INFO ]  	log_level: INFO
2022-10-04 09:46:18 [INFO ]  	lr: 0.01
2022-10-04 09:46:18 [INFO ]  	mode: distill_adapt
2022-10-04 09:46:18 [INFO ]  	nc: 3
2022-10-04 09:46:18 [INFO ]  	num_classes: 10
2022-10-04 09:46:18 [INFO ]  	num_workers: 8
2022-10-04 09:46:18 [INFO ]  	phase: train
2022-10-04 09:46:18 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 09:46:18 [INFO ]  	start_time: '2022-10-04 09:46:18'
2022-10-04 09:46:18 [INFO ]  	test_batch_size: 1024
2022-10-04 09:46:18 [INFO ]  	
2022-10-04 09:46:20 [INFO ]  train dataset size:	73257
2022-10-04 09:46:20 [INFO ]  test dataset size: 	26032
2022-10-04 09:46:20 [INFO ]  datasets built!
2022-10-04 09:46:20 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 09:46:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 09:46:22 [INFO ]  
2022-10-04 09:46:22 [INFO ]  Begin of epoch 0 :
2022-10-04 09:46:25 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:46:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:46:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:46:25 [INFO ]  	   step  1 (lr=0.020000)                    7.23%                   8.6965
2022-10-04 09:46:25 [INFO ]  
2022-10-04 09:46:25 [INFO ]  Epoch:    0	Loss: 8.6862	Data Time: 0.36s	Train Time: 0.04s
2022-10-04 09:46:27 [INFO ]  Epoch:    1	Loss: 2.9634	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:46:28 [INFO ]  Epoch:    2	Loss: 2.4417	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:30 [INFO ]  Epoch:    3	Loss: 2.3118	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:46:32 [INFO ]  Epoch:    4	Loss: 2.2425	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:34 [INFO ]  Epoch:    5	Loss: 2.1708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:46:36 [INFO ]  Epoch:    6	Loss: 2.1185	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:38 [INFO ]  Epoch:    7	Loss: 2.0573	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:46:39 [INFO ]  Epoch:    8	Loss: 2.0329	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:46:41 [INFO ]  Epoch:    9	Loss: 1.9180	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:43 [INFO ]  Epoch:   10	Loss: 1.8119	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:46:45 [INFO ]  Epoch:   11	Loss: 2.1002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:46:46 [INFO ]  Epoch:   12	Loss: 1.4219	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:46:48 [INFO ]  Epoch:   13	Loss: 1.3476	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:46:50 [INFO ]  Epoch:   14	Loss: 1.3365	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:46:52 [INFO ]  Epoch:   15	Loss: 1.3433	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:46:54 [INFO ]  Epoch:   16	Loss: 1.2332	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:55 [INFO ]  Epoch:   17	Loss: 1.0690	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:57 [INFO ]  Epoch:   18	Loss: 1.1282	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:46:59 [INFO ]  Epoch:   19	Loss: 0.9675	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:47:01 [INFO ]  Epoch:   20	Loss: 0.9762	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:47:03 [INFO ]  Epoch:   21	Loss: 0.9851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:05 [INFO ]  Epoch:   22	Loss: 0.8996	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:47:06 [INFO ]  Epoch:   23	Loss: 0.8620	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:47:08 [INFO ]  Epoch:   24	Loss: 0.9885	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:47:10 [INFO ]  Epoch:   25	Loss: 0.9352	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:12 [INFO ]  Epoch:   26	Loss: 1.0089	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:14 [INFO ]  Epoch:   27	Loss: 0.9640	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:47:16 [INFO ]  Epoch:   28	Loss: 0.8989	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:47:18 [INFO ]  Epoch:   29	Loss: 0.8988	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:20 [INFO ]  Epoch:   30	Loss: 0.8479	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:47:21 [INFO ]  Epoch:   31	Loss: 0.9388	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:23 [INFO ]  Epoch:   32	Loss: 0.7307	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:47:25 [INFO ]  Epoch:   33	Loss: 0.7889	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:27 [INFO ]  Epoch:   34	Loss: 0.7757	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:47:29 [INFO ]  Epoch:   35	Loss: 0.8327	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:47:31 [INFO ]  Epoch:   36	Loss: 0.7829	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:47:32 [INFO ]  Epoch:   37	Loss: 0.7035	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:47:34 [INFO ]  Epoch:   38	Loss: 0.6810	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:36 [INFO ]  Epoch:   39	Loss: 0.8175	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:38 [INFO ]  Epoch:   40	Loss: 0.9312	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:40 [INFO ]  Epoch:   41	Loss: 0.7412	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:47:42 [INFO ]  Epoch:   42	Loss: 0.7712	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:44 [INFO ]  Epoch:   43	Loss: 0.6864	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:47:45 [INFO ]  Epoch:   44	Loss: 0.7599	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:47:47 [INFO ]  Epoch:   45	Loss: 0.8257	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:47:49 [INFO ]  Epoch:   46	Loss: 0.7677	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:47:51 [INFO ]  Epoch:   47	Loss: 0.6440	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:52 [INFO ]  Epoch:   48	Loss: 0.6972	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:54 [INFO ]  Epoch:   49	Loss: 0.6914	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:47:56 [INFO ]  Epoch:   50	Loss: 0.6045	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:47:58 [INFO ]  Epoch:   51	Loss: 0.6542	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:48:00 [INFO ]  Epoch:   52	Loss: 0.7202	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:01 [INFO ]  Epoch:   53	Loss: 0.6868	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:03 [INFO ]  Epoch:   54	Loss: 0.6749	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:48:05 [INFO ]  Epoch:   55	Loss: 0.6704	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:07 [INFO ]  Epoch:   56	Loss: 0.6527	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:09 [INFO ]  Epoch:   57	Loss: 0.6106	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:48:11 [INFO ]  Epoch:   58	Loss: 0.6243	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:48:13 [INFO ]  Epoch:   59	Loss: 0.6621	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:48:15 [INFO ]  Epoch:   60	Loss: 0.6533	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:48:16 [INFO ]  Epoch:   61	Loss: 0.6532	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:48:18 [INFO ]  Epoch:   62	Loss: 0.7228	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:48:20 [INFO ]  Epoch:   63	Loss: 0.6157	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:48:22 [INFO ]  Epoch:   64	Loss: 0.5775	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:24 [INFO ]  Epoch:   65	Loss: 0.6147	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:25 [INFO ]  Epoch:   66	Loss: 0.5890	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:28 [INFO ]  Epoch:   67	Loss: 0.6561	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:30 [INFO ]  Epoch:   68	Loss: 0.6016	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:31 [INFO ]  Epoch:   69	Loss: 0.6137	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:48:33 [INFO ]  Epoch:   70	Loss: 0.6217	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:35 [INFO ]  Epoch:   71	Loss: 0.6368	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:37 [INFO ]  Epoch:   72	Loss: 0.6565	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:39 [INFO ]  Epoch:   73	Loss: 0.6158	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:40 [INFO ]  Epoch:   74	Loss: 0.6060	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:42 [INFO ]  Epoch:   75	Loss: 0.5854	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:44 [INFO ]  Epoch:   76	Loss: 0.5887	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:46 [INFO ]  Epoch:   77	Loss: 0.5861	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:48 [INFO ]  Epoch:   78	Loss: 0.6196	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:48:50 [INFO ]  Epoch:   79	Loss: 0.5971	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:48:51 [INFO ]  Epoch:   80	Loss: 0.6313	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:53 [INFO ]  Epoch:   81	Loss: 0.5947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:55 [INFO ]  Epoch:   82	Loss: 0.6277	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:48:57 [INFO ]  Epoch:   83	Loss: 0.5839	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:48:59 [INFO ]  Epoch:   84	Loss: 0.7558	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:01 [INFO ]  Epoch:   85	Loss: 0.6306	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:49:02 [INFO ]  Epoch:   86	Loss: 0.6432	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:49:04 [INFO ]  Epoch:   87	Loss: 0.5892	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:49:06 [INFO ]  Epoch:   88	Loss: 0.6407	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:49:08 [INFO ]  Epoch:   89	Loss: 0.5998	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:49:10 [INFO ]  Epoch:   90	Loss: 0.6699	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:49:12 [INFO ]  Epoch:   91	Loss: 0.6653	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:14 [INFO ]  Epoch:   92	Loss: 0.5737	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:49:16 [INFO ]  Epoch:   93	Loss: 0.6290	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:49:17 [INFO ]  Epoch:   94	Loss: 0.6194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:19 [INFO ]  Epoch:   95	Loss: 0.6257	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 09:49:21 [INFO ]  Epoch:   96	Loss: 0.6360	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:49:23 [INFO ]  Epoch:   97	Loss: 0.5974	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:25 [INFO ]  Epoch:   98	Loss: 0.6019	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:27 [INFO ]  Epoch:   99	Loss: 0.6378	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:49:29 [INFO ]  Epoch:  100	Loss: 0.5469	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:49:30 [INFO ]  Epoch:  101	Loss: 0.6086	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:49:32 [INFO ]  Epoch:  102	Loss: 0.6383	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:49:34 [INFO ]  Epoch:  103	Loss: 0.5512	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:49:36 [INFO ]  Epoch:  104	Loss: 0.6087	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:49:38 [INFO ]  Epoch:  105	Loss: 0.6707	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:49:40 [INFO ]  Epoch:  106	Loss: 0.6050	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:49:42 [INFO ]  Epoch:  107	Loss: 0.5975	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:49:44 [INFO ]  Epoch:  108	Loss: 0.5714	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:49:45 [INFO ]  Epoch:  109	Loss: 0.6165	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:47 [INFO ]  Epoch:  110	Loss: 0.6594	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:49:49 [INFO ]  Epoch:  111	Loss: 0.5378	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:49:51 [INFO ]  Epoch:  112	Loss: 0.6287	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:49:52 [INFO ]  Epoch:  113	Loss: 0.6869	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:49:55 [INFO ]  Epoch:  114	Loss: 0.6527	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:56 [INFO ]  Epoch:  115	Loss: 0.5868	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:49:58 [INFO ]  Epoch:  116	Loss: 0.5663	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:50:00 [INFO ]  Epoch:  117	Loss: 0.6166	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:50:02 [INFO ]  Epoch:  118	Loss: 0.6192	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:04 [INFO ]  Epoch:  119	Loss: 0.6238	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:05 [INFO ]  Epoch:  120	Loss: 0.6612	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:07 [INFO ]  Epoch:  121	Loss: 0.6065	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:09 [INFO ]  Epoch:  122	Loss: 0.5929	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:11 [INFO ]  Epoch:  123	Loss: 0.5934	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:50:13 [INFO ]  Epoch:  124	Loss: 0.5563	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:50:15 [INFO ]  Epoch:  125	Loss: 0.5842	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:50:16 [INFO ]  Epoch:  126	Loss: 0.6650	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:50:18 [INFO ]  Epoch:  127	Loss: 0.6797	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:50:20 [INFO ]  Epoch:  128	Loss: 0.6533	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:50:22 [INFO ]  Epoch:  129	Loss: 0.6087	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:24 [INFO ]  Epoch:  130	Loss: 0.5917	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:26 [INFO ]  Epoch:  131	Loss: 0.6075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:28 [INFO ]  Epoch:  132	Loss: 0.7321	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:30 [INFO ]  Epoch:  133	Loss: 0.6419	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:32 [INFO ]  Epoch:  134	Loss: 0.6128	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:50:34 [INFO ]  Epoch:  135	Loss: 0.5818	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:50:35 [INFO ]  Epoch:  136	Loss: 0.5619	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:37 [INFO ]  Epoch:  137	Loss: 0.6479	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:39 [INFO ]  Epoch:  138	Loss: 0.6280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:50:41 [INFO ]  Epoch:  139	Loss: 0.5630	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:43 [INFO ]  Epoch:  140	Loss: 0.5597	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:50:44 [INFO ]  Epoch:  141	Loss: 0.6907	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:50:46 [INFO ]  Epoch:  142	Loss: 0.6421	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:50:48 [INFO ]  Epoch:  143	Loss: 0.5589	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:50 [INFO ]  Epoch:  144	Loss: 0.5868	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:52 [INFO ]  Epoch:  145	Loss: 0.6248	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:50:53 [INFO ]  Epoch:  146	Loss: 0.6085	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:50:55 [INFO ]  Epoch:  147	Loss: 0.5861	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:50:57 [INFO ]  Epoch:  148	Loss: 0.6261	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:50:59 [INFO ]  Epoch:  149	Loss: 0.6409	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:00 [INFO ]  Epoch:  150	Loss: 0.6321	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:51:02 [INFO ]  Epoch:  151	Loss: 0.5530	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:51:04 [INFO ]  Epoch:  152	Loss: 0.6739	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:06 [INFO ]  Epoch:  153	Loss: 0.6258	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:51:08 [INFO ]  Epoch:  154	Loss: 0.6128	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:51:09 [INFO ]  Epoch:  155	Loss: 0.5837	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:11 [INFO ]  Epoch:  156	Loss: 0.6238	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:51:13 [INFO ]  Epoch:  157	Loss: 0.6079	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:51:15 [INFO ]  Epoch:  158	Loss: 0.5517	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:51:16 [INFO ]  Epoch:  159	Loss: 0.6098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:18 [INFO ]  Epoch:  160	Loss: 0.5966	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:20 [INFO ]  Epoch:  161	Loss: 0.5709	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:51:22 [INFO ]  Epoch:  162	Loss: 0.6380	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:24 [INFO ]  Epoch:  163	Loss: 0.5441	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:51:26 [INFO ]  Epoch:  164	Loss: 0.6099	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:51:28 [INFO ]  Epoch:  165	Loss: 0.6591	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:51:30 [INFO ]  Epoch:  166	Loss: 0.5827	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:51:32 [INFO ]  Epoch:  167	Loss: 0.6600	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:51:33 [INFO ]  Epoch:  168	Loss: 0.5310	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:51:35 [INFO ]  Epoch:  169	Loss: 0.5730	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:51:37 [INFO ]  Epoch:  170	Loss: 0.5539	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:51:39 [INFO ]  Epoch:  171	Loss: 0.5734	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:41 [INFO ]  Epoch:  172	Loss: 0.5993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:43 [INFO ]  Epoch:  173	Loss: 0.6531	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:45 [INFO ]  Epoch:  174	Loss: 0.5228	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 09:51:47 [INFO ]  Epoch:  175	Loss: 0.6079	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:51:48 [INFO ]  Epoch:  176	Loss: 0.5970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:50 [INFO ]  Epoch:  177	Loss: 0.7285	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:51:52 [INFO ]  Epoch:  178	Loss: 0.5950	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:54 [INFO ]  Epoch:  179	Loss: 0.5981	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:51:56 [INFO ]  Epoch:  180	Loss: 0.5781	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:51:58 [INFO ]  Epoch:  181	Loss: 0.5763	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 09:51:59 [INFO ]  Epoch:  182	Loss: 0.5766	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:01 [INFO ]  Epoch:  183	Loss: 0.6389	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:52:03 [INFO ]  Epoch:  184	Loss: 0.5632	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:52:05 [INFO ]  Epoch:  185	Loss: 0.6238	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:52:07 [INFO ]  Epoch:  186	Loss: 0.5882	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 09:52:09 [INFO ]  Epoch:  187	Loss: 0.6454	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 09:52:11 [INFO ]  Epoch:  188	Loss: 0.5929	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 09:52:12 [INFO ]  Epoch:  189	Loss: 0.5867	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:14 [INFO ]  Epoch:  190	Loss: 0.6103	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:16 [INFO ]  Epoch:  191	Loss: 0.5881	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:52:18 [INFO ]  Epoch:  192	Loss: 0.5719	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 09:52:20 [INFO ]  Epoch:  193	Loss: 0.5974	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 09:52:21 [INFO ]  Epoch:  194	Loss: 0.5673	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 09:52:23 [INFO ]  Epoch:  195	Loss: 0.6233	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:25 [INFO ]  Epoch:  196	Loss: 0.5414	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 09:52:27 [INFO ]  Epoch:  197	Loss: 0.6037	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 09:52:29 [INFO ]  Epoch:  198	Loss: 0.5733	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:31 [INFO ]  Epoch:  199	Loss: 0.6353	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 09:52:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 09:52:32 [INFO ]  
2022-10-04 09:52:32 [INFO ]  Final evaluation for SVHN :
2022-10-04 09:52:36 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:52:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:52:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 09:52:36 [INFO ]  	   step  1 (lr=0.395012)                   81.90%                   0.6738
2022-10-04 09:52:36 [INFO ]  
2022-10-04 09:52:36 [INFO ]  
2022-10-04 09:52:36 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 09:52:38 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 09:52:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 09:52:38 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 09:52:38 [INFO ]  	   step  1 (lr=0.395012)                   15.72%                   5.6326
2022-10-04 09:52:38 [INFO ]  
2022-10-04 09:52:38 [INFO ]  CPU Time: 3.42 minutes
2022-10-04 10:04:35 [INFO ]  ======================================== 2022-10-04 10:04:35 ========================================
2022-10-04 10:04:35 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 10:04:35 [INFO ]  Options: 
2022-10-04 10:04:35 [INFO ]  	base_dir: null
2022-10-04 10:04:35 [INFO ]  	batch_size: 1024
2022-10-04 10:04:35 [INFO ]  	checkpoint_interval: 300
2022-10-04 10:04:35 [INFO ]  	dataset: SVHN
2022-10-04 10:04:35 [INFO ]  	dataset_labels:
2022-10-04 10:04:35 [INFO ]  	- 0
2022-10-04 10:04:35 [INFO ]  	- 1
2022-10-04 10:04:35 [INFO ]  	- 2
2022-10-04 10:04:35 [INFO ]  	- 3
2022-10-04 10:04:35 [INFO ]  	- 4
2022-10-04 10:04:35 [INFO ]  	- 5
2022-10-04 10:04:35 [INFO ]  	- 6
2022-10-04 10:04:35 [INFO ]  	- 7
2022-10-04 10:04:35 [INFO ]  	- 8
2022-10-04 10:04:35 [INFO ]  	- 9
2022-10-04 10:04:35 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 10:04:35 [INFO ]  	- !!python/tuple
2022-10-04 10:04:35 [INFO ]  	    - 0.4379104971885681
2022-10-04 10:04:35 [INFO ]  	    - 0.44398033618927
2022-10-04 10:04:35 [INFO ]  	    - 0.4729299545288086
2022-10-04 10:04:35 [INFO ]  	- !!python/tuple
2022-10-04 10:04:35 [INFO ]  	    - 0.19803012907505035
2022-10-04 10:04:35 [INFO ]  	    - 0.2010156363248825
2022-10-04 10:04:35 [INFO ]  	    - 0.19703614711761475
2022-10-04 10:04:35 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 10:04:35 [INFO ]  	decay_epochs: 50
2022-10-04 10:04:35 [INFO ]  	decay_factor: 0.1
2022-10-04 10:04:35 [INFO ]  	device_id: 0
2022-10-04 10:04:35 [INFO ]  	distill_epochs: 1
2022-10-04 10:04:35 [INFO ]  	distill_lr: 0.02
2022-10-04 10:04:35 [INFO ]  	distill_steps: 1
2022-10-04 10:04:35 [INFO ]  	epochs: 200
2022-10-04 10:04:35 [INFO ]  	expand_cls: false
2022-10-04 10:04:35 [INFO ]  	forgetting_dataset: null
2022-10-04 10:04:35 [INFO ]  	init: xavier
2022-10-04 10:04:35 [INFO ]  	init_param: 1.0
2022-10-04 10:04:35 [INFO ]  	input_size: 32
2022-10-04 10:04:35 [INFO ]  	ipc: 20
2022-10-04 10:04:35 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 10:04:35 [INFO ]  	log_interval: 100
2022-10-04 10:04:35 [INFO ]  	log_level: INFO
2022-10-04 10:04:35 [INFO ]  	lr: 0.01
2022-10-04 10:04:35 [INFO ]  	mode: distill_adapt
2022-10-04 10:04:35 [INFO ]  	nc: 3
2022-10-04 10:04:35 [INFO ]  	num_classes: 10
2022-10-04 10:04:35 [INFO ]  	num_workers: 8
2022-10-04 10:04:35 [INFO ]  	phase: train
2022-10-04 10:04:35 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 10:04:35 [INFO ]  	start_time: '2022-10-04 10:04:35'
2022-10-04 10:04:35 [INFO ]  	test_batch_size: 1024
2022-10-04 10:04:35 [INFO ]  	
2022-10-04 10:04:37 [INFO ]  train dataset size:	73257
2022-10-04 10:04:37 [INFO ]  test dataset size: 	26032
2022-10-04 10:04:37 [INFO ]  datasets built!
2022-10-04 10:04:37 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 10:04:39 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 10:04:39 [INFO ]  
2022-10-04 10:04:39 [INFO ]  Begin of epoch 0 :
2022-10-04 10:04:42 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:04:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:04:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:04:42 [INFO ]  	   step  1 (lr=0.020000)                    7.00%                   8.5387
2022-10-04 10:04:42 [INFO ]  
2022-10-04 10:04:42 [INFO ]  Epoch:    0	Loss: 8.3990	Data Time: 0.37s	Train Time: 0.04s
2022-10-04 10:04:44 [INFO ]  Epoch:    1	Loss: 2.9981	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 10:04:46 [INFO ]  Epoch:    2	Loss: 2.4980	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:04:47 [INFO ]  Epoch:    3	Loss: 2.3050	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:04:49 [INFO ]  Epoch:    4	Loss: 2.2379	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:04:51 [INFO ]  Epoch:    5	Loss: 2.2023	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:04:53 [INFO ]  Epoch:    6	Loss: 2.1096	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:04:55 [INFO ]  Epoch:    7	Loss: 2.1267	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:04:57 [INFO ]  Epoch:    8	Loss: 2.0522	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:04:59 [INFO ]  Epoch:    9	Loss: 1.9787	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:05:00 [INFO ]  Epoch:   10	Loss: 1.8576	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:02 [INFO ]  Epoch:   11	Loss: 1.6641	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:04 [INFO ]  Epoch:   12	Loss: 1.5583	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:05:06 [INFO ]  Epoch:   13	Loss: 1.4813	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:05:08 [INFO ]  Epoch:   14	Loss: 1.3446	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:10 [INFO ]  Epoch:   15	Loss: 1.2223	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:05:11 [INFO ]  Epoch:   16	Loss: 1.1960	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:05:13 [INFO ]  Epoch:   17	Loss: 1.0559	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:15 [INFO ]  Epoch:   18	Loss: 1.0502	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:05:17 [INFO ]  Epoch:   19	Loss: 1.0431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:19 [INFO ]  Epoch:   20	Loss: 0.9492	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:20 [INFO ]  Epoch:   21	Loss: 1.0215	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:22 [INFO ]  Epoch:   22	Loss: 0.8916	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:05:24 [INFO ]  Epoch:   23	Loss: 0.9821	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:05:26 [INFO ]  Epoch:   24	Loss: 0.8744	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:28 [INFO ]  Epoch:   25	Loss: 0.9336	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:30 [INFO ]  Epoch:   26	Loss: 0.9253	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:31 [INFO ]  Epoch:   27	Loss: 0.9111	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:05:33 [INFO ]  Epoch:   28	Loss: 0.9331	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:05:35 [INFO ]  Epoch:   29	Loss: 0.9165	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:37 [INFO ]  Epoch:   30	Loss: 0.8170	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:39 [INFO ]  Epoch:   31	Loss: 0.9221	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:05:41 [INFO ]  Epoch:   32	Loss: 0.8656	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:43 [INFO ]  Epoch:   33	Loss: 0.8034	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:05:44 [INFO ]  Epoch:   34	Loss: 0.8248	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:46 [INFO ]  Epoch:   35	Loss: 0.7553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:49 [INFO ]  Epoch:   36	Loss: 0.6911	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:50 [INFO ]  Epoch:   37	Loss: 0.7111	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:52 [INFO ]  Epoch:   38	Loss: 0.7063	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:05:54 [INFO ]  Epoch:   39	Loss: 0.8541	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:05:56 [INFO ]  Epoch:   40	Loss: 0.8762	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:05:58 [INFO ]  Epoch:   41	Loss: 0.7801	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:06:00 [INFO ]  Epoch:   42	Loss: 0.7354	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:01 [INFO ]  Epoch:   43	Loss: 0.7632	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:06:03 [INFO ]  Epoch:   44	Loss: 0.6991	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:05 [INFO ]  Epoch:   45	Loss: 0.6540	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:07 [INFO ]  Epoch:   46	Loss: 0.7180	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:06:09 [INFO ]  Epoch:   47	Loss: 0.7416	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:06:11 [INFO ]  Epoch:   48	Loss: 0.6925	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:13 [INFO ]  Epoch:   49	Loss: 0.7909	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:06:15 [INFO ]  Epoch:   50	Loss: 0.6031	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:06:16 [INFO ]  Epoch:   51	Loss: 0.6808	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:06:18 [INFO ]  Epoch:   52	Loss: 0.6377	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:06:20 [INFO ]  Epoch:   53	Loss: 0.6678	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:06:22 [INFO ]  Epoch:   54	Loss: 0.6163	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:24 [INFO ]  Epoch:   55	Loss: 0.6925	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:26 [INFO ]  Epoch:   56	Loss: 0.6568	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:28 [INFO ]  Epoch:   57	Loss: 0.7138	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:06:29 [INFO ]  Epoch:   58	Loss: 0.6724	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:31 [INFO ]  Epoch:   59	Loss: 0.6606	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:06:33 [INFO ]  Epoch:   60	Loss: 0.6761	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:06:35 [INFO ]  Epoch:   61	Loss: 0.5666	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:37 [INFO ]  Epoch:   62	Loss: 0.6736	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:38 [INFO ]  Epoch:   63	Loss: 0.5555	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:40 [INFO ]  Epoch:   64	Loss: 0.6526	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:42 [INFO ]  Epoch:   65	Loss: 0.6808	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:06:44 [INFO ]  Epoch:   66	Loss: 0.6667	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:06:46 [INFO ]  Epoch:   67	Loss: 0.6538	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:06:48 [INFO ]  Epoch:   68	Loss: 0.6039	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:50 [INFO ]  Epoch:   69	Loss: 0.5664	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:06:51 [INFO ]  Epoch:   70	Loss: 0.6190	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:06:53 [INFO ]  Epoch:   71	Loss: 0.5963	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:06:55 [INFO ]  Epoch:   72	Loss: 0.5976	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:57 [INFO ]  Epoch:   73	Loss: 0.6569	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:06:58 [INFO ]  Epoch:   74	Loss: 0.6255	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:07:00 [INFO ]  Epoch:   75	Loss: 0.5854	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:02 [INFO ]  Epoch:   76	Loss: 0.5912	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:07:04 [INFO ]  Epoch:   77	Loss: 0.5963	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:07:06 [INFO ]  Epoch:   78	Loss: 0.6443	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:07:07 [INFO ]  Epoch:   79	Loss: 0.6767	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:09 [INFO ]  Epoch:   80	Loss: 0.6656	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:07:11 [INFO ]  Epoch:   81	Loss: 0.6312	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:07:13 [INFO ]  Epoch:   82	Loss: 0.6938	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:14 [INFO ]  Epoch:   83	Loss: 0.6627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:16 [INFO ]  Epoch:   84	Loss: 0.5995	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:18 [INFO ]  Epoch:   85	Loss: 0.6626	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:07:20 [INFO ]  Epoch:   86	Loss: 0.7087	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:07:22 [INFO ]  Epoch:   87	Loss: 0.6477	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:23 [INFO ]  Epoch:   88	Loss: 0.5579	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:25 [INFO ]  Epoch:   89	Loss: 0.6114	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:07:27 [INFO ]  Epoch:   90	Loss: 0.7165	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:07:29 [INFO ]  Epoch:   91	Loss: 0.5425	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:07:31 [INFO ]  Epoch:   92	Loss: 0.6346	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:33 [INFO ]  Epoch:   93	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:07:35 [INFO ]  Epoch:   94	Loss: 0.7643	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:07:36 [INFO ]  Epoch:   95	Loss: 0.6643	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:07:38 [INFO ]  Epoch:   96	Loss: 0.6048	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:07:40 [INFO ]  Epoch:   97	Loss: 0.5705	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:42 [INFO ]  Epoch:   98	Loss: 0.5897	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:07:44 [INFO ]  Epoch:   99	Loss: 0.6308	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:07:45 [INFO ]  Epoch:  100	Loss: 0.6358	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:47 [INFO ]  Epoch:  101	Loss: 0.6244	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:07:49 [INFO ]  Epoch:  102	Loss: 0.5774	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:51 [INFO ]  Epoch:  103	Loss: 0.6650	Data Time: 0.25s	Train Time: 0.00s
2022-10-04 10:07:53 [INFO ]  Epoch:  104	Loss: 0.6379	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:07:55 [INFO ]  Epoch:  105	Loss: 0.6053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:07:57 [INFO ]  Epoch:  106	Loss: 0.6578	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:07:58 [INFO ]  Epoch:  107	Loss: 0.5792	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:00 [INFO ]  Epoch:  108	Loss: 0.6278	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:02 [INFO ]  Epoch:  109	Loss: 0.6649	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:08:04 [INFO ]  Epoch:  110	Loss: 0.6367	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:06 [INFO ]  Epoch:  111	Loss: 0.5686	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:07 [INFO ]  Epoch:  112	Loss: 0.5804	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:09 [INFO ]  Epoch:  113	Loss: 0.6136	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:11 [INFO ]  Epoch:  114	Loss: 0.6858	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:08:13 [INFO ]  Epoch:  115	Loss: 0.5953	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:08:15 [INFO ]  Epoch:  116	Loss: 0.5070	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:16 [INFO ]  Epoch:  117	Loss: 0.4699	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:18 [INFO ]  Epoch:  118	Loss: 0.5686	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:08:20 [INFO ]  Epoch:  119	Loss: 0.6193	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:22 [INFO ]  Epoch:  120	Loss: 0.5737	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:24 [INFO ]  Epoch:  121	Loss: 0.5496	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:26 [INFO ]  Epoch:  122	Loss: 0.5646	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:08:27 [INFO ]  Epoch:  123	Loss: 0.6085	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:08:29 [INFO ]  Epoch:  124	Loss: 0.5463	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:31 [INFO ]  Epoch:  125	Loss: 0.5865	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:33 [INFO ]  Epoch:  126	Loss: 0.5969	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:08:35 [INFO ]  Epoch:  127	Loss: 0.6204	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:37 [INFO ]  Epoch:  128	Loss: 0.5571	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:08:39 [INFO ]  Epoch:  129	Loss: 0.5748	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:08:40 [INFO ]  Epoch:  130	Loss: 0.6005	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:42 [INFO ]  Epoch:  131	Loss: 0.5368	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:44 [INFO ]  Epoch:  132	Loss: 0.5041	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:46 [INFO ]  Epoch:  133	Loss: 0.5767	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:48 [INFO ]  Epoch:  134	Loss: 0.6150	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:50 [INFO ]  Epoch:  135	Loss: 0.5908	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:52 [INFO ]  Epoch:  136	Loss: 0.5836	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:08:53 [INFO ]  Epoch:  137	Loss: 0.6551	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:08:55 [INFO ]  Epoch:  138	Loss: 0.5764	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:08:57 [INFO ]  Epoch:  139	Loss: 0.5578	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:08:59 [INFO ]  Epoch:  140	Loss: 0.5722	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:09:01 [INFO ]  Epoch:  141	Loss: 0.5713	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:09:03 [INFO ]  Epoch:  142	Loss: 0.5968	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:05 [INFO ]  Epoch:  143	Loss: 0.6282	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:06 [INFO ]  Epoch:  144	Loss: 0.5897	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:09:08 [INFO ]  Epoch:  145	Loss: 0.6214	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:10 [INFO ]  Epoch:  146	Loss: 0.6074	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:12 [INFO ]  Epoch:  147	Loss: 0.5897	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:14 [INFO ]  Epoch:  148	Loss: 0.6588	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:15 [INFO ]  Epoch:  149	Loss: 0.5708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:17 [INFO ]  Epoch:  150	Loss: 0.5619	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:19 [INFO ]  Epoch:  151	Loss: 0.5897	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:21 [INFO ]  Epoch:  152	Loss: 0.5511	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:09:23 [INFO ]  Epoch:  153	Loss: 0.5465	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:25 [INFO ]  Epoch:  154	Loss: 0.6156	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:09:27 [INFO ]  Epoch:  155	Loss: 0.5787	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:09:28 [INFO ]  Epoch:  156	Loss: 0.6074	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:30 [INFO ]  Epoch:  157	Loss: 0.5918	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:09:32 [INFO ]  Epoch:  158	Loss: 0.6183	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:34 [INFO ]  Epoch:  159	Loss: 0.6163	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:09:36 [INFO ]  Epoch:  160	Loss: 0.6055	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:09:38 [INFO ]  Epoch:  161	Loss: 0.6105	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:40 [INFO ]  Epoch:  162	Loss: 0.5983	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:09:41 [INFO ]  Epoch:  163	Loss: 0.5530	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:43 [INFO ]  Epoch:  164	Loss: 0.5799	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:09:45 [INFO ]  Epoch:  165	Loss: 0.5438	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:09:47 [INFO ]  Epoch:  166	Loss: 0.6624	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:09:48 [INFO ]  Epoch:  167	Loss: 0.5583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:09:51 [INFO ]  Epoch:  168	Loss: 0.6666	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:53 [INFO ]  Epoch:  169	Loss: 0.5916	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:54 [INFO ]  Epoch:  170	Loss: 0.6013	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 10:09:56 [INFO ]  Epoch:  171	Loss: 0.6090	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:09:58 [INFO ]  Epoch:  172	Loss: 0.6490	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:10:00 [INFO ]  Epoch:  173	Loss: 0.5797	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:10:02 [INFO ]  Epoch:  174	Loss: 0.5533	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:10:04 [INFO ]  Epoch:  175	Loss: 0.5420	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:10:05 [INFO ]  Epoch:  176	Loss: 0.5181	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:10:07 [INFO ]  Epoch:  177	Loss: 0.6917	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:10:09 [INFO ]  Epoch:  178	Loss: 0.5671	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:11 [INFO ]  Epoch:  179	Loss: 0.5446	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:10:12 [INFO ]  Epoch:  180	Loss: 0.5744	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:10:14 [INFO ]  Epoch:  181	Loss: 0.5804	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:16 [INFO ]  Epoch:  182	Loss: 0.5854	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:10:18 [INFO ]  Epoch:  183	Loss: 0.5970	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:10:20 [INFO ]  Epoch:  184	Loss: 0.5871	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:10:22 [INFO ]  Epoch:  185	Loss: 0.5879	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:10:24 [INFO ]  Epoch:  186	Loss: 0.6782	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:10:26 [INFO ]  Epoch:  187	Loss: 0.6355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:27 [INFO ]  Epoch:  188	Loss: 0.5503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:29 [INFO ]  Epoch:  189	Loss: 0.5585	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:10:31 [INFO ]  Epoch:  190	Loss: 0.5620	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:10:33 [INFO ]  Epoch:  191	Loss: 0.5310	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:10:35 [INFO ]  Epoch:  192	Loss: 0.6011	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:10:37 [INFO ]  Epoch:  193	Loss: 0.5581	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:10:39 [INFO ]  Epoch:  194	Loss: 0.5655	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:10:40 [INFO ]  Epoch:  195	Loss: 0.5946	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:42 [INFO ]  Epoch:  196	Loss: 0.5998	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:10:44 [INFO ]  Epoch:  197	Loss: 0.6252	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:10:46 [INFO ]  Epoch:  198	Loss: 0.6305	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:10:48 [INFO ]  Epoch:  199	Loss: 0.5829	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:10:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 10:10:49 [INFO ]  
2022-10-04 10:10:49 [INFO ]  Final evaluation for SVHN :
2022-10-04 10:10:53 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:10:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:10:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:10:53 [INFO ]  	   step  1 (lr=0.403702)                   81.76%                   0.6627
2022-10-04 10:10:53 [INFO ]  
2022-10-04 10:10:53 [INFO ]  
2022-10-04 10:10:53 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 10:10:56 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:10:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:10:56 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 10:10:56 [INFO ]  	   step  1 (lr=0.403702)                   15.71%                   5.2559
2022-10-04 10:10:56 [INFO ]  
2022-10-04 10:10:56 [INFO ]  CPU Time: 3.43 minutes
2022-10-04 10:23:09 [INFO ]  ======================================== 2022-10-04 10:23:09 ========================================
2022-10-04 10:23:09 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 10:23:09 [INFO ]  Options: 
2022-10-04 10:23:09 [INFO ]  	base_dir: null
2022-10-04 10:23:09 [INFO ]  	batch_size: 1024
2022-10-04 10:23:09 [INFO ]  	checkpoint_interval: 300
2022-10-04 10:23:09 [INFO ]  	dataset: SVHN
2022-10-04 10:23:09 [INFO ]  	dataset_labels:
2022-10-04 10:23:09 [INFO ]  	- 0
2022-10-04 10:23:09 [INFO ]  	- 1
2022-10-04 10:23:09 [INFO ]  	- 2
2022-10-04 10:23:09 [INFO ]  	- 3
2022-10-04 10:23:09 [INFO ]  	- 4
2022-10-04 10:23:09 [INFO ]  	- 5
2022-10-04 10:23:09 [INFO ]  	- 6
2022-10-04 10:23:09 [INFO ]  	- 7
2022-10-04 10:23:09 [INFO ]  	- 8
2022-10-04 10:23:09 [INFO ]  	- 9
2022-10-04 10:23:09 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 10:23:09 [INFO ]  	- !!python/tuple
2022-10-04 10:23:09 [INFO ]  	    - 0.4379104971885681
2022-10-04 10:23:09 [INFO ]  	    - 0.44398033618927
2022-10-04 10:23:09 [INFO ]  	    - 0.4729299545288086
2022-10-04 10:23:09 [INFO ]  	- !!python/tuple
2022-10-04 10:23:09 [INFO ]  	    - 0.19803012907505035
2022-10-04 10:23:09 [INFO ]  	    - 0.2010156363248825
2022-10-04 10:23:09 [INFO ]  	    - 0.19703614711761475
2022-10-04 10:23:09 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 10:23:09 [INFO ]  	decay_epochs: 50
2022-10-04 10:23:09 [INFO ]  	decay_factor: 0.1
2022-10-04 10:23:09 [INFO ]  	device_id: 0
2022-10-04 10:23:09 [INFO ]  	distill_epochs: 1
2022-10-04 10:23:09 [INFO ]  	distill_lr: 0.02
2022-10-04 10:23:09 [INFO ]  	distill_steps: 1
2022-10-04 10:23:09 [INFO ]  	epochs: 200
2022-10-04 10:23:09 [INFO ]  	expand_cls: false
2022-10-04 10:23:09 [INFO ]  	forgetting_dataset: null
2022-10-04 10:23:09 [INFO ]  	init: xavier
2022-10-04 10:23:09 [INFO ]  	init_param: 1.0
2022-10-04 10:23:09 [INFO ]  	input_size: 32
2022-10-04 10:23:09 [INFO ]  	ipc: 20
2022-10-04 10:23:09 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 10:23:09 [INFO ]  	log_interval: 100
2022-10-04 10:23:09 [INFO ]  	log_level: INFO
2022-10-04 10:23:09 [INFO ]  	lr: 0.01
2022-10-04 10:23:09 [INFO ]  	mode: distill_adapt
2022-10-04 10:23:09 [INFO ]  	nc: 3
2022-10-04 10:23:09 [INFO ]  	num_classes: 10
2022-10-04 10:23:09 [INFO ]  	num_workers: 8
2022-10-04 10:23:09 [INFO ]  	phase: train
2022-10-04 10:23:09 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 10:23:09 [INFO ]  	start_time: '2022-10-04 10:23:09'
2022-10-04 10:23:09 [INFO ]  	test_batch_size: 1024
2022-10-04 10:23:09 [INFO ]  	
2022-10-04 10:23:11 [INFO ]  train dataset size:	73257
2022-10-04 10:23:11 [INFO ]  test dataset size: 	26032
2022-10-04 10:23:11 [INFO ]  datasets built!
2022-10-04 10:23:11 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 10:23:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 10:23:13 [INFO ]  
2022-10-04 10:23:13 [INFO ]  Begin of epoch 0 :
2022-10-04 10:23:16 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:23:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:23:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:23:16 [INFO ]  	   step  1 (lr=0.020000)                    7.16%                   9.1882
2022-10-04 10:23:16 [INFO ]  
2022-10-04 10:23:16 [INFO ]  Epoch:    0	Loss: 8.8785	Data Time: 0.37s	Train Time: 0.04s
2022-10-04 10:23:18 [INFO ]  Epoch:    1	Loss: 2.9236	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 10:23:20 [INFO ]  Epoch:    2	Loss: 2.5155	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:22 [INFO ]  Epoch:    3	Loss: 2.2997	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:23:23 [INFO ]  Epoch:    4	Loss: 2.2018	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:23:25 [INFO ]  Epoch:    5	Loss: 2.2039	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:23:27 [INFO ]  Epoch:    6	Loss: 2.1514	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:29 [INFO ]  Epoch:    7	Loss: 2.0793	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:23:31 [INFO ]  Epoch:    8	Loss: 2.0664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:32 [INFO ]  Epoch:    9	Loss: 1.9860	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:34 [INFO ]  Epoch:   10	Loss: 1.8310	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:36 [INFO ]  Epoch:   11	Loss: 1.6962	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:38 [INFO ]  Epoch:   12	Loss: 1.5889	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:40 [INFO ]  Epoch:   13	Loss: 1.5056	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:23:41 [INFO ]  Epoch:   14	Loss: 1.3040	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:23:43 [INFO ]  Epoch:   15	Loss: 1.2304	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:23:45 [INFO ]  Epoch:   16	Loss: 1.2170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:47 [INFO ]  Epoch:   17	Loss: 1.1824	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:23:49 [INFO ]  Epoch:   18	Loss: 1.1036	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:51 [INFO ]  Epoch:   19	Loss: 1.0812	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:23:52 [INFO ]  Epoch:   20	Loss: 0.9865	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:23:54 [INFO ]  Epoch:   21	Loss: 0.9692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:56 [INFO ]  Epoch:   22	Loss: 1.1754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:23:58 [INFO ]  Epoch:   23	Loss: 1.0037	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:24:00 [INFO ]  Epoch:   24	Loss: 1.0266	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:24:02 [INFO ]  Epoch:   25	Loss: 0.9895	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:03 [INFO ]  Epoch:   26	Loss: 0.9483	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:24:05 [INFO ]  Epoch:   27	Loss: 1.1209	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:24:07 [INFO ]  Epoch:   28	Loss: 0.9721	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:24:09 [INFO ]  Epoch:   29	Loss: 0.8316	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:24:11 [INFO ]  Epoch:   30	Loss: 0.8704	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:13 [INFO ]  Epoch:   31	Loss: 0.8832	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:24:14 [INFO ]  Epoch:   32	Loss: 0.8209	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:24:16 [INFO ]  Epoch:   33	Loss: 0.7222	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:24:19 [INFO ]  Epoch:   34	Loss: 0.8672	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:24:20 [INFO ]  Epoch:   35	Loss: 0.7974	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:24:22 [INFO ]  Epoch:   36	Loss: 0.7744	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:24 [INFO ]  Epoch:   37	Loss: 0.8391	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:24:26 [INFO ]  Epoch:   38	Loss: 0.8104	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:28 [INFO ]  Epoch:   39	Loss: 0.7900	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:24:30 [INFO ]  Epoch:   40	Loss: 0.8111	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:24:32 [INFO ]  Epoch:   41	Loss: 0.7755	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:33 [INFO ]  Epoch:   42	Loss: 0.7603	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:35 [INFO ]  Epoch:   43	Loss: 0.7705	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:24:37 [INFO ]  Epoch:   44	Loss: 0.7123	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:24:39 [INFO ]  Epoch:   45	Loss: 0.7180	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:41 [INFO ]  Epoch:   46	Loss: 0.7002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:43 [INFO ]  Epoch:   47	Loss: 0.6660	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:45 [INFO ]  Epoch:   48	Loss: 0.6975	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:46 [INFO ]  Epoch:   49	Loss: 0.7487	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:24:48 [INFO ]  Epoch:   50	Loss: 0.6012	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:24:50 [INFO ]  Epoch:   51	Loss: 0.5983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:24:52 [INFO ]  Epoch:   52	Loss: 0.7059	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:24:54 [INFO ]  Epoch:   53	Loss: 0.7042	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:24:55 [INFO ]  Epoch:   54	Loss: 0.7720	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:24:57 [INFO ]  Epoch:   55	Loss: 0.7123	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:24:59 [INFO ]  Epoch:   56	Loss: 0.5900	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:25:01 [INFO ]  Epoch:   57	Loss: 0.6363	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:03 [INFO ]  Epoch:   58	Loss: 0.7030	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:25:05 [INFO ]  Epoch:   59	Loss: 0.7085	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:25:07 [INFO ]  Epoch:   60	Loss: 0.6630	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:25:09 [INFO ]  Epoch:   61	Loss: 0.7055	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:25:11 [INFO ]  Epoch:   62	Loss: 0.5962	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:25:13 [INFO ]  Epoch:   63	Loss: 0.6119	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:25:14 [INFO ]  Epoch:   64	Loss: 0.6825	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:16 [INFO ]  Epoch:   65	Loss: 0.6349	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:25:18 [INFO ]  Epoch:   66	Loss: 0.6461	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:25:20 [INFO ]  Epoch:   67	Loss: 0.6092	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:22 [INFO ]  Epoch:   68	Loss: 0.6336	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:23 [INFO ]  Epoch:   69	Loss: 0.6976	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:25:25 [INFO ]  Epoch:   70	Loss: 0.6147	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:27 [INFO ]  Epoch:   71	Loss: 0.6492	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:25:29 [INFO ]  Epoch:   72	Loss: 0.6183	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:30 [INFO ]  Epoch:   73	Loss: 0.6088	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:33 [INFO ]  Epoch:   74	Loss: 0.5973	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:34 [INFO ]  Epoch:   75	Loss: 0.6558	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:25:36 [INFO ]  Epoch:   76	Loss: 0.6151	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:25:38 [INFO ]  Epoch:   77	Loss: 0.6125	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:40 [INFO ]  Epoch:   78	Loss: 0.5487	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:41 [INFO ]  Epoch:   79	Loss: 0.7194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:43 [INFO ]  Epoch:   80	Loss: 0.5920	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:45 [INFO ]  Epoch:   81	Loss: 0.5889	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:25:46 [INFO ]  Epoch:   82	Loss: 0.6635	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:25:48 [INFO ]  Epoch:   83	Loss: 0.6266	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:25:50 [INFO ]  Epoch:   84	Loss: 0.6931	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:52 [INFO ]  Epoch:   85	Loss: 0.5588	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:54 [INFO ]  Epoch:   86	Loss: 0.6799	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:55 [INFO ]  Epoch:   87	Loss: 0.5622	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:25:57 [INFO ]  Epoch:   88	Loss: 0.6388	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:25:59 [INFO ]  Epoch:   89	Loss: 0.6244	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:01 [INFO ]  Epoch:   90	Loss: 0.6238	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:02 [INFO ]  Epoch:   91	Loss: 0.6249	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:04 [INFO ]  Epoch:   92	Loss: 0.6554	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:26:06 [INFO ]  Epoch:   93	Loss: 0.6876	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:26:08 [INFO ]  Epoch:   94	Loss: 0.6594	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:10 [INFO ]  Epoch:   95	Loss: 0.6228	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:11 [INFO ]  Epoch:   96	Loss: 0.6240	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:13 [INFO ]  Epoch:   97	Loss: 0.6210	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:26:15 [INFO ]  Epoch:   98	Loss: 0.6117	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:17 [INFO ]  Epoch:   99	Loss: 0.6032	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:19 [INFO ]  Epoch:  100	Loss: 0.5902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:21 [INFO ]  Epoch:  101	Loss: 0.6445	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:22 [INFO ]  Epoch:  102	Loss: 0.5906	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:24 [INFO ]  Epoch:  103	Loss: 0.6279	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:26:26 [INFO ]  Epoch:  104	Loss: 0.6091	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:28 [INFO ]  Epoch:  105	Loss: 0.5500	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:30 [INFO ]  Epoch:  106	Loss: 0.7009	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:32 [INFO ]  Epoch:  107	Loss: 0.6050	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:33 [INFO ]  Epoch:  108	Loss: 0.5317	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:26:35 [INFO ]  Epoch:  109	Loss: 0.5709	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:26:37 [INFO ]  Epoch:  110	Loss: 0.6214	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:26:39 [INFO ]  Epoch:  111	Loss: 0.6348	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:41 [INFO ]  Epoch:  112	Loss: 0.6489	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:43 [INFO ]  Epoch:  113	Loss: 0.5772	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:45 [INFO ]  Epoch:  114	Loss: 0.6658	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:26:47 [INFO ]  Epoch:  115	Loss: 0.6568	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:26:49 [INFO ]  Epoch:  116	Loss: 0.5435	Data Time: 0.25s	Train Time: 0.00s
2022-10-04 10:26:50 [INFO ]  Epoch:  117	Loss: 0.6083	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:26:52 [INFO ]  Epoch:  118	Loss: 0.5585	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:26:54 [INFO ]  Epoch:  119	Loss: 0.6040	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:26:56 [INFO ]  Epoch:  120	Loss: 0.5842	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:26:58 [INFO ]  Epoch:  121	Loss: 0.6683	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:27:00 [INFO ]  Epoch:  122	Loss: 0.7075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:01 [INFO ]  Epoch:  123	Loss: 0.5870	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:27:03 [INFO ]  Epoch:  124	Loss: 0.5841	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:27:05 [INFO ]  Epoch:  125	Loss: 0.6186	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:07 [INFO ]  Epoch:  126	Loss: 0.5924	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:09 [INFO ]  Epoch:  127	Loss: 0.5705	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:27:11 [INFO ]  Epoch:  128	Loss: 0.5554	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:13 [INFO ]  Epoch:  129	Loss: 0.6184	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:27:15 [INFO ]  Epoch:  130	Loss: 0.5709	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:17 [INFO ]  Epoch:  131	Loss: 0.5895	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:27:18 [INFO ]  Epoch:  132	Loss: 0.6683	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:20 [INFO ]  Epoch:  133	Loss: 0.5932	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:27:22 [INFO ]  Epoch:  134	Loss: 0.6267	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:24 [INFO ]  Epoch:  135	Loss: 0.5906	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:27:26 [INFO ]  Epoch:  136	Loss: 0.6415	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:27:28 [INFO ]  Epoch:  137	Loss: 0.6222	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:30 [INFO ]  Epoch:  138	Loss: 0.5517	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:27:32 [INFO ]  Epoch:  139	Loss: 0.5545	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:33 [INFO ]  Epoch:  140	Loss: 0.6338	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:35 [INFO ]  Epoch:  141	Loss: 0.6247	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:37 [INFO ]  Epoch:  142	Loss: 0.6191	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:39 [INFO ]  Epoch:  143	Loss: 0.5440	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:41 [INFO ]  Epoch:  144	Loss: 0.5912	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:27:42 [INFO ]  Epoch:  145	Loss: 0.6420	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:44 [INFO ]  Epoch:  146	Loss: 0.6043	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:27:46 [INFO ]  Epoch:  147	Loss: 0.7020	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:48 [INFO ]  Epoch:  148	Loss: 0.6380	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:27:50 [INFO ]  Epoch:  149	Loss: 0.6068	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:52 [INFO ]  Epoch:  150	Loss: 0.5575	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:27:54 [INFO ]  Epoch:  151	Loss: 0.6573	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:27:56 [INFO ]  Epoch:  152	Loss: 0.6239	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:27:57 [INFO ]  Epoch:  153	Loss: 0.5361	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:27:59 [INFO ]  Epoch:  154	Loss: 0.6195	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:01 [INFO ]  Epoch:  155	Loss: 0.6173	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:03 [INFO ]  Epoch:  156	Loss: 0.5593	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:28:05 [INFO ]  Epoch:  157	Loss: 0.6798	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:07 [INFO ]  Epoch:  158	Loss: 0.6316	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:09 [INFO ]  Epoch:  159	Loss: 0.6763	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:11 [INFO ]  Epoch:  160	Loss: 0.6628	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:28:13 [INFO ]  Epoch:  161	Loss: 0.6154	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:14 [INFO ]  Epoch:  162	Loss: 0.6406	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:16 [INFO ]  Epoch:  163	Loss: 0.6276	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:28:18 [INFO ]  Epoch:  164	Loss: 0.6073	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:20 [INFO ]  Epoch:  165	Loss: 0.6026	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:22 [INFO ]  Epoch:  166	Loss: 0.6439	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:28:24 [INFO ]  Epoch:  167	Loss: 0.5477	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:26 [INFO ]  Epoch:  168	Loss: 0.6760	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:28 [INFO ]  Epoch:  169	Loss: 0.6029	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:29 [INFO ]  Epoch:  170	Loss: 0.5538	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:28:31 [INFO ]  Epoch:  171	Loss: 0.6075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:33 [INFO ]  Epoch:  172	Loss: 0.6639	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:35 [INFO ]  Epoch:  173	Loss: 0.5847	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:37 [INFO ]  Epoch:  174	Loss: 0.6043	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:28:38 [INFO ]  Epoch:  175	Loss: 0.5479	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:40 [INFO ]  Epoch:  176	Loss: 0.5403	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:28:42 [INFO ]  Epoch:  177	Loss: 0.5926	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:28:44 [INFO ]  Epoch:  178	Loss: 0.5529	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:28:46 [INFO ]  Epoch:  179	Loss: 0.6336	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:28:47 [INFO ]  Epoch:  180	Loss: 0.5728	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:49 [INFO ]  Epoch:  181	Loss: 0.6138	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:28:51 [INFO ]  Epoch:  182	Loss: 0.5951	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:53 [INFO ]  Epoch:  183	Loss: 0.5199	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:28:55 [INFO ]  Epoch:  184	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:28:57 [INFO ]  Epoch:  185	Loss: 0.6076	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:28:59 [INFO ]  Epoch:  186	Loss: 0.5675	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:29:00 [INFO ]  Epoch:  187	Loss: 0.5536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:02 [INFO ]  Epoch:  188	Loss: 0.6036	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:29:04 [INFO ]  Epoch:  189	Loss: 0.6661	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:29:06 [INFO ]  Epoch:  190	Loss: 0.6307	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:08 [INFO ]  Epoch:  191	Loss: 0.5649	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:29:09 [INFO ]  Epoch:  192	Loss: 0.5662	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:29:11 [INFO ]  Epoch:  193	Loss: 0.5317	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:13 [INFO ]  Epoch:  194	Loss: 0.5634	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:29:15 [INFO ]  Epoch:  195	Loss: 0.5272	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:17 [INFO ]  Epoch:  196	Loss: 0.5504	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:29:19 [INFO ]  Epoch:  197	Loss: 0.5656	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:20 [INFO ]  Epoch:  198	Loss: 0.6076	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:29:22 [INFO ]  Epoch:  199	Loss: 0.5898	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:29:24 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 10:29:24 [INFO ]  
2022-10-04 10:29:24 [INFO ]  Final evaluation for SVHN :
2022-10-04 10:29:27 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:29:27 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:29:27 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:29:27 [INFO ]  	   step  1 (lr=0.412407)                   81.54%                   0.6824
2022-10-04 10:29:27 [INFO ]  
2022-10-04 10:29:27 [INFO ]  
2022-10-04 10:29:27 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 10:29:30 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:29:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:29:30 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 10:29:30 [INFO ]  	   step  1 (lr=0.412407)                   15.74%                   5.1681
2022-10-04 10:29:30 [INFO ]  
2022-10-04 10:29:30 [INFO ]  CPU Time: 3.44 minutes
2022-10-04 10:31:24 [INFO ]  ======================================== 2022-10-04 10:31:24 ========================================
2022-10-04 10:31:24 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 10:31:24 [INFO ]  Options: 
2022-10-04 10:31:24 [INFO ]  	base_dir: null
2022-10-04 10:31:24 [INFO ]  	batch_size: 1024
2022-10-04 10:31:24 [INFO ]  	checkpoint_interval: 300
2022-10-04 10:31:24 [INFO ]  	dataset: SVHN
2022-10-04 10:31:24 [INFO ]  	dataset_labels:
2022-10-04 10:31:24 [INFO ]  	- 0
2022-10-04 10:31:24 [INFO ]  	- 1
2022-10-04 10:31:24 [INFO ]  	- 2
2022-10-04 10:31:24 [INFO ]  	- 3
2022-10-04 10:31:24 [INFO ]  	- 4
2022-10-04 10:31:24 [INFO ]  	- 5
2022-10-04 10:31:24 [INFO ]  	- 6
2022-10-04 10:31:24 [INFO ]  	- 7
2022-10-04 10:31:24 [INFO ]  	- 8
2022-10-04 10:31:24 [INFO ]  	- 9
2022-10-04 10:31:24 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 10:31:24 [INFO ]  	- !!python/tuple
2022-10-04 10:31:24 [INFO ]  	    - 0.4379104971885681
2022-10-04 10:31:24 [INFO ]  	    - 0.44398033618927
2022-10-04 10:31:24 [INFO ]  	    - 0.4729299545288086
2022-10-04 10:31:24 [INFO ]  	- !!python/tuple
2022-10-04 10:31:24 [INFO ]  	    - 0.19803012907505035
2022-10-04 10:31:24 [INFO ]  	    - 0.2010156363248825
2022-10-04 10:31:24 [INFO ]  	    - 0.19703614711761475
2022-10-04 10:31:24 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 10:31:24 [INFO ]  	decay_epochs: 50
2022-10-04 10:31:24 [INFO ]  	decay_factor: 0.1
2022-10-04 10:31:24 [INFO ]  	device_id: 0
2022-10-04 10:31:24 [INFO ]  	distill_epochs: 1
2022-10-04 10:31:24 [INFO ]  	distill_lr: 0.02
2022-10-04 10:31:24 [INFO ]  	distill_steps: 1
2022-10-04 10:31:24 [INFO ]  	epochs: 200
2022-10-04 10:31:24 [INFO ]  	expand_cls: false
2022-10-04 10:31:24 [INFO ]  	forgetting_dataset: null
2022-10-04 10:31:24 [INFO ]  	init: xavier
2022-10-04 10:31:24 [INFO ]  	init_param: 1.0
2022-10-04 10:31:24 [INFO ]  	input_size: 32
2022-10-04 10:31:24 [INFO ]  	ipc: 20
2022-10-04 10:31:24 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 10:31:24 [INFO ]  	log_interval: 100
2022-10-04 10:31:24 [INFO ]  	log_level: INFO
2022-10-04 10:31:24 [INFO ]  	lr: 0.01
2022-10-04 10:31:24 [INFO ]  	mode: distill_adapt
2022-10-04 10:31:24 [INFO ]  	nc: 3
2022-10-04 10:31:24 [INFO ]  	num_classes: 10
2022-10-04 10:31:24 [INFO ]  	num_workers: 8
2022-10-04 10:31:24 [INFO ]  	phase: train
2022-10-04 10:31:24 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 10:31:24 [INFO ]  	start_time: '2022-10-04 10:31:24'
2022-10-04 10:31:24 [INFO ]  	test_batch_size: 1024
2022-10-04 10:31:24 [INFO ]  	
2022-10-04 10:31:27 [INFO ]  train dataset size:	73257
2022-10-04 10:31:27 [INFO ]  test dataset size: 	26032
2022-10-04 10:31:27 [INFO ]  datasets built!
2022-10-04 10:31:27 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 10:31:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 10:31:28 [INFO ]  
2022-10-04 10:31:28 [INFO ]  Begin of epoch 0 :
2022-10-04 10:31:32 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:31:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:31:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:31:32 [INFO ]  	   step  1 (lr=0.020000)                    7.48%                   8.2346
2022-10-04 10:31:32 [INFO ]  
2022-10-04 10:31:32 [INFO ]  Epoch:    0	Loss: 7.6735	Data Time: 0.39s	Train Time: 0.04s
2022-10-04 10:31:33 [INFO ]  Epoch:    1	Loss: 3.0496	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:31:35 [INFO ]  Epoch:    2	Loss: 2.4128	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:31:37 [INFO ]  Epoch:    3	Loss: 2.2568	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:31:39 [INFO ]  Epoch:    4	Loss: 2.2342	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:31:41 [INFO ]  Epoch:    5	Loss: 2.1464	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:31:43 [INFO ]  Epoch:    6	Loss: 2.1447	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:31:44 [INFO ]  Epoch:    7	Loss: 2.1064	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:31:46 [INFO ]  Epoch:    8	Loss: 2.0664	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:31:48 [INFO ]  Epoch:    9	Loss: 1.9932	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:31:50 [INFO ]  Epoch:   10	Loss: 1.8201	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:31:51 [INFO ]  Epoch:   11	Loss: 1.6910	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:31:53 [INFO ]  Epoch:   12	Loss: 1.5854	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:31:55 [INFO ]  Epoch:   13	Loss: 1.4178	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:31:57 [INFO ]  Epoch:   14	Loss: 1.3263	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:31:59 [INFO ]  Epoch:   15	Loss: 1.3433	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:32:00 [INFO ]  Epoch:   16	Loss: 1.2302	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:32:02 [INFO ]  Epoch:   17	Loss: 1.1322	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:04 [INFO ]  Epoch:   18	Loss: 1.1572	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:06 [INFO ]  Epoch:   19	Loss: 1.0194	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:32:08 [INFO ]  Epoch:   20	Loss: 1.0319	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:32:10 [INFO ]  Epoch:   21	Loss: 0.9943	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:32:12 [INFO ]  Epoch:   22	Loss: 1.0233	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:32:14 [INFO ]  Epoch:   23	Loss: 0.9353	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:16 [INFO ]  Epoch:   24	Loss: 0.9619	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:32:17 [INFO ]  Epoch:   25	Loss: 0.9156	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:19 [INFO ]  Epoch:   26	Loss: 0.9527	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:21 [INFO ]  Epoch:   27	Loss: 1.0583	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:23 [INFO ]  Epoch:   28	Loss: 0.8124	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:32:25 [INFO ]  Epoch:   29	Loss: 0.7920	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:26 [INFO ]  Epoch:   30	Loss: 0.7633	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:32:28 [INFO ]  Epoch:   31	Loss: 0.7469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:30 [INFO ]  Epoch:   32	Loss: 0.8114	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:32:32 [INFO ]  Epoch:   33	Loss: 0.8167	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:32:34 [INFO ]  Epoch:   34	Loss: 1.0624	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:32:36 [INFO ]  Epoch:   35	Loss: 0.8178	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:32:38 [INFO ]  Epoch:   36	Loss: 0.7689	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:40 [INFO ]  Epoch:   37	Loss: 0.7125	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:32:41 [INFO ]  Epoch:   38	Loss: 0.7826	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:32:43 [INFO ]  Epoch:   39	Loss: 0.8053	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:32:45 [INFO ]  Epoch:   40	Loss: 0.7726	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:32:47 [INFO ]  Epoch:   41	Loss: 0.8762	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:32:49 [INFO ]  Epoch:   42	Loss: 0.7302	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:32:50 [INFO ]  Epoch:   43	Loss: 0.7702	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:32:52 [INFO ]  Epoch:   44	Loss: 0.7088	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:54 [INFO ]  Epoch:   45	Loss: 0.7126	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:56 [INFO ]  Epoch:   46	Loss: 0.6957	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:32:58 [INFO ]  Epoch:   47	Loss: 0.6855	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:00 [INFO ]  Epoch:   48	Loss: 0.7604	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:02 [INFO ]  Epoch:   49	Loss: 0.7157	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:04 [INFO ]  Epoch:   50	Loss: 0.6555	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:33:06 [INFO ]  Epoch:   51	Loss: 0.6111	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:33:07 [INFO ]  Epoch:   52	Loss: 0.5981	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:09 [INFO ]  Epoch:   53	Loss: 0.6162	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:11 [INFO ]  Epoch:   54	Loss: 0.5915	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:33:13 [INFO ]  Epoch:   55	Loss: 0.5779	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:15 [INFO ]  Epoch:   56	Loss: 0.6627	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:33:17 [INFO ]  Epoch:   57	Loss: 0.7219	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:19 [INFO ]  Epoch:   58	Loss: 0.5993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:20 [INFO ]  Epoch:   59	Loss: 0.6756	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:22 [INFO ]  Epoch:   60	Loss: 0.5616	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:24 [INFO ]  Epoch:   61	Loss: 0.6590	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:26 [INFO ]  Epoch:   62	Loss: 0.6117	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:33:28 [INFO ]  Epoch:   63	Loss: 0.5909	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:29 [INFO ]  Epoch:   64	Loss: 0.6449	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:31 [INFO ]  Epoch:   65	Loss: 0.6523	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:33:33 [INFO ]  Epoch:   66	Loss: 0.6619	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:35 [INFO ]  Epoch:   67	Loss: 0.6653	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:36 [INFO ]  Epoch:   68	Loss: 0.5918	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:33:39 [INFO ]  Epoch:   69	Loss: 0.6960	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:33:40 [INFO ]  Epoch:   70	Loss: 0.6775	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:42 [INFO ]  Epoch:   71	Loss: 0.5646	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:33:44 [INFO ]  Epoch:   72	Loss: 0.5538	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:33:46 [INFO ]  Epoch:   73	Loss: 0.5898	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:33:48 [INFO ]  Epoch:   74	Loss: 0.6372	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:33:50 [INFO ]  Epoch:   75	Loss: 0.6080	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:33:51 [INFO ]  Epoch:   76	Loss: 0.6201	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:53 [INFO ]  Epoch:   77	Loss: 0.6388	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:55 [INFO ]  Epoch:   78	Loss: 0.5659	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:57 [INFO ]  Epoch:   79	Loss: 0.6799	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:33:59 [INFO ]  Epoch:   80	Loss: 0.6327	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:01 [INFO ]  Epoch:   81	Loss: 0.6235	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:34:02 [INFO ]  Epoch:   82	Loss: 0.6828	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:04 [INFO ]  Epoch:   83	Loss: 0.6353	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:34:06 [INFO ]  Epoch:   84	Loss: 0.6352	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:08 [INFO ]  Epoch:   85	Loss: 0.5881	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:10 [INFO ]  Epoch:   86	Loss: 0.6159	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:34:11 [INFO ]  Epoch:   87	Loss: 0.6437	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:34:13 [INFO ]  Epoch:   88	Loss: 0.6346	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:34:15 [INFO ]  Epoch:   89	Loss: 0.5989	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:34:17 [INFO ]  Epoch:   90	Loss: 0.6075	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:19 [INFO ]  Epoch:   91	Loss: 0.5762	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:20 [INFO ]  Epoch:   92	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:22 [INFO ]  Epoch:   93	Loss: 0.6259	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:24 [INFO ]  Epoch:   94	Loss: 0.6403	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:34:26 [INFO ]  Epoch:   95	Loss: 0.6949	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:34:28 [INFO ]  Epoch:   96	Loss: 0.6841	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:34:29 [INFO ]  Epoch:   97	Loss: 0.5869	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:31 [INFO ]  Epoch:   98	Loss: 0.6174	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:33 [INFO ]  Epoch:   99	Loss: 0.6095	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:35 [INFO ]  Epoch:  100	Loss: 0.6303	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:37 [INFO ]  Epoch:  101	Loss: 0.5942	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:34:38 [INFO ]  Epoch:  102	Loss: 0.5873	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:34:40 [INFO ]  Epoch:  103	Loss: 0.5630	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:34:42 [INFO ]  Epoch:  104	Loss: 0.5664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:44 [INFO ]  Epoch:  105	Loss: 0.5974	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:34:46 [INFO ]  Epoch:  106	Loss: 0.5256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:48 [INFO ]  Epoch:  107	Loss: 0.5864	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:34:49 [INFO ]  Epoch:  108	Loss: 0.5415	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:34:51 [INFO ]  Epoch:  109	Loss: 0.6273	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:53 [INFO ]  Epoch:  110	Loss: 0.6679	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:34:55 [INFO ]  Epoch:  111	Loss: 0.6344	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:34:57 [INFO ]  Epoch:  112	Loss: 0.5719	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:34:58 [INFO ]  Epoch:  113	Loss: 0.5288	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:00 [INFO ]  Epoch:  114	Loss: 0.6440	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:02 [INFO ]  Epoch:  115	Loss: 0.6388	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:04 [INFO ]  Epoch:  116	Loss: 0.5406	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:06 [INFO ]  Epoch:  117	Loss: 0.5862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:08 [INFO ]  Epoch:  118	Loss: 0.5870	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:10 [INFO ]  Epoch:  119	Loss: 0.5776	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:11 [INFO ]  Epoch:  120	Loss: 0.6532	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:35:13 [INFO ]  Epoch:  121	Loss: 0.5989	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:15 [INFO ]  Epoch:  122	Loss: 0.6145	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:35:17 [INFO ]  Epoch:  123	Loss: 0.5653	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:19 [INFO ]  Epoch:  124	Loss: 0.6319	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:35:20 [INFO ]  Epoch:  125	Loss: 0.5613	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:22 [INFO ]  Epoch:  126	Loss: 0.6301	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:24 [INFO ]  Epoch:  127	Loss: 0.6477	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:35:26 [INFO ]  Epoch:  128	Loss: 0.5758	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:28 [INFO ]  Epoch:  129	Loss: 0.6345	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:35:29 [INFO ]  Epoch:  130	Loss: 0.6249	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:35:31 [INFO ]  Epoch:  131	Loss: 0.5210	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:33 [INFO ]  Epoch:  132	Loss: 0.6113	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:35:35 [INFO ]  Epoch:  133	Loss: 0.5697	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:35:37 [INFO ]  Epoch:  134	Loss: 0.6006	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:35:39 [INFO ]  Epoch:  135	Loss: 0.5805	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:40 [INFO ]  Epoch:  136	Loss: 0.6100	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:42 [INFO ]  Epoch:  137	Loss: 0.6003	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:44 [INFO ]  Epoch:  138	Loss: 0.5885	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:35:46 [INFO ]  Epoch:  139	Loss: 0.5641	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:35:48 [INFO ]  Epoch:  140	Loss: 0.6415	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:50 [INFO ]  Epoch:  141	Loss: 0.5820	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:35:51 [INFO ]  Epoch:  142	Loss: 0.6037	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:35:53 [INFO ]  Epoch:  143	Loss: 0.6624	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:35:55 [INFO ]  Epoch:  144	Loss: 0.6148	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:35:57 [INFO ]  Epoch:  145	Loss: 0.6020	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:35:59 [INFO ]  Epoch:  146	Loss: 0.6652	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:00 [INFO ]  Epoch:  147	Loss: 0.5905	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:02 [INFO ]  Epoch:  148	Loss: 0.6207	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:04 [INFO ]  Epoch:  149	Loss: 0.5764	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:36:06 [INFO ]  Epoch:  150	Loss: 0.5704	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:08 [INFO ]  Epoch:  151	Loss: 0.6132	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:36:09 [INFO ]  Epoch:  152	Loss: 0.5936	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:36:11 [INFO ]  Epoch:  153	Loss: 0.6059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:13 [INFO ]  Epoch:  154	Loss: 0.6564	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:15 [INFO ]  Epoch:  155	Loss: 0.5919	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:36:17 [INFO ]  Epoch:  156	Loss: 0.5777	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:18 [INFO ]  Epoch:  157	Loss: 0.5751	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:20 [INFO ]  Epoch:  158	Loss: 0.6116	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:22 [INFO ]  Epoch:  159	Loss: 0.6381	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:36:24 [INFO ]  Epoch:  160	Loss: 0.6166	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:36:26 [INFO ]  Epoch:  161	Loss: 0.5496	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:27 [INFO ]  Epoch:  162	Loss: 0.5842	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:29 [INFO ]  Epoch:  163	Loss: 0.6290	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:31 [INFO ]  Epoch:  164	Loss: 0.5853	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:33 [INFO ]  Epoch:  165	Loss: 0.6148	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:35 [INFO ]  Epoch:  166	Loss: 0.6262	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:36:37 [INFO ]  Epoch:  167	Loss: 0.6584	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:39 [INFO ]  Epoch:  168	Loss: 0.5698	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:36:41 [INFO ]  Epoch:  169	Loss: 0.5804	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:43 [INFO ]  Epoch:  170	Loss: 0.6052	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:36:45 [INFO ]  Epoch:  171	Loss: 0.5407	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:46 [INFO ]  Epoch:  172	Loss: 0.6122	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:48 [INFO ]  Epoch:  173	Loss: 0.5395	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:36:50 [INFO ]  Epoch:  174	Loss: 0.6276	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:36:52 [INFO ]  Epoch:  175	Loss: 0.5770	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:54 [INFO ]  Epoch:  176	Loss: 0.6375	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:36:55 [INFO ]  Epoch:  177	Loss: 0.5527	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:36:57 [INFO ]  Epoch:  178	Loss: 0.5991	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:36:59 [INFO ]  Epoch:  179	Loss: 0.6105	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:37:01 [INFO ]  Epoch:  180	Loss: 0.6494	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:37:03 [INFO ]  Epoch:  181	Loss: 0.5915	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:37:05 [INFO ]  Epoch:  182	Loss: 0.6458	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:37:07 [INFO ]  Epoch:  183	Loss: 0.5452	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:37:08 [INFO ]  Epoch:  184	Loss: 0.6514	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:37:10 [INFO ]  Epoch:  185	Loss: 0.6354	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:37:12 [INFO ]  Epoch:  186	Loss: 0.5927	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:37:14 [INFO ]  Epoch:  187	Loss: 0.5656	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:37:16 [INFO ]  Epoch:  188	Loss: 0.5411	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:37:17 [INFO ]  Epoch:  189	Loss: 0.5698	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:19 [INFO ]  Epoch:  190	Loss: 0.5036	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:21 [INFO ]  Epoch:  191	Loss: 0.5494	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:37:23 [INFO ]  Epoch:  192	Loss: 0.5971	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:37:24 [INFO ]  Epoch:  193	Loss: 0.6334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:26 [INFO ]  Epoch:  194	Loss: 0.5671	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:28 [INFO ]  Epoch:  195	Loss: 0.5732	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:37:30 [INFO ]  Epoch:  196	Loss: 0.5977	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:32 [INFO ]  Epoch:  197	Loss: 0.4924	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:37:34 [INFO ]  Epoch:  198	Loss: 0.6184	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:37:36 [INFO ]  Epoch:  199	Loss: 0.6013	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:37:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 10:37:37 [INFO ]  
2022-10-04 10:37:37 [INFO ]  Final evaluation for SVHN :
2022-10-04 10:37:40 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:37:40 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:37:40 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:37:40 [INFO ]  	   step  1 (lr=0.412583)                   82.40%                   0.6567
2022-10-04 10:37:40 [INFO ]  
2022-10-04 10:37:40 [INFO ]  
2022-10-04 10:37:40 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 10:37:43 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:37:43 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:37:43 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 10:37:43 [INFO ]  	   step  1 (lr=0.412583)                   16.35%                   4.9065
2022-10-04 10:37:43 [INFO ]  
2022-10-04 10:37:43 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 10:38:39 [INFO ]  ======================================== 2022-10-04 10:38:39 ========================================
2022-10-04 10:38:39 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 10:38:39 [INFO ]  Options: 
2022-10-04 10:38:39 [INFO ]  	base_dir: null
2022-10-04 10:38:39 [INFO ]  	batch_size: 1024
2022-10-04 10:38:39 [INFO ]  	checkpoint_interval: 300
2022-10-04 10:38:39 [INFO ]  	dataset: SVHN
2022-10-04 10:38:39 [INFO ]  	dataset_labels:
2022-10-04 10:38:39 [INFO ]  	- 0
2022-10-04 10:38:39 [INFO ]  	- 1
2022-10-04 10:38:39 [INFO ]  	- 2
2022-10-04 10:38:39 [INFO ]  	- 3
2022-10-04 10:38:39 [INFO ]  	- 4
2022-10-04 10:38:39 [INFO ]  	- 5
2022-10-04 10:38:39 [INFO ]  	- 6
2022-10-04 10:38:39 [INFO ]  	- 7
2022-10-04 10:38:39 [INFO ]  	- 8
2022-10-04 10:38:39 [INFO ]  	- 9
2022-10-04 10:38:39 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 10:38:39 [INFO ]  	- !!python/tuple
2022-10-04 10:38:39 [INFO ]  	    - 0.4379104971885681
2022-10-04 10:38:39 [INFO ]  	    - 0.44398033618927
2022-10-04 10:38:39 [INFO ]  	    - 0.4729299545288086
2022-10-04 10:38:39 [INFO ]  	- !!python/tuple
2022-10-04 10:38:39 [INFO ]  	    - 0.19803012907505035
2022-10-04 10:38:39 [INFO ]  	    - 0.2010156363248825
2022-10-04 10:38:39 [INFO ]  	    - 0.19703614711761475
2022-10-04 10:38:39 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 10:38:39 [INFO ]  	decay_epochs: 50
2022-10-04 10:38:39 [INFO ]  	decay_factor: 0.1
2022-10-04 10:38:39 [INFO ]  	device_id: 0
2022-10-04 10:38:39 [INFO ]  	distill_epochs: 1
2022-10-04 10:38:39 [INFO ]  	distill_lr: 0.02
2022-10-04 10:38:39 [INFO ]  	distill_steps: 1
2022-10-04 10:38:39 [INFO ]  	epochs: 200
2022-10-04 10:38:39 [INFO ]  	expand_cls: false
2022-10-04 10:38:39 [INFO ]  	forgetting_dataset: null
2022-10-04 10:38:39 [INFO ]  	init: xavier
2022-10-04 10:38:39 [INFO ]  	init_param: 1.0
2022-10-04 10:38:39 [INFO ]  	input_size: 32
2022-10-04 10:38:39 [INFO ]  	ipc: 20
2022-10-04 10:38:39 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 10:38:39 [INFO ]  	log_interval: 100
2022-10-04 10:38:39 [INFO ]  	log_level: INFO
2022-10-04 10:38:39 [INFO ]  	lr: 0.01
2022-10-04 10:38:39 [INFO ]  	mode: distill_adapt
2022-10-04 10:38:39 [INFO ]  	nc: 3
2022-10-04 10:38:39 [INFO ]  	num_classes: 10
2022-10-04 10:38:39 [INFO ]  	num_workers: 8
2022-10-04 10:38:39 [INFO ]  	phase: train
2022-10-04 10:38:39 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 10:38:39 [INFO ]  	start_time: '2022-10-04 10:38:39'
2022-10-04 10:38:39 [INFO ]  	test_batch_size: 1024
2022-10-04 10:38:39 [INFO ]  	
2022-10-04 10:38:41 [INFO ]  train dataset size:	73257
2022-10-04 10:38:41 [INFO ]  test dataset size: 	26032
2022-10-04 10:38:41 [INFO ]  datasets built!
2022-10-04 10:38:41 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 10:38:43 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 10:38:43 [INFO ]  
2022-10-04 10:38:43 [INFO ]  Begin of epoch 0 :
2022-10-04 10:38:46 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:38:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:38:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:38:46 [INFO ]  	   step  1 (lr=0.020000)                    7.11%                   8.7300
2022-10-04 10:38:46 [INFO ]  
2022-10-04 10:38:46 [INFO ]  Epoch:    0	Loss: 9.0593	Data Time: 0.38s	Train Time: 0.04s
2022-10-04 10:38:48 [INFO ]  Epoch:    1	Loss: 3.0153	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 10:38:50 [INFO ]  Epoch:    2	Loss: 2.3985	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:38:52 [INFO ]  Epoch:    3	Loss: 2.2859	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:38:54 [INFO ]  Epoch:    4	Loss: 2.2027	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:38:55 [INFO ]  Epoch:    5	Loss: 2.1838	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:38:57 [INFO ]  Epoch:    6	Loss: 2.1662	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:38:59 [INFO ]  Epoch:    7	Loss: 2.1119	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:01 [INFO ]  Epoch:    8	Loss: 2.0572	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:03 [INFO ]  Epoch:    9	Loss: 1.9870	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:05 [INFO ]  Epoch:   10	Loss: 1.9078	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:07 [INFO ]  Epoch:   11	Loss: 1.7986	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:09 [INFO ]  Epoch:   12	Loss: 1.5703	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:10 [INFO ]  Epoch:   13	Loss: 1.4364	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:12 [INFO ]  Epoch:   14	Loss: 1.3889	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:39:14 [INFO ]  Epoch:   15	Loss: 1.3165	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:16 [INFO ]  Epoch:   16	Loss: 1.2156	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:39:18 [INFO ]  Epoch:   17	Loss: 1.2172	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:39:20 [INFO ]  Epoch:   18	Loss: 1.1009	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:39:21 [INFO ]  Epoch:   19	Loss: 1.0408	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:23 [INFO ]  Epoch:   20	Loss: 1.0155	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:39:25 [INFO ]  Epoch:   21	Loss: 1.1159	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:27 [INFO ]  Epoch:   22	Loss: 1.1092	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:39:29 [INFO ]  Epoch:   23	Loss: 0.9472	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:31 [INFO ]  Epoch:   24	Loss: 1.1490	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:39:33 [INFO ]  Epoch:   25	Loss: 0.9146	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:39:34 [INFO ]  Epoch:   26	Loss: 0.9307	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:36 [INFO ]  Epoch:   27	Loss: 0.9004	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:39:38 [INFO ]  Epoch:   28	Loss: 0.8136	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:39:40 [INFO ]  Epoch:   29	Loss: 0.7918	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:42 [INFO ]  Epoch:   30	Loss: 0.8310	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:44 [INFO ]  Epoch:   31	Loss: 1.0426	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:39:46 [INFO ]  Epoch:   32	Loss: 0.8283	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:39:47 [INFO ]  Epoch:   33	Loss: 0.7699	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:39:49 [INFO ]  Epoch:   34	Loss: 0.7804	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:39:51 [INFO ]  Epoch:   35	Loss: 0.7912	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:39:53 [INFO ]  Epoch:   36	Loss: 0.8118	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:39:55 [INFO ]  Epoch:   37	Loss: 0.6613	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:39:56 [INFO ]  Epoch:   38	Loss: 0.7206	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:39:59 [INFO ]  Epoch:   39	Loss: 0.7053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:00 [INFO ]  Epoch:   40	Loss: 0.8566	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:02 [INFO ]  Epoch:   41	Loss: 0.7157	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:40:04 [INFO ]  Epoch:   42	Loss: 0.6939	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:40:06 [INFO ]  Epoch:   43	Loss: 0.7816	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:40:08 [INFO ]  Epoch:   44	Loss: 0.7883	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:10 [INFO ]  Epoch:   45	Loss: 0.6752	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:40:11 [INFO ]  Epoch:   46	Loss: 0.7603	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:13 [INFO ]  Epoch:   47	Loss: 0.6979	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:15 [INFO ]  Epoch:   48	Loss: 0.6604	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:17 [INFO ]  Epoch:   49	Loss: 0.6465	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:40:19 [INFO ]  Epoch:   50	Loss: 0.6008	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:40:21 [INFO ]  Epoch:   51	Loss: 0.6361	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:23 [INFO ]  Epoch:   52	Loss: 0.6407	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:24 [INFO ]  Epoch:   53	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:26 [INFO ]  Epoch:   54	Loss: 0.5996	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:28 [INFO ]  Epoch:   55	Loss: 0.6355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:30 [INFO ]  Epoch:   56	Loss: 0.6327	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:32 [INFO ]  Epoch:   57	Loss: 0.6107	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:40:34 [INFO ]  Epoch:   58	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:36 [INFO ]  Epoch:   59	Loss: 0.6498	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:40:37 [INFO ]  Epoch:   60	Loss: 0.6125	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:40:39 [INFO ]  Epoch:   61	Loss: 0.6351	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:40:41 [INFO ]  Epoch:   62	Loss: 0.6515	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:43 [INFO ]  Epoch:   63	Loss: 0.6750	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:45 [INFO ]  Epoch:   64	Loss: 0.6711	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:46 [INFO ]  Epoch:   65	Loss: 0.6819	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:48 [INFO ]  Epoch:   66	Loss: 0.6055	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:50 [INFO ]  Epoch:   67	Loss: 0.6240	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:52 [INFO ]  Epoch:   68	Loss: 0.6558	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:40:54 [INFO ]  Epoch:   69	Loss: 0.6940	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:56 [INFO ]  Epoch:   70	Loss: 0.6263	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:40:57 [INFO ]  Epoch:   71	Loss: 0.6188	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:40:59 [INFO ]  Epoch:   72	Loss: 0.6620	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:01 [INFO ]  Epoch:   73	Loss: 0.6340	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:41:03 [INFO ]  Epoch:   74	Loss: 0.6075	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:41:05 [INFO ]  Epoch:   75	Loss: 0.6171	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:41:06 [INFO ]  Epoch:   76	Loss: 0.6628	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:08 [INFO ]  Epoch:   77	Loss: 0.6344	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:10 [INFO ]  Epoch:   78	Loss: 0.6308	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:41:12 [INFO ]  Epoch:   79	Loss: 0.6480	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:41:14 [INFO ]  Epoch:   80	Loss: 0.6055	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:16 [INFO ]  Epoch:   81	Loss: 0.6403	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:41:18 [INFO ]  Epoch:   82	Loss: 0.6310	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:20 [INFO ]  Epoch:   83	Loss: 0.6622	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:41:21 [INFO ]  Epoch:   84	Loss: 0.6882	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:41:23 [INFO ]  Epoch:   85	Loss: 0.6201	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:25 [INFO ]  Epoch:   86	Loss: 0.6135	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:27 [INFO ]  Epoch:   87	Loss: 0.6212	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:29 [INFO ]  Epoch:   88	Loss: 0.5651	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:31 [INFO ]  Epoch:   89	Loss: 0.5897	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:41:33 [INFO ]  Epoch:   90	Loss: 0.6404	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:41:34 [INFO ]  Epoch:   91	Loss: 0.5545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:36 [INFO ]  Epoch:   92	Loss: 0.5886	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:41:38 [INFO ]  Epoch:   93	Loss: 0.5887	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:40 [INFO ]  Epoch:   94	Loss: 0.6282	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:42 [INFO ]  Epoch:   95	Loss: 0.6008	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:41:43 [INFO ]  Epoch:   96	Loss: 0.6400	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:41:45 [INFO ]  Epoch:   97	Loss: 0.6616	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:41:47 [INFO ]  Epoch:   98	Loss: 0.6021	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:41:49 [INFO ]  Epoch:   99	Loss: 0.6622	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:51 [INFO ]  Epoch:  100	Loss: 0.6519	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:41:53 [INFO ]  Epoch:  101	Loss: 0.6979	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:41:55 [INFO ]  Epoch:  102	Loss: 0.5979	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:41:57 [INFO ]  Epoch:  103	Loss: 0.6530	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:41:58 [INFO ]  Epoch:  104	Loss: 0.6127	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:00 [INFO ]  Epoch:  105	Loss: 0.6126	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:42:02 [INFO ]  Epoch:  106	Loss: 0.6340	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:42:04 [INFO ]  Epoch:  107	Loss: 0.5609	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:42:06 [INFO ]  Epoch:  108	Loss: 0.5831	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:42:08 [INFO ]  Epoch:  109	Loss: 0.5771	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:09 [INFO ]  Epoch:  110	Loss: 0.5550	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:11 [INFO ]  Epoch:  111	Loss: 0.6136	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:42:13 [INFO ]  Epoch:  112	Loss: 0.5893	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:15 [INFO ]  Epoch:  113	Loss: 0.6064	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:17 [INFO ]  Epoch:  114	Loss: 0.5664	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:42:18 [INFO ]  Epoch:  115	Loss: 0.6430	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:42:20 [INFO ]  Epoch:  116	Loss: 0.6085	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:22 [INFO ]  Epoch:  117	Loss: 0.6132	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:24 [INFO ]  Epoch:  118	Loss: 0.6205	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:42:26 [INFO ]  Epoch:  119	Loss: 0.6012	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:42:28 [INFO ]  Epoch:  120	Loss: 0.6226	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:42:30 [INFO ]  Epoch:  121	Loss: 0.5844	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:42:31 [INFO ]  Epoch:  122	Loss: 0.6548	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:33 [INFO ]  Epoch:  123	Loss: 0.6106	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:42:35 [INFO ]  Epoch:  124	Loss: 0.5787	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:42:37 [INFO ]  Epoch:  125	Loss: 0.6303	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:39 [INFO ]  Epoch:  126	Loss: 0.5632	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:42:40 [INFO ]  Epoch:  127	Loss: 0.6737	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:43 [INFO ]  Epoch:  128	Loss: 0.6495	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:42:44 [INFO ]  Epoch:  129	Loss: 0.5679	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:46 [INFO ]  Epoch:  130	Loss: 0.6457	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:42:48 [INFO ]  Epoch:  131	Loss: 0.5355	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:42:50 [INFO ]  Epoch:  132	Loss: 0.7533	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:42:52 [INFO ]  Epoch:  133	Loss: 0.6208	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:42:54 [INFO ]  Epoch:  134	Loss: 0.5082	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:42:56 [INFO ]  Epoch:  135	Loss: 0.6616	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:42:58 [INFO ]  Epoch:  136	Loss: 0.5640	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:42:59 [INFO ]  Epoch:  137	Loss: 0.6254	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:01 [INFO ]  Epoch:  138	Loss: 0.5927	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:43:03 [INFO ]  Epoch:  139	Loss: 0.6171	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:05 [INFO ]  Epoch:  140	Loss: 0.6637	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:07 [INFO ]  Epoch:  141	Loss: 0.6320	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:43:09 [INFO ]  Epoch:  142	Loss: 0.6039	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:43:11 [INFO ]  Epoch:  143	Loss: 0.6154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:13 [INFO ]  Epoch:  144	Loss: 0.5896	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:43:14 [INFO ]  Epoch:  145	Loss: 0.6015	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:16 [INFO ]  Epoch:  146	Loss: 0.6983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:18 [INFO ]  Epoch:  147	Loss: 0.5561	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:43:20 [INFO ]  Epoch:  148	Loss: 0.5835	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:43:22 [INFO ]  Epoch:  149	Loss: 0.6969	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:23 [INFO ]  Epoch:  150	Loss: 0.5689	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:25 [INFO ]  Epoch:  151	Loss: 0.5741	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:43:27 [INFO ]  Epoch:  152	Loss: 0.5898	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:29 [INFO ]  Epoch:  153	Loss: 0.6006	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:43:31 [INFO ]  Epoch:  154	Loss: 0.6279	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:33 [INFO ]  Epoch:  155	Loss: 0.6185	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:35 [INFO ]  Epoch:  156	Loss: 0.5785	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:36 [INFO ]  Epoch:  157	Loss: 0.5933	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:43:38 [INFO ]  Epoch:  158	Loss: 0.6137	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:43:40 [INFO ]  Epoch:  159	Loss: 0.6137	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:43:42 [INFO ]  Epoch:  160	Loss: 0.6115	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:43 [INFO ]  Epoch:  161	Loss: 0.5956	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:45 [INFO ]  Epoch:  162	Loss: 0.5858	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:43:47 [INFO ]  Epoch:  163	Loss: 0.6460	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:49 [INFO ]  Epoch:  164	Loss: 0.6435	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:43:51 [INFO ]  Epoch:  165	Loss: 0.5125	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:43:53 [INFO ]  Epoch:  166	Loss: 0.6187	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:43:55 [INFO ]  Epoch:  167	Loss: 0.6191	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:43:57 [INFO ]  Epoch:  168	Loss: 0.5372	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:43:58 [INFO ]  Epoch:  169	Loss: 0.6860	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:44:00 [INFO ]  Epoch:  170	Loss: 0.6063	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:44:02 [INFO ]  Epoch:  171	Loss: 0.6442	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:04 [INFO ]  Epoch:  172	Loss: 0.6353	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:06 [INFO ]  Epoch:  173	Loss: 0.6245	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:08 [INFO ]  Epoch:  174	Loss: 0.5480	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:10 [INFO ]  Epoch:  175	Loss: 0.6040	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:44:12 [INFO ]  Epoch:  176	Loss: 0.6008	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:14 [INFO ]  Epoch:  177	Loss: 0.6046	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:16 [INFO ]  Epoch:  178	Loss: 0.7081	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:18 [INFO ]  Epoch:  179	Loss: 0.6664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:20 [INFO ]  Epoch:  180	Loss: 0.5735	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:21 [INFO ]  Epoch:  181	Loss: 0.6587	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:44:23 [INFO ]  Epoch:  182	Loss: 0.6560	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:25 [INFO ]  Epoch:  183	Loss: 0.6345	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:27 [INFO ]  Epoch:  184	Loss: 0.5773	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:29 [INFO ]  Epoch:  185	Loss: 0.5809	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:44:31 [INFO ]  Epoch:  186	Loss: 0.5797	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:33 [INFO ]  Epoch:  187	Loss: 0.5995	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:35 [INFO ]  Epoch:  188	Loss: 0.6234	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:44:36 [INFO ]  Epoch:  189	Loss: 0.5876	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:44:38 [INFO ]  Epoch:  190	Loss: 0.6786	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:44:40 [INFO ]  Epoch:  191	Loss: 0.5480	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:42 [INFO ]  Epoch:  192	Loss: 0.5490	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:44 [INFO ]  Epoch:  193	Loss: 0.6158	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:46 [INFO ]  Epoch:  194	Loss: 0.6173	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:47 [INFO ]  Epoch:  195	Loss: 0.6509	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:49 [INFO ]  Epoch:  196	Loss: 0.5763	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:44:51 [INFO ]  Epoch:  197	Loss: 0.5963	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:44:53 [INFO ]  Epoch:  198	Loss: 0.5424	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:44:55 [INFO ]  Epoch:  199	Loss: 0.5031	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:44:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 10:44:56 [INFO ]  
2022-10-04 10:44:56 [INFO ]  Final evaluation for SVHN :
2022-10-04 10:45:00 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:45:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:45:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:45:00 [INFO ]  	   step  1 (lr=0.410340)                   81.75%                   0.6756
2022-10-04 10:45:00 [INFO ]  
2022-10-04 10:45:00 [INFO ]  
2022-10-04 10:45:00 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 10:45:02 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:45:02 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:45:02 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 10:45:02 [INFO ]  	   step  1 (lr=0.410340)                   15.73%                   5.0425
2022-10-04 10:45:02 [INFO ]  
2022-10-04 10:45:02 [INFO ]  CPU Time: 3.48 minutes
2022-10-04 10:49:12 [INFO ]  ======================================== 2022-10-04 10:49:12 ========================================
2022-10-04 10:49:12 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 10:49:12 [INFO ]  Options: 
2022-10-04 10:49:12 [INFO ]  	base_dir: null
2022-10-04 10:49:12 [INFO ]  	batch_size: 1024
2022-10-04 10:49:12 [INFO ]  	checkpoint_interval: 300
2022-10-04 10:49:12 [INFO ]  	dataset: SVHN
2022-10-04 10:49:12 [INFO ]  	dataset_labels:
2022-10-04 10:49:12 [INFO ]  	- 0
2022-10-04 10:49:12 [INFO ]  	- 1
2022-10-04 10:49:12 [INFO ]  	- 2
2022-10-04 10:49:12 [INFO ]  	- 3
2022-10-04 10:49:12 [INFO ]  	- 4
2022-10-04 10:49:12 [INFO ]  	- 5
2022-10-04 10:49:12 [INFO ]  	- 6
2022-10-04 10:49:12 [INFO ]  	- 7
2022-10-04 10:49:12 [INFO ]  	- 8
2022-10-04 10:49:12 [INFO ]  	- 9
2022-10-04 10:49:12 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 10:49:12 [INFO ]  	- !!python/tuple
2022-10-04 10:49:12 [INFO ]  	    - 0.4379104971885681
2022-10-04 10:49:12 [INFO ]  	    - 0.44398033618927
2022-10-04 10:49:12 [INFO ]  	    - 0.4729299545288086
2022-10-04 10:49:12 [INFO ]  	- !!python/tuple
2022-10-04 10:49:12 [INFO ]  	    - 0.19803012907505035
2022-10-04 10:49:12 [INFO ]  	    - 0.2010156363248825
2022-10-04 10:49:12 [INFO ]  	    - 0.19703614711761475
2022-10-04 10:49:12 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 10:49:12 [INFO ]  	decay_epochs: 50
2022-10-04 10:49:12 [INFO ]  	decay_factor: 0.1
2022-10-04 10:49:12 [INFO ]  	device_id: 0
2022-10-04 10:49:12 [INFO ]  	distill_epochs: 1
2022-10-04 10:49:12 [INFO ]  	distill_lr: 0.02
2022-10-04 10:49:12 [INFO ]  	distill_steps: 1
2022-10-04 10:49:12 [INFO ]  	epochs: 200
2022-10-04 10:49:12 [INFO ]  	expand_cls: false
2022-10-04 10:49:12 [INFO ]  	forgetting_dataset: null
2022-10-04 10:49:12 [INFO ]  	init: xavier
2022-10-04 10:49:12 [INFO ]  	init_param: 1.0
2022-10-04 10:49:12 [INFO ]  	input_size: 32
2022-10-04 10:49:12 [INFO ]  	ipc: 25
2022-10-04 10:49:12 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 10:49:12 [INFO ]  	log_interval: 100
2022-10-04 10:49:12 [INFO ]  	log_level: INFO
2022-10-04 10:49:12 [INFO ]  	lr: 0.01
2022-10-04 10:49:12 [INFO ]  	mode: distill_adapt
2022-10-04 10:49:12 [INFO ]  	nc: 3
2022-10-04 10:49:12 [INFO ]  	num_classes: 10
2022-10-04 10:49:12 [INFO ]  	num_workers: 8
2022-10-04 10:49:12 [INFO ]  	phase: train
2022-10-04 10:49:12 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 10:49:12 [INFO ]  	start_time: '2022-10-04 10:49:12'
2022-10-04 10:49:12 [INFO ]  	test_batch_size: 1024
2022-10-04 10:49:12 [INFO ]  	
2022-10-04 10:49:15 [INFO ]  train dataset size:	73257
2022-10-04 10:49:15 [INFO ]  test dataset size: 	26032
2022-10-04 10:49:15 [INFO ]  datasets built!
2022-10-04 10:49:15 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 10:49:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 10:49:16 [INFO ]  
2022-10-04 10:49:16 [INFO ]  Begin of epoch 0 :
2022-10-04 10:49:20 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:49:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:49:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:49:20 [INFO ]  	   step  1 (lr=0.020000)                    7.00%                   9.1919
2022-10-04 10:49:20 [INFO ]  
2022-10-04 10:49:20 [INFO ]  Epoch:    0	Loss: 8.7322	Data Time: 0.39s	Train Time: 0.04s
2022-10-04 10:49:21 [INFO ]  Epoch:    1	Loss: 2.9003	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:49:23 [INFO ]  Epoch:    2	Loss: 2.5011	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:49:25 [INFO ]  Epoch:    3	Loss: 2.2553	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:49:27 [INFO ]  Epoch:    4	Loss: 2.2040	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:49:29 [INFO ]  Epoch:    5	Loss: 2.1980	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:31 [INFO ]  Epoch:    6	Loss: 2.1333	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:33 [INFO ]  Epoch:    7	Loss: 2.1186	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:35 [INFO ]  Epoch:    8	Loss: 2.0692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:37 [INFO ]  Epoch:    9	Loss: 1.9799	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:49:39 [INFO ]  Epoch:   10	Loss: 1.9118	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 10:49:41 [INFO ]  Epoch:   11	Loss: 1.7677	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:42 [INFO ]  Epoch:   12	Loss: 1.5581	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:49:44 [INFO ]  Epoch:   13	Loss: 1.4029	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:49:46 [INFO ]  Epoch:   14	Loss: 1.3582	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:49:48 [INFO ]  Epoch:   15	Loss: 1.3107	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:49:50 [INFO ]  Epoch:   16	Loss: 1.1796	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:49:51 [INFO ]  Epoch:   17	Loss: 1.1921	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:53 [INFO ]  Epoch:   18	Loss: 1.2049	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:49:55 [INFO ]  Epoch:   19	Loss: 1.0917	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:49:57 [INFO ]  Epoch:   20	Loss: 1.0297	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:49:59 [INFO ]  Epoch:   21	Loss: 0.9852	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:00 [INFO ]  Epoch:   22	Loss: 1.0304	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:02 [INFO ]  Epoch:   23	Loss: 0.8993	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:04 [INFO ]  Epoch:   24	Loss: 0.8808	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:50:06 [INFO ]  Epoch:   25	Loss: 0.8653	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:08 [INFO ]  Epoch:   26	Loss: 0.8648	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:09 [INFO ]  Epoch:   27	Loss: 0.9121	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:11 [INFO ]  Epoch:   28	Loss: 0.9158	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:13 [INFO ]  Epoch:   29	Loss: 0.8543	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:50:15 [INFO ]  Epoch:   30	Loss: 0.8845	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:50:17 [INFO ]  Epoch:   31	Loss: 0.8424	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:18 [INFO ]  Epoch:   32	Loss: 0.8674	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:50:20 [INFO ]  Epoch:   33	Loss: 0.8552	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:50:22 [INFO ]  Epoch:   34	Loss: 0.9276	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:50:24 [INFO ]  Epoch:   35	Loss: 0.7702	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:50:26 [INFO ]  Epoch:   36	Loss: 0.7804	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:50:28 [INFO ]  Epoch:   37	Loss: 0.8388	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:50:30 [INFO ]  Epoch:   38	Loss: 0.7094	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:50:32 [INFO ]  Epoch:   39	Loss: 0.8015	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:50:33 [INFO ]  Epoch:   40	Loss: 0.6294	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:50:35 [INFO ]  Epoch:   41	Loss: 0.7716	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:50:37 [INFO ]  Epoch:   42	Loss: 0.6507	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:39 [INFO ]  Epoch:   43	Loss: 0.7265	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:50:41 [INFO ]  Epoch:   44	Loss: 0.8123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:43 [INFO ]  Epoch:   45	Loss: 0.8943	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:45 [INFO ]  Epoch:   46	Loss: 0.7364	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:46 [INFO ]  Epoch:   47	Loss: 0.8014	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:50:48 [INFO ]  Epoch:   48	Loss: 0.6619	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:50 [INFO ]  Epoch:   49	Loss: 0.6873	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:50:52 [INFO ]  Epoch:   50	Loss: 0.5967	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:54 [INFO ]  Epoch:   51	Loss: 0.6960	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:56 [INFO ]  Epoch:   52	Loss: 0.7223	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:50:58 [INFO ]  Epoch:   53	Loss: 0.6263	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:50:59 [INFO ]  Epoch:   54	Loss: 0.6731	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:01 [INFO ]  Epoch:   55	Loss: 0.7149	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:51:03 [INFO ]  Epoch:   56	Loss: 0.6802	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:51:05 [INFO ]  Epoch:   57	Loss: 0.7379	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:06 [INFO ]  Epoch:   58	Loss: 0.6334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:09 [INFO ]  Epoch:   59	Loss: 0.7326	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:51:10 [INFO ]  Epoch:   60	Loss: 0.6109	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:51:12 [INFO ]  Epoch:   61	Loss: 0.5863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:14 [INFO ]  Epoch:   62	Loss: 0.6858	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:16 [INFO ]  Epoch:   63	Loss: 0.6662	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:18 [INFO ]  Epoch:   64	Loss: 0.6471	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:51:20 [INFO ]  Epoch:   65	Loss: 0.7538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:22 [INFO ]  Epoch:   66	Loss: 0.7657	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:24 [INFO ]  Epoch:   67	Loss: 0.6714	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:26 [INFO ]  Epoch:   68	Loss: 0.6163	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:51:27 [INFO ]  Epoch:   69	Loss: 0.5957	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:29 [INFO ]  Epoch:   70	Loss: 0.6140	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:31 [INFO ]  Epoch:   71	Loss: 0.6523	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:51:33 [INFO ]  Epoch:   72	Loss: 0.6418	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:35 [INFO ]  Epoch:   73	Loss: 0.6166	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:37 [INFO ]  Epoch:   74	Loss: 0.6592	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:51:38 [INFO ]  Epoch:   75	Loss: 0.6980	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:51:40 [INFO ]  Epoch:   76	Loss: 0.6597	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:42 [INFO ]  Epoch:   77	Loss: 0.6474	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:44 [INFO ]  Epoch:   78	Loss: 0.5467	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:46 [INFO ]  Epoch:   79	Loss: 0.6658	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:51:48 [INFO ]  Epoch:   80	Loss: 0.6066	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:51:50 [INFO ]  Epoch:   81	Loss: 0.6317	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:51:52 [INFO ]  Epoch:   82	Loss: 0.6906	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:51:54 [INFO ]  Epoch:   83	Loss: 0.6147	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:51:56 [INFO ]  Epoch:   84	Loss: 0.6190	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:51:57 [INFO ]  Epoch:   85	Loss: 0.6452	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:51:59 [INFO ]  Epoch:   86	Loss: 0.5883	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:52:01 [INFO ]  Epoch:   87	Loss: 0.6330	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:52:03 [INFO ]  Epoch:   88	Loss: 0.5614	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:05 [INFO ]  Epoch:   89	Loss: 0.6384	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:52:07 [INFO ]  Epoch:   90	Loss: 0.5911	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:52:09 [INFO ]  Epoch:   91	Loss: 0.5843	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:52:10 [INFO ]  Epoch:   92	Loss: 0.6816	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:12 [INFO ]  Epoch:   93	Loss: 0.6184	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:52:14 [INFO ]  Epoch:   94	Loss: 0.6388	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:52:16 [INFO ]  Epoch:   95	Loss: 0.5942	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:52:18 [INFO ]  Epoch:   96	Loss: 0.5824	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:20 [INFO ]  Epoch:   97	Loss: 0.6290	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:21 [INFO ]  Epoch:   98	Loss: 0.6284	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:23 [INFO ]  Epoch:   99	Loss: 0.6181	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:52:25 [INFO ]  Epoch:  100	Loss: 0.6192	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:52:27 [INFO ]  Epoch:  101	Loss: 0.5576	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:29 [INFO ]  Epoch:  102	Loss: 0.5780	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:52:31 [INFO ]  Epoch:  103	Loss: 0.5477	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:32 [INFO ]  Epoch:  104	Loss: 0.5982	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:34 [INFO ]  Epoch:  105	Loss: 0.6004	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:36 [INFO ]  Epoch:  106	Loss: 0.5753	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:52:38 [INFO ]  Epoch:  107	Loss: 0.6146	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:52:40 [INFO ]  Epoch:  108	Loss: 0.5948	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:42 [INFO ]  Epoch:  109	Loss: 0.6206	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:52:43 [INFO ]  Epoch:  110	Loss: 0.6401	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:52:45 [INFO ]  Epoch:  111	Loss: 0.6288	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:47 [INFO ]  Epoch:  112	Loss: 0.6287	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:49 [INFO ]  Epoch:  113	Loss: 0.6197	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:51 [INFO ]  Epoch:  114	Loss: 0.6190	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:53 [INFO ]  Epoch:  115	Loss: 0.6325	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:52:55 [INFO ]  Epoch:  116	Loss: 0.6200	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:56 [INFO ]  Epoch:  117	Loss: 0.5642	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:52:58 [INFO ]  Epoch:  118	Loss: 0.5511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:53:00 [INFO ]  Epoch:  119	Loss: 0.5502	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:53:02 [INFO ]  Epoch:  120	Loss: 0.6030	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:53:04 [INFO ]  Epoch:  121	Loss: 0.5646	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:53:06 [INFO ]  Epoch:  122	Loss: 0.6211	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:53:08 [INFO ]  Epoch:  123	Loss: 0.6633	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:53:10 [INFO ]  Epoch:  124	Loss: 0.6428	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:53:12 [INFO ]  Epoch:  125	Loss: 0.5751	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:13 [INFO ]  Epoch:  126	Loss: 0.5831	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:53:15 [INFO ]  Epoch:  127	Loss: 0.5352	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:53:17 [INFO ]  Epoch:  128	Loss: 0.6038	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:19 [INFO ]  Epoch:  129	Loss: 0.5914	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:53:21 [INFO ]  Epoch:  130	Loss: 0.5636	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:23 [INFO ]  Epoch:  131	Loss: 0.5636	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:53:24 [INFO ]  Epoch:  132	Loss: 0.6098	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:53:26 [INFO ]  Epoch:  133	Loss: 0.5125	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:28 [INFO ]  Epoch:  134	Loss: 0.6080	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:30 [INFO ]  Epoch:  135	Loss: 0.6182	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:32 [INFO ]  Epoch:  136	Loss: 0.6030	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:53:33 [INFO ]  Epoch:  137	Loss: 0.6031	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:53:35 [INFO ]  Epoch:  138	Loss: 0.5888	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:53:37 [INFO ]  Epoch:  139	Loss: 0.5990	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:53:39 [INFO ]  Epoch:  140	Loss: 0.6286	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:41 [INFO ]  Epoch:  141	Loss: 0.5900	Data Time: 0.26s	Train Time: 0.00s
2022-10-04 10:53:43 [INFO ]  Epoch:  142	Loss: 0.5569	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:53:45 [INFO ]  Epoch:  143	Loss: 0.6166	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:53:47 [INFO ]  Epoch:  144	Loss: 0.5942	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:53:48 [INFO ]  Epoch:  145	Loss: 0.6192	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:53:50 [INFO ]  Epoch:  146	Loss: 0.5467	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:53:52 [INFO ]  Epoch:  147	Loss: 0.5804	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:53:54 [INFO ]  Epoch:  148	Loss: 0.6497	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:53:55 [INFO ]  Epoch:  149	Loss: 0.5948	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 10:53:57 [INFO ]  Epoch:  150	Loss: 0.6073	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:53:59 [INFO ]  Epoch:  151	Loss: 0.6499	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:54:01 [INFO ]  Epoch:  152	Loss: 0.6023	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:54:03 [INFO ]  Epoch:  153	Loss: 0.5598	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:05 [INFO ]  Epoch:  154	Loss: 0.5600	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:54:06 [INFO ]  Epoch:  155	Loss: 0.5554	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:54:08 [INFO ]  Epoch:  156	Loss: 0.5797	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:54:10 [INFO ]  Epoch:  157	Loss: 0.5795	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:12 [INFO ]  Epoch:  158	Loss: 0.6593	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:54:14 [INFO ]  Epoch:  159	Loss: 0.5725	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:54:16 [INFO ]  Epoch:  160	Loss: 0.6088	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:54:18 [INFO ]  Epoch:  161	Loss: 0.5977	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:54:20 [INFO ]  Epoch:  162	Loss: 0.6522	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:22 [INFO ]  Epoch:  163	Loss: 0.6096	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:54:24 [INFO ]  Epoch:  164	Loss: 0.6406	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:54:26 [INFO ]  Epoch:  165	Loss: 0.6496	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:54:28 [INFO ]  Epoch:  166	Loss: 0.6355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:54:30 [INFO ]  Epoch:  167	Loss: 0.5850	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:54:31 [INFO ]  Epoch:  168	Loss: 0.6387	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:33 [INFO ]  Epoch:  169	Loss: 0.5545	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 10:54:35 [INFO ]  Epoch:  170	Loss: 0.5720	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 10:54:37 [INFO ]  Epoch:  171	Loss: 0.6003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:54:39 [INFO ]  Epoch:  172	Loss: 0.5484	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:41 [INFO ]  Epoch:  173	Loss: 0.5786	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:54:43 [INFO ]  Epoch:  174	Loss: 0.6413	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:54:45 [INFO ]  Epoch:  175	Loss: 0.6640	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:47 [INFO ]  Epoch:  176	Loss: 0.6045	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:54:48 [INFO ]  Epoch:  177	Loss: 0.6343	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 10:54:50 [INFO ]  Epoch:  178	Loss: 0.5850	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:54:52 [INFO ]  Epoch:  179	Loss: 0.6123	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 10:54:54 [INFO ]  Epoch:  180	Loss: 0.5552	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:54:56 [INFO ]  Epoch:  181	Loss: 0.6941	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 10:54:57 [INFO ]  Epoch:  182	Loss: 0.5637	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:54:59 [INFO ]  Epoch:  183	Loss: 0.5804	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:55:01 [INFO ]  Epoch:  184	Loss: 0.5496	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 10:55:03 [INFO ]  Epoch:  185	Loss: 0.6269	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:05 [INFO ]  Epoch:  186	Loss: 0.6404	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:55:07 [INFO ]  Epoch:  187	Loss: 0.6005	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:09 [INFO ]  Epoch:  188	Loss: 0.5538	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:55:11 [INFO ]  Epoch:  189	Loss: 0.6619	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:12 [INFO ]  Epoch:  190	Loss: 0.6031	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:14 [INFO ]  Epoch:  191	Loss: 0.5953	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:55:16 [INFO ]  Epoch:  192	Loss: 0.5413	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:18 [INFO ]  Epoch:  193	Loss: 0.6141	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 10:55:20 [INFO ]  Epoch:  194	Loss: 0.6326	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:22 [INFO ]  Epoch:  195	Loss: 0.6216	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:24 [INFO ]  Epoch:  196	Loss: 0.6303	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 10:55:26 [INFO ]  Epoch:  197	Loss: 0.5733	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:28 [INFO ]  Epoch:  198	Loss: 0.6065	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 10:55:29 [INFO ]  Epoch:  199	Loss: 0.6273	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 10:55:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 10:55:31 [INFO ]  
2022-10-04 10:55:31 [INFO ]  Final evaluation for SVHN :
2022-10-04 10:55:34 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:55:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:55:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 10:55:34 [INFO ]  	   step  1 (lr=0.412939)                   82.06%                   0.6669
2022-10-04 10:55:34 [INFO ]  
2022-10-04 10:55:34 [INFO ]  
2022-10-04 10:55:34 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 10:55:37 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 10:55:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 10:55:37 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 10:55:37 [INFO ]  	   step  1 (lr=0.412939)                   16.66%                   5.2518
2022-10-04 10:55:37 [INFO ]  
2022-10-04 10:55:37 [INFO ]  CPU Time: 3.50 minutes
2022-10-04 11:06:13 [INFO ]  ======================================== 2022-10-04 11:06:13 ========================================
2022-10-04 11:06:13 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 11:06:13 [INFO ]  Options: 
2022-10-04 11:06:13 [INFO ]  	base_dir: null
2022-10-04 11:06:13 [INFO ]  	batch_size: 1024
2022-10-04 11:06:13 [INFO ]  	checkpoint_interval: 300
2022-10-04 11:06:13 [INFO ]  	dataset: SVHN
2022-10-04 11:06:13 [INFO ]  	dataset_labels:
2022-10-04 11:06:13 [INFO ]  	- 0
2022-10-04 11:06:13 [INFO ]  	- 1
2022-10-04 11:06:13 [INFO ]  	- 2
2022-10-04 11:06:13 [INFO ]  	- 3
2022-10-04 11:06:13 [INFO ]  	- 4
2022-10-04 11:06:13 [INFO ]  	- 5
2022-10-04 11:06:13 [INFO ]  	- 6
2022-10-04 11:06:13 [INFO ]  	- 7
2022-10-04 11:06:13 [INFO ]  	- 8
2022-10-04 11:06:13 [INFO ]  	- 9
2022-10-04 11:06:13 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 11:06:13 [INFO ]  	- !!python/tuple
2022-10-04 11:06:13 [INFO ]  	    - 0.4379104971885681
2022-10-04 11:06:13 [INFO ]  	    - 0.44398033618927
2022-10-04 11:06:13 [INFO ]  	    - 0.4729299545288086
2022-10-04 11:06:13 [INFO ]  	- !!python/tuple
2022-10-04 11:06:13 [INFO ]  	    - 0.19803012907505035
2022-10-04 11:06:13 [INFO ]  	    - 0.2010156363248825
2022-10-04 11:06:13 [INFO ]  	    - 0.19703614711761475
2022-10-04 11:06:13 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 11:06:13 [INFO ]  	decay_epochs: 50
2022-10-04 11:06:13 [INFO ]  	decay_factor: 0.1
2022-10-04 11:06:13 [INFO ]  	device_id: 0
2022-10-04 11:06:13 [INFO ]  	distill_epochs: 1
2022-10-04 11:06:13 [INFO ]  	distill_lr: 0.02
2022-10-04 11:06:13 [INFO ]  	distill_steps: 1
2022-10-04 11:06:13 [INFO ]  	epochs: 200
2022-10-04 11:06:13 [INFO ]  	expand_cls: false
2022-10-04 11:06:13 [INFO ]  	forgetting_dataset: null
2022-10-04 11:06:13 [INFO ]  	init: xavier
2022-10-04 11:06:13 [INFO ]  	init_param: 1.0
2022-10-04 11:06:13 [INFO ]  	input_size: 32
2022-10-04 11:06:13 [INFO ]  	ipc: 25
2022-10-04 11:06:13 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 11:06:13 [INFO ]  	log_interval: 100
2022-10-04 11:06:13 [INFO ]  	log_level: INFO
2022-10-04 11:06:13 [INFO ]  	lr: 0.01
2022-10-04 11:06:13 [INFO ]  	mode: distill_adapt
2022-10-04 11:06:13 [INFO ]  	nc: 3
2022-10-04 11:06:13 [INFO ]  	num_classes: 10
2022-10-04 11:06:13 [INFO ]  	num_workers: 8
2022-10-04 11:06:13 [INFO ]  	phase: train
2022-10-04 11:06:13 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 11:06:13 [INFO ]  	start_time: '2022-10-04 11:06:13'
2022-10-04 11:06:13 [INFO ]  	test_batch_size: 1024
2022-10-04 11:06:13 [INFO ]  	
2022-10-04 11:06:15 [INFO ]  train dataset size:	73257
2022-10-04 11:06:15 [INFO ]  test dataset size: 	26032
2022-10-04 11:06:15 [INFO ]  datasets built!
2022-10-04 11:06:15 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 11:06:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 11:06:16 [INFO ]  
2022-10-04 11:06:16 [INFO ]  Begin of epoch 0 :
2022-10-04 11:06:20 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:06:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:06:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:06:20 [INFO ]  	   step  1 (lr=0.020000)                    7.45%                   8.5662
2022-10-04 11:06:20 [INFO ]  
2022-10-04 11:06:20 [INFO ]  Epoch:    0	Loss: 8.4699	Data Time: 0.38s	Train Time: 0.04s
2022-10-04 11:06:22 [INFO ]  Epoch:    1	Loss: 3.0635	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 11:06:23 [INFO ]  Epoch:    2	Loss: 2.4450	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:06:25 [INFO ]  Epoch:    3	Loss: 2.2851	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:06:27 [INFO ]  Epoch:    4	Loss: 2.1672	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:06:29 [INFO ]  Epoch:    5	Loss: 2.1906	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:31 [INFO ]  Epoch:    6	Loss: 2.1292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:33 [INFO ]  Epoch:    7	Loss: 2.0895	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:06:35 [INFO ]  Epoch:    8	Loss: 2.0453	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:06:36 [INFO ]  Epoch:    9	Loss: 1.9457	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:06:38 [INFO ]  Epoch:   10	Loss: 1.9248	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:06:40 [INFO ]  Epoch:   11	Loss: 1.6907	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:06:42 [INFO ]  Epoch:   12	Loss: 1.5500	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 11:06:44 [INFO ]  Epoch:   13	Loss: 1.4890	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:46 [INFO ]  Epoch:   14	Loss: 1.3595	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:06:47 [INFO ]  Epoch:   15	Loss: 1.3068	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:49 [INFO ]  Epoch:   16	Loss: 1.2540	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:06:51 [INFO ]  Epoch:   17	Loss: 1.2554	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:06:53 [INFO ]  Epoch:   18	Loss: 1.0626	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:55 [INFO ]  Epoch:   19	Loss: 1.2200	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:06:57 [INFO ]  Epoch:   20	Loss: 1.0811	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:06:59 [INFO ]  Epoch:   21	Loss: 1.2098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:01 [INFO ]  Epoch:   22	Loss: 1.2185	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:07:03 [INFO ]  Epoch:   23	Loss: 1.0580	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:07:05 [INFO ]  Epoch:   24	Loss: 1.2750	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:07:07 [INFO ]  Epoch:   25	Loss: 0.9156	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:07:08 [INFO ]  Epoch:   26	Loss: 0.9144	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:07:10 [INFO ]  Epoch:   27	Loss: 1.0317	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:12 [INFO ]  Epoch:   28	Loss: 0.8614	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:07:14 [INFO ]  Epoch:   29	Loss: 0.8092	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:16 [INFO ]  Epoch:   30	Loss: 0.8904	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:07:17 [INFO ]  Epoch:   31	Loss: 0.8299	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:19 [INFO ]  Epoch:   32	Loss: 0.8478	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:21 [INFO ]  Epoch:   33	Loss: 0.7753	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:07:23 [INFO ]  Epoch:   34	Loss: 0.6850	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:25 [INFO ]  Epoch:   35	Loss: 1.1690	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:07:27 [INFO ]  Epoch:   36	Loss: 0.7143	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:07:29 [INFO ]  Epoch:   37	Loss: 0.7674	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:30 [INFO ]  Epoch:   38	Loss: 0.8129	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:07:32 [INFO ]  Epoch:   39	Loss: 0.9012	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:07:34 [INFO ]  Epoch:   40	Loss: 0.7546	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:07:36 [INFO ]  Epoch:   41	Loss: 0.9522	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:07:38 [INFO ]  Epoch:   42	Loss: 0.7813	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:40 [INFO ]  Epoch:   43	Loss: 0.6865	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:42 [INFO ]  Epoch:   44	Loss: 0.7128	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:43 [INFO ]  Epoch:   45	Loss: 0.7091	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:07:45 [INFO ]  Epoch:   46	Loss: 0.6622	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:07:47 [INFO ]  Epoch:   47	Loss: 0.7191	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:49 [INFO ]  Epoch:   48	Loss: 0.8214	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:07:51 [INFO ]  Epoch:   49	Loss: 0.7356	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:52 [INFO ]  Epoch:   50	Loss: 0.6726	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:07:54 [INFO ]  Epoch:   51	Loss: 0.6123	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:07:56 [INFO ]  Epoch:   52	Loss: 0.7059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:07:58 [INFO ]  Epoch:   53	Loss: 0.6595	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:08:00 [INFO ]  Epoch:   54	Loss: 0.6858	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 11:08:02 [INFO ]  Epoch:   55	Loss: 0.6373	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:04 [INFO ]  Epoch:   56	Loss: 0.6922	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:08:05 [INFO ]  Epoch:   57	Loss: 0.6983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:07 [INFO ]  Epoch:   58	Loss: 0.6346	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:08:09 [INFO ]  Epoch:   59	Loss: 0.6747	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:08:11 [INFO ]  Epoch:   60	Loss: 0.5596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:13 [INFO ]  Epoch:   61	Loss: 0.6078	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:15 [INFO ]  Epoch:   62	Loss: 0.6235	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:17 [INFO ]  Epoch:   63	Loss: 0.6705	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:19 [INFO ]  Epoch:   64	Loss: 0.6844	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:08:20 [INFO ]  Epoch:   65	Loss: 0.6517	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:08:22 [INFO ]  Epoch:   66	Loss: 0.6460	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:08:24 [INFO ]  Epoch:   67	Loss: 0.5758	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:26 [INFO ]  Epoch:   68	Loss: 0.5908	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:08:28 [INFO ]  Epoch:   69	Loss: 0.6067	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:08:29 [INFO ]  Epoch:   70	Loss: 0.6257	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:31 [INFO ]  Epoch:   71	Loss: 0.6353	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:08:33 [INFO ]  Epoch:   72	Loss: 0.5927	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:08:35 [INFO ]  Epoch:   73	Loss: 0.5557	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:08:37 [INFO ]  Epoch:   74	Loss: 0.5902	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:08:39 [INFO ]  Epoch:   75	Loss: 0.6143	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:08:41 [INFO ]  Epoch:   76	Loss: 0.5715	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:42 [INFO ]  Epoch:   77	Loss: 0.6386	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:08:44 [INFO ]  Epoch:   78	Loss: 0.6039	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:08:46 [INFO ]  Epoch:   79	Loss: 0.5498	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:08:48 [INFO ]  Epoch:   80	Loss: 0.6672	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:08:50 [INFO ]  Epoch:   81	Loss: 0.5788	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:08:52 [INFO ]  Epoch:   82	Loss: 0.6369	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:08:54 [INFO ]  Epoch:   83	Loss: 0.5924	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:08:56 [INFO ]  Epoch:   84	Loss: 0.5869	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:08:57 [INFO ]  Epoch:   85	Loss: 0.6627	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:08:59 [INFO ]  Epoch:   86	Loss: 0.5540	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:09:01 [INFO ]  Epoch:   87	Loss: 0.6565	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:09:03 [INFO ]  Epoch:   88	Loss: 0.6600	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:05 [INFO ]  Epoch:   89	Loss: 0.6381	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:07 [INFO ]  Epoch:   90	Loss: 0.5805	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:09:09 [INFO ]  Epoch:   91	Loss: 0.6030	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:09:10 [INFO ]  Epoch:   92	Loss: 0.6178	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:12 [INFO ]  Epoch:   93	Loss: 0.6053	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:09:14 [INFO ]  Epoch:   94	Loss: 0.6298	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:16 [INFO ]  Epoch:   95	Loss: 0.5727	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:09:18 [INFO ]  Epoch:   96	Loss: 0.5780	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:20 [INFO ]  Epoch:   97	Loss: 0.5535	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:09:22 [INFO ]  Epoch:   98	Loss: 0.6677	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:23 [INFO ]  Epoch:   99	Loss: 0.5947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:25 [INFO ]  Epoch:  100	Loss: 0.5474	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:27 [INFO ]  Epoch:  101	Loss: 0.6586	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:09:29 [INFO ]  Epoch:  102	Loss: 0.5794	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:31 [INFO ]  Epoch:  103	Loss: 0.5861	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:33 [INFO ]  Epoch:  104	Loss: 0.5816	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:09:35 [INFO ]  Epoch:  105	Loss: 0.6280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:36 [INFO ]  Epoch:  106	Loss: 0.6173	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:09:38 [INFO ]  Epoch:  107	Loss: 0.5704	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:40 [INFO ]  Epoch:  108	Loss: 0.5081	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:09:42 [INFO ]  Epoch:  109	Loss: 0.5566	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:09:43 [INFO ]  Epoch:  110	Loss: 0.5441	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:45 [INFO ]  Epoch:  111	Loss: 0.5840	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:47 [INFO ]  Epoch:  112	Loss: 0.5973	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:49 [INFO ]  Epoch:  113	Loss: 0.5629	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:51 [INFO ]  Epoch:  114	Loss: 0.5485	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:09:53 [INFO ]  Epoch:  115	Loss: 0.6420	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:55 [INFO ]  Epoch:  116	Loss: 0.5989	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:09:56 [INFO ]  Epoch:  117	Loss: 0.5758	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:09:58 [INFO ]  Epoch:  118	Loss: 0.5940	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:00 [INFO ]  Epoch:  119	Loss: 0.5774	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:02 [INFO ]  Epoch:  120	Loss: 0.6482	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:04 [INFO ]  Epoch:  121	Loss: 0.5876	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:10:06 [INFO ]  Epoch:  122	Loss: 0.5977	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:10:08 [INFO ]  Epoch:  123	Loss: 0.6284	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:10 [INFO ]  Epoch:  124	Loss: 0.6764	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:10:12 [INFO ]  Epoch:  125	Loss: 0.6117	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:10:13 [INFO ]  Epoch:  126	Loss: 0.4861	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:15 [INFO ]  Epoch:  127	Loss: 0.6540	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:17 [INFO ]  Epoch:  128	Loss: 0.5850	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:10:19 [INFO ]  Epoch:  129	Loss: 0.6485	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:21 [INFO ]  Epoch:  130	Loss: 0.5774	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:23 [INFO ]  Epoch:  131	Loss: 0.5862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:24 [INFO ]  Epoch:  132	Loss: 0.5684	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:26 [INFO ]  Epoch:  133	Loss: 0.6137	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:10:28 [INFO ]  Epoch:  134	Loss: 0.6639	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:10:30 [INFO ]  Epoch:  135	Loss: 0.6420	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:32 [INFO ]  Epoch:  136	Loss: 0.6107	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:10:33 [INFO ]  Epoch:  137	Loss: 0.6210	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:10:35 [INFO ]  Epoch:  138	Loss: 0.6111	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:10:37 [INFO ]  Epoch:  139	Loss: 0.5910	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:10:39 [INFO ]  Epoch:  140	Loss: 0.5417	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:41 [INFO ]  Epoch:  141	Loss: 0.5349	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:10:43 [INFO ]  Epoch:  142	Loss: 0.6429	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:45 [INFO ]  Epoch:  143	Loss: 0.5843	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:10:47 [INFO ]  Epoch:  144	Loss: 0.6286	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:49 [INFO ]  Epoch:  145	Loss: 0.6286	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:10:51 [INFO ]  Epoch:  146	Loss: 0.5909	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:53 [INFO ]  Epoch:  147	Loss: 0.6068	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:10:55 [INFO ]  Epoch:  148	Loss: 0.5594	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:10:56 [INFO ]  Epoch:  149	Loss: 0.5788	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:10:58 [INFO ]  Epoch:  150	Loss: 0.5796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:00 [INFO ]  Epoch:  151	Loss: 0.5626	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:02 [INFO ]  Epoch:  152	Loss: 0.5841	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:03 [INFO ]  Epoch:  153	Loss: 0.5581	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:11:05 [INFO ]  Epoch:  154	Loss: 0.5797	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:07 [INFO ]  Epoch:  155	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:09 [INFO ]  Epoch:  156	Loss: 0.6293	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:11:11 [INFO ]  Epoch:  157	Loss: 0.6512	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:11:13 [INFO ]  Epoch:  158	Loss: 0.5692	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:11:15 [INFO ]  Epoch:  159	Loss: 0.5604	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:16 [INFO ]  Epoch:  160	Loss: 0.5800	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:11:18 [INFO ]  Epoch:  161	Loss: 0.7000	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:20 [INFO ]  Epoch:  162	Loss: 0.6221	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:11:22 [INFO ]  Epoch:  163	Loss: 0.5692	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:11:24 [INFO ]  Epoch:  164	Loss: 0.5872	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:26 [INFO ]  Epoch:  165	Loss: 0.5239	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:11:28 [INFO ]  Epoch:  166	Loss: 0.6028	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:11:29 [INFO ]  Epoch:  167	Loss: 0.6009	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:31 [INFO ]  Epoch:  168	Loss: 0.5950	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:11:33 [INFO ]  Epoch:  169	Loss: 0.5275	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:35 [INFO ]  Epoch:  170	Loss: 0.5789	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:37 [INFO ]  Epoch:  171	Loss: 0.5606	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 11:11:39 [INFO ]  Epoch:  172	Loss: 0.6054	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:11:41 [INFO ]  Epoch:  173	Loss: 0.6327	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:43 [INFO ]  Epoch:  174	Loss: 0.5697	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:11:45 [INFO ]  Epoch:  175	Loss: 0.5796	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:47 [INFO ]  Epoch:  176	Loss: 0.6043	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:11:48 [INFO ]  Epoch:  177	Loss: 0.5918	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:11:50 [INFO ]  Epoch:  178	Loss: 0.5244	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:11:52 [INFO ]  Epoch:  179	Loss: 0.5941	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:11:54 [INFO ]  Epoch:  180	Loss: 0.5924	Data Time: 0.13s	Train Time: 0.01s
2022-10-04 11:11:56 [INFO ]  Epoch:  181	Loss: 0.5966	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:11:58 [INFO ]  Epoch:  182	Loss: 0.5477	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:12:00 [INFO ]  Epoch:  183	Loss: 0.5853	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:12:02 [INFO ]  Epoch:  184	Loss: 0.4878	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:03 [INFO ]  Epoch:  185	Loss: 0.5824	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:05 [INFO ]  Epoch:  186	Loss: 0.5590	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:07 [INFO ]  Epoch:  187	Loss: 0.6194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:09 [INFO ]  Epoch:  188	Loss: 0.6015	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:12:11 [INFO ]  Epoch:  189	Loss: 0.5366	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:12:13 [INFO ]  Epoch:  190	Loss: 0.5945	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:15 [INFO ]  Epoch:  191	Loss: 0.6236	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:16 [INFO ]  Epoch:  192	Loss: 0.5899	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:12:18 [INFO ]  Epoch:  193	Loss: 0.5722	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:12:20 [INFO ]  Epoch:  194	Loss: 0.6150	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:12:22 [INFO ]  Epoch:  195	Loss: 0.5356	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:12:24 [INFO ]  Epoch:  196	Loss: 0.5548	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:26 [INFO ]  Epoch:  197	Loss: 0.6247	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:12:27 [INFO ]  Epoch:  198	Loss: 0.6419	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:29 [INFO ]  Epoch:  199	Loss: 0.6168	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:12:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 11:12:31 [INFO ]  
2022-10-04 11:12:31 [INFO ]  Final evaluation for SVHN :
2022-10-04 11:12:34 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:12:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:12:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:12:34 [INFO ]  	   step  1 (lr=0.413256)                   82.44%                   0.6613
2022-10-04 11:12:34 [INFO ]  
2022-10-04 11:12:34 [INFO ]  
2022-10-04 11:12:34 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 11:12:37 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:12:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:12:37 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 11:12:37 [INFO ]  	   step  1 (lr=0.413256)                   15.05%                   5.6373
2022-10-04 11:12:37 [INFO ]  
2022-10-04 11:12:37 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 11:23:17 [INFO ]  ======================================== 2022-10-04 11:23:17 ========================================
2022-10-04 11:23:17 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 11:23:17 [INFO ]  Options: 
2022-10-04 11:23:17 [INFO ]  	base_dir: null
2022-10-04 11:23:17 [INFO ]  	batch_size: 1024
2022-10-04 11:23:17 [INFO ]  	checkpoint_interval: 300
2022-10-04 11:23:17 [INFO ]  	dataset: SVHN
2022-10-04 11:23:17 [INFO ]  	dataset_labels:
2022-10-04 11:23:17 [INFO ]  	- 0
2022-10-04 11:23:17 [INFO ]  	- 1
2022-10-04 11:23:17 [INFO ]  	- 2
2022-10-04 11:23:17 [INFO ]  	- 3
2022-10-04 11:23:17 [INFO ]  	- 4
2022-10-04 11:23:17 [INFO ]  	- 5
2022-10-04 11:23:17 [INFO ]  	- 6
2022-10-04 11:23:17 [INFO ]  	- 7
2022-10-04 11:23:17 [INFO ]  	- 8
2022-10-04 11:23:17 [INFO ]  	- 9
2022-10-04 11:23:17 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 11:23:17 [INFO ]  	- !!python/tuple
2022-10-04 11:23:17 [INFO ]  	    - 0.4379104971885681
2022-10-04 11:23:17 [INFO ]  	    - 0.44398033618927
2022-10-04 11:23:17 [INFO ]  	    - 0.4729299545288086
2022-10-04 11:23:17 [INFO ]  	- !!python/tuple
2022-10-04 11:23:17 [INFO ]  	    - 0.19803012907505035
2022-10-04 11:23:17 [INFO ]  	    - 0.2010156363248825
2022-10-04 11:23:17 [INFO ]  	    - 0.19703614711761475
2022-10-04 11:23:17 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 11:23:17 [INFO ]  	decay_epochs: 50
2022-10-04 11:23:17 [INFO ]  	decay_factor: 0.1
2022-10-04 11:23:17 [INFO ]  	device_id: 0
2022-10-04 11:23:17 [INFO ]  	distill_epochs: 1
2022-10-04 11:23:17 [INFO ]  	distill_lr: 0.02
2022-10-04 11:23:17 [INFO ]  	distill_steps: 1
2022-10-04 11:23:17 [INFO ]  	epochs: 200
2022-10-04 11:23:17 [INFO ]  	expand_cls: false
2022-10-04 11:23:17 [INFO ]  	forgetting_dataset: null
2022-10-04 11:23:17 [INFO ]  	init: xavier
2022-10-04 11:23:17 [INFO ]  	init_param: 1.0
2022-10-04 11:23:17 [INFO ]  	input_size: 32
2022-10-04 11:23:17 [INFO ]  	ipc: 25
2022-10-04 11:23:17 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 11:23:17 [INFO ]  	log_interval: 100
2022-10-04 11:23:17 [INFO ]  	log_level: INFO
2022-10-04 11:23:17 [INFO ]  	lr: 0.01
2022-10-04 11:23:17 [INFO ]  	mode: distill_adapt
2022-10-04 11:23:17 [INFO ]  	nc: 3
2022-10-04 11:23:17 [INFO ]  	num_classes: 10
2022-10-04 11:23:17 [INFO ]  	num_workers: 8
2022-10-04 11:23:17 [INFO ]  	phase: train
2022-10-04 11:23:17 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 11:23:17 [INFO ]  	start_time: '2022-10-04 11:23:17'
2022-10-04 11:23:17 [INFO ]  	test_batch_size: 1024
2022-10-04 11:23:17 [INFO ]  	
2022-10-04 11:23:19 [INFO ]  train dataset size:	73257
2022-10-04 11:23:19 [INFO ]  test dataset size: 	26032
2022-10-04 11:23:19 [INFO ]  datasets built!
2022-10-04 11:23:19 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 11:23:21 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 11:23:21 [INFO ]  
2022-10-04 11:23:21 [INFO ]  Begin of epoch 0 :
2022-10-04 11:23:24 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:23:24 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:23:24 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:23:24 [INFO ]  	   step  1 (lr=0.020000)                    7.23%                   8.5562
2022-10-04 11:23:24 [INFO ]  
2022-10-04 11:23:24 [INFO ]  Epoch:    0	Loss: 8.0719	Data Time: 0.37s	Train Time: 0.04s
2022-10-04 11:23:26 [INFO ]  Epoch:    1	Loss: 3.0076	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:27 [INFO ]  Epoch:    2	Loss: 2.4708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:29 [INFO ]  Epoch:    3	Loss: 2.2606	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:23:31 [INFO ]  Epoch:    4	Loss: 2.1955	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:33 [INFO ]  Epoch:    5	Loss: 2.1692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:35 [INFO ]  Epoch:    6	Loss: 2.1365	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:23:37 [INFO ]  Epoch:    7	Loss: 2.0895	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:39 [INFO ]  Epoch:    8	Loss: 2.0465	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:23:41 [INFO ]  Epoch:    9	Loss: 1.9203	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:42 [INFO ]  Epoch:   10	Loss: 1.8133	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:44 [INFO ]  Epoch:   11	Loss: 1.6263	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:46 [INFO ]  Epoch:   12	Loss: 1.4740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:23:48 [INFO ]  Epoch:   13	Loss: 1.4970	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:23:49 [INFO ]  Epoch:   14	Loss: 1.3444	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:23:51 [INFO ]  Epoch:   15	Loss: 1.2642	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:23:53 [INFO ]  Epoch:   16	Loss: 1.2660	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:23:55 [INFO ]  Epoch:   17	Loss: 1.1729	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:23:57 [INFO ]  Epoch:   18	Loss: 1.0118	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:23:59 [INFO ]  Epoch:   19	Loss: 1.0538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:00 [INFO ]  Epoch:   20	Loss: 1.0519	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:24:02 [INFO ]  Epoch:   21	Loss: 1.0869	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:24:04 [INFO ]  Epoch:   22	Loss: 0.9209	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:24:06 [INFO ]  Epoch:   23	Loss: 0.9970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:08 [INFO ]  Epoch:   24	Loss: 0.9420	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:24:09 [INFO ]  Epoch:   25	Loss: 0.9170	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:24:11 [INFO ]  Epoch:   26	Loss: 0.9206	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:13 [INFO ]  Epoch:   27	Loss: 0.9088	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:15 [INFO ]  Epoch:   28	Loss: 0.9015	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:24:16 [INFO ]  Epoch:   29	Loss: 0.8254	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:24:18 [INFO ]  Epoch:   30	Loss: 0.7780	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:24:20 [INFO ]  Epoch:   31	Loss: 0.8466	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:24:22 [INFO ]  Epoch:   32	Loss: 0.7494	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:24:24 [INFO ]  Epoch:   33	Loss: 0.9119	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:25 [INFO ]  Epoch:   34	Loss: 0.9190	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:27 [INFO ]  Epoch:   35	Loss: 0.7418	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:24:29 [INFO ]  Epoch:   36	Loss: 0.7884	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:24:30 [INFO ]  Epoch:   37	Loss: 0.7499	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:24:32 [INFO ]  Epoch:   38	Loss: 0.7989	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:24:34 [INFO ]  Epoch:   39	Loss: 0.7558	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:24:36 [INFO ]  Epoch:   40	Loss: 0.7580	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:38 [INFO ]  Epoch:   41	Loss: 0.8102	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:24:39 [INFO ]  Epoch:   42	Loss: 0.7106	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:41 [INFO ]  Epoch:   43	Loss: 0.6730	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:24:43 [INFO ]  Epoch:   44	Loss: 0.6781	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:24:45 [INFO ]  Epoch:   45	Loss: 0.7272	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:24:47 [INFO ]  Epoch:   46	Loss: 0.7405	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:24:49 [INFO ]  Epoch:   47	Loss: 0.7721	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:51 [INFO ]  Epoch:   48	Loss: 0.7385	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:24:52 [INFO ]  Epoch:   49	Loss: 0.6744	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:54 [INFO ]  Epoch:   50	Loss: 0.6845	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:24:56 [INFO ]  Epoch:   51	Loss: 0.6378	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:24:58 [INFO ]  Epoch:   52	Loss: 0.6017	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:00 [INFO ]  Epoch:   53	Loss: 0.6223	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:25:02 [INFO ]  Epoch:   54	Loss: 0.6607	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:25:03 [INFO ]  Epoch:   55	Loss: 0.6488	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:05 [INFO ]  Epoch:   56	Loss: 0.6062	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:07 [INFO ]  Epoch:   57	Loss: 0.6547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:09 [INFO ]  Epoch:   58	Loss: 0.6830	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:25:10 [INFO ]  Epoch:   59	Loss: 0.5842	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:25:12 [INFO ]  Epoch:   60	Loss: 0.6793	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:14 [INFO ]  Epoch:   61	Loss: 0.6162	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:25:16 [INFO ]  Epoch:   62	Loss: 0.6203	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:18 [INFO ]  Epoch:   63	Loss: 0.6195	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:25:19 [INFO ]  Epoch:   64	Loss: 0.6469	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:25:21 [INFO ]  Epoch:   65	Loss: 0.5810	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:25:23 [INFO ]  Epoch:   66	Loss: 0.6615	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:25 [INFO ]  Epoch:   67	Loss: 0.6331	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:25:26 [INFO ]  Epoch:   68	Loss: 0.7148	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:25:28 [INFO ]  Epoch:   69	Loss: 0.7219	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:25:30 [INFO ]  Epoch:   70	Loss: 0.6884	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:32 [INFO ]  Epoch:   71	Loss: 0.6339	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:25:34 [INFO ]  Epoch:   72	Loss: 0.5826	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:25:35 [INFO ]  Epoch:   73	Loss: 0.6743	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:25:37 [INFO ]  Epoch:   74	Loss: 0.6920	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:25:39 [INFO ]  Epoch:   75	Loss: 0.6285	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:25:41 [INFO ]  Epoch:   76	Loss: 0.6221	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:25:43 [INFO ]  Epoch:   77	Loss: 0.5993	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:25:45 [INFO ]  Epoch:   78	Loss: 0.6555	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:25:47 [INFO ]  Epoch:   79	Loss: 0.6370	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:48 [INFO ]  Epoch:   80	Loss: 0.6309	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:50 [INFO ]  Epoch:   81	Loss: 0.5682	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:52 [INFO ]  Epoch:   82	Loss: 0.7337	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:25:54 [INFO ]  Epoch:   83	Loss: 0.6565	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:25:56 [INFO ]  Epoch:   84	Loss: 0.6209	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:25:58 [INFO ]  Epoch:   85	Loss: 0.5660	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:26:00 [INFO ]  Epoch:   86	Loss: 0.6212	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:26:01 [INFO ]  Epoch:   87	Loss: 0.6374	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:03 [INFO ]  Epoch:   88	Loss: 0.5904	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:26:05 [INFO ]  Epoch:   89	Loss: 0.6301	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:07 [INFO ]  Epoch:   90	Loss: 0.5532	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:26:08 [INFO ]  Epoch:   91	Loss: 0.6128	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:10 [INFO ]  Epoch:   92	Loss: 0.6025	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:26:12 [INFO ]  Epoch:   93	Loss: 0.5813	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:26:14 [INFO ]  Epoch:   94	Loss: 0.5762	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:16 [INFO ]  Epoch:   95	Loss: 0.6737	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:26:17 [INFO ]  Epoch:   96	Loss: 0.5891	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:19 [INFO ]  Epoch:   97	Loss: 0.6585	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:26:21 [INFO ]  Epoch:   98	Loss: 0.6238	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:26:23 [INFO ]  Epoch:   99	Loss: 0.5558	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:26:25 [INFO ]  Epoch:  100	Loss: 0.5761	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:26:27 [INFO ]  Epoch:  101	Loss: 0.6621	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:29 [INFO ]  Epoch:  102	Loss: 0.5771	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:26:31 [INFO ]  Epoch:  103	Loss: 0.6112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:33 [INFO ]  Epoch:  104	Loss: 0.5820	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:26:34 [INFO ]  Epoch:  105	Loss: 0.6288	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:26:36 [INFO ]  Epoch:  106	Loss: 0.5393	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:26:38 [INFO ]  Epoch:  107	Loss: 0.6230	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:40 [INFO ]  Epoch:  108	Loss: 0.5511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:42 [INFO ]  Epoch:  109	Loss: 0.6534	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:43 [INFO ]  Epoch:  110	Loss: 0.6192	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:45 [INFO ]  Epoch:  111	Loss: 0.5886	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:47 [INFO ]  Epoch:  112	Loss: 0.6304	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:26:49 [INFO ]  Epoch:  113	Loss: 0.6097	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:51 [INFO ]  Epoch:  114	Loss: 0.5689	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:26:53 [INFO ]  Epoch:  115	Loss: 0.6103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:26:54 [INFO ]  Epoch:  116	Loss: 0.6051	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:26:56 [INFO ]  Epoch:  117	Loss: 0.6601	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:26:58 [INFO ]  Epoch:  118	Loss: 0.6501	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:27:00 [INFO ]  Epoch:  119	Loss: 0.6331	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:02 [INFO ]  Epoch:  120	Loss: 0.6334	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:27:04 [INFO ]  Epoch:  121	Loss: 0.6614	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:06 [INFO ]  Epoch:  122	Loss: 0.5663	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:27:08 [INFO ]  Epoch:  123	Loss: 0.6112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:09 [INFO ]  Epoch:  124	Loss: 0.5948	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:11 [INFO ]  Epoch:  125	Loss: 0.5796	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:27:13 [INFO ]  Epoch:  126	Loss: 0.6020	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:27:15 [INFO ]  Epoch:  127	Loss: 0.6377	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:27:17 [INFO ]  Epoch:  128	Loss: 0.6554	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:27:19 [INFO ]  Epoch:  129	Loss: 0.6087	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:27:21 [INFO ]  Epoch:  130	Loss: 0.5988	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:23 [INFO ]  Epoch:  131	Loss: 0.5996	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:27:24 [INFO ]  Epoch:  132	Loss: 0.6939	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:26 [INFO ]  Epoch:  133	Loss: 0.5648	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:27:28 [INFO ]  Epoch:  134	Loss: 0.6343	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:30 [INFO ]  Epoch:  135	Loss: 0.5819	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:32 [INFO ]  Epoch:  136	Loss: 0.5547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:34 [INFO ]  Epoch:  137	Loss: 0.6064	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:36 [INFO ]  Epoch:  138	Loss: 0.6505	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:27:37 [INFO ]  Epoch:  139	Loss: 0.6283	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:39 [INFO ]  Epoch:  140	Loss: 0.6114	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:41 [INFO ]  Epoch:  141	Loss: 0.6187	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:43 [INFO ]  Epoch:  142	Loss: 0.5980	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:45 [INFO ]  Epoch:  143	Loss: 0.5562	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:27:47 [INFO ]  Epoch:  144	Loss: 0.7476	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:48 [INFO ]  Epoch:  145	Loss: 0.6037	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:50 [INFO ]  Epoch:  146	Loss: 0.6588	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:52 [INFO ]  Epoch:  147	Loss: 0.5948	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:27:54 [INFO ]  Epoch:  148	Loss: 0.5847	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:56 [INFO ]  Epoch:  149	Loss: 0.6046	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:27:58 [INFO ]  Epoch:  150	Loss: 0.6228	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:00 [INFO ]  Epoch:  151	Loss: 0.5570	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:01 [INFO ]  Epoch:  152	Loss: 0.5316	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:03 [INFO ]  Epoch:  153	Loss: 0.5793	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:05 [INFO ]  Epoch:  154	Loss: 0.6376	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:07 [INFO ]  Epoch:  155	Loss: 0.6375	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:28:09 [INFO ]  Epoch:  156	Loss: 0.6508	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:28:11 [INFO ]  Epoch:  157	Loss: 0.6011	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:28:13 [INFO ]  Epoch:  158	Loss: 0.6069	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:28:15 [INFO ]  Epoch:  159	Loss: 0.5686	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:28:16 [INFO ]  Epoch:  160	Loss: 0.5801	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:18 [INFO ]  Epoch:  161	Loss: 0.5605	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:28:20 [INFO ]  Epoch:  162	Loss: 0.6169	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:28:22 [INFO ]  Epoch:  163	Loss: 0.6957	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:24 [INFO ]  Epoch:  164	Loss: 0.6019	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:26 [INFO ]  Epoch:  165	Loss: 0.6512	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:28:28 [INFO ]  Epoch:  166	Loss: 0.6083	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:30 [INFO ]  Epoch:  167	Loss: 0.6001	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:32 [INFO ]  Epoch:  168	Loss: 0.6164	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:28:33 [INFO ]  Epoch:  169	Loss: 0.6387	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:35 [INFO ]  Epoch:  170	Loss: 0.5457	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:28:37 [INFO ]  Epoch:  171	Loss: 0.6189	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:28:39 [INFO ]  Epoch:  172	Loss: 0.5923	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:28:41 [INFO ]  Epoch:  173	Loss: 0.6626	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:28:43 [INFO ]  Epoch:  174	Loss: 0.5878	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:44 [INFO ]  Epoch:  175	Loss: 0.6602	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:46 [INFO ]  Epoch:  176	Loss: 0.5758	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:48 [INFO ]  Epoch:  177	Loss: 0.5558	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:50 [INFO ]  Epoch:  178	Loss: 0.6246	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:28:52 [INFO ]  Epoch:  179	Loss: 0.5749	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:53 [INFO ]  Epoch:  180	Loss: 0.6316	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:28:55 [INFO ]  Epoch:  181	Loss: 0.6016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:57 [INFO ]  Epoch:  182	Loss: 0.6118	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:28:59 [INFO ]  Epoch:  183	Loss: 0.5802	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:29:00 [INFO ]  Epoch:  184	Loss: 0.6296	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:02 [INFO ]  Epoch:  185	Loss: 0.5738	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:29:04 [INFO ]  Epoch:  186	Loss: 0.6418	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:29:06 [INFO ]  Epoch:  187	Loss: 0.5747	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:08 [INFO ]  Epoch:  188	Loss: 0.6408	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:29:10 [INFO ]  Epoch:  189	Loss: 0.5469	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:11 [INFO ]  Epoch:  190	Loss: 0.6324	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:29:13 [INFO ]  Epoch:  191	Loss: 0.5293	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:15 [INFO ]  Epoch:  192	Loss: 0.6405	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:29:17 [INFO ]  Epoch:  193	Loss: 0.6360	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:29:19 [INFO ]  Epoch:  194	Loss: 0.5948	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:29:20 [INFO ]  Epoch:  195	Loss: 0.5768	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:22 [INFO ]  Epoch:  196	Loss: 0.6300	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:24 [INFO ]  Epoch:  197	Loss: 0.5586	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:29:26 [INFO ]  Epoch:  198	Loss: 0.6034	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:29:28 [INFO ]  Epoch:  199	Loss: 0.6655	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:29:29 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 11:29:29 [INFO ]  
2022-10-04 11:29:29 [INFO ]  Final evaluation for SVHN :
2022-10-04 11:29:32 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:29:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:29:32 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:29:32 [INFO ]  	   step  1 (lr=0.406508)                   81.77%                   0.6788
2022-10-04 11:29:32 [INFO ]  
2022-10-04 11:29:32 [INFO ]  
2022-10-04 11:29:32 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 11:29:35 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:29:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:29:35 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 11:29:35 [INFO ]  	   step  1 (lr=0.406508)                   16.32%                   5.8856
2022-10-04 11:29:35 [INFO ]  
2022-10-04 11:29:35 [INFO ]  CPU Time: 3.47 minutes
2022-10-04 11:35:30 [INFO ]  ======================================== 2022-10-04 11:35:30 ========================================
2022-10-04 11:35:30 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 11:35:30 [INFO ]  Options: 
2022-10-04 11:35:30 [INFO ]  	base_dir: null
2022-10-04 11:35:30 [INFO ]  	batch_size: 1024
2022-10-04 11:35:30 [INFO ]  	checkpoint_interval: 300
2022-10-04 11:35:30 [INFO ]  	dataset: SVHN
2022-10-04 11:35:30 [INFO ]  	dataset_labels:
2022-10-04 11:35:30 [INFO ]  	- 0
2022-10-04 11:35:30 [INFO ]  	- 1
2022-10-04 11:35:30 [INFO ]  	- 2
2022-10-04 11:35:30 [INFO ]  	- 3
2022-10-04 11:35:30 [INFO ]  	- 4
2022-10-04 11:35:30 [INFO ]  	- 5
2022-10-04 11:35:30 [INFO ]  	- 6
2022-10-04 11:35:30 [INFO ]  	- 7
2022-10-04 11:35:30 [INFO ]  	- 8
2022-10-04 11:35:30 [INFO ]  	- 9
2022-10-04 11:35:30 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 11:35:30 [INFO ]  	- !!python/tuple
2022-10-04 11:35:30 [INFO ]  	    - 0.4379104971885681
2022-10-04 11:35:30 [INFO ]  	    - 0.44398033618927
2022-10-04 11:35:30 [INFO ]  	    - 0.4729299545288086
2022-10-04 11:35:30 [INFO ]  	- !!python/tuple
2022-10-04 11:35:30 [INFO ]  	    - 0.19803012907505035
2022-10-04 11:35:30 [INFO ]  	    - 0.2010156363248825
2022-10-04 11:35:30 [INFO ]  	    - 0.19703614711761475
2022-10-04 11:35:30 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 11:35:30 [INFO ]  	decay_epochs: 50
2022-10-04 11:35:30 [INFO ]  	decay_factor: 0.1
2022-10-04 11:35:30 [INFO ]  	device_id: 0
2022-10-04 11:35:30 [INFO ]  	distill_epochs: 1
2022-10-04 11:35:30 [INFO ]  	distill_lr: 0.02
2022-10-04 11:35:30 [INFO ]  	distill_steps: 1
2022-10-04 11:35:30 [INFO ]  	epochs: 200
2022-10-04 11:35:30 [INFO ]  	expand_cls: false
2022-10-04 11:35:30 [INFO ]  	forgetting_dataset: null
2022-10-04 11:35:30 [INFO ]  	init: xavier
2022-10-04 11:35:30 [INFO ]  	init_param: 1.0
2022-10-04 11:35:30 [INFO ]  	input_size: 32
2022-10-04 11:35:30 [INFO ]  	ipc: 25
2022-10-04 11:35:30 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 11:35:30 [INFO ]  	log_interval: 100
2022-10-04 11:35:30 [INFO ]  	log_level: INFO
2022-10-04 11:35:30 [INFO ]  	lr: 0.01
2022-10-04 11:35:30 [INFO ]  	mode: distill_adapt
2022-10-04 11:35:30 [INFO ]  	nc: 3
2022-10-04 11:35:30 [INFO ]  	num_classes: 10
2022-10-04 11:35:30 [INFO ]  	num_workers: 8
2022-10-04 11:35:30 [INFO ]  	phase: train
2022-10-04 11:35:30 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 11:35:30 [INFO ]  	start_time: '2022-10-04 11:35:30'
2022-10-04 11:35:30 [INFO ]  	test_batch_size: 1024
2022-10-04 11:35:30 [INFO ]  	
2022-10-04 11:35:32 [INFO ]  train dataset size:	73257
2022-10-04 11:35:32 [INFO ]  test dataset size: 	26032
2022-10-04 11:35:32 [INFO ]  datasets built!
2022-10-04 11:35:32 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 11:35:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 11:35:34 [INFO ]  
2022-10-04 11:35:34 [INFO ]  Begin of epoch 0 :
2022-10-04 11:35:37 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:35:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:35:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:35:37 [INFO ]  	   step  1 (lr=0.020000)                    6.82%                   9.1585
2022-10-04 11:35:37 [INFO ]  
2022-10-04 11:35:37 [INFO ]  Epoch:    0	Loss: 9.4931	Data Time: 0.38s	Train Time: 0.04s
2022-10-04 11:35:39 [INFO ]  Epoch:    1	Loss: 3.0536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:35:41 [INFO ]  Epoch:    2	Loss: 2.4630	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:35:42 [INFO ]  Epoch:    3	Loss: 2.2800	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:35:44 [INFO ]  Epoch:    4	Loss: 2.2172	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:35:46 [INFO ]  Epoch:    5	Loss: 2.1936	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:35:48 [INFO ]  Epoch:    6	Loss: 2.1563	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:35:49 [INFO ]  Epoch:    7	Loss: 2.1044	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:35:51 [INFO ]  Epoch:    8	Loss: 2.0949	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:35:53 [INFO ]  Epoch:    9	Loss: 2.0373	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:35:55 [INFO ]  Epoch:   10	Loss: 1.8791	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:35:57 [INFO ]  Epoch:   11	Loss: 1.7112	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:35:59 [INFO ]  Epoch:   12	Loss: 1.5958	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:01 [INFO ]  Epoch:   13	Loss: 1.4705	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:03 [INFO ]  Epoch:   14	Loss: 1.4192	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:36:04 [INFO ]  Epoch:   15	Loss: 1.2164	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:36:06 [INFO ]  Epoch:   16	Loss: 1.1403	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:36:08 [INFO ]  Epoch:   17	Loss: 1.1432	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:36:10 [INFO ]  Epoch:   18	Loss: 1.0920	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:36:11 [INFO ]  Epoch:   19	Loss: 1.1160	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:36:13 [INFO ]  Epoch:   20	Loss: 1.0803	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:36:15 [INFO ]  Epoch:   21	Loss: 0.9158	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:17 [INFO ]  Epoch:   22	Loss: 0.9540	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:19 [INFO ]  Epoch:   23	Loss: 0.9373	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:36:20 [INFO ]  Epoch:   24	Loss: 0.9121	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:36:22 [INFO ]  Epoch:   25	Loss: 0.8847	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:24 [INFO ]  Epoch:   26	Loss: 0.8298	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:36:26 [INFO ]  Epoch:   27	Loss: 0.8790	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:28 [INFO ]  Epoch:   28	Loss: 0.8946	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:36:30 [INFO ]  Epoch:   29	Loss: 0.9002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:31 [INFO ]  Epoch:   30	Loss: 0.8229	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:33 [INFO ]  Epoch:   31	Loss: 0.8158	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:35 [INFO ]  Epoch:   32	Loss: 0.8514	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:36:37 [INFO ]  Epoch:   33	Loss: 0.8103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:39 [INFO ]  Epoch:   34	Loss: 0.7643	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:41 [INFO ]  Epoch:   35	Loss: 0.7490	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:43 [INFO ]  Epoch:   36	Loss: 0.8328	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:36:45 [INFO ]  Epoch:   37	Loss: 0.7620	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:36:46 [INFO ]  Epoch:   38	Loss: 0.9107	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:48 [INFO ]  Epoch:   39	Loss: 0.7380	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:50 [INFO ]  Epoch:   40	Loss: 0.7807	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:36:52 [INFO ]  Epoch:   41	Loss: 0.7311	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:36:54 [INFO ]  Epoch:   42	Loss: 0.7064	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:36:56 [INFO ]  Epoch:   43	Loss: 0.7915	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:57 [INFO ]  Epoch:   44	Loss: 0.6818	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:36:59 [INFO ]  Epoch:   45	Loss: 0.7251	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:37:01 [INFO ]  Epoch:   46	Loss: 0.7942	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:37:03 [INFO ]  Epoch:   47	Loss: 0.7031	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:04 [INFO ]  Epoch:   48	Loss: 0.6583	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:37:06 [INFO ]  Epoch:   49	Loss: 0.6491	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:37:08 [INFO ]  Epoch:   50	Loss: 0.6525	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:10 [INFO ]  Epoch:   51	Loss: 0.6201	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:12 [INFO ]  Epoch:   52	Loss: 0.5646	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:37:13 [INFO ]  Epoch:   53	Loss: 0.6460	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:15 [INFO ]  Epoch:   54	Loss: 0.5912	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:17 [INFO ]  Epoch:   55	Loss: 0.6700	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:19 [INFO ]  Epoch:   56	Loss: 0.5777	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:37:21 [INFO ]  Epoch:   57	Loss: 0.6202	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:37:23 [INFO ]  Epoch:   58	Loss: 0.6656	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:37:24 [INFO ]  Epoch:   59	Loss: 0.6248	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:37:26 [INFO ]  Epoch:   60	Loss: 0.6130	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:37:28 [INFO ]  Epoch:   61	Loss: 0.6362	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:37:30 [INFO ]  Epoch:   62	Loss: 0.6482	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:31 [INFO ]  Epoch:   63	Loss: 0.6029	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:33 [INFO ]  Epoch:   64	Loss: 0.6218	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:37:35 [INFO ]  Epoch:   65	Loss: 0.6245	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:37 [INFO ]  Epoch:   66	Loss: 0.6190	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:39 [INFO ]  Epoch:   67	Loss: 0.5927	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:37:40 [INFO ]  Epoch:   68	Loss: 0.5695	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:42 [INFO ]  Epoch:   69	Loss: 0.5921	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:37:44 [INFO ]  Epoch:   70	Loss: 0.6164	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:37:46 [INFO ]  Epoch:   71	Loss: 0.6324	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:37:48 [INFO ]  Epoch:   72	Loss: 0.6155	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:37:50 [INFO ]  Epoch:   73	Loss: 0.6344	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:51 [INFO ]  Epoch:   74	Loss: 0.6245	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:53 [INFO ]  Epoch:   75	Loss: 0.5196	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:37:55 [INFO ]  Epoch:   76	Loss: 0.6274	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:37:57 [INFO ]  Epoch:   77	Loss: 0.5887	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:37:59 [INFO ]  Epoch:   78	Loss: 0.7327	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:38:00 [INFO ]  Epoch:   79	Loss: 0.6050	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:38:02 [INFO ]  Epoch:   80	Loss: 0.6228	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:04 [INFO ]  Epoch:   81	Loss: 0.5830	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:38:06 [INFO ]  Epoch:   82	Loss: 0.5251	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:38:08 [INFO ]  Epoch:   83	Loss: 0.5272	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:10 [INFO ]  Epoch:   84	Loss: 0.6274	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:11 [INFO ]  Epoch:   85	Loss: 0.6737	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:38:13 [INFO ]  Epoch:   86	Loss: 0.6152	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:38:15 [INFO ]  Epoch:   87	Loss: 0.5857	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:38:17 [INFO ]  Epoch:   88	Loss: 0.6930	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:38:18 [INFO ]  Epoch:   89	Loss: 0.6013	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:20 [INFO ]  Epoch:   90	Loss: 0.5527	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:38:22 [INFO ]  Epoch:   91	Loss: 0.6910	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:38:24 [INFO ]  Epoch:   92	Loss: 0.5999	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:38:26 [INFO ]  Epoch:   93	Loss: 0.6211	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:28 [INFO ]  Epoch:   94	Loss: 0.6320	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:38:30 [INFO ]  Epoch:   95	Loss: 0.6348	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:38:31 [INFO ]  Epoch:   96	Loss: 0.6058	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:38:33 [INFO ]  Epoch:   97	Loss: 0.6997	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:38:35 [INFO ]  Epoch:   98	Loss: 0.5712	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:37 [INFO ]  Epoch:   99	Loss: 0.6225	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:39 [INFO ]  Epoch:  100	Loss: 0.5774	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:41 [INFO ]  Epoch:  101	Loss: 0.6272	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:38:43 [INFO ]  Epoch:  102	Loss: 0.5978	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:45 [INFO ]  Epoch:  103	Loss: 0.5581	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:38:46 [INFO ]  Epoch:  104	Loss: 0.5348	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:48 [INFO ]  Epoch:  105	Loss: 0.5993	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:38:50 [INFO ]  Epoch:  106	Loss: 0.5686	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:38:52 [INFO ]  Epoch:  107	Loss: 0.6047	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:38:54 [INFO ]  Epoch:  108	Loss: 0.5894	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:38:56 [INFO ]  Epoch:  109	Loss: 0.6068	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:38:58 [INFO ]  Epoch:  110	Loss: 0.5778	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:38:59 [INFO ]  Epoch:  111	Loss: 0.6368	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:01 [INFO ]  Epoch:  112	Loss: 0.6203	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:39:03 [INFO ]  Epoch:  113	Loss: 0.6511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:05 [INFO ]  Epoch:  114	Loss: 0.5942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:07 [INFO ]  Epoch:  115	Loss: 0.6233	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:08 [INFO ]  Epoch:  116	Loss: 0.6142	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:10 [INFO ]  Epoch:  117	Loss: 0.5896	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:39:12 [INFO ]  Epoch:  118	Loss: 0.5957	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:39:14 [INFO ]  Epoch:  119	Loss: 0.4977	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:39:16 [INFO ]  Epoch:  120	Loss: 0.5015	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:39:17 [INFO ]  Epoch:  121	Loss: 0.5601	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:39:19 [INFO ]  Epoch:  122	Loss: 0.5534	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:39:21 [INFO ]  Epoch:  123	Loss: 0.5749	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:23 [INFO ]  Epoch:  124	Loss: 0.5864	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:39:25 [INFO ]  Epoch:  125	Loss: 0.5973	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:39:26 [INFO ]  Epoch:  126	Loss: 0.6000	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:28 [INFO ]  Epoch:  127	Loss: 0.5942	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:30 [INFO ]  Epoch:  128	Loss: 0.6033	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:39:32 [INFO ]  Epoch:  129	Loss: 0.5741	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:33 [INFO ]  Epoch:  130	Loss: 0.5398	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:35 [INFO ]  Epoch:  131	Loss: 0.5796	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:39:37 [INFO ]  Epoch:  132	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:39 [INFO ]  Epoch:  133	Loss: 0.5305	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:39:41 [INFO ]  Epoch:  134	Loss: 0.6410	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:43 [INFO ]  Epoch:  135	Loss: 0.6171	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:45 [INFO ]  Epoch:  136	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:47 [INFO ]  Epoch:  137	Loss: 0.5836	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:48 [INFO ]  Epoch:  138	Loss: 0.5111	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:39:50 [INFO ]  Epoch:  139	Loss: 0.6187	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:39:52 [INFO ]  Epoch:  140	Loss: 0.6020	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:39:54 [INFO ]  Epoch:  141	Loss: 0.5236	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:56 [INFO ]  Epoch:  142	Loss: 0.6123	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:39:57 [INFO ]  Epoch:  143	Loss: 0.5762	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:39:59 [INFO ]  Epoch:  144	Loss: 0.6052	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:01 [INFO ]  Epoch:  145	Loss: 0.5612	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:40:03 [INFO ]  Epoch:  146	Loss: 0.5659	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:40:05 [INFO ]  Epoch:  147	Loss: 0.5680	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:06 [INFO ]  Epoch:  148	Loss: 0.6090	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:08 [INFO ]  Epoch:  149	Loss: 0.5507	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:10 [INFO ]  Epoch:  150	Loss: 0.6120	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:12 [INFO ]  Epoch:  151	Loss: 0.5816	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:40:14 [INFO ]  Epoch:  152	Loss: 0.5632	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:15 [INFO ]  Epoch:  153	Loss: 0.5736	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:40:17 [INFO ]  Epoch:  154	Loss: 0.5943	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:40:19 [INFO ]  Epoch:  155	Loss: 0.5730	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:40:21 [INFO ]  Epoch:  156	Loss: 0.5953	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:23 [INFO ]  Epoch:  157	Loss: 0.5601	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:25 [INFO ]  Epoch:  158	Loss: 0.5189	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:40:26 [INFO ]  Epoch:  159	Loss: 0.5613	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:28 [INFO ]  Epoch:  160	Loss: 0.5755	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:40:30 [INFO ]  Epoch:  161	Loss: 0.6266	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:32 [INFO ]  Epoch:  162	Loss: 0.5015	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:40:34 [INFO ]  Epoch:  163	Loss: 0.5146	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:40:36 [INFO ]  Epoch:  164	Loss: 0.5799	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:40:37 [INFO ]  Epoch:  165	Loss: 0.6512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:39 [INFO ]  Epoch:  166	Loss: 0.5043	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:40:41 [INFO ]  Epoch:  167	Loss: 0.5776	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:40:43 [INFO ]  Epoch:  168	Loss: 0.6572	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:45 [INFO ]  Epoch:  169	Loss: 0.5659	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:47 [INFO ]  Epoch:  170	Loss: 0.5705	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:49 [INFO ]  Epoch:  171	Loss: 0.5200	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:40:51 [INFO ]  Epoch:  172	Loss: 0.5752	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:40:53 [INFO ]  Epoch:  173	Loss: 0.5674	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:40:55 [INFO ]  Epoch:  174	Loss: 0.5964	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:40:56 [INFO ]  Epoch:  175	Loss: 0.5854	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:40:58 [INFO ]  Epoch:  176	Loss: 0.5658	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:41:00 [INFO ]  Epoch:  177	Loss: 0.6189	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:41:02 [INFO ]  Epoch:  178	Loss: 0.5653	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:41:04 [INFO ]  Epoch:  179	Loss: 0.6119	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:41:05 [INFO ]  Epoch:  180	Loss: 0.6128	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:07 [INFO ]  Epoch:  181	Loss: 0.5651	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:09 [INFO ]  Epoch:  182	Loss: 0.5670	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:11 [INFO ]  Epoch:  183	Loss: 0.6252	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:13 [INFO ]  Epoch:  184	Loss: 0.6180	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:41:15 [INFO ]  Epoch:  185	Loss: 0.5975	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:17 [INFO ]  Epoch:  186	Loss: 0.6326	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:41:18 [INFO ]  Epoch:  187	Loss: 0.6000	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:20 [INFO ]  Epoch:  188	Loss: 0.6598	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:41:22 [INFO ]  Epoch:  189	Loss: 0.4595	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:41:24 [INFO ]  Epoch:  190	Loss: 0.5649	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:41:26 [INFO ]  Epoch:  191	Loss: 0.5835	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:41:27 [INFO ]  Epoch:  192	Loss: 0.5652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:29 [INFO ]  Epoch:  193	Loss: 0.6487	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:41:31 [INFO ]  Epoch:  194	Loss: 0.5628	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:33 [INFO ]  Epoch:  195	Loss: 0.5475	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:41:35 [INFO ]  Epoch:  196	Loss: 0.5739	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:41:36 [INFO ]  Epoch:  197	Loss: 0.5935	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:39 [INFO ]  Epoch:  198	Loss: 0.6186	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:41:40 [INFO ]  Epoch:  199	Loss: 0.5883	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:41:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 11:41:42 [INFO ]  
2022-10-04 11:41:42 [INFO ]  Final evaluation for SVHN :
2022-10-04 11:41:45 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:41:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:41:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:41:45 [INFO ]  	   step  1 (lr=0.426338)                   82.21%                   0.6608
2022-10-04 11:41:45 [INFO ]  
2022-10-04 11:41:45 [INFO ]  
2022-10-04 11:41:45 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 11:41:48 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:41:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:41:48 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 11:41:48 [INFO ]  	   step  1 (lr=0.426338)                   16.72%                   5.5592
2022-10-04 11:41:48 [INFO ]  
2022-10-04 11:41:48 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 11:42:03 [INFO ]  ======================================== 2022-10-04 11:42:03 ========================================
2022-10-04 11:42:03 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 11:42:03 [INFO ]  Options: 
2022-10-04 11:42:03 [INFO ]  	base_dir: null
2022-10-04 11:42:03 [INFO ]  	batch_size: 1024
2022-10-04 11:42:03 [INFO ]  	checkpoint_interval: 300
2022-10-04 11:42:03 [INFO ]  	dataset: SVHN
2022-10-04 11:42:03 [INFO ]  	dataset_labels:
2022-10-04 11:42:03 [INFO ]  	- 0
2022-10-04 11:42:03 [INFO ]  	- 1
2022-10-04 11:42:03 [INFO ]  	- 2
2022-10-04 11:42:03 [INFO ]  	- 3
2022-10-04 11:42:03 [INFO ]  	- 4
2022-10-04 11:42:03 [INFO ]  	- 5
2022-10-04 11:42:03 [INFO ]  	- 6
2022-10-04 11:42:03 [INFO ]  	- 7
2022-10-04 11:42:03 [INFO ]  	- 8
2022-10-04 11:42:03 [INFO ]  	- 9
2022-10-04 11:42:03 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 11:42:03 [INFO ]  	- !!python/tuple
2022-10-04 11:42:03 [INFO ]  	    - 0.4379104971885681
2022-10-04 11:42:03 [INFO ]  	    - 0.44398033618927
2022-10-04 11:42:03 [INFO ]  	    - 0.4729299545288086
2022-10-04 11:42:03 [INFO ]  	- !!python/tuple
2022-10-04 11:42:03 [INFO ]  	    - 0.19803012907505035
2022-10-04 11:42:03 [INFO ]  	    - 0.2010156363248825
2022-10-04 11:42:03 [INFO ]  	    - 0.19703614711761475
2022-10-04 11:42:03 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 11:42:03 [INFO ]  	decay_epochs: 50
2022-10-04 11:42:03 [INFO ]  	decay_factor: 0.1
2022-10-04 11:42:03 [INFO ]  	device_id: 0
2022-10-04 11:42:03 [INFO ]  	distill_epochs: 1
2022-10-04 11:42:03 [INFO ]  	distill_lr: 0.02
2022-10-04 11:42:03 [INFO ]  	distill_steps: 1
2022-10-04 11:42:03 [INFO ]  	epochs: 200
2022-10-04 11:42:03 [INFO ]  	expand_cls: false
2022-10-04 11:42:03 [INFO ]  	forgetting_dataset: null
2022-10-04 11:42:03 [INFO ]  	init: xavier
2022-10-04 11:42:03 [INFO ]  	init_param: 1.0
2022-10-04 11:42:03 [INFO ]  	input_size: 32
2022-10-04 11:42:03 [INFO ]  	ipc: 25
2022-10-04 11:42:03 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 11:42:03 [INFO ]  	log_interval: 100
2022-10-04 11:42:03 [INFO ]  	log_level: INFO
2022-10-04 11:42:03 [INFO ]  	lr: 0.01
2022-10-04 11:42:03 [INFO ]  	mode: distill_adapt
2022-10-04 11:42:03 [INFO ]  	nc: 3
2022-10-04 11:42:03 [INFO ]  	num_classes: 10
2022-10-04 11:42:03 [INFO ]  	num_workers: 8
2022-10-04 11:42:03 [INFO ]  	phase: train
2022-10-04 11:42:03 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 11:42:03 [INFO ]  	start_time: '2022-10-04 11:42:03'
2022-10-04 11:42:03 [INFO ]  	test_batch_size: 1024
2022-10-04 11:42:03 [INFO ]  	
2022-10-04 11:42:06 [INFO ]  train dataset size:	73257
2022-10-04 11:42:06 [INFO ]  test dataset size: 	26032
2022-10-04 11:42:06 [INFO ]  datasets built!
2022-10-04 11:42:06 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 11:42:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 11:42:07 [INFO ]  
2022-10-04 11:42:07 [INFO ]  Begin of epoch 0 :
2022-10-04 11:42:11 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:42:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:42:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:42:11 [INFO ]  	   step  1 (lr=0.020000)                    7.13%                   9.0064
2022-10-04 11:42:11 [INFO ]  
2022-10-04 11:42:11 [INFO ]  Epoch:    0	Loss: 8.8214	Data Time: 0.39s	Train Time: 0.04s
2022-10-04 11:42:12 [INFO ]  Epoch:    1	Loss: 3.0580	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 11:42:14 [INFO ]  Epoch:    2	Loss: 2.5225	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:42:16 [INFO ]  Epoch:    3	Loss: 2.3136	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:42:18 [INFO ]  Epoch:    4	Loss: 2.2313	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:42:20 [INFO ]  Epoch:    5	Loss: 2.1994	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:42:22 [INFO ]  Epoch:    6	Loss: 2.1708	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:42:24 [INFO ]  Epoch:    7	Loss: 2.1506	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:42:26 [INFO ]  Epoch:    8	Loss: 2.0719	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:42:28 [INFO ]  Epoch:    9	Loss: 1.9957	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:42:29 [INFO ]  Epoch:   10	Loss: 1.9378	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:42:31 [INFO ]  Epoch:   11	Loss: 1.7612	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 11:42:33 [INFO ]  Epoch:   12	Loss: 1.5942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:42:35 [INFO ]  Epoch:   13	Loss: 1.4946	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:42:37 [INFO ]  Epoch:   14	Loss: 1.3555	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:42:39 [INFO ]  Epoch:   15	Loss: 1.4424	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:42:41 [INFO ]  Epoch:   16	Loss: 1.2603	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:42:42 [INFO ]  Epoch:   17	Loss: 1.1515	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:42:44 [INFO ]  Epoch:   18	Loss: 1.1762	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:42:46 [INFO ]  Epoch:   19	Loss: 1.1030	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:42:48 [INFO ]  Epoch:   20	Loss: 1.1401	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:42:50 [INFO ]  Epoch:   21	Loss: 1.0359	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:42:51 [INFO ]  Epoch:   22	Loss: 1.0453	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:42:53 [INFO ]  Epoch:   23	Loss: 0.9166	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:42:55 [INFO ]  Epoch:   24	Loss: 0.9061	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:42:57 [INFO ]  Epoch:   25	Loss: 0.9429	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:42:59 [INFO ]  Epoch:   26	Loss: 0.8915	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:43:00 [INFO ]  Epoch:   27	Loss: 0.8747	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:02 [INFO ]  Epoch:   28	Loss: 0.8929	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:43:04 [INFO ]  Epoch:   29	Loss: 0.8797	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:43:06 [INFO ]  Epoch:   30	Loss: 0.8562	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:43:08 [INFO ]  Epoch:   31	Loss: 0.9607	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:43:10 [INFO ]  Epoch:   32	Loss: 1.1491	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:11 [INFO ]  Epoch:   33	Loss: 0.8199	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:13 [INFO ]  Epoch:   34	Loss: 0.7546	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:43:15 [INFO ]  Epoch:   35	Loss: 0.8306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:17 [INFO ]  Epoch:   36	Loss: 0.9427	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:43:19 [INFO ]  Epoch:   37	Loss: 0.8510	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:43:21 [INFO ]  Epoch:   38	Loss: 0.8099	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:23 [INFO ]  Epoch:   39	Loss: 0.9175	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:43:24 [INFO ]  Epoch:   40	Loss: 0.7474	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:43:26 [INFO ]  Epoch:   41	Loss: 0.8728	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:43:28 [INFO ]  Epoch:   42	Loss: 0.7224	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:43:30 [INFO ]  Epoch:   43	Loss: 0.8517	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:43:32 [INFO ]  Epoch:   44	Loss: 0.7410	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:43:33 [INFO ]  Epoch:   45	Loss: 0.7461	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:43:35 [INFO ]  Epoch:   46	Loss: 0.7571	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:43:37 [INFO ]  Epoch:   47	Loss: 0.8916	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:43:39 [INFO ]  Epoch:   48	Loss: 0.6965	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:43:41 [INFO ]  Epoch:   49	Loss: 0.7038	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:43 [INFO ]  Epoch:   50	Loss: 0.6552	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:43:45 [INFO ]  Epoch:   51	Loss: 0.6478	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:46 [INFO ]  Epoch:   52	Loss: 0.6293	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:43:48 [INFO ]  Epoch:   53	Loss: 0.6030	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:43:50 [INFO ]  Epoch:   54	Loss: 0.6450	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:43:52 [INFO ]  Epoch:   55	Loss: 0.6183	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:54 [INFO ]  Epoch:   56	Loss: 0.5412	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:43:55 [INFO ]  Epoch:   57	Loss: 0.6985	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:43:57 [INFO ]  Epoch:   58	Loss: 0.5953	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:43:59 [INFO ]  Epoch:   59	Loss: 0.6401	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:44:01 [INFO ]  Epoch:   60	Loss: 0.6779	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:03 [INFO ]  Epoch:   61	Loss: 0.6587	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:44:05 [INFO ]  Epoch:   62	Loss: 0.6100	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:44:06 [INFO ]  Epoch:   63	Loss: 0.6059	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:44:08 [INFO ]  Epoch:   64	Loss: 0.5989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:10 [INFO ]  Epoch:   65	Loss: 0.6601	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:44:12 [INFO ]  Epoch:   66	Loss: 0.6365	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:14 [INFO ]  Epoch:   67	Loss: 0.6266	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:16 [INFO ]  Epoch:   68	Loss: 0.6333	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:44:17 [INFO ]  Epoch:   69	Loss: 0.6413	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 11:44:19 [INFO ]  Epoch:   70	Loss: 0.6578	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:21 [INFO ]  Epoch:   71	Loss: 0.5658	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:23 [INFO ]  Epoch:   72	Loss: 0.6391	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 11:44:25 [INFO ]  Epoch:   73	Loss: 0.6536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:27 [INFO ]  Epoch:   74	Loss: 0.5686	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:44:29 [INFO ]  Epoch:   75	Loss: 0.6554	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:44:31 [INFO ]  Epoch:   76	Loss: 0.6453	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:32 [INFO ]  Epoch:   77	Loss: 0.6285	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:44:34 [INFO ]  Epoch:   78	Loss: 0.6641	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:44:36 [INFO ]  Epoch:   79	Loss: 0.6613	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:38 [INFO ]  Epoch:   80	Loss: 0.6214	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:40 [INFO ]  Epoch:   81	Loss: 0.6546	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:44:42 [INFO ]  Epoch:   82	Loss: 0.5956	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:44 [INFO ]  Epoch:   83	Loss: 0.5756	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:44:46 [INFO ]  Epoch:   84	Loss: 0.6028	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:48 [INFO ]  Epoch:   85	Loss: 0.5770	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:49 [INFO ]  Epoch:   86	Loss: 0.6241	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:44:51 [INFO ]  Epoch:   87	Loss: 0.6345	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:44:53 [INFO ]  Epoch:   88	Loss: 0.5627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:44:55 [INFO ]  Epoch:   89	Loss: 0.6364	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:44:57 [INFO ]  Epoch:   90	Loss: 0.6340	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:44:59 [INFO ]  Epoch:   91	Loss: 0.5799	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:45:01 [INFO ]  Epoch:   92	Loss: 0.5715	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:02 [INFO ]  Epoch:   93	Loss: 0.6371	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:04 [INFO ]  Epoch:   94	Loss: 0.6698	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:06 [INFO ]  Epoch:   95	Loss: 0.6372	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:08 [INFO ]  Epoch:   96	Loss: 0.6136	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:10 [INFO ]  Epoch:   97	Loss: 0.5528	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:45:12 [INFO ]  Epoch:   98	Loss: 0.6734	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:45:14 [INFO ]  Epoch:   99	Loss: 0.6591	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:16 [INFO ]  Epoch:  100	Loss: 0.5896	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:45:18 [INFO ]  Epoch:  101	Loss: 0.5903	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:45:20 [INFO ]  Epoch:  102	Loss: 0.6164	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:22 [INFO ]  Epoch:  103	Loss: 0.6892	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:45:24 [INFO ]  Epoch:  104	Loss: 0.6123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:26 [INFO ]  Epoch:  105	Loss: 0.6396	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:28 [INFO ]  Epoch:  106	Loss: 0.5774	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:45:30 [INFO ]  Epoch:  107	Loss: 0.6284	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:45:32 [INFO ]  Epoch:  108	Loss: 0.5900	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:45:34 [INFO ]  Epoch:  109	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:35 [INFO ]  Epoch:  110	Loss: 0.6117	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:37 [INFO ]  Epoch:  111	Loss: 0.5814	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:39 [INFO ]  Epoch:  112	Loss: 0.6075	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:41 [INFO ]  Epoch:  113	Loss: 0.5583	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:45:43 [INFO ]  Epoch:  114	Loss: 0.5930	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:45:44 [INFO ]  Epoch:  115	Loss: 0.5821	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:46 [INFO ]  Epoch:  116	Loss: 0.6350	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:48 [INFO ]  Epoch:  117	Loss: 0.6572	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:50 [INFO ]  Epoch:  118	Loss: 0.5874	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:52 [INFO ]  Epoch:  119	Loss: 0.6105	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:45:53 [INFO ]  Epoch:  120	Loss: 0.5519	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:45:55 [INFO ]  Epoch:  121	Loss: 0.5126	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:45:58 [INFO ]  Epoch:  122	Loss: 0.6524	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:45:59 [INFO ]  Epoch:  123	Loss: 0.5901	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:01 [INFO ]  Epoch:  124	Loss: 0.6550	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:46:03 [INFO ]  Epoch:  125	Loss: 0.5796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:05 [INFO ]  Epoch:  126	Loss: 0.5838	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:46:07 [INFO ]  Epoch:  127	Loss: 0.6075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:09 [INFO ]  Epoch:  128	Loss: 0.5742	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:46:10 [INFO ]  Epoch:  129	Loss: 0.6389	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:12 [INFO ]  Epoch:  130	Loss: 0.5770	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:46:14 [INFO ]  Epoch:  131	Loss: 0.6613	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:46:16 [INFO ]  Epoch:  132	Loss: 0.6357	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:18 [INFO ]  Epoch:  133	Loss: 0.5869	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:46:20 [INFO ]  Epoch:  134	Loss: 0.5478	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:22 [INFO ]  Epoch:  135	Loss: 0.6306	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:23 [INFO ]  Epoch:  136	Loss: 0.7017	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:46:25 [INFO ]  Epoch:  137	Loss: 0.5717	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:46:27 [INFO ]  Epoch:  138	Loss: 0.5528	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:29 [INFO ]  Epoch:  139	Loss: 0.6288	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:46:31 [INFO ]  Epoch:  140	Loss: 0.6037	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:33 [INFO ]  Epoch:  141	Loss: 0.5488	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:35 [INFO ]  Epoch:  142	Loss: 0.5623	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:37 [INFO ]  Epoch:  143	Loss: 0.6965	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:39 [INFO ]  Epoch:  144	Loss: 0.6573	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:46:41 [INFO ]  Epoch:  145	Loss: 0.6436	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:46:42 [INFO ]  Epoch:  146	Loss: 0.6031	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:46:44 [INFO ]  Epoch:  147	Loss: 0.5876	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:46 [INFO ]  Epoch:  148	Loss: 0.5905	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:46:48 [INFO ]  Epoch:  149	Loss: 0.6037	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:46:50 [INFO ]  Epoch:  150	Loss: 0.6163	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:46:52 [INFO ]  Epoch:  151	Loss: 0.6732	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:46:54 [INFO ]  Epoch:  152	Loss: 0.5768	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:46:56 [INFO ]  Epoch:  153	Loss: 0.6158	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:46:57 [INFO ]  Epoch:  154	Loss: 0.6427	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:47:00 [INFO ]  Epoch:  155	Loss: 0.5931	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:47:01 [INFO ]  Epoch:  156	Loss: 0.6545	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:47:03 [INFO ]  Epoch:  157	Loss: 0.5469	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:05 [INFO ]  Epoch:  158	Loss: 0.5115	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 11:47:07 [INFO ]  Epoch:  159	Loss: 0.4934	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:47:09 [INFO ]  Epoch:  160	Loss: 0.5507	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:11 [INFO ]  Epoch:  161	Loss: 0.5485	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:13 [INFO ]  Epoch:  162	Loss: 0.5392	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:47:15 [INFO ]  Epoch:  163	Loss: 0.6382	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:47:17 [INFO ]  Epoch:  164	Loss: 0.5668	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:47:19 [INFO ]  Epoch:  165	Loss: 0.5986	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:47:20 [INFO ]  Epoch:  166	Loss: 0.5817	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:47:22 [INFO ]  Epoch:  167	Loss: 0.5828	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:24 [INFO ]  Epoch:  168	Loss: 0.6391	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:47:26 [INFO ]  Epoch:  169	Loss: 0.6404	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:47:28 [INFO ]  Epoch:  170	Loss: 0.5595	Data Time: 0.23s	Train Time: 0.00s
2022-10-04 11:47:29 [INFO ]  Epoch:  171	Loss: 0.5842	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:47:31 [INFO ]  Epoch:  172	Loss: 0.6396	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 11:47:33 [INFO ]  Epoch:  173	Loss: 0.5577	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:47:35 [INFO ]  Epoch:  174	Loss: 0.5946	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:47:37 [INFO ]  Epoch:  175	Loss: 0.5489	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:47:39 [INFO ]  Epoch:  176	Loss: 0.5619	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:47:41 [INFO ]  Epoch:  177	Loss: 0.6393	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:42 [INFO ]  Epoch:  178	Loss: 0.5395	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:47:44 [INFO ]  Epoch:  179	Loss: 0.6507	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 11:47:46 [INFO ]  Epoch:  180	Loss: 0.6302	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:48 [INFO ]  Epoch:  181	Loss: 0.5693	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:47:50 [INFO ]  Epoch:  182	Loss: 0.7375	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:47:52 [INFO ]  Epoch:  183	Loss: 0.6276	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:47:54 [INFO ]  Epoch:  184	Loss: 0.5864	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:47:55 [INFO ]  Epoch:  185	Loss: 0.6171	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:47:57 [INFO ]  Epoch:  186	Loss: 0.6019	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 11:47:59 [INFO ]  Epoch:  187	Loss: 0.5635	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 11:48:01 [INFO ]  Epoch:  188	Loss: 0.6236	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:03 [INFO ]  Epoch:  189	Loss: 0.5522	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:04 [INFO ]  Epoch:  190	Loss: 0.5741	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:48:06 [INFO ]  Epoch:  191	Loss: 0.5783	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 11:48:08 [INFO ]  Epoch:  192	Loss: 0.6093	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 11:48:10 [INFO ]  Epoch:  193	Loss: 0.5745	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:12 [INFO ]  Epoch:  194	Loss: 0.5446	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 11:48:14 [INFO ]  Epoch:  195	Loss: 0.6151	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 11:48:15 [INFO ]  Epoch:  196	Loss: 0.5271	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:17 [INFO ]  Epoch:  197	Loss: 0.6086	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:19 [INFO ]  Epoch:  198	Loss: 0.5812	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 11:48:21 [INFO ]  Epoch:  199	Loss: 0.5734	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 11:48:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 11:48:22 [INFO ]  
2022-10-04 11:48:22 [INFO ]  Final evaluation for SVHN :
2022-10-04 11:48:26 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:48:26 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:48:26 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 11:48:26 [INFO ]  	   step  1 (lr=0.433811)                   81.96%                   0.6699
2022-10-04 11:48:26 [INFO ]  
2022-10-04 11:48:26 [INFO ]  
2022-10-04 11:48:26 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 11:48:28 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 11:48:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 11:48:28 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 11:48:28 [INFO ]  	   step  1 (lr=0.433811)                   16.76%                   5.5480
2022-10-04 11:48:28 [INFO ]  
2022-10-04 11:48:28 [INFO ]  CPU Time: 3.47 minutes
2022-10-04 11:59:59 [INFO ]  ======================================== 2022-10-04 11:59:59 ========================================
2022-10-04 11:59:59 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 11:59:59 [INFO ]  Options: 
2022-10-04 11:59:59 [INFO ]  	base_dir: null
2022-10-04 11:59:59 [INFO ]  	batch_size: 1024
2022-10-04 11:59:59 [INFO ]  	checkpoint_interval: 300
2022-10-04 11:59:59 [INFO ]  	dataset: SVHN
2022-10-04 11:59:59 [INFO ]  	dataset_labels:
2022-10-04 11:59:59 [INFO ]  	- 0
2022-10-04 11:59:59 [INFO ]  	- 1
2022-10-04 11:59:59 [INFO ]  	- 2
2022-10-04 11:59:59 [INFO ]  	- 3
2022-10-04 11:59:59 [INFO ]  	- 4
2022-10-04 11:59:59 [INFO ]  	- 5
2022-10-04 11:59:59 [INFO ]  	- 6
2022-10-04 11:59:59 [INFO ]  	- 7
2022-10-04 11:59:59 [INFO ]  	- 8
2022-10-04 11:59:59 [INFO ]  	- 9
2022-10-04 11:59:59 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 11:59:59 [INFO ]  	- !!python/tuple
2022-10-04 11:59:59 [INFO ]  	    - 0.4379104971885681
2022-10-04 11:59:59 [INFO ]  	    - 0.44398033618927
2022-10-04 11:59:59 [INFO ]  	    - 0.4729299545288086
2022-10-04 11:59:59 [INFO ]  	- !!python/tuple
2022-10-04 11:59:59 [INFO ]  	    - 0.19803012907505035
2022-10-04 11:59:59 [INFO ]  	    - 0.2010156363248825
2022-10-04 11:59:59 [INFO ]  	    - 0.19703614711761475
2022-10-04 11:59:59 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 11:59:59 [INFO ]  	decay_epochs: 50
2022-10-04 11:59:59 [INFO ]  	decay_factor: 0.1
2022-10-04 11:59:59 [INFO ]  	device_id: 0
2022-10-04 11:59:59 [INFO ]  	distill_epochs: 1
2022-10-04 11:59:59 [INFO ]  	distill_lr: 0.02
2022-10-04 11:59:59 [INFO ]  	distill_steps: 1
2022-10-04 11:59:59 [INFO ]  	epochs: 200
2022-10-04 11:59:59 [INFO ]  	expand_cls: false
2022-10-04 11:59:59 [INFO ]  	forgetting_dataset: null
2022-10-04 11:59:59 [INFO ]  	init: xavier
2022-10-04 11:59:59 [INFO ]  	init_param: 1.0
2022-10-04 11:59:59 [INFO ]  	input_size: 32
2022-10-04 11:59:59 [INFO ]  	ipc: 50
2022-10-04 11:59:59 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 11:59:59 [INFO ]  	log_interval: 100
2022-10-04 11:59:59 [INFO ]  	log_level: INFO
2022-10-04 11:59:59 [INFO ]  	lr: 0.01
2022-10-04 11:59:59 [INFO ]  	mode: distill_adapt
2022-10-04 11:59:59 [INFO ]  	nc: 3
2022-10-04 11:59:59 [INFO ]  	num_classes: 10
2022-10-04 11:59:59 [INFO ]  	num_workers: 8
2022-10-04 11:59:59 [INFO ]  	phase: train
2022-10-04 11:59:59 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 11:59:59 [INFO ]  	start_time: '2022-10-04 11:59:59'
2022-10-04 11:59:59 [INFO ]  	test_batch_size: 1024
2022-10-04 11:59:59 [INFO ]  	
2022-10-04 12:00:01 [INFO ]  train dataset size:	73257
2022-10-04 12:00:01 [INFO ]  test dataset size: 	26032
2022-10-04 12:00:01 [INFO ]  datasets built!
2022-10-04 12:00:01 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 12:00:03 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 12:00:03 [INFO ]  
2022-10-04 12:00:03 [INFO ]  Begin of epoch 0 :
2022-10-04 12:00:07 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:00:07 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:00:07 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:00:07 [INFO ]  	   step  1 (lr=0.020000)                    7.08%                   9.1344
2022-10-04 12:00:07 [INFO ]  
2022-10-04 12:00:07 [INFO ]  Epoch:    0	Loss: 9.2303	Data Time: 0.41s	Train Time: 0.05s
2022-10-04 12:00:08 [INFO ]  Epoch:    1	Loss: 3.0592	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:00:10 [INFO ]  Epoch:    2	Loss: 2.5703	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:12 [INFO ]  Epoch:    3	Loss: 2.3459	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:00:14 [INFO ]  Epoch:    4	Loss: 2.2245	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:00:16 [INFO ]  Epoch:    5	Loss: 2.1658	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:17 [INFO ]  Epoch:    6	Loss: 2.1343	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:19 [INFO ]  Epoch:    7	Loss: 2.1202	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:21 [INFO ]  Epoch:    8	Loss: 2.0630	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:23 [INFO ]  Epoch:    9	Loss: 1.9850	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 12:00:25 [INFO ]  Epoch:   10	Loss: 1.8808	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:27 [INFO ]  Epoch:   11	Loss: 1.8125	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:29 [INFO ]  Epoch:   12	Loss: 1.5601	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:00:31 [INFO ]  Epoch:   13	Loss: 1.5538	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:33 [INFO ]  Epoch:   14	Loss: 1.4415	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:00:34 [INFO ]  Epoch:   15	Loss: 1.2723	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:36 [INFO ]  Epoch:   16	Loss: 1.3077	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:00:38 [INFO ]  Epoch:   17	Loss: 1.1280	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:00:40 [INFO ]  Epoch:   18	Loss: 1.2064	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:42 [INFO ]  Epoch:   19	Loss: 1.2122	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:00:44 [INFO ]  Epoch:   20	Loss: 1.1208	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:00:45 [INFO ]  Epoch:   21	Loss: 0.9947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:47 [INFO ]  Epoch:   22	Loss: 1.0341	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:00:49 [INFO ]  Epoch:   23	Loss: 0.9192	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:00:51 [INFO ]  Epoch:   24	Loss: 0.8886	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:53 [INFO ]  Epoch:   25	Loss: 0.8877	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:00:55 [INFO ]  Epoch:   26	Loss: 0.8578	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:56 [INFO ]  Epoch:   27	Loss: 0.9447	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:00:58 [INFO ]  Epoch:   28	Loss: 0.9291	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:00 [INFO ]  Epoch:   29	Loss: 0.8856	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:01:02 [INFO ]  Epoch:   30	Loss: 0.7589	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:04 [INFO ]  Epoch:   31	Loss: 0.8041	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:06 [INFO ]  Epoch:   32	Loss: 0.8047	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:01:07 [INFO ]  Epoch:   33	Loss: 0.7566	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:09 [INFO ]  Epoch:   34	Loss: 0.9074	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 12:01:11 [INFO ]  Epoch:   35	Loss: 0.7814	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:13 [INFO ]  Epoch:   36	Loss: 0.7612	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:01:14 [INFO ]  Epoch:   37	Loss: 0.7745	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:16 [INFO ]  Epoch:   38	Loss: 0.8128	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:01:18 [INFO ]  Epoch:   39	Loss: 0.6981	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:20 [INFO ]  Epoch:   40	Loss: 0.7768	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:22 [INFO ]  Epoch:   41	Loss: 0.6861	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:24 [INFO ]  Epoch:   42	Loss: 0.8740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:01:26 [INFO ]  Epoch:   43	Loss: 0.6701	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:27 [INFO ]  Epoch:   44	Loss: 0.7894	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:01:29 [INFO ]  Epoch:   45	Loss: 0.7254	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:31 [INFO ]  Epoch:   46	Loss: 0.7138	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:33 [INFO ]  Epoch:   47	Loss: 0.7085	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:35 [INFO ]  Epoch:   48	Loss: 0.7128	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:37 [INFO ]  Epoch:   49	Loss: 0.6307	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:39 [INFO ]  Epoch:   50	Loss: 0.5846	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:01:40 [INFO ]  Epoch:   51	Loss: 0.6686	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:01:42 [INFO ]  Epoch:   52	Loss: 0.5988	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:44 [INFO ]  Epoch:   53	Loss: 0.5939	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:01:46 [INFO ]  Epoch:   54	Loss: 0.6231	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:01:48 [INFO ]  Epoch:   55	Loss: 0.6510	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:50 [INFO ]  Epoch:   56	Loss: 0.5717	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:01:52 [INFO ]  Epoch:   57	Loss: 0.6213	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:01:53 [INFO ]  Epoch:   58	Loss: 0.6305	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:01:55 [INFO ]  Epoch:   59	Loss: 0.6485	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:01:57 [INFO ]  Epoch:   60	Loss: 0.6208	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:01:59 [INFO ]  Epoch:   61	Loss: 0.6553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:01 [INFO ]  Epoch:   62	Loss: 0.6895	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:02:03 [INFO ]  Epoch:   63	Loss: 0.6207	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:02:04 [INFO ]  Epoch:   64	Loss: 0.5599	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:06 [INFO ]  Epoch:   65	Loss: 0.6151	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:02:08 [INFO ]  Epoch:   66	Loss: 0.5965	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:10 [INFO ]  Epoch:   67	Loss: 0.6419	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:02:12 [INFO ]  Epoch:   68	Loss: 0.5946	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:14 [INFO ]  Epoch:   69	Loss: 0.5930	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:02:16 [INFO ]  Epoch:   70	Loss: 0.6396	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:17 [INFO ]  Epoch:   71	Loss: 0.6737	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:02:19 [INFO ]  Epoch:   72	Loss: 0.5651	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:21 [INFO ]  Epoch:   73	Loss: 0.5663	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:02:23 [INFO ]  Epoch:   74	Loss: 0.6212	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:02:24 [INFO ]  Epoch:   75	Loss: 0.5775	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:26 [INFO ]  Epoch:   76	Loss: 0.6058	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:28 [INFO ]  Epoch:   77	Loss: 0.5990	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:02:30 [INFO ]  Epoch:   78	Loss: 0.5082	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:02:32 [INFO ]  Epoch:   79	Loss: 0.5723	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:33 [INFO ]  Epoch:   80	Loss: 0.6400	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:02:35 [INFO ]  Epoch:   81	Loss: 0.6141	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:02:37 [INFO ]  Epoch:   82	Loss: 0.5699	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:02:39 [INFO ]  Epoch:   83	Loss: 0.6189	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:02:41 [INFO ]  Epoch:   84	Loss: 0.5863	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:02:43 [INFO ]  Epoch:   85	Loss: 0.6786	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:02:44 [INFO ]  Epoch:   86	Loss: 0.5590	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:02:46 [INFO ]  Epoch:   87	Loss: 0.6316	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:02:48 [INFO ]  Epoch:   88	Loss: 0.6475	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:02:50 [INFO ]  Epoch:   89	Loss: 0.5201	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:02:52 [INFO ]  Epoch:   90	Loss: 0.5432	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 12:02:54 [INFO ]  Epoch:   91	Loss: 0.5701	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:56 [INFO ]  Epoch:   92	Loss: 0.5829	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:58 [INFO ]  Epoch:   93	Loss: 0.5324	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:02:59 [INFO ]  Epoch:   94	Loss: 0.5795	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:01 [INFO ]  Epoch:   95	Loss: 0.5607	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:03 [INFO ]  Epoch:   96	Loss: 0.6075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:05 [INFO ]  Epoch:   97	Loss: 0.5941	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:03:07 [INFO ]  Epoch:   98	Loss: 0.5765	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:09 [INFO ]  Epoch:   99	Loss: 0.6168	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:11 [INFO ]  Epoch:  100	Loss: 0.5195	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:03:12 [INFO ]  Epoch:  101	Loss: 0.5390	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:03:14 [INFO ]  Epoch:  102	Loss: 0.5931	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:16 [INFO ]  Epoch:  103	Loss: 0.5858	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:18 [INFO ]  Epoch:  104	Loss: 0.5834	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:03:20 [INFO ]  Epoch:  105	Loss: 0.5758	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:21 [INFO ]  Epoch:  106	Loss: 0.6131	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:23 [INFO ]  Epoch:  107	Loss: 0.6239	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:03:25 [INFO ]  Epoch:  108	Loss: 0.5518	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:03:27 [INFO ]  Epoch:  109	Loss: 0.5827	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:03:29 [INFO ]  Epoch:  110	Loss: 0.5902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:31 [INFO ]  Epoch:  111	Loss: 0.5492	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:03:33 [INFO ]  Epoch:  112	Loss: 0.6088	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:03:34 [INFO ]  Epoch:  113	Loss: 0.6911	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:36 [INFO ]  Epoch:  114	Loss: 0.5386	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:38 [INFO ]  Epoch:  115	Loss: 0.5716	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:40 [INFO ]  Epoch:  116	Loss: 0.6559	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:42 [INFO ]  Epoch:  117	Loss: 0.5867	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:44 [INFO ]  Epoch:  118	Loss: 0.5751	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:03:46 [INFO ]  Epoch:  119	Loss: 0.5262	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:03:48 [INFO ]  Epoch:  120	Loss: 0.6113	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 12:03:50 [INFO ]  Epoch:  121	Loss: 0.6512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:51 [INFO ]  Epoch:  122	Loss: 0.5547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:03:53 [INFO ]  Epoch:  123	Loss: 0.5890	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:03:55 [INFO ]  Epoch:  124	Loss: 0.5864	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:03:57 [INFO ]  Epoch:  125	Loss: 0.5983	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:03:59 [INFO ]  Epoch:  126	Loss: 0.5229	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:04:01 [INFO ]  Epoch:  127	Loss: 0.5781	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:03 [INFO ]  Epoch:  128	Loss: 0.5664	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:04:05 [INFO ]  Epoch:  129	Loss: 0.5778	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:04:06 [INFO ]  Epoch:  130	Loss: 0.5582	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:04:08 [INFO ]  Epoch:  131	Loss: 0.5600	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:04:10 [INFO ]  Epoch:  132	Loss: 0.5865	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:04:12 [INFO ]  Epoch:  133	Loss: 0.5325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:14 [INFO ]  Epoch:  134	Loss: 0.4996	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:04:16 [INFO ]  Epoch:  135	Loss: 0.5896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:17 [INFO ]  Epoch:  136	Loss: 0.6041	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:04:19 [INFO ]  Epoch:  137	Loss: 0.6653	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:21 [INFO ]  Epoch:  138	Loss: 0.5714	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:23 [INFO ]  Epoch:  139	Loss: 0.5384	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 12:04:25 [INFO ]  Epoch:  140	Loss: 0.5880	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:04:26 [INFO ]  Epoch:  141	Loss: 0.5886	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:28 [INFO ]  Epoch:  142	Loss: 0.5096	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:30 [INFO ]  Epoch:  143	Loss: 0.5325	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:04:32 [INFO ]  Epoch:  144	Loss: 0.5972	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:34 [INFO ]  Epoch:  145	Loss: 0.5798	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:36 [INFO ]  Epoch:  146	Loss: 0.5782	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:38 [INFO ]  Epoch:  147	Loss: 0.6091	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:40 [INFO ]  Epoch:  148	Loss: 0.5875	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:04:42 [INFO ]  Epoch:  149	Loss: 0.5533	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:04:43 [INFO ]  Epoch:  150	Loss: 0.5960	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:45 [INFO ]  Epoch:  151	Loss: 0.6362	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:04:47 [INFO ]  Epoch:  152	Loss: 0.5594	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:04:49 [INFO ]  Epoch:  153	Loss: 0.5805	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:51 [INFO ]  Epoch:  154	Loss: 0.5329	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:04:52 [INFO ]  Epoch:  155	Loss: 0.5426	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:54 [INFO ]  Epoch:  156	Loss: 0.5522	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:04:56 [INFO ]  Epoch:  157	Loss: 0.5435	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:04:58 [INFO ]  Epoch:  158	Loss: 0.5118	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:05:00 [INFO ]  Epoch:  159	Loss: 0.5218	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:05:02 [INFO ]  Epoch:  160	Loss: 0.5944	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:03 [INFO ]  Epoch:  161	Loss: 0.5774	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:05:05 [INFO ]  Epoch:  162	Loss: 0.5164	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:07 [INFO ]  Epoch:  163	Loss: 0.6026	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:05:09 [INFO ]  Epoch:  164	Loss: 0.6394	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 12:05:11 [INFO ]  Epoch:  165	Loss: 0.5322	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:05:12 [INFO ]  Epoch:  166	Loss: 0.4937	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:14 [INFO ]  Epoch:  167	Loss: 0.6255	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:16 [INFO ]  Epoch:  168	Loss: 0.6125	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:18 [INFO ]  Epoch:  169	Loss: 0.5449	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:05:20 [INFO ]  Epoch:  170	Loss: 0.5024	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:05:21 [INFO ]  Epoch:  171	Loss: 0.5866	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:23 [INFO ]  Epoch:  172	Loss: 0.5878	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:05:25 [INFO ]  Epoch:  173	Loss: 0.6196	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:27 [INFO ]  Epoch:  174	Loss: 0.4888	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:29 [INFO ]  Epoch:  175	Loss: 0.6269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:31 [INFO ]  Epoch:  176	Loss: 0.5640	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:33 [INFO ]  Epoch:  177	Loss: 0.5640	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:05:35 [INFO ]  Epoch:  178	Loss: 0.4746	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:37 [INFO ]  Epoch:  179	Loss: 0.5771	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:38 [INFO ]  Epoch:  180	Loss: 0.6146	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:05:41 [INFO ]  Epoch:  181	Loss: 0.5966	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:42 [INFO ]  Epoch:  182	Loss: 0.5435	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:44 [INFO ]  Epoch:  183	Loss: 0.5815	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:05:46 [INFO ]  Epoch:  184	Loss: 0.4871	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:05:48 [INFO ]  Epoch:  185	Loss: 0.6161	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:05:50 [INFO ]  Epoch:  186	Loss: 0.5557	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:52 [INFO ]  Epoch:  187	Loss: 0.5755	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:05:53 [INFO ]  Epoch:  188	Loss: 0.5292	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:05:55 [INFO ]  Epoch:  189	Loss: 0.5673	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:05:57 [INFO ]  Epoch:  190	Loss: 0.6028	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:05:59 [INFO ]  Epoch:  191	Loss: 0.5817	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:06:01 [INFO ]  Epoch:  192	Loss: 0.4721	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:06:03 [INFO ]  Epoch:  193	Loss: 0.5728	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:06:05 [INFO ]  Epoch:  194	Loss: 0.5277	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:06:07 [INFO ]  Epoch:  195	Loss: 0.6426	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:06:08 [INFO ]  Epoch:  196	Loss: 0.5887	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:06:10 [INFO ]  Epoch:  197	Loss: 0.5041	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:06:12 [INFO ]  Epoch:  198	Loss: 0.6298	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:06:14 [INFO ]  Epoch:  199	Loss: 0.5525	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:06:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 12:06:15 [INFO ]  
2022-10-04 12:06:15 [INFO ]  Final evaluation for SVHN :
2022-10-04 12:06:19 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:06:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:06:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:06:19 [INFO ]  	   step  1 (lr=0.442650)                   82.28%                   0.6626
2022-10-04 12:06:19 [INFO ]  
2022-10-04 12:06:19 [INFO ]  
2022-10-04 12:06:19 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 12:06:22 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:06:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:06:22 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 12:06:22 [INFO ]  	   step  1 (lr=0.442650)                   15.01%                   5.5182
2022-10-04 12:06:22 [INFO ]  
2022-10-04 12:06:22 [INFO ]  CPU Time: 3.48 minutes
2022-10-04 12:07:28 [INFO ]  ======================================== 2022-10-04 12:07:28 ========================================
2022-10-04 12:07:28 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 12:07:28 [INFO ]  Options: 
2022-10-04 12:07:28 [INFO ]  	base_dir: null
2022-10-04 12:07:28 [INFO ]  	batch_size: 1024
2022-10-04 12:07:28 [INFO ]  	checkpoint_interval: 300
2022-10-04 12:07:28 [INFO ]  	dataset: SVHN
2022-10-04 12:07:28 [INFO ]  	dataset_labels:
2022-10-04 12:07:28 [INFO ]  	- 0
2022-10-04 12:07:28 [INFO ]  	- 1
2022-10-04 12:07:28 [INFO ]  	- 2
2022-10-04 12:07:28 [INFO ]  	- 3
2022-10-04 12:07:28 [INFO ]  	- 4
2022-10-04 12:07:28 [INFO ]  	- 5
2022-10-04 12:07:28 [INFO ]  	- 6
2022-10-04 12:07:28 [INFO ]  	- 7
2022-10-04 12:07:28 [INFO ]  	- 8
2022-10-04 12:07:28 [INFO ]  	- 9
2022-10-04 12:07:28 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 12:07:28 [INFO ]  	- !!python/tuple
2022-10-04 12:07:28 [INFO ]  	    - 0.4379104971885681
2022-10-04 12:07:28 [INFO ]  	    - 0.44398033618927
2022-10-04 12:07:28 [INFO ]  	    - 0.4729299545288086
2022-10-04 12:07:28 [INFO ]  	- !!python/tuple
2022-10-04 12:07:28 [INFO ]  	    - 0.19803012907505035
2022-10-04 12:07:28 [INFO ]  	    - 0.2010156363248825
2022-10-04 12:07:28 [INFO ]  	    - 0.19703614711761475
2022-10-04 12:07:28 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 12:07:28 [INFO ]  	decay_epochs: 50
2022-10-04 12:07:28 [INFO ]  	decay_factor: 0.1
2022-10-04 12:07:28 [INFO ]  	device_id: 0
2022-10-04 12:07:28 [INFO ]  	distill_epochs: 1
2022-10-04 12:07:28 [INFO ]  	distill_lr: 0.02
2022-10-04 12:07:28 [INFO ]  	distill_steps: 1
2022-10-04 12:07:28 [INFO ]  	epochs: 200
2022-10-04 12:07:28 [INFO ]  	expand_cls: false
2022-10-04 12:07:28 [INFO ]  	forgetting_dataset: null
2022-10-04 12:07:28 [INFO ]  	init: xavier
2022-10-04 12:07:28 [INFO ]  	init_param: 1.0
2022-10-04 12:07:28 [INFO ]  	input_size: 32
2022-10-04 12:07:28 [INFO ]  	ipc: 50
2022-10-04 12:07:28 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 12:07:28 [INFO ]  	log_interval: 100
2022-10-04 12:07:28 [INFO ]  	log_level: INFO
2022-10-04 12:07:28 [INFO ]  	lr: 0.01
2022-10-04 12:07:28 [INFO ]  	mode: distill_adapt
2022-10-04 12:07:28 [INFO ]  	nc: 3
2022-10-04 12:07:28 [INFO ]  	num_classes: 10
2022-10-04 12:07:28 [INFO ]  	num_workers: 8
2022-10-04 12:07:28 [INFO ]  	phase: train
2022-10-04 12:07:28 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 12:07:28 [INFO ]  	start_time: '2022-10-04 12:07:28'
2022-10-04 12:07:28 [INFO ]  	test_batch_size: 1024
2022-10-04 12:07:28 [INFO ]  	
2022-10-04 12:07:30 [INFO ]  train dataset size:	73257
2022-10-04 12:07:30 [INFO ]  test dataset size: 	26032
2022-10-04 12:07:30 [INFO ]  datasets built!
2022-10-04 12:07:30 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 12:07:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 12:07:32 [INFO ]  
2022-10-04 12:07:32 [INFO ]  Begin of epoch 0 :
2022-10-04 12:07:36 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:07:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:07:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:07:36 [INFO ]  	   step  1 (lr=0.020000)                    7.06%                   8.9046
2022-10-04 12:07:36 [INFO ]  
2022-10-04 12:07:36 [INFO ]  Epoch:    0	Loss: 9.6289	Data Time: 0.39s	Train Time: 0.05s
2022-10-04 12:07:37 [INFO ]  Epoch:    1	Loss: 3.0447	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:07:39 [INFO ]  Epoch:    2	Loss: 2.5069	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:07:41 [INFO ]  Epoch:    3	Loss: 2.3114	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:07:43 [INFO ]  Epoch:    4	Loss: 2.2302	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:07:45 [INFO ]  Epoch:    5	Loss: 2.1788	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:07:47 [INFO ]  Epoch:    6	Loss: 2.1546	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:07:48 [INFO ]  Epoch:    7	Loss: 2.0948	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:07:50 [INFO ]  Epoch:    8	Loss: 2.0623	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:07:52 [INFO ]  Epoch:    9	Loss: 2.0307	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:07:54 [INFO ]  Epoch:   10	Loss: 1.8940	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:07:56 [INFO ]  Epoch:   11	Loss: 1.7990	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:07:58 [INFO ]  Epoch:   12	Loss: 1.6099	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:00 [INFO ]  Epoch:   13	Loss: 1.5133	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:01 [INFO ]  Epoch:   14	Loss: 1.4070	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:03 [INFO ]  Epoch:   15	Loss: 1.3079	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:08:05 [INFO ]  Epoch:   16	Loss: 1.2813	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:08:07 [INFO ]  Epoch:   17	Loss: 1.1926	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:08:09 [INFO ]  Epoch:   18	Loss: 1.0771	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:08:11 [INFO ]  Epoch:   19	Loss: 1.1544	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:08:13 [INFO ]  Epoch:   20	Loss: 1.0756	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:08:15 [INFO ]  Epoch:   21	Loss: 0.9688	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:08:16 [INFO ]  Epoch:   22	Loss: 1.0276	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:08:18 [INFO ]  Epoch:   23	Loss: 0.9842	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:08:20 [INFO ]  Epoch:   24	Loss: 0.8809	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:08:22 [INFO ]  Epoch:   25	Loss: 1.0994	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:24 [INFO ]  Epoch:   26	Loss: 0.8584	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:08:26 [INFO ]  Epoch:   27	Loss: 0.8043	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:08:28 [INFO ]  Epoch:   28	Loss: 0.8359	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:29 [INFO ]  Epoch:   29	Loss: 0.8147	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:08:31 [INFO ]  Epoch:   30	Loss: 0.7759	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:08:33 [INFO ]  Epoch:   31	Loss: 0.7682	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:08:35 [INFO ]  Epoch:   32	Loss: 1.0220	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:37 [INFO ]  Epoch:   33	Loss: 0.7597	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:39 [INFO ]  Epoch:   34	Loss: 0.8566	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:40 [INFO ]  Epoch:   35	Loss: 0.8480	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:42 [INFO ]  Epoch:   36	Loss: 0.6666	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:08:44 [INFO ]  Epoch:   37	Loss: 0.7104	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:46 [INFO ]  Epoch:   38	Loss: 0.7991	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:08:48 [INFO ]  Epoch:   39	Loss: 0.6599	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:08:50 [INFO ]  Epoch:   40	Loss: 0.7673	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:52 [INFO ]  Epoch:   41	Loss: 0.6408	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:08:54 [INFO ]  Epoch:   42	Loss: 0.7605	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:08:56 [INFO ]  Epoch:   43	Loss: 0.8370	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:08:58 [INFO ]  Epoch:   44	Loss: 0.8817	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:08:59 [INFO ]  Epoch:   45	Loss: 0.7655	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:01 [INFO ]  Epoch:   46	Loss: 0.6578	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:03 [INFO ]  Epoch:   47	Loss: 0.6769	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:09:05 [INFO ]  Epoch:   48	Loss: 0.6989	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:07 [INFO ]  Epoch:   49	Loss: 0.6640	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:09 [INFO ]  Epoch:   50	Loss: 0.6800	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:09:11 [INFO ]  Epoch:   51	Loss: 0.6361	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:13 [INFO ]  Epoch:   52	Loss: 0.5929	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:14 [INFO ]  Epoch:   53	Loss: 0.6714	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:09:16 [INFO ]  Epoch:   54	Loss: 0.6710	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:09:18 [INFO ]  Epoch:   55	Loss: 0.5998	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:09:20 [INFO ]  Epoch:   56	Loss: 0.7116	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:09:22 [INFO ]  Epoch:   57	Loss: 0.6370	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:09:23 [INFO ]  Epoch:   58	Loss: 0.7217	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:09:25 [INFO ]  Epoch:   59	Loss: 0.6835	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:27 [INFO ]  Epoch:   60	Loss: 0.6204	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:09:30 [INFO ]  Epoch:   61	Loss: 0.6108	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 12:09:31 [INFO ]  Epoch:   62	Loss: 0.7556	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:09:33 [INFO ]  Epoch:   63	Loss: 0.6523	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:09:35 [INFO ]  Epoch:   64	Loss: 0.6691	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:09:37 [INFO ]  Epoch:   65	Loss: 0.5738	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:39 [INFO ]  Epoch:   66	Loss: 0.5502	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:41 [INFO ]  Epoch:   67	Loss: 0.5503	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:09:43 [INFO ]  Epoch:   68	Loss: 0.5953	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:09:45 [INFO ]  Epoch:   69	Loss: 0.5840	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:09:46 [INFO ]  Epoch:   70	Loss: 0.5482	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:48 [INFO ]  Epoch:   71	Loss: 0.6647	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:50 [INFO ]  Epoch:   72	Loss: 0.6697	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:09:52 [INFO ]  Epoch:   73	Loss: 0.6550	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:54 [INFO ]  Epoch:   74	Loss: 0.6580	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:09:56 [INFO ]  Epoch:   75	Loss: 0.5812	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:09:57 [INFO ]  Epoch:   76	Loss: 0.5634	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:09:59 [INFO ]  Epoch:   77	Loss: 0.5462	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:10:01 [INFO ]  Epoch:   78	Loss: 0.5651	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:10:03 [INFO ]  Epoch:   79	Loss: 0.5679	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:05 [INFO ]  Epoch:   80	Loss: 0.5361	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:07 [INFO ]  Epoch:   81	Loss: 0.5526	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:10:08 [INFO ]  Epoch:   82	Loss: 0.6503	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:10 [INFO ]  Epoch:   83	Loss: 0.6014	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:10:12 [INFO ]  Epoch:   84	Loss: 0.5607	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:10:14 [INFO ]  Epoch:   85	Loss: 0.5815	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:10:16 [INFO ]  Epoch:   86	Loss: 0.6214	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:10:18 [INFO ]  Epoch:   87	Loss: 0.5232	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:20 [INFO ]  Epoch:   88	Loss: 0.5785	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:22 [INFO ]  Epoch:   89	Loss: 0.6776	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:10:24 [INFO ]  Epoch:   90	Loss: 0.5911	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:10:26 [INFO ]  Epoch:   91	Loss: 0.5959	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:10:27 [INFO ]  Epoch:   92	Loss: 0.5299	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:29 [INFO ]  Epoch:   93	Loss: 0.5107	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:10:31 [INFO ]  Epoch:   94	Loss: 0.5807	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:10:33 [INFO ]  Epoch:   95	Loss: 0.5842	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:10:35 [INFO ]  Epoch:   96	Loss: 0.6318	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:10:37 [INFO ]  Epoch:   97	Loss: 0.5556	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:10:39 [INFO ]  Epoch:   98	Loss: 0.5588	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:10:41 [INFO ]  Epoch:   99	Loss: 0.5857	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:10:42 [INFO ]  Epoch:  100	Loss: 0.5809	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:10:44 [INFO ]  Epoch:  101	Loss: 0.5965	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:10:46 [INFO ]  Epoch:  102	Loss: 0.6328	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:10:48 [INFO ]  Epoch:  103	Loss: 0.5773	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:10:50 [INFO ]  Epoch:  104	Loss: 0.5774	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:52 [INFO ]  Epoch:  105	Loss: 0.5977	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:10:54 [INFO ]  Epoch:  106	Loss: 0.5446	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:10:56 [INFO ]  Epoch:  107	Loss: 0.5757	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:10:58 [INFO ]  Epoch:  108	Loss: 0.5926	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:10:59 [INFO ]  Epoch:  109	Loss: 0.6824	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:01 [INFO ]  Epoch:  110	Loss: 0.5697	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:03 [INFO ]  Epoch:  111	Loss: 0.5992	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:11:05 [INFO ]  Epoch:  112	Loss: 0.6077	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:07 [INFO ]  Epoch:  113	Loss: 0.5882	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:11:09 [INFO ]  Epoch:  114	Loss: 0.7080	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:11 [INFO ]  Epoch:  115	Loss: 0.5545	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:11:12 [INFO ]  Epoch:  116	Loss: 0.5894	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:14 [INFO ]  Epoch:  117	Loss: 0.5372	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:11:16 [INFO ]  Epoch:  118	Loss: 0.5862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:18 [INFO ]  Epoch:  119	Loss: 0.5762	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:20 [INFO ]  Epoch:  120	Loss: 0.6039	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:22 [INFO ]  Epoch:  121	Loss: 0.5525	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:11:24 [INFO ]  Epoch:  122	Loss: 0.6598	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:11:25 [INFO ]  Epoch:  123	Loss: 0.5507	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:11:27 [INFO ]  Epoch:  124	Loss: 0.5424	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:11:29 [INFO ]  Epoch:  125	Loss: 0.5752	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:31 [INFO ]  Epoch:  126	Loss: 0.5862	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:33 [INFO ]  Epoch:  127	Loss: 0.5209	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:35 [INFO ]  Epoch:  128	Loss: 0.6163	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:36 [INFO ]  Epoch:  129	Loss: 0.6481	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:38 [INFO ]  Epoch:  130	Loss: 0.5318	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:40 [INFO ]  Epoch:  131	Loss: 0.4896	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:42 [INFO ]  Epoch:  132	Loss: 0.6342	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:44 [INFO ]  Epoch:  133	Loss: 0.5304	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:11:46 [INFO ]  Epoch:  134	Loss: 0.6026	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:48 [INFO ]  Epoch:  135	Loss: 0.5099	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:50 [INFO ]  Epoch:  136	Loss: 0.6129	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:11:52 [INFO ]  Epoch:  137	Loss: 0.6137	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:11:54 [INFO ]  Epoch:  138	Loss: 0.5747	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:11:55 [INFO ]  Epoch:  139	Loss: 0.5370	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:11:57 [INFO ]  Epoch:  140	Loss: 0.6563	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:11:59 [INFO ]  Epoch:  141	Loss: 0.5547	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:01 [INFO ]  Epoch:  142	Loss: 0.5648	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:03 [INFO ]  Epoch:  143	Loss: 0.6095	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:04 [INFO ]  Epoch:  144	Loss: 0.6148	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:12:06 [INFO ]  Epoch:  145	Loss: 0.5890	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:08 [INFO ]  Epoch:  146	Loss: 0.6284	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:12:10 [INFO ]  Epoch:  147	Loss: 0.6667	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:12:12 [INFO ]  Epoch:  148	Loss: 0.5431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:14 [INFO ]  Epoch:  149	Loss: 0.5888	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:12:16 [INFO ]  Epoch:  150	Loss: 0.5517	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:18 [INFO ]  Epoch:  151	Loss: 0.5152	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:12:20 [INFO ]  Epoch:  152	Loss: 0.6008	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:12:22 [INFO ]  Epoch:  153	Loss: 0.5233	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:12:24 [INFO ]  Epoch:  154	Loss: 0.4699	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:25 [INFO ]  Epoch:  155	Loss: 0.5782	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:27 [INFO ]  Epoch:  156	Loss: 0.5566	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:29 [INFO ]  Epoch:  157	Loss: 0.5547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:31 [INFO ]  Epoch:  158	Loss: 0.5709	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:12:33 [INFO ]  Epoch:  159	Loss: 0.5958	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:35 [INFO ]  Epoch:  160	Loss: 0.6135	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:12:37 [INFO ]  Epoch:  161	Loss: 0.5533	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:39 [INFO ]  Epoch:  162	Loss: 0.5462	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:12:41 [INFO ]  Epoch:  163	Loss: 0.5513	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:12:43 [INFO ]  Epoch:  164	Loss: 0.6073	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:12:44 [INFO ]  Epoch:  165	Loss: 0.5215	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:12:46 [INFO ]  Epoch:  166	Loss: 0.5950	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:12:48 [INFO ]  Epoch:  167	Loss: 0.6617	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:12:50 [INFO ]  Epoch:  168	Loss: 0.6116	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:52 [INFO ]  Epoch:  169	Loss: 0.5468	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:54 [INFO ]  Epoch:  170	Loss: 0.6036	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:12:56 [INFO ]  Epoch:  171	Loss: 0.5764	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:12:58 [INFO ]  Epoch:  172	Loss: 0.5648	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:13:00 [INFO ]  Epoch:  173	Loss: 0.6186	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:13:02 [INFO ]  Epoch:  174	Loss: 0.5951	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:13:04 [INFO ]  Epoch:  175	Loss: 0.6053	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:13:06 [INFO ]  Epoch:  176	Loss: 0.5971	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:08 [INFO ]  Epoch:  177	Loss: 0.5199	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:10 [INFO ]  Epoch:  178	Loss: 0.5005	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:13:12 [INFO ]  Epoch:  179	Loss: 0.5715	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:13:14 [INFO ]  Epoch:  180	Loss: 0.5485	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:13:16 [INFO ]  Epoch:  181	Loss: 0.5428	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:13:17 [INFO ]  Epoch:  182	Loss: 0.5278	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:13:19 [INFO ]  Epoch:  183	Loss: 0.5692	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:13:21 [INFO ]  Epoch:  184	Loss: 0.5716	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:13:23 [INFO ]  Epoch:  185	Loss: 0.6393	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:13:25 [INFO ]  Epoch:  186	Loss: 0.5939	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:13:27 [INFO ]  Epoch:  187	Loss: 0.6242	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:28 [INFO ]  Epoch:  188	Loss: 0.5334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:13:30 [INFO ]  Epoch:  189	Loss: 0.5358	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:32 [INFO ]  Epoch:  190	Loss: 0.5790	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:34 [INFO ]  Epoch:  191	Loss: 0.5766	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:36 [INFO ]  Epoch:  192	Loss: 0.6104	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:13:38 [INFO ]  Epoch:  193	Loss: 0.5936	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:40 [INFO ]  Epoch:  194	Loss: 0.5779	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:41 [INFO ]  Epoch:  195	Loss: 0.5718	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:43 [INFO ]  Epoch:  196	Loss: 0.6313	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:45 [INFO ]  Epoch:  197	Loss: 0.5896	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:13:47 [INFO ]  Epoch:  198	Loss: 0.5607	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:13:49 [INFO ]  Epoch:  199	Loss: 0.6282	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:13:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 12:13:50 [INFO ]  
2022-10-04 12:13:50 [INFO ]  Final evaluation for SVHN :
2022-10-04 12:13:54 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:13:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:13:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:13:54 [INFO ]  	   step  1 (lr=0.442248)                   82.30%                   0.6545
2022-10-04 12:13:54 [INFO ]  
2022-10-04 12:13:54 [INFO ]  
2022-10-04 12:13:54 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 12:13:57 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:13:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:13:57 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 12:13:57 [INFO ]  	   step  1 (lr=0.442248)                   15.54%                   5.6766
2022-10-04 12:13:57 [INFO ]  
2022-10-04 12:13:57 [INFO ]  CPU Time: 3.52 minutes
2022-10-04 12:36:33 [INFO ]  ======================================== 2022-10-04 12:36:33 ========================================
2022-10-04 12:36:33 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 12:36:33 [INFO ]  Options: 
2022-10-04 12:36:33 [INFO ]  	base_dir: null
2022-10-04 12:36:33 [INFO ]  	batch_size: 1024
2022-10-04 12:36:33 [INFO ]  	checkpoint_interval: 300
2022-10-04 12:36:33 [INFO ]  	dataset: SVHN
2022-10-04 12:36:33 [INFO ]  	dataset_labels:
2022-10-04 12:36:33 [INFO ]  	- 0
2022-10-04 12:36:33 [INFO ]  	- 1
2022-10-04 12:36:33 [INFO ]  	- 2
2022-10-04 12:36:33 [INFO ]  	- 3
2022-10-04 12:36:33 [INFO ]  	- 4
2022-10-04 12:36:33 [INFO ]  	- 5
2022-10-04 12:36:33 [INFO ]  	- 6
2022-10-04 12:36:33 [INFO ]  	- 7
2022-10-04 12:36:33 [INFO ]  	- 8
2022-10-04 12:36:33 [INFO ]  	- 9
2022-10-04 12:36:33 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 12:36:33 [INFO ]  	- !!python/tuple
2022-10-04 12:36:33 [INFO ]  	    - 0.4379104971885681
2022-10-04 12:36:33 [INFO ]  	    - 0.44398033618927
2022-10-04 12:36:33 [INFO ]  	    - 0.4729299545288086
2022-10-04 12:36:33 [INFO ]  	- !!python/tuple
2022-10-04 12:36:33 [INFO ]  	    - 0.19803012907505035
2022-10-04 12:36:33 [INFO ]  	    - 0.2010156363248825
2022-10-04 12:36:33 [INFO ]  	    - 0.19703614711761475
2022-10-04 12:36:33 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 12:36:33 [INFO ]  	decay_epochs: 50
2022-10-04 12:36:33 [INFO ]  	decay_factor: 0.1
2022-10-04 12:36:33 [INFO ]  	device_id: 0
2022-10-04 12:36:33 [INFO ]  	distill_epochs: 1
2022-10-04 12:36:33 [INFO ]  	distill_lr: 0.02
2022-10-04 12:36:33 [INFO ]  	distill_steps: 1
2022-10-04 12:36:33 [INFO ]  	epochs: 200
2022-10-04 12:36:33 [INFO ]  	expand_cls: false
2022-10-04 12:36:33 [INFO ]  	forgetting_dataset: null
2022-10-04 12:36:33 [INFO ]  	init: xavier
2022-10-04 12:36:33 [INFO ]  	init_param: 1.0
2022-10-04 12:36:33 [INFO ]  	input_size: 32
2022-10-04 12:36:33 [INFO ]  	ipc: 50
2022-10-04 12:36:33 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 12:36:33 [INFO ]  	log_interval: 100
2022-10-04 12:36:33 [INFO ]  	log_level: INFO
2022-10-04 12:36:33 [INFO ]  	lr: 0.01
2022-10-04 12:36:33 [INFO ]  	mode: distill_adapt
2022-10-04 12:36:33 [INFO ]  	nc: 3
2022-10-04 12:36:33 [INFO ]  	num_classes: 10
2022-10-04 12:36:33 [INFO ]  	num_workers: 8
2022-10-04 12:36:33 [INFO ]  	phase: train
2022-10-04 12:36:33 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 12:36:33 [INFO ]  	start_time: '2022-10-04 12:36:33'
2022-10-04 12:36:33 [INFO ]  	test_batch_size: 1024
2022-10-04 12:36:33 [INFO ]  	
2022-10-04 12:36:35 [INFO ]  train dataset size:	73257
2022-10-04 12:36:35 [INFO ]  test dataset size: 	26032
2022-10-04 12:36:35 [INFO ]  datasets built!
2022-10-04 12:36:35 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 12:36:37 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 12:36:37 [INFO ]  
2022-10-04 12:36:37 [INFO ]  Begin of epoch 0 :
2022-10-04 12:36:41 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:36:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:36:41 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:36:41 [INFO ]  	   step  1 (lr=0.020000)                    7.03%                   8.7882
2022-10-04 12:36:41 [INFO ]  
2022-10-04 12:36:41 [INFO ]  Epoch:    0	Loss: 9.1446	Data Time: 0.40s	Train Time: 0.05s
2022-10-04 12:36:42 [INFO ]  Epoch:    1	Loss: 2.9426	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:36:44 [INFO ]  Epoch:    2	Loss: 2.4538	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:36:46 [INFO ]  Epoch:    3	Loss: 2.3030	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:36:47 [INFO ]  Epoch:    4	Loss: 2.2082	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:36:49 [INFO ]  Epoch:    5	Loss: 2.1805	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:36:51 [INFO ]  Epoch:    6	Loss: 2.1288	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:36:53 [INFO ]  Epoch:    7	Loss: 2.0694	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:36:55 [INFO ]  Epoch:    8	Loss: 2.0158	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:36:57 [INFO ]  Epoch:    9	Loss: 1.9455	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:36:58 [INFO ]  Epoch:   10	Loss: 1.7514	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:37:00 [INFO ]  Epoch:   11	Loss: 1.6881	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 12:37:02 [INFO ]  Epoch:   12	Loss: 1.4897	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:37:04 [INFO ]  Epoch:   13	Loss: 1.3500	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:37:06 [INFO ]  Epoch:   14	Loss: 1.4911	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:37:08 [INFO ]  Epoch:   15	Loss: 1.2356	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:37:09 [INFO ]  Epoch:   16	Loss: 1.1149	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:11 [INFO ]  Epoch:   17	Loss: 1.0843	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:13 [INFO ]  Epoch:   18	Loss: 1.0007	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 12:37:15 [INFO ]  Epoch:   19	Loss: 0.9676	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:37:17 [INFO ]  Epoch:   20	Loss: 1.0952	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:18 [INFO ]  Epoch:   21	Loss: 0.9634	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:20 [INFO ]  Epoch:   22	Loss: 0.9928	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:37:22 [INFO ]  Epoch:   23	Loss: 0.9361	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:24 [INFO ]  Epoch:   24	Loss: 0.8547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:26 [INFO ]  Epoch:   25	Loss: 0.9515	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:37:27 [INFO ]  Epoch:   26	Loss: 0.9015	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:37:29 [INFO ]  Epoch:   27	Loss: 0.7869	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:31 [INFO ]  Epoch:   28	Loss: 0.7687	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:33 [INFO ]  Epoch:   29	Loss: 0.8138	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:37:35 [INFO ]  Epoch:   30	Loss: 0.8346	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:37 [INFO ]  Epoch:   31	Loss: 1.3605	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:37:38 [INFO ]  Epoch:   32	Loss: 0.7879	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:40 [INFO ]  Epoch:   33	Loss: 0.8100	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:37:42 [INFO ]  Epoch:   34	Loss: 0.7541	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:37:44 [INFO ]  Epoch:   35	Loss: 0.8085	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:37:46 [INFO ]  Epoch:   36	Loss: 0.7701	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:37:48 [INFO ]  Epoch:   37	Loss: 0.6801	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:50 [INFO ]  Epoch:   38	Loss: 0.7366	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:37:51 [INFO ]  Epoch:   39	Loss: 0.6377	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:37:53 [INFO ]  Epoch:   40	Loss: 0.7451	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:55 [INFO ]  Epoch:   41	Loss: 0.6566	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:37:57 [INFO ]  Epoch:   42	Loss: 0.7111	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:37:59 [INFO ]  Epoch:   43	Loss: 0.7112	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:00 [INFO ]  Epoch:   44	Loss: 0.8034	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:02 [INFO ]  Epoch:   45	Loss: 0.7286	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:04 [INFO ]  Epoch:   46	Loss: 0.7044	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:38:06 [INFO ]  Epoch:   47	Loss: 0.7338	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:08 [INFO ]  Epoch:   48	Loss: 0.6644	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:10 [INFO ]  Epoch:   49	Loss: 0.7068	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:38:11 [INFO ]  Epoch:   50	Loss: 0.6972	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:38:13 [INFO ]  Epoch:   51	Loss: 0.6224	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:15 [INFO ]  Epoch:   52	Loss: 0.6221	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:38:17 [INFO ]  Epoch:   53	Loss: 0.6269	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:38:19 [INFO ]  Epoch:   54	Loss: 0.6394	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:21 [INFO ]  Epoch:   55	Loss: 0.5833	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:22 [INFO ]  Epoch:   56	Loss: 0.6412	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:38:24 [INFO ]  Epoch:   57	Loss: 0.6487	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:38:26 [INFO ]  Epoch:   58	Loss: 0.5936	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:38:28 [INFO ]  Epoch:   59	Loss: 0.6355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:30 [INFO ]  Epoch:   60	Loss: 0.6266	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:38:32 [INFO ]  Epoch:   61	Loss: 0.6315	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:34 [INFO ]  Epoch:   62	Loss: 0.5752	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:36 [INFO ]  Epoch:   63	Loss: 0.6146	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:38 [INFO ]  Epoch:   64	Loss: 0.6105	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:39 [INFO ]  Epoch:   65	Loss: 0.6517	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:41 [INFO ]  Epoch:   66	Loss: 0.5952	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:38:43 [INFO ]  Epoch:   67	Loss: 0.7040	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:38:45 [INFO ]  Epoch:   68	Loss: 0.6261	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:38:47 [INFO ]  Epoch:   69	Loss: 0.6704	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:49 [INFO ]  Epoch:   70	Loss: 0.6272	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:38:50 [INFO ]  Epoch:   71	Loss: 0.5864	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:38:52 [INFO ]  Epoch:   72	Loss: 0.6235	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:38:54 [INFO ]  Epoch:   73	Loss: 0.6020	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:38:56 [INFO ]  Epoch:   74	Loss: 0.5366	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:38:58 [INFO ]  Epoch:   75	Loss: 0.6692	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:38:59 [INFO ]  Epoch:   76	Loss: 0.5342	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:01 [INFO ]  Epoch:   77	Loss: 0.5454	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:03 [INFO ]  Epoch:   78	Loss: 0.6236	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:39:05 [INFO ]  Epoch:   79	Loss: 0.5884	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:39:06 [INFO ]  Epoch:   80	Loss: 0.5923	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:39:08 [INFO ]  Epoch:   81	Loss: 0.6313	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:10 [INFO ]  Epoch:   82	Loss: 0.6137	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:39:12 [INFO ]  Epoch:   83	Loss: 0.6222	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:14 [INFO ]  Epoch:   84	Loss: 0.6672	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:39:16 [INFO ]  Epoch:   85	Loss: 0.5538	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:39:17 [INFO ]  Epoch:   86	Loss: 0.5985	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:19 [INFO ]  Epoch:   87	Loss: 0.6168	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:21 [INFO ]  Epoch:   88	Loss: 0.5789	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:23 [INFO ]  Epoch:   89	Loss: 0.6284	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:39:25 [INFO ]  Epoch:   90	Loss: 0.5467	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:39:27 [INFO ]  Epoch:   91	Loss: 0.6585	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:39:29 [INFO ]  Epoch:   92	Loss: 0.6360	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:30 [INFO ]  Epoch:   93	Loss: 0.6039	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:32 [INFO ]  Epoch:   94	Loss: 0.6040	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:39:34 [INFO ]  Epoch:   95	Loss: 0.5653	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:36 [INFO ]  Epoch:   96	Loss: 0.5907	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:39:38 [INFO ]  Epoch:   97	Loss: 0.5581	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:39:40 [INFO ]  Epoch:   98	Loss: 0.5753	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:42 [INFO ]  Epoch:   99	Loss: 0.6530	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:44 [INFO ]  Epoch:  100	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:39:45 [INFO ]  Epoch:  101	Loss: 0.5757	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:39:47 [INFO ]  Epoch:  102	Loss: 0.6744	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:39:49 [INFO ]  Epoch:  103	Loss: 0.5851	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:39:51 [INFO ]  Epoch:  104	Loss: 0.6321	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:53 [INFO ]  Epoch:  105	Loss: 0.6194	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:39:55 [INFO ]  Epoch:  106	Loss: 0.5592	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:39:56 [INFO ]  Epoch:  107	Loss: 0.5913	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:39:58 [INFO ]  Epoch:  108	Loss: 0.6427	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:40:00 [INFO ]  Epoch:  109	Loss: 0.6567	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:02 [INFO ]  Epoch:  110	Loss: 0.5540	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:04 [INFO ]  Epoch:  111	Loss: 0.5969	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:40:06 [INFO ]  Epoch:  112	Loss: 0.5474	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:40:08 [INFO ]  Epoch:  113	Loss: 0.6053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:09 [INFO ]  Epoch:  114	Loss: 0.6127	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:40:11 [INFO ]  Epoch:  115	Loss: 0.6031	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:40:13 [INFO ]  Epoch:  116	Loss: 0.5586	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:40:15 [INFO ]  Epoch:  117	Loss: 0.4977	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:40:17 [INFO ]  Epoch:  118	Loss: 0.6003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:19 [INFO ]  Epoch:  119	Loss: 0.6441	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:40:21 [INFO ]  Epoch:  120	Loss: 0.5286	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:22 [INFO ]  Epoch:  121	Loss: 0.5716	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:24 [INFO ]  Epoch:  122	Loss: 0.5646	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:26 [INFO ]  Epoch:  123	Loss: 0.5601	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:40:28 [INFO ]  Epoch:  124	Loss: 0.5737	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:40:30 [INFO ]  Epoch:  125	Loss: 0.5999	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:31 [INFO ]  Epoch:  126	Loss: 0.5965	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:40:33 [INFO ]  Epoch:  127	Loss: 0.6346	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:35 [INFO ]  Epoch:  128	Loss: 0.5873	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:37 [INFO ]  Epoch:  129	Loss: 0.5908	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:39 [INFO ]  Epoch:  130	Loss: 0.5392	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:41 [INFO ]  Epoch:  131	Loss: 0.5402	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:43 [INFO ]  Epoch:  132	Loss: 0.5802	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:45 [INFO ]  Epoch:  133	Loss: 0.5932	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:40:47 [INFO ]  Epoch:  134	Loss: 0.5684	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:49 [INFO ]  Epoch:  135	Loss: 0.6164	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:40:51 [INFO ]  Epoch:  136	Loss: 0.5291	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:40:53 [INFO ]  Epoch:  137	Loss: 0.5499	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:40:55 [INFO ]  Epoch:  138	Loss: 0.6223	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:56 [INFO ]  Epoch:  139	Loss: 0.5935	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:40:58 [INFO ]  Epoch:  140	Loss: 0.5959	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:41:00 [INFO ]  Epoch:  141	Loss: 0.5773	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:02 [INFO ]  Epoch:  142	Loss: 0.6259	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:04 [INFO ]  Epoch:  143	Loss: 0.6249	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:41:05 [INFO ]  Epoch:  144	Loss: 0.5188	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:41:07 [INFO ]  Epoch:  145	Loss: 0.5418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:09 [INFO ]  Epoch:  146	Loss: 0.5439	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:41:11 [INFO ]  Epoch:  147	Loss: 0.5890	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:41:13 [INFO ]  Epoch:  148	Loss: 0.5613	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:14 [INFO ]  Epoch:  149	Loss: 0.6000	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:16 [INFO ]  Epoch:  150	Loss: 0.6429	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:41:18 [INFO ]  Epoch:  151	Loss: 0.5288	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:20 [INFO ]  Epoch:  152	Loss: 0.5612	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:41:22 [INFO ]  Epoch:  153	Loss: 0.6122	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:41:23 [INFO ]  Epoch:  154	Loss: 0.6499	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:25 [INFO ]  Epoch:  155	Loss: 0.6107	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:27 [INFO ]  Epoch:  156	Loss: 0.6140	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:41:29 [INFO ]  Epoch:  157	Loss: 0.5072	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:41:31 [INFO ]  Epoch:  158	Loss: 0.6342	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:41:33 [INFO ]  Epoch:  159	Loss: 0.6059	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:41:35 [INFO ]  Epoch:  160	Loss: 0.5427	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:41:37 [INFO ]  Epoch:  161	Loss: 0.5929	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:39 [INFO ]  Epoch:  162	Loss: 0.5167	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:41:41 [INFO ]  Epoch:  163	Loss: 0.5641	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:41:43 [INFO ]  Epoch:  164	Loss: 0.5695	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:45 [INFO ]  Epoch:  165	Loss: 0.6113	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:41:46 [INFO ]  Epoch:  166	Loss: 0.5862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:48 [INFO ]  Epoch:  167	Loss: 0.5472	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:50 [INFO ]  Epoch:  168	Loss: 0.5670	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:41:52 [INFO ]  Epoch:  169	Loss: 0.5443	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:54 [INFO ]  Epoch:  170	Loss: 0.5537	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:41:55 [INFO ]  Epoch:  171	Loss: 0.5510	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:57 [INFO ]  Epoch:  172	Loss: 0.5163	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:41:59 [INFO ]  Epoch:  173	Loss: 0.5998	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:42:01 [INFO ]  Epoch:  174	Loss: 0.5693	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:42:03 [INFO ]  Epoch:  175	Loss: 0.5572	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:05 [INFO ]  Epoch:  176	Loss: 0.5677	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:42:07 [INFO ]  Epoch:  177	Loss: 0.5610	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:42:09 [INFO ]  Epoch:  178	Loss: 0.5790	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:42:10 [INFO ]  Epoch:  179	Loss: 0.5680	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:42:12 [INFO ]  Epoch:  180	Loss: 0.6262	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:42:14 [INFO ]  Epoch:  181	Loss: 0.6515	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:42:16 [INFO ]  Epoch:  182	Loss: 0.6082	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:42:18 [INFO ]  Epoch:  183	Loss: 0.5778	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:20 [INFO ]  Epoch:  184	Loss: 0.5927	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:42:22 [INFO ]  Epoch:  185	Loss: 0.5448	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:23 [INFO ]  Epoch:  186	Loss: 0.5740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:25 [INFO ]  Epoch:  187	Loss: 0.5653	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:42:27 [INFO ]  Epoch:  188	Loss: 0.5804	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:29 [INFO ]  Epoch:  189	Loss: 0.5382	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:42:31 [INFO ]  Epoch:  190	Loss: 0.5715	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:33 [INFO ]  Epoch:  191	Loss: 0.5803	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:42:35 [INFO ]  Epoch:  192	Loss: 0.5590	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:42:37 [INFO ]  Epoch:  193	Loss: 0.5979	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:42:39 [INFO ]  Epoch:  194	Loss: 0.5131	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:42:41 [INFO ]  Epoch:  195	Loss: 0.5881	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:42:42 [INFO ]  Epoch:  196	Loss: 0.5562	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:44 [INFO ]  Epoch:  197	Loss: 0.5911	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:42:46 [INFO ]  Epoch:  198	Loss: 0.6005	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:42:48 [INFO ]  Epoch:  199	Loss: 0.6148	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:42:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 12:42:49 [INFO ]  
2022-10-04 12:42:49 [INFO ]  Final evaluation for SVHN :
2022-10-04 12:42:53 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:42:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:42:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:42:53 [INFO ]  	   step  1 (lr=0.441562)                   82.14%                   0.6650
2022-10-04 12:42:53 [INFO ]  
2022-10-04 12:42:53 [INFO ]  
2022-10-04 12:42:53 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 12:42:56 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:42:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:42:56 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 12:42:56 [INFO ]  	   step  1 (lr=0.441562)                   14.68%                   5.7132
2022-10-04 12:42:56 [INFO ]  
2022-10-04 12:42:56 [INFO ]  CPU Time: 3.49 minutes
2022-10-04 12:48:40 [INFO ]  ======================================== 2022-10-04 12:48:40 ========================================
2022-10-04 12:48:40 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 12:48:40 [INFO ]  Options: 
2022-10-04 12:48:40 [INFO ]  	base_dir: null
2022-10-04 12:48:40 [INFO ]  	batch_size: 1024
2022-10-04 12:48:40 [INFO ]  	checkpoint_interval: 300
2022-10-04 12:48:40 [INFO ]  	dataset: SVHN
2022-10-04 12:48:40 [INFO ]  	dataset_labels:
2022-10-04 12:48:40 [INFO ]  	- 0
2022-10-04 12:48:40 [INFO ]  	- 1
2022-10-04 12:48:40 [INFO ]  	- 2
2022-10-04 12:48:40 [INFO ]  	- 3
2022-10-04 12:48:40 [INFO ]  	- 4
2022-10-04 12:48:40 [INFO ]  	- 5
2022-10-04 12:48:40 [INFO ]  	- 6
2022-10-04 12:48:40 [INFO ]  	- 7
2022-10-04 12:48:40 [INFO ]  	- 8
2022-10-04 12:48:40 [INFO ]  	- 9
2022-10-04 12:48:40 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 12:48:40 [INFO ]  	- !!python/tuple
2022-10-04 12:48:40 [INFO ]  	    - 0.4379104971885681
2022-10-04 12:48:40 [INFO ]  	    - 0.44398033618927
2022-10-04 12:48:40 [INFO ]  	    - 0.4729299545288086
2022-10-04 12:48:40 [INFO ]  	- !!python/tuple
2022-10-04 12:48:40 [INFO ]  	    - 0.19803012907505035
2022-10-04 12:48:40 [INFO ]  	    - 0.2010156363248825
2022-10-04 12:48:40 [INFO ]  	    - 0.19703614711761475
2022-10-04 12:48:40 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 12:48:40 [INFO ]  	decay_epochs: 50
2022-10-04 12:48:40 [INFO ]  	decay_factor: 0.1
2022-10-04 12:48:40 [INFO ]  	device_id: 0
2022-10-04 12:48:40 [INFO ]  	distill_epochs: 1
2022-10-04 12:48:40 [INFO ]  	distill_lr: 0.02
2022-10-04 12:48:40 [INFO ]  	distill_steps: 1
2022-10-04 12:48:40 [INFO ]  	epochs: 200
2022-10-04 12:48:40 [INFO ]  	expand_cls: false
2022-10-04 12:48:40 [INFO ]  	forgetting_dataset: null
2022-10-04 12:48:40 [INFO ]  	init: xavier
2022-10-04 12:48:40 [INFO ]  	init_param: 1.0
2022-10-04 12:48:40 [INFO ]  	input_size: 32
2022-10-04 12:48:40 [INFO ]  	ipc: 50
2022-10-04 12:48:40 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 12:48:40 [INFO ]  	log_interval: 100
2022-10-04 12:48:40 [INFO ]  	log_level: INFO
2022-10-04 12:48:40 [INFO ]  	lr: 0.01
2022-10-04 12:48:40 [INFO ]  	mode: distill_adapt
2022-10-04 12:48:40 [INFO ]  	nc: 3
2022-10-04 12:48:40 [INFO ]  	num_classes: 10
2022-10-04 12:48:40 [INFO ]  	num_workers: 8
2022-10-04 12:48:40 [INFO ]  	phase: train
2022-10-04 12:48:40 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 12:48:40 [INFO ]  	start_time: '2022-10-04 12:48:40'
2022-10-04 12:48:40 [INFO ]  	test_batch_size: 1024
2022-10-04 12:48:40 [INFO ]  	
2022-10-04 12:48:42 [INFO ]  train dataset size:	73257
2022-10-04 12:48:42 [INFO ]  test dataset size: 	26032
2022-10-04 12:48:42 [INFO ]  datasets built!
2022-10-04 12:48:42 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 12:48:44 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 12:48:44 [INFO ]  
2022-10-04 12:48:44 [INFO ]  Begin of epoch 0 :
2022-10-04 12:48:48 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:48:48 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:48:48 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:48:48 [INFO ]  	   step  1 (lr=0.020000)                    7.05%                   8.8891
2022-10-04 12:48:48 [INFO ]  
2022-10-04 12:48:48 [INFO ]  Epoch:    0	Loss: 9.4385	Data Time: 0.40s	Train Time: 0.05s
2022-10-04 12:48:49 [INFO ]  Epoch:    1	Loss: 2.9914	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:48:51 [INFO ]  Epoch:    2	Loss: 2.4535	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:48:53 [INFO ]  Epoch:    3	Loss: 2.3249	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:48:55 [INFO ]  Epoch:    4	Loss: 2.2107	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:48:57 [INFO ]  Epoch:    5	Loss: 2.1601	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:48:59 [INFO ]  Epoch:    6	Loss: 2.1613	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:49:01 [INFO ]  Epoch:    7	Loss: 2.1014	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:49:02 [INFO ]  Epoch:    8	Loss: 2.0538	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:04 [INFO ]  Epoch:    9	Loss: 1.9553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:06 [INFO ]  Epoch:   10	Loss: 1.8715	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:49:08 [INFO ]  Epoch:   11	Loss: 1.7997	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:49:10 [INFO ]  Epoch:   12	Loss: 1.6402	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:49:12 [INFO ]  Epoch:   13	Loss: 1.4192	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:14 [INFO ]  Epoch:   14	Loss: 1.4009	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:49:15 [INFO ]  Epoch:   15	Loss: 1.2808	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:17 [INFO ]  Epoch:   16	Loss: 1.1658	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:49:19 [INFO ]  Epoch:   17	Loss: 1.2447	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:21 [INFO ]  Epoch:   18	Loss: 1.1178	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:49:23 [INFO ]  Epoch:   19	Loss: 1.1533	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:49:24 [INFO ]  Epoch:   20	Loss: 0.9238	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:26 [INFO ]  Epoch:   21	Loss: 1.0278	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:49:28 [INFO ]  Epoch:   22	Loss: 0.9441	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:30 [INFO ]  Epoch:   23	Loss: 1.0259	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:32 [INFO ]  Epoch:   24	Loss: 1.0279	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:49:34 [INFO ]  Epoch:   25	Loss: 0.9377	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:36 [INFO ]  Epoch:   26	Loss: 1.2941	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:38 [INFO ]  Epoch:   27	Loss: 0.8659	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:39 [INFO ]  Epoch:   28	Loss: 0.8418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:41 [INFO ]  Epoch:   29	Loss: 0.8551	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:43 [INFO ]  Epoch:   30	Loss: 0.8016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:45 [INFO ]  Epoch:   31	Loss: 0.8340	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:46 [INFO ]  Epoch:   32	Loss: 0.8523	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:49:49 [INFO ]  Epoch:   33	Loss: 0.8846	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:49:50 [INFO ]  Epoch:   34	Loss: 0.8597	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:49:52 [INFO ]  Epoch:   35	Loss: 0.8249	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:49:54 [INFO ]  Epoch:   36	Loss: 0.8855	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:49:56 [INFO ]  Epoch:   37	Loss: 1.1155	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:49:58 [INFO ]  Epoch:   38	Loss: 0.7411	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:00 [INFO ]  Epoch:   39	Loss: 0.6735	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:50:01 [INFO ]  Epoch:   40	Loss: 0.6725	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:03 [INFO ]  Epoch:   41	Loss: 0.6921	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:50:05 [INFO ]  Epoch:   42	Loss: 0.7931	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:50:07 [INFO ]  Epoch:   43	Loss: 0.6808	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:09 [INFO ]  Epoch:   44	Loss: 0.8335	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:50:11 [INFO ]  Epoch:   45	Loss: 0.7059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:13 [INFO ]  Epoch:   46	Loss: 0.7658	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:15 [INFO ]  Epoch:   47	Loss: 0.7392	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:17 [INFO ]  Epoch:   48	Loss: 0.7137	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:50:18 [INFO ]  Epoch:   49	Loss: 0.7018	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:20 [INFO ]  Epoch:   50	Loss: 0.5581	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:50:22 [INFO ]  Epoch:   51	Loss: 0.6646	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:24 [INFO ]  Epoch:   52	Loss: 0.6314	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:26 [INFO ]  Epoch:   53	Loss: 0.5766	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:50:28 [INFO ]  Epoch:   54	Loss: 0.5862	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:29 [INFO ]  Epoch:   55	Loss: 0.5906	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:50:31 [INFO ]  Epoch:   56	Loss: 0.6946	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:33 [INFO ]  Epoch:   57	Loss: 0.5979	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:35 [INFO ]  Epoch:   58	Loss: 0.6039	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:50:37 [INFO ]  Epoch:   59	Loss: 0.6116	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:39 [INFO ]  Epoch:   60	Loss: 0.5926	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:50:41 [INFO ]  Epoch:   61	Loss: 0.6364	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:50:42 [INFO ]  Epoch:   62	Loss: 0.6156	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:50:44 [INFO ]  Epoch:   63	Loss: 0.5865	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:46 [INFO ]  Epoch:   64	Loss: 0.6716	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:50:48 [INFO ]  Epoch:   65	Loss: 0.6003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:50 [INFO ]  Epoch:   66	Loss: 0.6813	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:50:52 [INFO ]  Epoch:   67	Loss: 0.6341	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:54 [INFO ]  Epoch:   68	Loss: 0.6535	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:50:56 [INFO ]  Epoch:   69	Loss: 0.5945	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:50:57 [INFO ]  Epoch:   70	Loss: 0.5735	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:50:59 [INFO ]  Epoch:   71	Loss: 0.6266	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:51:01 [INFO ]  Epoch:   72	Loss: 0.6360	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:03 [INFO ]  Epoch:   73	Loss: 0.6122	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 12:51:05 [INFO ]  Epoch:   74	Loss: 0.5929	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:07 [INFO ]  Epoch:   75	Loss: 0.6347	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:51:09 [INFO ]  Epoch:   76	Loss: 0.5449	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:10 [INFO ]  Epoch:   77	Loss: 0.5666	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:51:12 [INFO ]  Epoch:   78	Loss: 0.5095	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:14 [INFO ]  Epoch:   79	Loss: 0.6263	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:51:16 [INFO ]  Epoch:   80	Loss: 0.5567	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:18 [INFO ]  Epoch:   81	Loss: 0.5424	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:51:20 [INFO ]  Epoch:   82	Loss: 0.6206	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:51:21 [INFO ]  Epoch:   83	Loss: 0.6366	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:23 [INFO ]  Epoch:   84	Loss: 0.5662	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:51:25 [INFO ]  Epoch:   85	Loss: 0.5755	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:27 [INFO ]  Epoch:   86	Loss: 0.4810	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:29 [INFO ]  Epoch:   87	Loss: 0.6648	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:51:31 [INFO ]  Epoch:   88	Loss: 0.6186	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:33 [INFO ]  Epoch:   89	Loss: 0.6302	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:51:34 [INFO ]  Epoch:   90	Loss: 0.6053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:36 [INFO ]  Epoch:   91	Loss: 0.5508	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:51:38 [INFO ]  Epoch:   92	Loss: 0.6801	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:40 [INFO ]  Epoch:   93	Loss: 0.5399	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:42 [INFO ]  Epoch:   94	Loss: 0.6500	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:51:43 [INFO ]  Epoch:   95	Loss: 0.7167	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:51:45 [INFO ]  Epoch:   96	Loss: 0.5838	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:51:47 [INFO ]  Epoch:   97	Loss: 0.6324	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:49 [INFO ]  Epoch:   98	Loss: 0.6401	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:51 [INFO ]  Epoch:   99	Loss: 0.5315	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:51:52 [INFO ]  Epoch:  100	Loss: 0.5444	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:54 [INFO ]  Epoch:  101	Loss: 0.6539	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:51:56 [INFO ]  Epoch:  102	Loss: 0.6466	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:51:58 [INFO ]  Epoch:  103	Loss: 0.5679	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:52:00 [INFO ]  Epoch:  104	Loss: 0.6294	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:02 [INFO ]  Epoch:  105	Loss: 0.5842	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:04 [INFO ]  Epoch:  106	Loss: 0.6028	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:52:05 [INFO ]  Epoch:  107	Loss: 0.5252	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:07 [INFO ]  Epoch:  108	Loss: 0.5246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:09 [INFO ]  Epoch:  109	Loss: 0.6136	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:11 [INFO ]  Epoch:  110	Loss: 0.5894	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:13 [INFO ]  Epoch:  111	Loss: 0.6463	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:52:15 [INFO ]  Epoch:  112	Loss: 0.5956	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:52:17 [INFO ]  Epoch:  113	Loss: 0.5727	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:52:19 [INFO ]  Epoch:  114	Loss: 0.5630	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:20 [INFO ]  Epoch:  115	Loss: 0.6598	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:22 [INFO ]  Epoch:  116	Loss: 0.5936	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:24 [INFO ]  Epoch:  117	Loss: 0.7286	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:52:26 [INFO ]  Epoch:  118	Loss: 0.6473	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:52:28 [INFO ]  Epoch:  119	Loss: 0.5465	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:52:29 [INFO ]  Epoch:  120	Loss: 0.5406	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:31 [INFO ]  Epoch:  121	Loss: 0.5363	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:33 [INFO ]  Epoch:  122	Loss: 0.5664	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:52:35 [INFO ]  Epoch:  123	Loss: 0.5586	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:52:37 [INFO ]  Epoch:  124	Loss: 0.6438	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:52:39 [INFO ]  Epoch:  125	Loss: 0.6080	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:52:41 [INFO ]  Epoch:  126	Loss: 0.5914	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:43 [INFO ]  Epoch:  127	Loss: 0.5872	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:52:45 [INFO ]  Epoch:  128	Loss: 0.5419	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:52:46 [INFO ]  Epoch:  129	Loss: 0.5580	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 12:52:48 [INFO ]  Epoch:  130	Loss: 0.5709	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:50 [INFO ]  Epoch:  131	Loss: 0.5862	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:52 [INFO ]  Epoch:  132	Loss: 0.5600	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:52:54 [INFO ]  Epoch:  133	Loss: 0.5814	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:52:56 [INFO ]  Epoch:  134	Loss: 0.5696	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:52:58 [INFO ]  Epoch:  135	Loss: 0.5941	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:52:59 [INFO ]  Epoch:  136	Loss: 0.5935	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:53:01 [INFO ]  Epoch:  137	Loss: 0.5625	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:03 [INFO ]  Epoch:  138	Loss: 0.6592	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:53:05 [INFO ]  Epoch:  139	Loss: 0.5000	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:53:07 [INFO ]  Epoch:  140	Loss: 0.6185	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:53:08 [INFO ]  Epoch:  141	Loss: 0.5796	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:53:10 [INFO ]  Epoch:  142	Loss: 0.5659	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:53:12 [INFO ]  Epoch:  143	Loss: 0.6004	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:14 [INFO ]  Epoch:  144	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:15 [INFO ]  Epoch:  145	Loss: 0.5694	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:53:17 [INFO ]  Epoch:  146	Loss: 0.6886	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:19 [INFO ]  Epoch:  147	Loss: 0.6249	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:21 [INFO ]  Epoch:  148	Loss: 0.5290	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:23 [INFO ]  Epoch:  149	Loss: 0.5239	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:25 [INFO ]  Epoch:  150	Loss: 0.5327	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:27 [INFO ]  Epoch:  151	Loss: 0.5289	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:28 [INFO ]  Epoch:  152	Loss: 0.5950	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:53:30 [INFO ]  Epoch:  153	Loss: 0.6008	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:32 [INFO ]  Epoch:  154	Loss: 0.6283	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:34 [INFO ]  Epoch:  155	Loss: 0.5666	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:36 [INFO ]  Epoch:  156	Loss: 0.6304	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:53:38 [INFO ]  Epoch:  157	Loss: 0.5520	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:53:40 [INFO ]  Epoch:  158	Loss: 0.6553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:42 [INFO ]  Epoch:  159	Loss: 0.5651	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:43 [INFO ]  Epoch:  160	Loss: 0.6332	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:53:45 [INFO ]  Epoch:  161	Loss: 0.5684	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:53:47 [INFO ]  Epoch:  162	Loss: 0.5331	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:49 [INFO ]  Epoch:  163	Loss: 0.5503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:51 [INFO ]  Epoch:  164	Loss: 0.5990	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:53:52 [INFO ]  Epoch:  165	Loss: 0.5989	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:53:54 [INFO ]  Epoch:  166	Loss: 0.5658	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:53:56 [INFO ]  Epoch:  167	Loss: 0.5342	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:53:58 [INFO ]  Epoch:  168	Loss: 0.5906	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:54:00 [INFO ]  Epoch:  169	Loss: 0.6601	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:02 [INFO ]  Epoch:  170	Loss: 0.5842	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:54:04 [INFO ]  Epoch:  171	Loss: 0.5923	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:54:06 [INFO ]  Epoch:  172	Loss: 0.5712	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:54:08 [INFO ]  Epoch:  173	Loss: 0.6502	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:54:09 [INFO ]  Epoch:  174	Loss: 0.5877	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:54:11 [INFO ]  Epoch:  175	Loss: 0.5915	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:54:13 [INFO ]  Epoch:  176	Loss: 0.5693	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:15 [INFO ]  Epoch:  177	Loss: 0.5371	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:54:17 [INFO ]  Epoch:  178	Loss: 0.5886	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:54:18 [INFO ]  Epoch:  179	Loss: 0.6031	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:20 [INFO ]  Epoch:  180	Loss: 0.5502	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:54:22 [INFO ]  Epoch:  181	Loss: 0.5639	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:54:24 [INFO ]  Epoch:  182	Loss: 0.5306	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:26 [INFO ]  Epoch:  183	Loss: 0.6350	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:54:27 [INFO ]  Epoch:  184	Loss: 0.4862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:30 [INFO ]  Epoch:  185	Loss: 0.6098	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:54:32 [INFO ]  Epoch:  186	Loss: 0.5499	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:54:33 [INFO ]  Epoch:  187	Loss: 0.5821	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:54:35 [INFO ]  Epoch:  188	Loss: 0.5793	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:54:37 [INFO ]  Epoch:  189	Loss: 0.5584	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:39 [INFO ]  Epoch:  190	Loss: 0.6293	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:54:41 [INFO ]  Epoch:  191	Loss: 0.5814	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:54:43 [INFO ]  Epoch:  192	Loss: 0.5564	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:54:44 [INFO ]  Epoch:  193	Loss: 0.5811	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:54:46 [INFO ]  Epoch:  194	Loss: 0.6132	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:54:48 [INFO ]  Epoch:  195	Loss: 0.5221	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:54:50 [INFO ]  Epoch:  196	Loss: 0.6678	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:54:52 [INFO ]  Epoch:  197	Loss: 0.6024	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:54:54 [INFO ]  Epoch:  198	Loss: 0.5672	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:54:56 [INFO ]  Epoch:  199	Loss: 0.6750	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:54:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 12:54:57 [INFO ]  
2022-10-04 12:54:57 [INFO ]  Final evaluation for SVHN :
2022-10-04 12:55:01 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:55:01 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:55:01 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:55:01 [INFO ]  	   step  1 (lr=0.449378)                   82.18%                   0.6666
2022-10-04 12:55:01 [INFO ]  
2022-10-04 12:55:01 [INFO ]  
2022-10-04 12:55:01 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 12:55:04 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:55:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:55:04 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 12:55:04 [INFO ]  	   step  1 (lr=0.449378)                   14.88%                   5.3021
2022-10-04 12:55:04 [INFO ]  
2022-10-04 12:55:04 [INFO ]  CPU Time: 3.48 minutes
2022-10-04 12:57:38 [INFO ]  ======================================== 2022-10-04 12:57:38 ========================================
2022-10-04 12:57:38 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 12:57:38 [INFO ]  Options: 
2022-10-04 12:57:38 [INFO ]  	base_dir: null
2022-10-04 12:57:38 [INFO ]  	batch_size: 1024
2022-10-04 12:57:38 [INFO ]  	checkpoint_interval: 300
2022-10-04 12:57:38 [INFO ]  	dataset: SVHN
2022-10-04 12:57:38 [INFO ]  	dataset_labels:
2022-10-04 12:57:38 [INFO ]  	- 0
2022-10-04 12:57:38 [INFO ]  	- 1
2022-10-04 12:57:38 [INFO ]  	- 2
2022-10-04 12:57:38 [INFO ]  	- 3
2022-10-04 12:57:38 [INFO ]  	- 4
2022-10-04 12:57:38 [INFO ]  	- 5
2022-10-04 12:57:38 [INFO ]  	- 6
2022-10-04 12:57:38 [INFO ]  	- 7
2022-10-04 12:57:38 [INFO ]  	- 8
2022-10-04 12:57:38 [INFO ]  	- 9
2022-10-04 12:57:38 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 12:57:38 [INFO ]  	- !!python/tuple
2022-10-04 12:57:38 [INFO ]  	    - 0.4379104971885681
2022-10-04 12:57:38 [INFO ]  	    - 0.44398033618927
2022-10-04 12:57:38 [INFO ]  	    - 0.4729299545288086
2022-10-04 12:57:38 [INFO ]  	- !!python/tuple
2022-10-04 12:57:38 [INFO ]  	    - 0.19803012907505035
2022-10-04 12:57:38 [INFO ]  	    - 0.2010156363248825
2022-10-04 12:57:38 [INFO ]  	    - 0.19703614711761475
2022-10-04 12:57:38 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 12:57:38 [INFO ]  	decay_epochs: 50
2022-10-04 12:57:38 [INFO ]  	decay_factor: 0.1
2022-10-04 12:57:38 [INFO ]  	device_id: 0
2022-10-04 12:57:38 [INFO ]  	distill_epochs: 1
2022-10-04 12:57:38 [INFO ]  	distill_lr: 0.02
2022-10-04 12:57:38 [INFO ]  	distill_steps: 1
2022-10-04 12:57:38 [INFO ]  	epochs: 200
2022-10-04 12:57:38 [INFO ]  	expand_cls: false
2022-10-04 12:57:38 [INFO ]  	forgetting_dataset: null
2022-10-04 12:57:38 [INFO ]  	init: xavier
2022-10-04 12:57:38 [INFO ]  	init_param: 1.0
2022-10-04 12:57:38 [INFO ]  	input_size: 32
2022-10-04 12:57:38 [INFO ]  	ipc: 50
2022-10-04 12:57:38 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 12:57:38 [INFO ]  	log_interval: 100
2022-10-04 12:57:38 [INFO ]  	log_level: INFO
2022-10-04 12:57:38 [INFO ]  	lr: 0.01
2022-10-04 12:57:38 [INFO ]  	mode: distill_adapt
2022-10-04 12:57:38 [INFO ]  	nc: 3
2022-10-04 12:57:38 [INFO ]  	num_classes: 10
2022-10-04 12:57:38 [INFO ]  	num_workers: 8
2022-10-04 12:57:38 [INFO ]  	phase: train
2022-10-04 12:57:38 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 12:57:38 [INFO ]  	start_time: '2022-10-04 12:57:38'
2022-10-04 12:57:38 [INFO ]  	test_batch_size: 1024
2022-10-04 12:57:38 [INFO ]  	
2022-10-04 12:57:40 [INFO ]  train dataset size:	73257
2022-10-04 12:57:40 [INFO ]  test dataset size: 	26032
2022-10-04 12:57:40 [INFO ]  datasets built!
2022-10-04 12:57:40 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 12:57:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 12:57:42 [INFO ]  
2022-10-04 12:57:42 [INFO ]  Begin of epoch 0 :
2022-10-04 12:57:46 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 12:57:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 12:57:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 12:57:46 [INFO ]  	   step  1 (lr=0.020000)                    7.08%                   8.8265
2022-10-04 12:57:46 [INFO ]  
2022-10-04 12:57:46 [INFO ]  Epoch:    0	Loss: 8.1624	Data Time: 0.39s	Train Time: 0.05s
2022-10-04 12:57:47 [INFO ]  Epoch:    1	Loss: 3.0773	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:57:49 [INFO ]  Epoch:    2	Loss: 2.5034	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:57:51 [INFO ]  Epoch:    3	Loss: 2.3122	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:57:53 [INFO ]  Epoch:    4	Loss: 2.2261	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:57:55 [INFO ]  Epoch:    5	Loss: 2.1594	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 12:57:57 [INFO ]  Epoch:    6	Loss: 2.1566	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:57:59 [INFO ]  Epoch:    7	Loss: 2.1101	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:01 [INFO ]  Epoch:    8	Loss: 2.0827	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:58:02 [INFO ]  Epoch:    9	Loss: 1.9696	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:58:04 [INFO ]  Epoch:   10	Loss: 1.8686	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:06 [INFO ]  Epoch:   11	Loss: 1.6878	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:58:08 [INFO ]  Epoch:   12	Loss: 1.5211	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:58:10 [INFO ]  Epoch:   13	Loss: 1.4118	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:58:12 [INFO ]  Epoch:   14	Loss: 1.2924	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 12:58:14 [INFO ]  Epoch:   15	Loss: 1.2369	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:16 [INFO ]  Epoch:   16	Loss: 1.2031	Data Time: 0.26s	Train Time: 0.00s
2022-10-04 12:58:18 [INFO ]  Epoch:   17	Loss: 1.1582	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:19 [INFO ]  Epoch:   18	Loss: 1.0364	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:58:21 [INFO ]  Epoch:   19	Loss: 1.0878	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:58:23 [INFO ]  Epoch:   20	Loss: 1.1114	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:25 [INFO ]  Epoch:   21	Loss: 1.0400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:58:27 [INFO ]  Epoch:   22	Loss: 1.0565	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:58:28 [INFO ]  Epoch:   23	Loss: 0.9221	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:30 [INFO ]  Epoch:   24	Loss: 0.9605	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:32 [INFO ]  Epoch:   25	Loss: 0.9376	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:34 [INFO ]  Epoch:   26	Loss: 0.9463	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:58:36 [INFO ]  Epoch:   27	Loss: 0.9179	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:58:38 [INFO ]  Epoch:   28	Loss: 0.8105	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:58:40 [INFO ]  Epoch:   29	Loss: 0.8433	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:41 [INFO ]  Epoch:   30	Loss: 0.9432	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 12:58:44 [INFO ]  Epoch:   31	Loss: 0.8093	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:58:45 [INFO ]  Epoch:   32	Loss: 0.6702	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:58:47 [INFO ]  Epoch:   33	Loss: 0.7798	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:49 [INFO ]  Epoch:   34	Loss: 0.8049	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:51 [INFO ]  Epoch:   35	Loss: 0.8630	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:53 [INFO ]  Epoch:   36	Loss: 0.8187	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:58:55 [INFO ]  Epoch:   37	Loss: 0.7267	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:58:57 [INFO ]  Epoch:   38	Loss: 0.6974	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:58:59 [INFO ]  Epoch:   39	Loss: 0.7320	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:59:01 [INFO ]  Epoch:   40	Loss: 0.7053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:02 [INFO ]  Epoch:   41	Loss: 0.8139	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:59:04 [INFO ]  Epoch:   42	Loss: 0.8132	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:06 [INFO ]  Epoch:   43	Loss: 0.7838	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:08 [INFO ]  Epoch:   44	Loss: 0.7566	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:59:10 [INFO ]  Epoch:   45	Loss: 0.7126	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 12:59:12 [INFO ]  Epoch:   46	Loss: 0.7651	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:59:14 [INFO ]  Epoch:   47	Loss: 0.6587	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:59:15 [INFO ]  Epoch:   48	Loss: 0.6391	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:59:17 [INFO ]  Epoch:   49	Loss: 0.7910	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:19 [INFO ]  Epoch:   50	Loss: 0.6372	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:21 [INFO ]  Epoch:   51	Loss: 0.6977	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 12:59:23 [INFO ]  Epoch:   52	Loss: 0.6349	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:25 [INFO ]  Epoch:   53	Loss: 0.6213	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:59:27 [INFO ]  Epoch:   54	Loss: 0.6243	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:59:29 [INFO ]  Epoch:   55	Loss: 0.6093	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:31 [INFO ]  Epoch:   56	Loss: 0.6209	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 12:59:33 [INFO ]  Epoch:   57	Loss: 0.5647	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 12:59:35 [INFO ]  Epoch:   58	Loss: 0.6117	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:59:36 [INFO ]  Epoch:   59	Loss: 0.6354	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 12:59:38 [INFO ]  Epoch:   60	Loss: 0.6797	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 12:59:40 [INFO ]  Epoch:   61	Loss: 0.5647	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:42 [INFO ]  Epoch:   62	Loss: 0.6686	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:44 [INFO ]  Epoch:   63	Loss: 0.5348	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:46 [INFO ]  Epoch:   64	Loss: 0.6467	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:48 [INFO ]  Epoch:   65	Loss: 0.6401	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:50 [INFO ]  Epoch:   66	Loss: 0.6045	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:51 [INFO ]  Epoch:   67	Loss: 0.6858	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 12:59:53 [INFO ]  Epoch:   68	Loss: 0.6389	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:55 [INFO ]  Epoch:   69	Loss: 0.6517	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 12:59:57 [INFO ]  Epoch:   70	Loss: 0.6348	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 12:59:59 [INFO ]  Epoch:   71	Loss: 0.5919	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:01 [INFO ]  Epoch:   72	Loss: 0.7083	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:00:03 [INFO ]  Epoch:   73	Loss: 0.6622	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:00:04 [INFO ]  Epoch:   74	Loss: 0.6370	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:06 [INFO ]  Epoch:   75	Loss: 0.6515	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:00:08 [INFO ]  Epoch:   76	Loss: 0.6100	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:00:10 [INFO ]  Epoch:   77	Loss: 0.6687	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:00:12 [INFO ]  Epoch:   78	Loss: 0.5665	Data Time: 0.28s	Train Time: 0.01s
2022-10-04 13:00:14 [INFO ]  Epoch:   79	Loss: 0.6558	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:16 [INFO ]  Epoch:   80	Loss: 0.5554	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:00:18 [INFO ]  Epoch:   81	Loss: 0.5796	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:00:19 [INFO ]  Epoch:   82	Loss: 0.6019	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:21 [INFO ]  Epoch:   83	Loss: 0.6069	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:23 [INFO ]  Epoch:   84	Loss: 0.6032	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:25 [INFO ]  Epoch:   85	Loss: 0.5612	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:00:27 [INFO ]  Epoch:   86	Loss: 0.5270	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:29 [INFO ]  Epoch:   87	Loss: 0.5381	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:31 [INFO ]  Epoch:   88	Loss: 0.6250	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:00:33 [INFO ]  Epoch:   89	Loss: 0.5809	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:35 [INFO ]  Epoch:   90	Loss: 0.6186	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:00:37 [INFO ]  Epoch:   91	Loss: 0.5624	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:00:39 [INFO ]  Epoch:   92	Loss: 0.5906	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:40 [INFO ]  Epoch:   93	Loss: 0.5648	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:42 [INFO ]  Epoch:   94	Loss: 0.6253	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:44 [INFO ]  Epoch:   95	Loss: 0.5888	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:00:46 [INFO ]  Epoch:   96	Loss: 0.6288	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:00:48 [INFO ]  Epoch:   97	Loss: 0.5930	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:00:50 [INFO ]  Epoch:   98	Loss: 0.6349	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:52 [INFO ]  Epoch:   99	Loss: 0.5912	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:00:53 [INFO ]  Epoch:  100	Loss: 0.5538	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:00:55 [INFO ]  Epoch:  101	Loss: 0.5723	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:00:57 [INFO ]  Epoch:  102	Loss: 0.5588	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:00:59 [INFO ]  Epoch:  103	Loss: 0.5303	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:01:01 [INFO ]  Epoch:  104	Loss: 0.6303	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:03 [INFO ]  Epoch:  105	Loss: 0.6318	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:01:05 [INFO ]  Epoch:  106	Loss: 0.6448	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:01:07 [INFO ]  Epoch:  107	Loss: 0.5769	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:09 [INFO ]  Epoch:  108	Loss: 0.5441	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:01:11 [INFO ]  Epoch:  109	Loss: 0.6374	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:12 [INFO ]  Epoch:  110	Loss: 0.6044	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:01:14 [INFO ]  Epoch:  111	Loss: 0.5851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:01:16 [INFO ]  Epoch:  112	Loss: 0.5781	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:01:18 [INFO ]  Epoch:  113	Loss: 0.5700	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:01:20 [INFO ]  Epoch:  114	Loss: 0.6640	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:22 [INFO ]  Epoch:  115	Loss: 0.6197	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:01:24 [INFO ]  Epoch:  116	Loss: 0.5615	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 13:01:26 [INFO ]  Epoch:  117	Loss: 0.5829	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:27 [INFO ]  Epoch:  118	Loss: 0.5519	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:29 [INFO ]  Epoch:  119	Loss: 0.6283	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:01:31 [INFO ]  Epoch:  120	Loss: 0.6267	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:33 [INFO ]  Epoch:  121	Loss: 0.5431	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:35 [INFO ]  Epoch:  122	Loss: 0.5534	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:01:37 [INFO ]  Epoch:  123	Loss: 0.5441	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:38 [INFO ]  Epoch:  124	Loss: 0.5739	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:40 [INFO ]  Epoch:  125	Loss: 0.5707	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:42 [INFO ]  Epoch:  126	Loss: 0.6292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:01:44 [INFO ]  Epoch:  127	Loss: 0.5977	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:46 [INFO ]  Epoch:  128	Loss: 0.6864	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:48 [INFO ]  Epoch:  129	Loss: 0.6159	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:01:50 [INFO ]  Epoch:  130	Loss: 0.6080	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:01:52 [INFO ]  Epoch:  131	Loss: 0.5671	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:01:53 [INFO ]  Epoch:  132	Loss: 0.6491	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:01:55 [INFO ]  Epoch:  133	Loss: 0.5678	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:01:57 [INFO ]  Epoch:  134	Loss: 0.5983	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:01:59 [INFO ]  Epoch:  135	Loss: 0.5673	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:01 [INFO ]  Epoch:  136	Loss: 0.5650	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:03 [INFO ]  Epoch:  137	Loss: 0.5412	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:05 [INFO ]  Epoch:  138	Loss: 0.5961	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:07 [INFO ]  Epoch:  139	Loss: 0.5315	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:02:09 [INFO ]  Epoch:  140	Loss: 0.5836	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:10 [INFO ]  Epoch:  141	Loss: 0.5980	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:12 [INFO ]  Epoch:  142	Loss: 0.6405	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:02:14 [INFO ]  Epoch:  143	Loss: 0.6936	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:16 [INFO ]  Epoch:  144	Loss: 0.5384	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:18 [INFO ]  Epoch:  145	Loss: 0.5165	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:20 [INFO ]  Epoch:  146	Loss: 0.6016	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:22 [INFO ]  Epoch:  147	Loss: 0.5792	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:24 [INFO ]  Epoch:  148	Loss: 0.6160	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:02:26 [INFO ]  Epoch:  149	Loss: 0.6186	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:02:28 [INFO ]  Epoch:  150	Loss: 0.5851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:29 [INFO ]  Epoch:  151	Loss: 0.5522	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:31 [INFO ]  Epoch:  152	Loss: 0.5895	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:33 [INFO ]  Epoch:  153	Loss: 0.5674	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 13:02:35 [INFO ]  Epoch:  154	Loss: 0.5644	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:37 [INFO ]  Epoch:  155	Loss: 0.6186	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:02:40 [INFO ]  Epoch:  156	Loss: 0.5670	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:02:41 [INFO ]  Epoch:  157	Loss: 0.5319	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:43 [INFO ]  Epoch:  158	Loss: 0.6261	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:02:45 [INFO ]  Epoch:  159	Loss: 0.5287	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:47 [INFO ]  Epoch:  160	Loss: 0.5936	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:49 [INFO ]  Epoch:  161	Loss: 0.5658	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:02:51 [INFO ]  Epoch:  162	Loss: 0.5556	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:02:52 [INFO ]  Epoch:  163	Loss: 0.5997	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:02:54 [INFO ]  Epoch:  164	Loss: 0.5222	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:02:56 [INFO ]  Epoch:  165	Loss: 0.6001	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:02:58 [INFO ]  Epoch:  166	Loss: 0.6645	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:03:00 [INFO ]  Epoch:  167	Loss: 0.5250	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 13:03:02 [INFO ]  Epoch:  168	Loss: 0.5762	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:03:04 [INFO ]  Epoch:  169	Loss: 0.5262	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:03:06 [INFO ]  Epoch:  170	Loss: 0.6399	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:08 [INFO ]  Epoch:  171	Loss: 0.6236	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:03:10 [INFO ]  Epoch:  172	Loss: 0.5671	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:03:12 [INFO ]  Epoch:  173	Loss: 0.5654	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:13 [INFO ]  Epoch:  174	Loss: 0.6408	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:03:15 [INFO ]  Epoch:  175	Loss: 0.6010	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:17 [INFO ]  Epoch:  176	Loss: 0.5731	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:19 [INFO ]  Epoch:  177	Loss: 0.5973	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 13:03:21 [INFO ]  Epoch:  178	Loss: 0.6405	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:03:23 [INFO ]  Epoch:  179	Loss: 0.5886	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:03:24 [INFO ]  Epoch:  180	Loss: 0.6044	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:03:26 [INFO ]  Epoch:  181	Loss: 0.6577	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:03:28 [INFO ]  Epoch:  182	Loss: 0.5914	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:03:30 [INFO ]  Epoch:  183	Loss: 0.5647	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:32 [INFO ]  Epoch:  184	Loss: 0.4960	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:34 [INFO ]  Epoch:  185	Loss: 0.5872	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:03:36 [INFO ]  Epoch:  186	Loss: 0.6335	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:03:38 [INFO ]  Epoch:  187	Loss: 0.6622	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:03:39 [INFO ]  Epoch:  188	Loss: 0.6065	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:41 [INFO ]  Epoch:  189	Loss: 0.5854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:03:43 [INFO ]  Epoch:  190	Loss: 0.5701	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:03:45 [INFO ]  Epoch:  191	Loss: 0.6263	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:03:47 [INFO ]  Epoch:  192	Loss: 0.6526	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:03:49 [INFO ]  Epoch:  193	Loss: 0.6225	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:51 [INFO ]  Epoch:  194	Loss: 0.5824	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:03:53 [INFO ]  Epoch:  195	Loss: 0.5544	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:03:54 [INFO ]  Epoch:  196	Loss: 0.6291	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:03:56 [INFO ]  Epoch:  197	Loss: 0.5518	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:03:58 [INFO ]  Epoch:  198	Loss: 0.6395	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:04:00 [INFO ]  Epoch:  199	Loss: 0.6456	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:04:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 13:04:02 [INFO ]  
2022-10-04 13:04:02 [INFO ]  Final evaluation for SVHN :
2022-10-04 13:04:05 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:04:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:04:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:04:05 [INFO ]  	   step  1 (lr=0.441353)                   82.14%                   0.6676
2022-10-04 13:04:05 [INFO ]  
2022-10-04 13:04:05 [INFO ]  
2022-10-04 13:04:05 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 13:04:08 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:04:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:04:08 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 13:04:08 [INFO ]  	   step  1 (lr=0.441353)                   13.85%                   5.8761
2022-10-04 13:04:08 [INFO ]  
2022-10-04 13:04:08 [INFO ]  CPU Time: 3.51 minutes
2022-10-04 13:15:57 [INFO ]  ======================================== 2022-10-04 13:15:57 ========================================
2022-10-04 13:15:57 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 13:15:57 [INFO ]  Options: 
2022-10-04 13:15:57 [INFO ]  	base_dir: null
2022-10-04 13:15:57 [INFO ]  	batch_size: 1024
2022-10-04 13:15:57 [INFO ]  	checkpoint_interval: 300
2022-10-04 13:15:57 [INFO ]  	dataset: SVHN
2022-10-04 13:15:57 [INFO ]  	dataset_labels:
2022-10-04 13:15:57 [INFO ]  	- 0
2022-10-04 13:15:57 [INFO ]  	- 1
2022-10-04 13:15:57 [INFO ]  	- 2
2022-10-04 13:15:57 [INFO ]  	- 3
2022-10-04 13:15:57 [INFO ]  	- 4
2022-10-04 13:15:57 [INFO ]  	- 5
2022-10-04 13:15:57 [INFO ]  	- 6
2022-10-04 13:15:57 [INFO ]  	- 7
2022-10-04 13:15:57 [INFO ]  	- 8
2022-10-04 13:15:57 [INFO ]  	- 9
2022-10-04 13:15:57 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 13:15:57 [INFO ]  	- !!python/tuple
2022-10-04 13:15:57 [INFO ]  	    - 0.4379104971885681
2022-10-04 13:15:57 [INFO ]  	    - 0.44398033618927
2022-10-04 13:15:57 [INFO ]  	    - 0.4729299545288086
2022-10-04 13:15:57 [INFO ]  	- !!python/tuple
2022-10-04 13:15:57 [INFO ]  	    - 0.19803012907505035
2022-10-04 13:15:57 [INFO ]  	    - 0.2010156363248825
2022-10-04 13:15:57 [INFO ]  	    - 0.19703614711761475
2022-10-04 13:15:57 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 13:15:57 [INFO ]  	decay_epochs: 50
2022-10-04 13:15:57 [INFO ]  	decay_factor: 0.1
2022-10-04 13:15:57 [INFO ]  	device_id: 0
2022-10-04 13:15:57 [INFO ]  	distill_epochs: 1
2022-10-04 13:15:57 [INFO ]  	distill_lr: 0.02
2022-10-04 13:15:57 [INFO ]  	distill_steps: 1
2022-10-04 13:15:57 [INFO ]  	epochs: 200
2022-10-04 13:15:57 [INFO ]  	expand_cls: false
2022-10-04 13:15:57 [INFO ]  	forgetting_dataset: null
2022-10-04 13:15:57 [INFO ]  	init: xavier
2022-10-04 13:15:57 [INFO ]  	init_param: 1.0
2022-10-04 13:15:57 [INFO ]  	input_size: 32
2022-10-04 13:15:57 [INFO ]  	ipc: 75
2022-10-04 13:15:57 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 13:15:57 [INFO ]  	log_interval: 100
2022-10-04 13:15:57 [INFO ]  	log_level: INFO
2022-10-04 13:15:57 [INFO ]  	lr: 0.01
2022-10-04 13:15:57 [INFO ]  	mode: distill_adapt
2022-10-04 13:15:57 [INFO ]  	nc: 3
2022-10-04 13:15:57 [INFO ]  	num_classes: 10
2022-10-04 13:15:57 [INFO ]  	num_workers: 8
2022-10-04 13:15:57 [INFO ]  	phase: train
2022-10-04 13:15:57 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 13:15:57 [INFO ]  	start_time: '2022-10-04 13:15:57'
2022-10-04 13:15:57 [INFO ]  	test_batch_size: 1024
2022-10-04 13:15:57 [INFO ]  	
2022-10-04 13:15:59 [INFO ]  train dataset size:	73257
2022-10-04 13:15:59 [INFO ]  test dataset size: 	26032
2022-10-04 13:15:59 [INFO ]  datasets built!
2022-10-04 13:15:59 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 13:16:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 13:16:01 [INFO ]  
2022-10-04 13:16:01 [INFO ]  Begin of epoch 0 :
2022-10-04 13:16:04 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:16:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:16:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:16:04 [INFO ]  	   step  1 (lr=0.020000)                    7.06%                   8.8397
2022-10-04 13:16:04 [INFO ]  
2022-10-04 13:16:04 [INFO ]  Epoch:    0	Loss: 8.5298	Data Time: 0.39s	Train Time: 0.06s
2022-10-04 13:16:06 [INFO ]  Epoch:    1	Loss: 3.0512	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:16:08 [INFO ]  Epoch:    2	Loss: 2.5202	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:16:09 [INFO ]  Epoch:    3	Loss: 2.2790	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:11 [INFO ]  Epoch:    4	Loss: 2.2165	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:13 [INFO ]  Epoch:    5	Loss: 2.1688	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:16:15 [INFO ]  Epoch:    6	Loss: 2.1574	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:16:16 [INFO ]  Epoch:    7	Loss: 2.0931	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:18 [INFO ]  Epoch:    8	Loss: 2.0574	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:16:20 [INFO ]  Epoch:    9	Loss: 1.9963	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:16:22 [INFO ]  Epoch:   10	Loss: 1.8705	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:16:24 [INFO ]  Epoch:   11	Loss: 1.7096	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:16:26 [INFO ]  Epoch:   12	Loss: 1.5701	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:27 [INFO ]  Epoch:   13	Loss: 1.4546	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:16:29 [INFO ]  Epoch:   14	Loss: 1.3962	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:16:31 [INFO ]  Epoch:   15	Loss: 1.1903	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:33 [INFO ]  Epoch:   16	Loss: 1.2039	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:16:35 [INFO ]  Epoch:   17	Loss: 1.1551	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:16:37 [INFO ]  Epoch:   18	Loss: 1.1015	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:16:39 [INFO ]  Epoch:   19	Loss: 0.9796	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:16:41 [INFO ]  Epoch:   20	Loss: 0.9732	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:16:43 [INFO ]  Epoch:   21	Loss: 0.9473	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:16:44 [INFO ]  Epoch:   22	Loss: 0.8819	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:46 [INFO ]  Epoch:   23	Loss: 0.9729	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:48 [INFO ]  Epoch:   24	Loss: 1.0085	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:50 [INFO ]  Epoch:   25	Loss: 0.8490	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:52 [INFO ]  Epoch:   26	Loss: 0.8919	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:16:53 [INFO ]  Epoch:   27	Loss: 0.8659	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:55 [INFO ]  Epoch:   28	Loss: 0.9134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:16:57 [INFO ]  Epoch:   29	Loss: 0.8071	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:16:59 [INFO ]  Epoch:   30	Loss: 0.7471	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:17:01 [INFO ]  Epoch:   31	Loss: 0.8558	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:02 [INFO ]  Epoch:   32	Loss: 0.7376	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:04 [INFO ]  Epoch:   33	Loss: 0.7324	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:17:06 [INFO ]  Epoch:   34	Loss: 0.7422	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:08 [INFO ]  Epoch:   35	Loss: 0.7586	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:10 [INFO ]  Epoch:   36	Loss: 0.7125	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:17:12 [INFO ]  Epoch:   37	Loss: 0.8197	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:14 [INFO ]  Epoch:   38	Loss: 0.9277	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:17:15 [INFO ]  Epoch:   39	Loss: 0.8757	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:17 [INFO ]  Epoch:   40	Loss: 0.6813	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:17:19 [INFO ]  Epoch:   41	Loss: 0.7610	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:17:21 [INFO ]  Epoch:   42	Loss: 0.7075	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:23 [INFO ]  Epoch:   43	Loss: 0.8388	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:17:25 [INFO ]  Epoch:   44	Loss: 0.7019	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:17:26 [INFO ]  Epoch:   45	Loss: 0.7015	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:17:28 [INFO ]  Epoch:   46	Loss: 0.7510	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:17:30 [INFO ]  Epoch:   47	Loss: 0.7135	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:32 [INFO ]  Epoch:   48	Loss: 0.6877	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:17:34 [INFO ]  Epoch:   49	Loss: 0.8183	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:36 [INFO ]  Epoch:   50	Loss: 0.6047	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:17:37 [INFO ]  Epoch:   51	Loss: 0.7042	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:39 [INFO ]  Epoch:   52	Loss: 0.6863	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:17:41 [INFO ]  Epoch:   53	Loss: 0.7040	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:17:43 [INFO ]  Epoch:   54	Loss: 0.6220	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:17:45 [INFO ]  Epoch:   55	Loss: 0.5888	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:17:47 [INFO ]  Epoch:   56	Loss: 0.6282	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:17:49 [INFO ]  Epoch:   57	Loss: 0.6452	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:51 [INFO ]  Epoch:   58	Loss: 0.6674	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:17:52 [INFO ]  Epoch:   59	Loss: 0.5618	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:17:54 [INFO ]  Epoch:   60	Loss: 0.5837	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:17:56 [INFO ]  Epoch:   61	Loss: 0.6348	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:17:58 [INFO ]  Epoch:   62	Loss: 0.5879	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:18:00 [INFO ]  Epoch:   63	Loss: 0.6293	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:02 [INFO ]  Epoch:   64	Loss: 0.6422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:18:04 [INFO ]  Epoch:   65	Loss: 0.5491	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:18:06 [INFO ]  Epoch:   66	Loss: 0.6368	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:18:07 [INFO ]  Epoch:   67	Loss: 0.6488	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:18:09 [INFO ]  Epoch:   68	Loss: 0.6098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:11 [INFO ]  Epoch:   69	Loss: 0.6142	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:18:13 [INFO ]  Epoch:   70	Loss: 0.5963	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:18:15 [INFO ]  Epoch:   71	Loss: 0.5534	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:17 [INFO ]  Epoch:   72	Loss: 0.5808	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:18 [INFO ]  Epoch:   73	Loss: 0.6357	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:18:20 [INFO ]  Epoch:   74	Loss: 0.5962	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:22 [INFO ]  Epoch:   75	Loss: 0.5632	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:18:24 [INFO ]  Epoch:   76	Loss: 0.5987	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:18:26 [INFO ]  Epoch:   77	Loss: 0.6580	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:28 [INFO ]  Epoch:   78	Loss: 0.5980	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:30 [INFO ]  Epoch:   79	Loss: 0.5176	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:18:31 [INFO ]  Epoch:   80	Loss: 0.5745	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:33 [INFO ]  Epoch:   81	Loss: 0.6170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:35 [INFO ]  Epoch:   82	Loss: 0.6234	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:37 [INFO ]  Epoch:   83	Loss: 0.6708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:39 [INFO ]  Epoch:   84	Loss: 0.5960	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:18:41 [INFO ]  Epoch:   85	Loss: 0.6837	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:18:43 [INFO ]  Epoch:   86	Loss: 0.6083	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:45 [INFO ]  Epoch:   87	Loss: 0.6227	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:18:46 [INFO ]  Epoch:   88	Loss: 0.5387	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:48 [INFO ]  Epoch:   89	Loss: 0.5622	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:18:50 [INFO ]  Epoch:   90	Loss: 0.5629	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:52 [INFO ]  Epoch:   91	Loss: 0.6421	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:54 [INFO ]  Epoch:   92	Loss: 0.5940	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:18:55 [INFO ]  Epoch:   93	Loss: 0.5466	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:18:57 [INFO ]  Epoch:   94	Loss: 0.5974	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:18:59 [INFO ]  Epoch:   95	Loss: 0.5707	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:01 [INFO ]  Epoch:   96	Loss: 0.6221	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:03 [INFO ]  Epoch:   97	Loss: 0.5608	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:05 [INFO ]  Epoch:   98	Loss: 0.6735	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:06 [INFO ]  Epoch:   99	Loss: 0.6023	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:19:08 [INFO ]  Epoch:  100	Loss: 0.5680	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:10 [INFO ]  Epoch:  101	Loss: 0.5983	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:19:12 [INFO ]  Epoch:  102	Loss: 0.6047	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:19:14 [INFO ]  Epoch:  103	Loss: 0.5500	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:19:16 [INFO ]  Epoch:  104	Loss: 0.6217	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:17 [INFO ]  Epoch:  105	Loss: 0.6050	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:19 [INFO ]  Epoch:  106	Loss: 0.5774	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:21 [INFO ]  Epoch:  107	Loss: 0.6077	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:23 [INFO ]  Epoch:  108	Loss: 0.6194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:25 [INFO ]  Epoch:  109	Loss: 0.6539	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:26 [INFO ]  Epoch:  110	Loss: 0.4807	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:19:28 [INFO ]  Epoch:  111	Loss: 0.5427	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:30 [INFO ]  Epoch:  112	Loss: 0.5778	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:32 [INFO ]  Epoch:  113	Loss: 0.6161	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:19:34 [INFO ]  Epoch:  114	Loss: 0.6099	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:35 [INFO ]  Epoch:  115	Loss: 0.5698	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:37 [INFO ]  Epoch:  116	Loss: 0.5759	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:19:39 [INFO ]  Epoch:  117	Loss: 0.6300	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:41 [INFO ]  Epoch:  118	Loss: 0.5783	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:43 [INFO ]  Epoch:  119	Loss: 0.5494	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:45 [INFO ]  Epoch:  120	Loss: 0.5714	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:47 [INFO ]  Epoch:  121	Loss: 0.5426	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:19:49 [INFO ]  Epoch:  122	Loss: 0.6003	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:19:50 [INFO ]  Epoch:  123	Loss: 0.5443	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:52 [INFO ]  Epoch:  124	Loss: 0.5654	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:19:54 [INFO ]  Epoch:  125	Loss: 0.6018	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:19:56 [INFO ]  Epoch:  126	Loss: 0.6114	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:19:58 [INFO ]  Epoch:  127	Loss: 0.5833	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:00 [INFO ]  Epoch:  128	Loss: 0.5839	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:02 [INFO ]  Epoch:  129	Loss: 0.5395	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:03 [INFO ]  Epoch:  130	Loss: 0.6955	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:05 [INFO ]  Epoch:  131	Loss: 0.5884	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:07 [INFO ]  Epoch:  132	Loss: 0.5860	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:20:09 [INFO ]  Epoch:  133	Loss: 0.5875	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:11 [INFO ]  Epoch:  134	Loss: 0.5265	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:13 [INFO ]  Epoch:  135	Loss: 0.6091	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:20:15 [INFO ]  Epoch:  136	Loss: 0.6090	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 13:20:17 [INFO ]  Epoch:  137	Loss: 0.6041	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:18 [INFO ]  Epoch:  138	Loss: 0.5702	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:20:20 [INFO ]  Epoch:  139	Loss: 0.5555	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:20:22 [INFO ]  Epoch:  140	Loss: 0.5115	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:20:24 [INFO ]  Epoch:  141	Loss: 0.5609	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:20:25 [INFO ]  Epoch:  142	Loss: 0.5815	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:27 [INFO ]  Epoch:  143	Loss: 0.6463	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:20:29 [INFO ]  Epoch:  144	Loss: 0.6168	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:31 [INFO ]  Epoch:  145	Loss: 0.5806	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:20:33 [INFO ]  Epoch:  146	Loss: 0.5632	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:35 [INFO ]  Epoch:  147	Loss: 0.5996	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:20:36 [INFO ]  Epoch:  148	Loss: 0.6119	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:38 [INFO ]  Epoch:  149	Loss: 0.6184	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:20:40 [INFO ]  Epoch:  150	Loss: 0.5860	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:42 [INFO ]  Epoch:  151	Loss: 0.5458	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:20:44 [INFO ]  Epoch:  152	Loss: 0.5062	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:45 [INFO ]  Epoch:  153	Loss: 0.6164	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:47 [INFO ]  Epoch:  154	Loss: 0.5295	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:49 [INFO ]  Epoch:  155	Loss: 0.6027	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:20:51 [INFO ]  Epoch:  156	Loss: 0.5666	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:20:53 [INFO ]  Epoch:  157	Loss: 0.5942	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:20:55 [INFO ]  Epoch:  158	Loss: 0.5669	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:20:57 [INFO ]  Epoch:  159	Loss: 0.6229	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:20:59 [INFO ]  Epoch:  160	Loss: 0.5442	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:21:00 [INFO ]  Epoch:  161	Loss: 0.5835	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:02 [INFO ]  Epoch:  162	Loss: 0.5939	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:04 [INFO ]  Epoch:  163	Loss: 0.6010	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:21:06 [INFO ]  Epoch:  164	Loss: 0.5635	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:08 [INFO ]  Epoch:  165	Loss: 0.6302	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:21:10 [INFO ]  Epoch:  166	Loss: 0.5295	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:11 [INFO ]  Epoch:  167	Loss: 0.6206	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:13 [INFO ]  Epoch:  168	Loss: 0.5854	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:15 [INFO ]  Epoch:  169	Loss: 0.6051	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:21:17 [INFO ]  Epoch:  170	Loss: 0.6519	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:19 [INFO ]  Epoch:  171	Loss: 0.5813	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:21 [INFO ]  Epoch:  172	Loss: 0.5599	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:22 [INFO ]  Epoch:  173	Loss: 0.5596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:24 [INFO ]  Epoch:  174	Loss: 0.5452	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:26 [INFO ]  Epoch:  175	Loss: 0.5422	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:21:28 [INFO ]  Epoch:  176	Loss: 0.5810	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:30 [INFO ]  Epoch:  177	Loss: 0.5700	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:32 [INFO ]  Epoch:  178	Loss: 0.5592	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:21:34 [INFO ]  Epoch:  179	Loss: 0.6127	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:21:36 [INFO ]  Epoch:  180	Loss: 0.6350	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:38 [INFO ]  Epoch:  181	Loss: 0.6109	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:21:40 [INFO ]  Epoch:  182	Loss: 0.6224	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:41 [INFO ]  Epoch:  183	Loss: 0.5903	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:21:43 [INFO ]  Epoch:  184	Loss: 0.6009	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:45 [INFO ]  Epoch:  185	Loss: 0.5404	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:21:47 [INFO ]  Epoch:  186	Loss: 0.6243	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:21:49 [INFO ]  Epoch:  187	Loss: 0.6045	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:21:51 [INFO ]  Epoch:  188	Loss: 0.6276	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:21:53 [INFO ]  Epoch:  189	Loss: 0.5800	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:21:55 [INFO ]  Epoch:  190	Loss: 0.5041	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:21:56 [INFO ]  Epoch:  191	Loss: 0.6243	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:21:58 [INFO ]  Epoch:  192	Loss: 0.5926	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:22:00 [INFO ]  Epoch:  193	Loss: 0.5633	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:22:02 [INFO ]  Epoch:  194	Loss: 0.5549	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:22:04 [INFO ]  Epoch:  195	Loss: 0.4929	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:22:06 [INFO ]  Epoch:  196	Loss: 0.5422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:22:08 [INFO ]  Epoch:  197	Loss: 0.4970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:22:10 [INFO ]  Epoch:  198	Loss: 0.5837	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:22:12 [INFO ]  Epoch:  199	Loss: 0.5171	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:22:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 13:22:13 [INFO ]  
2022-10-04 13:22:13 [INFO ]  Final evaluation for SVHN :
2022-10-04 13:22:17 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:22:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:22:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:22:17 [INFO ]  	   step  1 (lr=0.449818)                   82.34%                   0.6557
2022-10-04 13:22:17 [INFO ]  
2022-10-04 13:22:17 [INFO ]  
2022-10-04 13:22:17 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 13:22:20 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:22:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:22:20 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 13:22:20 [INFO ]  	   step  1 (lr=0.449818)                   15.30%                   5.6991
2022-10-04 13:22:20 [INFO ]  
2022-10-04 13:22:20 [INFO ]  CPU Time: 3.53 minutes
2022-10-04 13:24:46 [INFO ]  ======================================== 2022-10-04 13:24:46 ========================================
2022-10-04 13:24:46 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 13:24:46 [INFO ]  Options: 
2022-10-04 13:24:46 [INFO ]  	base_dir: null
2022-10-04 13:24:46 [INFO ]  	batch_size: 1024
2022-10-04 13:24:46 [INFO ]  	checkpoint_interval: 300
2022-10-04 13:24:46 [INFO ]  	dataset: SVHN
2022-10-04 13:24:46 [INFO ]  	dataset_labels:
2022-10-04 13:24:46 [INFO ]  	- 0
2022-10-04 13:24:46 [INFO ]  	- 1
2022-10-04 13:24:46 [INFO ]  	- 2
2022-10-04 13:24:46 [INFO ]  	- 3
2022-10-04 13:24:46 [INFO ]  	- 4
2022-10-04 13:24:46 [INFO ]  	- 5
2022-10-04 13:24:46 [INFO ]  	- 6
2022-10-04 13:24:46 [INFO ]  	- 7
2022-10-04 13:24:46 [INFO ]  	- 8
2022-10-04 13:24:46 [INFO ]  	- 9
2022-10-04 13:24:46 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 13:24:46 [INFO ]  	- !!python/tuple
2022-10-04 13:24:46 [INFO ]  	    - 0.4379104971885681
2022-10-04 13:24:46 [INFO ]  	    - 0.44398033618927
2022-10-04 13:24:46 [INFO ]  	    - 0.4729299545288086
2022-10-04 13:24:46 [INFO ]  	- !!python/tuple
2022-10-04 13:24:46 [INFO ]  	    - 0.19803012907505035
2022-10-04 13:24:46 [INFO ]  	    - 0.2010156363248825
2022-10-04 13:24:46 [INFO ]  	    - 0.19703614711761475
2022-10-04 13:24:46 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 13:24:46 [INFO ]  	decay_epochs: 50
2022-10-04 13:24:46 [INFO ]  	decay_factor: 0.1
2022-10-04 13:24:46 [INFO ]  	device_id: 0
2022-10-04 13:24:46 [INFO ]  	distill_epochs: 1
2022-10-04 13:24:46 [INFO ]  	distill_lr: 0.02
2022-10-04 13:24:46 [INFO ]  	distill_steps: 1
2022-10-04 13:24:46 [INFO ]  	epochs: 200
2022-10-04 13:24:46 [INFO ]  	expand_cls: false
2022-10-04 13:24:46 [INFO ]  	forgetting_dataset: null
2022-10-04 13:24:46 [INFO ]  	init: xavier
2022-10-04 13:24:46 [INFO ]  	init_param: 1.0
2022-10-04 13:24:46 [INFO ]  	input_size: 32
2022-10-04 13:24:46 [INFO ]  	ipc: 75
2022-10-04 13:24:46 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 13:24:46 [INFO ]  	log_interval: 100
2022-10-04 13:24:46 [INFO ]  	log_level: INFO
2022-10-04 13:24:46 [INFO ]  	lr: 0.01
2022-10-04 13:24:46 [INFO ]  	mode: distill_adapt
2022-10-04 13:24:46 [INFO ]  	nc: 3
2022-10-04 13:24:46 [INFO ]  	num_classes: 10
2022-10-04 13:24:46 [INFO ]  	num_workers: 8
2022-10-04 13:24:46 [INFO ]  	phase: train
2022-10-04 13:24:46 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 13:24:46 [INFO ]  	start_time: '2022-10-04 13:24:46'
2022-10-04 13:24:46 [INFO ]  	test_batch_size: 1024
2022-10-04 13:24:46 [INFO ]  	
2022-10-04 13:24:48 [INFO ]  train dataset size:	73257
2022-10-04 13:24:48 [INFO ]  test dataset size: 	26032
2022-10-04 13:24:48 [INFO ]  datasets built!
2022-10-04 13:24:48 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 13:24:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 13:24:50 [INFO ]  
2022-10-04 13:24:50 [INFO ]  Begin of epoch 0 :
2022-10-04 13:24:53 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:24:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:24:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:24:53 [INFO ]  	   step  1 (lr=0.020000)                    7.10%                   8.9923
2022-10-04 13:24:53 [INFO ]  
2022-10-04 13:24:53 [INFO ]  Epoch:    0	Loss: 8.0084	Data Time: 0.39s	Train Time: 0.07s
2022-10-04 13:24:55 [INFO ]  Epoch:    1	Loss: 3.0305	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:24:57 [INFO ]  Epoch:    2	Loss: 2.5554	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:24:58 [INFO ]  Epoch:    3	Loss: 2.2703	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:00 [INFO ]  Epoch:    4	Loss: 2.2081	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:02 [INFO ]  Epoch:    5	Loss: 2.1669	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:25:04 [INFO ]  Epoch:    6	Loss: 2.1598	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:25:06 [INFO ]  Epoch:    7	Loss: 2.0964	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:25:07 [INFO ]  Epoch:    8	Loss: 2.0199	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:25:09 [INFO ]  Epoch:    9	Loss: 1.9561	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:11 [INFO ]  Epoch:   10	Loss: 1.8514	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:25:13 [INFO ]  Epoch:   11	Loss: 1.6831	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:15 [INFO ]  Epoch:   12	Loss: 1.5577	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:25:17 [INFO ]  Epoch:   13	Loss: 1.4142	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:25:18 [INFO ]  Epoch:   14	Loss: 1.3692	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:25:20 [INFO ]  Epoch:   15	Loss: 1.1846	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:22 [INFO ]  Epoch:   16	Loss: 1.1393	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:24 [INFO ]  Epoch:   17	Loss: 1.0999	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:25:26 [INFO ]  Epoch:   18	Loss: 1.0912	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:28 [INFO ]  Epoch:   19	Loss: 1.2383	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:29 [INFO ]  Epoch:   20	Loss: 1.0378	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:31 [INFO ]  Epoch:   21	Loss: 1.0848	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:33 [INFO ]  Epoch:   22	Loss: 0.9403	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:25:35 [INFO ]  Epoch:   23	Loss: 1.0641	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:25:37 [INFO ]  Epoch:   24	Loss: 0.8885	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:38 [INFO ]  Epoch:   25	Loss: 0.8887	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:40 [INFO ]  Epoch:   26	Loss: 0.8232	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:42 [INFO ]  Epoch:   27	Loss: 0.8484	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:25:44 [INFO ]  Epoch:   28	Loss: 0.7718	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:45 [INFO ]  Epoch:   29	Loss: 1.1450	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:25:47 [INFO ]  Epoch:   30	Loss: 0.8284	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:25:49 [INFO ]  Epoch:   31	Loss: 0.6932	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:51 [INFO ]  Epoch:   32	Loss: 0.7983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:25:53 [INFO ]  Epoch:   33	Loss: 0.7880	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:25:55 [INFO ]  Epoch:   34	Loss: 0.7757	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:25:57 [INFO ]  Epoch:   35	Loss: 0.7238	Data Time: 0.23s	Train Time: 0.00s
2022-10-04 13:25:59 [INFO ]  Epoch:   36	Loss: 0.7552	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:26:01 [INFO ]  Epoch:   37	Loss: 0.7759	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:26:03 [INFO ]  Epoch:   38	Loss: 0.6669	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:26:05 [INFO ]  Epoch:   39	Loss: 0.7208	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:06 [INFO ]  Epoch:   40	Loss: 0.7420	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:26:08 [INFO ]  Epoch:   41	Loss: 0.8828	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:26:10 [INFO ]  Epoch:   42	Loss: 0.7497	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:26:12 [INFO ]  Epoch:   43	Loss: 0.8238	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:14 [INFO ]  Epoch:   44	Loss: 0.6130	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:15 [INFO ]  Epoch:   45	Loss: 0.6413	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:26:17 [INFO ]  Epoch:   46	Loss: 0.7323	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:26:19 [INFO ]  Epoch:   47	Loss: 0.7679	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:26:21 [INFO ]  Epoch:   48	Loss: 0.7069	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:23 [INFO ]  Epoch:   49	Loss: 0.6587	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:26:25 [INFO ]  Epoch:   50	Loss: 0.5763	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:26:27 [INFO ]  Epoch:   51	Loss: 0.6387	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:26:29 [INFO ]  Epoch:   52	Loss: 0.6696	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:26:31 [INFO ]  Epoch:   53	Loss: 0.6160	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:26:33 [INFO ]  Epoch:   54	Loss: 0.6280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:34 [INFO ]  Epoch:   55	Loss: 0.6249	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:36 [INFO ]  Epoch:   56	Loss: 0.6452	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:38 [INFO ]  Epoch:   57	Loss: 0.6059	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:26:40 [INFO ]  Epoch:   58	Loss: 0.6191	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:26:42 [INFO ]  Epoch:   59	Loss: 0.6106	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:26:43 [INFO ]  Epoch:   60	Loss: 0.6704	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:26:45 [INFO ]  Epoch:   61	Loss: 0.5754	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:26:47 [INFO ]  Epoch:   62	Loss: 0.6336	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:26:49 [INFO ]  Epoch:   63	Loss: 0.6471	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:51 [INFO ]  Epoch:   64	Loss: 0.5802	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:26:53 [INFO ]  Epoch:   65	Loss: 0.6772	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:26:55 [INFO ]  Epoch:   66	Loss: 0.5924	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:26:57 [INFO ]  Epoch:   67	Loss: 0.6503	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:26:58 [INFO ]  Epoch:   68	Loss: 0.5994	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:00 [INFO ]  Epoch:   69	Loss: 0.6288	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:27:03 [INFO ]  Epoch:   70	Loss: 0.6255	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:27:04 [INFO ]  Epoch:   71	Loss: 0.5333	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:27:06 [INFO ]  Epoch:   72	Loss: 0.5267	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:27:08 [INFO ]  Epoch:   73	Loss: 0.5468	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:27:10 [INFO ]  Epoch:   74	Loss: 0.6121	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:12 [INFO ]  Epoch:   75	Loss: 0.5917	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:14 [INFO ]  Epoch:   76	Loss: 0.6407	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:27:16 [INFO ]  Epoch:   77	Loss: 0.5227	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:17 [INFO ]  Epoch:   78	Loss: 0.5627	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:27:19 [INFO ]  Epoch:   79	Loss: 0.6060	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:27:21 [INFO ]  Epoch:   80	Loss: 0.6406	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:23 [INFO ]  Epoch:   81	Loss: 0.6279	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:27:25 [INFO ]  Epoch:   82	Loss: 0.5657	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:27 [INFO ]  Epoch:   83	Loss: 0.6512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:29 [INFO ]  Epoch:   84	Loss: 0.5688	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:27:31 [INFO ]  Epoch:   85	Loss: 0.6346	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:27:32 [INFO ]  Epoch:   86	Loss: 0.5772	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:27:34 [INFO ]  Epoch:   87	Loss: 0.5850	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:27:36 [INFO ]  Epoch:   88	Loss: 0.6057	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:27:38 [INFO ]  Epoch:   89	Loss: 0.5927	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:40 [INFO ]  Epoch:   90	Loss: 0.6596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:42 [INFO ]  Epoch:   91	Loss: 0.5190	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:27:44 [INFO ]  Epoch:   92	Loss: 0.5680	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:27:46 [INFO ]  Epoch:   93	Loss: 0.5933	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:27:48 [INFO ]  Epoch:   94	Loss: 0.5536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:49 [INFO ]  Epoch:   95	Loss: 0.5927	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:27:51 [INFO ]  Epoch:   96	Loss: 0.6145	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:27:53 [INFO ]  Epoch:   97	Loss: 0.5952	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:27:55 [INFO ]  Epoch:   98	Loss: 0.5402	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:27:57 [INFO ]  Epoch:   99	Loss: 0.5386	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:27:59 [INFO ]  Epoch:  100	Loss: 0.5522	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:28:00 [INFO ]  Epoch:  101	Loss: 0.6631	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:28:02 [INFO ]  Epoch:  102	Loss: 0.5437	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:28:04 [INFO ]  Epoch:  103	Loss: 0.6079	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:28:06 [INFO ]  Epoch:  104	Loss: 0.6262	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:28:08 [INFO ]  Epoch:  105	Loss: 0.5971	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:10 [INFO ]  Epoch:  106	Loss: 0.5865	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:12 [INFO ]  Epoch:  107	Loss: 0.5589	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:13 [INFO ]  Epoch:  108	Loss: 0.5259	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:28:15 [INFO ]  Epoch:  109	Loss: 0.5768	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:28:17 [INFO ]  Epoch:  110	Loss: 0.6135	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:28:19 [INFO ]  Epoch:  111	Loss: 0.5971	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:28:21 [INFO ]  Epoch:  112	Loss: 0.5366	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:28:23 [INFO ]  Epoch:  113	Loss: 0.6187	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:24 [INFO ]  Epoch:  114	Loss: 0.4711	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:26 [INFO ]  Epoch:  115	Loss: 0.5817	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:28 [INFO ]  Epoch:  116	Loss: 0.5515	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:30 [INFO ]  Epoch:  117	Loss: 0.5370	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:28:32 [INFO ]  Epoch:  118	Loss: 0.5368	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:33 [INFO ]  Epoch:  119	Loss: 0.5798	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:35 [INFO ]  Epoch:  120	Loss: 0.5978	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:37 [INFO ]  Epoch:  121	Loss: 0.6208	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:28:39 [INFO ]  Epoch:  122	Loss: 0.5925	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:41 [INFO ]  Epoch:  123	Loss: 0.5542	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:28:43 [INFO ]  Epoch:  124	Loss: 0.5147	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:45 [INFO ]  Epoch:  125	Loss: 0.5453	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:46 [INFO ]  Epoch:  126	Loss: 0.6351	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:48 [INFO ]  Epoch:  127	Loss: 0.6310	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:50 [INFO ]  Epoch:  128	Loss: 0.5840	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:28:52 [INFO ]  Epoch:  129	Loss: 0.5574	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:54 [INFO ]  Epoch:  130	Loss: 0.5451	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:28:55 [INFO ]  Epoch:  131	Loss: 0.5545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:28:57 [INFO ]  Epoch:  132	Loss: 0.6643	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:28:59 [INFO ]  Epoch:  133	Loss: 0.5571	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:29:01 [INFO ]  Epoch:  134	Loss: 0.5642	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:29:03 [INFO ]  Epoch:  135	Loss: 0.5218	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:05 [INFO ]  Epoch:  136	Loss: 0.5909	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:29:06 [INFO ]  Epoch:  137	Loss: 0.5687	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:29:08 [INFO ]  Epoch:  138	Loss: 0.5252	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:29:10 [INFO ]  Epoch:  139	Loss: 0.5766	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:12 [INFO ]  Epoch:  140	Loss: 0.6493	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:29:14 [INFO ]  Epoch:  141	Loss: 0.6042	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:29:16 [INFO ]  Epoch:  142	Loss: 0.5302	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:29:18 [INFO ]  Epoch:  143	Loss: 0.5997	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:19 [INFO ]  Epoch:  144	Loss: 0.5819	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:21 [INFO ]  Epoch:  145	Loss: 0.5639	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:23 [INFO ]  Epoch:  146	Loss: 0.5310	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:25 [INFO ]  Epoch:  147	Loss: 0.5691	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:29:27 [INFO ]  Epoch:  148	Loss: 0.5499	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:29:29 [INFO ]  Epoch:  149	Loss: 0.5568	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:29:31 [INFO ]  Epoch:  150	Loss: 0.5201	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:29:33 [INFO ]  Epoch:  151	Loss: 0.6098	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:29:35 [INFO ]  Epoch:  152	Loss: 0.6213	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:29:36 [INFO ]  Epoch:  153	Loss: 0.5548	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:29:38 [INFO ]  Epoch:  154	Loss: 0.6114	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 13:29:40 [INFO ]  Epoch:  155	Loss: 0.5745	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:29:42 [INFO ]  Epoch:  156	Loss: 0.6095	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:29:44 [INFO ]  Epoch:  157	Loss: 0.5854	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:29:46 [INFO ]  Epoch:  158	Loss: 0.5661	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:48 [INFO ]  Epoch:  159	Loss: 0.5849	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:29:50 [INFO ]  Epoch:  160	Loss: 0.5047	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:52 [INFO ]  Epoch:  161	Loss: 0.5632	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:29:54 [INFO ]  Epoch:  162	Loss: 0.5658	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:56 [INFO ]  Epoch:  163	Loss: 0.5664	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:29:57 [INFO ]  Epoch:  164	Loss: 0.5811	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:29:59 [INFO ]  Epoch:  165	Loss: 0.5828	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:01 [INFO ]  Epoch:  166	Loss: 0.6547	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:30:03 [INFO ]  Epoch:  167	Loss: 0.5750	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 13:30:05 [INFO ]  Epoch:  168	Loss: 0.5826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:07 [INFO ]  Epoch:  169	Loss: 0.5869	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:30:09 [INFO ]  Epoch:  170	Loss: 0.6129	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:30:11 [INFO ]  Epoch:  171	Loss: 0.4967	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:30:13 [INFO ]  Epoch:  172	Loss: 0.5680	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:15 [INFO ]  Epoch:  173	Loss: 0.6063	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:30:16 [INFO ]  Epoch:  174	Loss: 0.5773	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:30:18 [INFO ]  Epoch:  175	Loss: 0.5782	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:30:20 [INFO ]  Epoch:  176	Loss: 0.5080	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:30:22 [INFO ]  Epoch:  177	Loss: 0.5211	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:30:24 [INFO ]  Epoch:  178	Loss: 0.5882	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:26 [INFO ]  Epoch:  179	Loss: 0.5704	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:28 [INFO ]  Epoch:  180	Loss: 0.5763	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:30:30 [INFO ]  Epoch:  181	Loss: 0.6092	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:32 [INFO ]  Epoch:  182	Loss: 0.5651	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:30:33 [INFO ]  Epoch:  183	Loss: 0.5519	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:35 [INFO ]  Epoch:  184	Loss: 0.5263	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:37 [INFO ]  Epoch:  185	Loss: 0.5809	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:30:39 [INFO ]  Epoch:  186	Loss: 0.6223	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:30:41 [INFO ]  Epoch:  187	Loss: 0.4978	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:43 [INFO ]  Epoch:  188	Loss: 0.5769	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:30:45 [INFO ]  Epoch:  189	Loss: 0.4707	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:46 [INFO ]  Epoch:  190	Loss: 0.6037	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:30:48 [INFO ]  Epoch:  191	Loss: 0.6366	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:30:50 [INFO ]  Epoch:  192	Loss: 0.5985	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:30:52 [INFO ]  Epoch:  193	Loss: 0.5749	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:30:54 [INFO ]  Epoch:  194	Loss: 0.5290	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:30:56 [INFO ]  Epoch:  195	Loss: 0.5452	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:30:58 [INFO ]  Epoch:  196	Loss: 0.6356	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:31:00 [INFO ]  Epoch:  197	Loss: 0.5849	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:31:01 [INFO ]  Epoch:  198	Loss: 0.5421	Data Time: 0.18s	Train Time: 0.02s
2022-10-04 13:31:03 [INFO ]  Epoch:  199	Loss: 0.5229	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:31:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 13:31:05 [INFO ]  
2022-10-04 13:31:05 [INFO ]  Final evaluation for SVHN :
2022-10-04 13:31:08 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:31:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:31:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:31:08 [INFO ]  	   step  1 (lr=0.460943)                   82.69%                   0.6454
2022-10-04 13:31:08 [INFO ]  
2022-10-04 13:31:08 [INFO ]  
2022-10-04 13:31:08 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 13:31:11 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:31:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:31:11 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 13:31:11 [INFO ]  	   step  1 (lr=0.460943)                   15.79%                   5.7646
2022-10-04 13:31:11 [INFO ]  
2022-10-04 13:31:11 [INFO ]  CPU Time: 3.51 minutes
2022-10-04 13:37:01 [INFO ]  ======================================== 2022-10-04 13:37:01 ========================================
2022-10-04 13:37:01 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 13:37:01 [INFO ]  Options: 
2022-10-04 13:37:01 [INFO ]  	base_dir: null
2022-10-04 13:37:01 [INFO ]  	batch_size: 1024
2022-10-04 13:37:01 [INFO ]  	checkpoint_interval: 300
2022-10-04 13:37:01 [INFO ]  	dataset: SVHN
2022-10-04 13:37:01 [INFO ]  	dataset_labels:
2022-10-04 13:37:01 [INFO ]  	- 0
2022-10-04 13:37:01 [INFO ]  	- 1
2022-10-04 13:37:01 [INFO ]  	- 2
2022-10-04 13:37:01 [INFO ]  	- 3
2022-10-04 13:37:01 [INFO ]  	- 4
2022-10-04 13:37:01 [INFO ]  	- 5
2022-10-04 13:37:01 [INFO ]  	- 6
2022-10-04 13:37:01 [INFO ]  	- 7
2022-10-04 13:37:01 [INFO ]  	- 8
2022-10-04 13:37:01 [INFO ]  	- 9
2022-10-04 13:37:01 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 13:37:01 [INFO ]  	- !!python/tuple
2022-10-04 13:37:01 [INFO ]  	    - 0.4379104971885681
2022-10-04 13:37:01 [INFO ]  	    - 0.44398033618927
2022-10-04 13:37:01 [INFO ]  	    - 0.4729299545288086
2022-10-04 13:37:01 [INFO ]  	- !!python/tuple
2022-10-04 13:37:01 [INFO ]  	    - 0.19803012907505035
2022-10-04 13:37:01 [INFO ]  	    - 0.2010156363248825
2022-10-04 13:37:01 [INFO ]  	    - 0.19703614711761475
2022-10-04 13:37:01 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 13:37:01 [INFO ]  	decay_epochs: 50
2022-10-04 13:37:01 [INFO ]  	decay_factor: 0.1
2022-10-04 13:37:01 [INFO ]  	device_id: 0
2022-10-04 13:37:01 [INFO ]  	distill_epochs: 1
2022-10-04 13:37:01 [INFO ]  	distill_lr: 0.02
2022-10-04 13:37:01 [INFO ]  	distill_steps: 1
2022-10-04 13:37:01 [INFO ]  	epochs: 200
2022-10-04 13:37:01 [INFO ]  	expand_cls: false
2022-10-04 13:37:01 [INFO ]  	forgetting_dataset: null
2022-10-04 13:37:01 [INFO ]  	init: xavier
2022-10-04 13:37:01 [INFO ]  	init_param: 1.0
2022-10-04 13:37:01 [INFO ]  	input_size: 32
2022-10-04 13:37:01 [INFO ]  	ipc: 75
2022-10-04 13:37:01 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 13:37:01 [INFO ]  	log_interval: 100
2022-10-04 13:37:01 [INFO ]  	log_level: INFO
2022-10-04 13:37:01 [INFO ]  	lr: 0.01
2022-10-04 13:37:01 [INFO ]  	mode: distill_adapt
2022-10-04 13:37:01 [INFO ]  	nc: 3
2022-10-04 13:37:01 [INFO ]  	num_classes: 10
2022-10-04 13:37:01 [INFO ]  	num_workers: 8
2022-10-04 13:37:01 [INFO ]  	phase: train
2022-10-04 13:37:01 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 13:37:01 [INFO ]  	start_time: '2022-10-04 13:37:01'
2022-10-04 13:37:01 [INFO ]  	test_batch_size: 1024
2022-10-04 13:37:01 [INFO ]  	
2022-10-04 13:37:03 [INFO ]  train dataset size:	73257
2022-10-04 13:37:03 [INFO ]  test dataset size: 	26032
2022-10-04 13:37:03 [INFO ]  datasets built!
2022-10-04 13:37:03 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 13:37:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 13:37:05 [INFO ]  
2022-10-04 13:37:05 [INFO ]  Begin of epoch 0 :
2022-10-04 13:37:08 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:37:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:37:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:37:08 [INFO ]  	   step  1 (lr=0.020000)                    7.12%                   8.7732
2022-10-04 13:37:08 [INFO ]  
2022-10-04 13:37:08 [INFO ]  Epoch:    0	Loss: 8.8362	Data Time: 0.40s	Train Time: 0.07s
2022-10-04 13:37:10 [INFO ]  Epoch:    1	Loss: 2.9759	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:37:12 [INFO ]  Epoch:    2	Loss: 2.4876	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:13 [INFO ]  Epoch:    3	Loss: 2.2681	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:37:15 [INFO ]  Epoch:    4	Loss: 2.2077	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:17 [INFO ]  Epoch:    5	Loss: 2.1947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:19 [INFO ]  Epoch:    6	Loss: 2.1495	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:21 [INFO ]  Epoch:    7	Loss: 2.1168	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:37:22 [INFO ]  Epoch:    8	Loss: 2.0327	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:37:24 [INFO ]  Epoch:    9	Loss: 1.9798	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:37:26 [INFO ]  Epoch:   10	Loss: 1.8818	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:28 [INFO ]  Epoch:   11	Loss: 1.7789	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:30 [INFO ]  Epoch:   12	Loss: 1.6507	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 13:37:32 [INFO ]  Epoch:   13	Loss: 1.4824	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:37:34 [INFO ]  Epoch:   14	Loss: 1.2663	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:37:36 [INFO ]  Epoch:   15	Loss: 1.2881	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:37:37 [INFO ]  Epoch:   16	Loss: 1.2755	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:39 [INFO ]  Epoch:   17	Loss: 1.1437	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:41 [INFO ]  Epoch:   18	Loss: 1.1700	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:43 [INFO ]  Epoch:   19	Loss: 1.1468	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:44 [INFO ]  Epoch:   20	Loss: 1.0516	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:37:46 [INFO ]  Epoch:   21	Loss: 0.9916	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:37:48 [INFO ]  Epoch:   22	Loss: 0.9362	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:37:50 [INFO ]  Epoch:   23	Loss: 1.0369	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:37:52 [INFO ]  Epoch:   24	Loss: 0.8735	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:37:54 [INFO ]  Epoch:   25	Loss: 0.9048	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:37:56 [INFO ]  Epoch:   26	Loss: 0.9164	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:37:57 [INFO ]  Epoch:   27	Loss: 0.8507	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:37:59 [INFO ]  Epoch:   28	Loss: 0.9093	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:01 [INFO ]  Epoch:   29	Loss: 0.9318	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:38:03 [INFO ]  Epoch:   30	Loss: 0.8269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:05 [INFO ]  Epoch:   31	Loss: 0.8793	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:07 [INFO ]  Epoch:   32	Loss: 0.7917	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:38:09 [INFO ]  Epoch:   33	Loss: 0.8246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:11 [INFO ]  Epoch:   34	Loss: 0.9217	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:38:12 [INFO ]  Epoch:   35	Loss: 0.8077	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:38:14 [INFO ]  Epoch:   36	Loss: 0.8010	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:16 [INFO ]  Epoch:   37	Loss: 0.7768	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:38:18 [INFO ]  Epoch:   38	Loss: 0.8995	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:38:20 [INFO ]  Epoch:   39	Loss: 0.7548	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:38:22 [INFO ]  Epoch:   40	Loss: 0.7826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:24 [INFO ]  Epoch:   41	Loss: 0.6563	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:26 [INFO ]  Epoch:   42	Loss: 0.7818	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:38:27 [INFO ]  Epoch:   43	Loss: 0.7602	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:38:29 [INFO ]  Epoch:   44	Loss: 0.6882	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:38:31 [INFO ]  Epoch:   45	Loss: 0.7856	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:33 [INFO ]  Epoch:   46	Loss: 0.7875	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:38:35 [INFO ]  Epoch:   47	Loss: 0.6558	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:38:37 [INFO ]  Epoch:   48	Loss: 0.6654	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:38:39 [INFO ]  Epoch:   49	Loss: 0.7291	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:38:41 [INFO ]  Epoch:   50	Loss: 0.5754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:42 [INFO ]  Epoch:   51	Loss: 0.6720	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:38:44 [INFO ]  Epoch:   52	Loss: 0.6157	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:46 [INFO ]  Epoch:   53	Loss: 0.6198	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:48 [INFO ]  Epoch:   54	Loss: 0.6512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:50 [INFO ]  Epoch:   55	Loss: 0.5858	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:52 [INFO ]  Epoch:   56	Loss: 0.7004	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:38:54 [INFO ]  Epoch:   57	Loss: 0.6009	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:38:56 [INFO ]  Epoch:   58	Loss: 0.5430	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:38:58 [INFO ]  Epoch:   59	Loss: 0.7169	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:39:00 [INFO ]  Epoch:   60	Loss: 0.6695	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:01 [INFO ]  Epoch:   61	Loss: 0.6396	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:03 [INFO ]  Epoch:   62	Loss: 0.6410	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:05 [INFO ]  Epoch:   63	Loss: 0.6116	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:39:07 [INFO ]  Epoch:   64	Loss: 0.6555	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:39:08 [INFO ]  Epoch:   65	Loss: 0.6736	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:10 [INFO ]  Epoch:   66	Loss: 0.6139	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:39:12 [INFO ]  Epoch:   67	Loss: 0.5223	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:14 [INFO ]  Epoch:   68	Loss: 0.6170	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:39:16 [INFO ]  Epoch:   69	Loss: 0.5496	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:39:18 [INFO ]  Epoch:   70	Loss: 0.5609	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:39:20 [INFO ]  Epoch:   71	Loss: 0.6228	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:39:21 [INFO ]  Epoch:   72	Loss: 0.6687	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:23 [INFO ]  Epoch:   73	Loss: 0.5845	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:25 [INFO ]  Epoch:   74	Loss: 0.6181	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:39:27 [INFO ]  Epoch:   75	Loss: 0.6614	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:39:29 [INFO ]  Epoch:   76	Loss: 0.6294	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:31 [INFO ]  Epoch:   77	Loss: 0.5862	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:39:33 [INFO ]  Epoch:   78	Loss: 0.5829	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:34 [INFO ]  Epoch:   79	Loss: 0.5731	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:36 [INFO ]  Epoch:   80	Loss: 0.5962	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:38 [INFO ]  Epoch:   81	Loss: 0.5855	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:40 [INFO ]  Epoch:   82	Loss: 0.5940	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:42 [INFO ]  Epoch:   83	Loss: 0.6242	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:44 [INFO ]  Epoch:   84	Loss: 0.5650	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:46 [INFO ]  Epoch:   85	Loss: 0.5648	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:48 [INFO ]  Epoch:   86	Loss: 0.5442	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:49 [INFO ]  Epoch:   87	Loss: 0.6101	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:39:51 [INFO ]  Epoch:   88	Loss: 0.5951	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:39:53 [INFO ]  Epoch:   89	Loss: 0.6041	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:39:55 [INFO ]  Epoch:   90	Loss: 0.5514	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:39:57 [INFO ]  Epoch:   91	Loss: 0.5892	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:39:59 [INFO ]  Epoch:   92	Loss: 0.5345	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:40:01 [INFO ]  Epoch:   93	Loss: 0.5847	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:03 [INFO ]  Epoch:   94	Loss: 0.5932	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:40:05 [INFO ]  Epoch:   95	Loss: 0.6236	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:40:06 [INFO ]  Epoch:   96	Loss: 0.6073	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:40:09 [INFO ]  Epoch:   97	Loss: 0.5308	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:40:10 [INFO ]  Epoch:   98	Loss: 0.5577	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:12 [INFO ]  Epoch:   99	Loss: 0.5282	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:40:14 [INFO ]  Epoch:  100	Loss: 0.5590	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:16 [INFO ]  Epoch:  101	Loss: 0.6617	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 13:40:18 [INFO ]  Epoch:  102	Loss: 0.6038	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:20 [INFO ]  Epoch:  103	Loss: 0.5207	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:22 [INFO ]  Epoch:  104	Loss: 0.5631	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:40:24 [INFO ]  Epoch:  105	Loss: 0.5511	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:26 [INFO ]  Epoch:  106	Loss: 0.5795	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:40:28 [INFO ]  Epoch:  107	Loss: 0.6214	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:29 [INFO ]  Epoch:  108	Loss: 0.6009	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:40:31 [INFO ]  Epoch:  109	Loss: 0.5581	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:40:33 [INFO ]  Epoch:  110	Loss: 0.5537	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:35 [INFO ]  Epoch:  111	Loss: 0.5016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:36 [INFO ]  Epoch:  112	Loss: 0.5772	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:40:38 [INFO ]  Epoch:  113	Loss: 0.5394	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:41 [INFO ]  Epoch:  114	Loss: 0.5519	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:40:42 [INFO ]  Epoch:  115	Loss: 0.4869	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:44 [INFO ]  Epoch:  116	Loss: 0.5144	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:46 [INFO ]  Epoch:  117	Loss: 0.5530	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:48 [INFO ]  Epoch:  118	Loss: 0.5554	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:49 [INFO ]  Epoch:  119	Loss: 0.5997	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:51 [INFO ]  Epoch:  120	Loss: 0.6241	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:40:53 [INFO ]  Epoch:  121	Loss: 0.5511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:55 [INFO ]  Epoch:  122	Loss: 0.5863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:40:56 [INFO ]  Epoch:  123	Loss: 0.5733	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:40:58 [INFO ]  Epoch:  124	Loss: 0.5424	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:41:00 [INFO ]  Epoch:  125	Loss: 0.5614	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:41:02 [INFO ]  Epoch:  126	Loss: 0.5510	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:04 [INFO ]  Epoch:  127	Loss: 0.5447	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:41:06 [INFO ]  Epoch:  128	Loss: 0.5984	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:41:08 [INFO ]  Epoch:  129	Loss: 0.5478	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:10 [INFO ]  Epoch:  130	Loss: 0.4958	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:11 [INFO ]  Epoch:  131	Loss: 0.5857	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:13 [INFO ]  Epoch:  132	Loss: 0.5920	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:41:15 [INFO ]  Epoch:  133	Loss: 0.5786	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:41:17 [INFO ]  Epoch:  134	Loss: 0.6332	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:19 [INFO ]  Epoch:  135	Loss: 0.6112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:20 [INFO ]  Epoch:  136	Loss: 0.5675	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 13:41:22 [INFO ]  Epoch:  137	Loss: 0.6183	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:41:24 [INFO ]  Epoch:  138	Loss: 0.5466	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:41:26 [INFO ]  Epoch:  139	Loss: 0.5898	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:41:27 [INFO ]  Epoch:  140	Loss: 0.4977	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:41:29 [INFO ]  Epoch:  141	Loss: 0.5497	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 13:41:31 [INFO ]  Epoch:  142	Loss: 0.5804	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:41:33 [INFO ]  Epoch:  143	Loss: 0.5440	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:41:35 [INFO ]  Epoch:  144	Loss: 0.5529	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:41:37 [INFO ]  Epoch:  145	Loss: 0.5806	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:41:38 [INFO ]  Epoch:  146	Loss: 0.5931	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:41 [INFO ]  Epoch:  147	Loss: 0.5707	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:41:42 [INFO ]  Epoch:  148	Loss: 0.5644	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:41:44 [INFO ]  Epoch:  149	Loss: 0.5647	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:41:46 [INFO ]  Epoch:  150	Loss: 0.5594	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:41:48 [INFO ]  Epoch:  151	Loss: 0.5674	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:41:50 [INFO ]  Epoch:  152	Loss: 0.5505	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:41:52 [INFO ]  Epoch:  153	Loss: 0.6177	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:54 [INFO ]  Epoch:  154	Loss: 0.5896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:55 [INFO ]  Epoch:  155	Loss: 0.5280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:41:57 [INFO ]  Epoch:  156	Loss: 0.5271	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:41:59 [INFO ]  Epoch:  157	Loss: 0.4843	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:01 [INFO ]  Epoch:  158	Loss: 0.5119	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:42:03 [INFO ]  Epoch:  159	Loss: 0.5723	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:42:05 [INFO ]  Epoch:  160	Loss: 0.6101	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:42:07 [INFO ]  Epoch:  161	Loss: 0.5710	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:09 [INFO ]  Epoch:  162	Loss: 0.5691	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:10 [INFO ]  Epoch:  163	Loss: 0.5144	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:12 [INFO ]  Epoch:  164	Loss: 0.5703	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:42:14 [INFO ]  Epoch:  165	Loss: 0.5458	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:42:16 [INFO ]  Epoch:  166	Loss: 0.6203	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 13:42:18 [INFO ]  Epoch:  167	Loss: 0.5325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:20 [INFO ]  Epoch:  168	Loss: 0.5786	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:42:22 [INFO ]  Epoch:  169	Loss: 0.5124	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:42:24 [INFO ]  Epoch:  170	Loss: 0.5862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:26 [INFO ]  Epoch:  171	Loss: 0.6007	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:27 [INFO ]  Epoch:  172	Loss: 0.6042	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 13:42:29 [INFO ]  Epoch:  173	Loss: 0.5265	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:31 [INFO ]  Epoch:  174	Loss: 0.6004	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:33 [INFO ]  Epoch:  175	Loss: 0.5329	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 13:42:35 [INFO ]  Epoch:  176	Loss: 0.5384	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:42:37 [INFO ]  Epoch:  177	Loss: 0.5018	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:42:38 [INFO ]  Epoch:  178	Loss: 0.4762	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:40 [INFO ]  Epoch:  179	Loss: 0.5757	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:42:42 [INFO ]  Epoch:  180	Loss: 0.4902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:44 [INFO ]  Epoch:  181	Loss: 0.5835	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:46 [INFO ]  Epoch:  182	Loss: 0.5133	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:48 [INFO ]  Epoch:  183	Loss: 0.5657	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:50 [INFO ]  Epoch:  184	Loss: 0.5016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:51 [INFO ]  Epoch:  185	Loss: 0.5542	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:42:53 [INFO ]  Epoch:  186	Loss: 0.4891	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:42:55 [INFO ]  Epoch:  187	Loss: 0.5465	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 13:42:57 [INFO ]  Epoch:  188	Loss: 0.5304	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:42:59 [INFO ]  Epoch:  189	Loss: 0.5876	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:43:01 [INFO ]  Epoch:  190	Loss: 0.5753	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:43:02 [INFO ]  Epoch:  191	Loss: 0.5339	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 13:43:04 [INFO ]  Epoch:  192	Loss: 0.5679	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:43:06 [INFO ]  Epoch:  193	Loss: 0.5770	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:43:08 [INFO ]  Epoch:  194	Loss: 0.6477	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:43:09 [INFO ]  Epoch:  195	Loss: 0.5469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:43:11 [INFO ]  Epoch:  196	Loss: 0.5128	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:43:13 [INFO ]  Epoch:  197	Loss: 0.5926	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 13:43:15 [INFO ]  Epoch:  198	Loss: 0.5949	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 13:43:17 [INFO ]  Epoch:  199	Loss: 0.5727	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 13:43:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 13:43:18 [INFO ]  
2022-10-04 13:43:18 [INFO ]  Final evaluation for SVHN :
2022-10-04 13:43:22 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:43:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:43:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 13:43:22 [INFO ]  	   step  1 (lr=0.479574)                   82.54%                   0.6470
2022-10-04 13:43:22 [INFO ]  
2022-10-04 13:43:22 [INFO ]  
2022-10-04 13:43:22 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 13:43:25 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 13:43:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 13:43:25 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 13:43:25 [INFO ]  	   step  1 (lr=0.479574)                   15.53%                   5.0886
2022-10-04 13:43:25 [INFO ]  
2022-10-04 13:43:25 [INFO ]  CPU Time: 3.51 minutes
2022-10-04 14:07:06 [INFO ]  ======================================== 2022-10-04 14:07:06 ========================================
2022-10-04 14:07:06 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:07:06 [INFO ]  Options: 
2022-10-04 14:07:06 [INFO ]  	base_dir: null
2022-10-04 14:07:06 [INFO ]  	batch_size: 1024
2022-10-04 14:07:06 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:07:06 [INFO ]  	dataset: SVHN
2022-10-04 14:07:06 [INFO ]  	dataset_labels:
2022-10-04 14:07:06 [INFO ]  	- 0
2022-10-04 14:07:06 [INFO ]  	- 1
2022-10-04 14:07:06 [INFO ]  	- 2
2022-10-04 14:07:06 [INFO ]  	- 3
2022-10-04 14:07:06 [INFO ]  	- 4
2022-10-04 14:07:06 [INFO ]  	- 5
2022-10-04 14:07:06 [INFO ]  	- 6
2022-10-04 14:07:06 [INFO ]  	- 7
2022-10-04 14:07:06 [INFO ]  	- 8
2022-10-04 14:07:06 [INFO ]  	- 9
2022-10-04 14:07:06 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:07:06 [INFO ]  	- !!python/tuple
2022-10-04 14:07:06 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:07:06 [INFO ]  	    - 0.44398033618927
2022-10-04 14:07:06 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:07:06 [INFO ]  	- !!python/tuple
2022-10-04 14:07:06 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:07:06 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:07:06 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:07:06 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:07:06 [INFO ]  	decay_epochs: 50
2022-10-04 14:07:06 [INFO ]  	decay_factor: 0.1
2022-10-04 14:07:06 [INFO ]  	device_id: 0
2022-10-04 14:07:06 [INFO ]  	distill_epochs: 1
2022-10-04 14:07:06 [INFO ]  	distill_lr: 0.02
2022-10-04 14:07:06 [INFO ]  	distill_steps: 1
2022-10-04 14:07:06 [INFO ]  	epochs: 200
2022-10-04 14:07:06 [INFO ]  	expand_cls: false
2022-10-04 14:07:06 [INFO ]  	forgetting_dataset: null
2022-10-04 14:07:06 [INFO ]  	init: xavier
2022-10-04 14:07:06 [INFO ]  	init_param: 1.0
2022-10-04 14:07:06 [INFO ]  	input_size: 32
2022-10-04 14:07:06 [INFO ]  	ipc: 75
2022-10-04 14:07:06 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:07:06 [INFO ]  	log_interval: 100
2022-10-04 14:07:06 [INFO ]  	log_level: INFO
2022-10-04 14:07:06 [INFO ]  	lr: 0.01
2022-10-04 14:07:06 [INFO ]  	mode: distill_adapt
2022-10-04 14:07:06 [INFO ]  	nc: 3
2022-10-04 14:07:06 [INFO ]  	num_classes: 10
2022-10-04 14:07:06 [INFO ]  	num_workers: 8
2022-10-04 14:07:06 [INFO ]  	phase: train
2022-10-04 14:07:06 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:07:06 [INFO ]  	start_time: '2022-10-04 14:07:06'
2022-10-04 14:07:06 [INFO ]  	test_batch_size: 1024
2022-10-04 14:07:06 [INFO ]  	
2022-10-04 14:07:08 [INFO ]  train dataset size:	73257
2022-10-04 14:07:08 [INFO ]  test dataset size: 	26032
2022-10-04 14:07:08 [INFO ]  datasets built!
2022-10-04 14:07:08 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:07:10 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:07:10 [INFO ]  
2022-10-04 14:07:10 [INFO ]  Begin of epoch 0 :
2022-10-04 14:07:13 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:07:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:07:13 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:07:13 [INFO ]  	   step  1 (lr=0.020000)                    7.05%                   8.8045
2022-10-04 14:07:13 [INFO ]  
2022-10-04 14:07:13 [INFO ]  Epoch:    0	Loss: 8.6160	Data Time: 0.37s	Train Time: 0.07s
2022-10-04 14:07:15 [INFO ]  Epoch:    1	Loss: 3.0504	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:07:17 [INFO ]  Epoch:    2	Loss: 2.5079	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:19 [INFO ]  Epoch:    3	Loss: 2.2828	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:21 [INFO ]  Epoch:    4	Loss: 2.2293	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:22 [INFO ]  Epoch:    5	Loss: 2.1704	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:24 [INFO ]  Epoch:    6	Loss: 2.1312	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:26 [INFO ]  Epoch:    7	Loss: 2.0977	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:28 [INFO ]  Epoch:    8	Loss: 2.0508	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:07:30 [INFO ]  Epoch:    9	Loss: 1.9295	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:07:32 [INFO ]  Epoch:   10	Loss: 1.8144	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:07:33 [INFO ]  Epoch:   11	Loss: 1.6358	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:35 [INFO ]  Epoch:   12	Loss: 1.5165	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:37 [INFO ]  Epoch:   13	Loss: 1.3803	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 14:07:39 [INFO ]  Epoch:   14	Loss: 1.3372	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:41 [INFO ]  Epoch:   15	Loss: 1.2268	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:43 [INFO ]  Epoch:   16	Loss: 1.1938	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:07:44 [INFO ]  Epoch:   17	Loss: 1.1118	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:07:46 [INFO ]  Epoch:   18	Loss: 1.1405	Data Time: 0.17s	Train Time: 0.00s
2022-10-04 14:07:48 [INFO ]  Epoch:   19	Loss: 1.0369	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:07:50 [INFO ]  Epoch:   20	Loss: 1.0797	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:52 [INFO ]  Epoch:   21	Loss: 0.9625	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:07:54 [INFO ]  Epoch:   22	Loss: 0.9785	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:07:56 [INFO ]  Epoch:   23	Loss: 0.9626	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:07:57 [INFO ]  Epoch:   24	Loss: 0.9730	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:07:59 [INFO ]  Epoch:   25	Loss: 0.9483	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:08:01 [INFO ]  Epoch:   26	Loss: 0.8607	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:03 [INFO ]  Epoch:   27	Loss: 0.8508	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:04 [INFO ]  Epoch:   28	Loss: 0.7944	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:08:06 [INFO ]  Epoch:   29	Loss: 0.7652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:08 [INFO ]  Epoch:   30	Loss: 0.8417	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:10 [INFO ]  Epoch:   31	Loss: 0.7835	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:12 [INFO ]  Epoch:   32	Loss: 0.8568	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:08:14 [INFO ]  Epoch:   33	Loss: 0.7623	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:16 [INFO ]  Epoch:   34	Loss: 0.8302	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:18 [INFO ]  Epoch:   35	Loss: 0.8016	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:19 [INFO ]  Epoch:   36	Loss: 0.8118	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:21 [INFO ]  Epoch:   37	Loss: 1.1910	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:23 [INFO ]  Epoch:   38	Loss: 0.7384	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:25 [INFO ]  Epoch:   39	Loss: 0.7879	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:27 [INFO ]  Epoch:   40	Loss: 0.7180	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:29 [INFO ]  Epoch:   41	Loss: 0.6850	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:31 [INFO ]  Epoch:   42	Loss: 0.6450	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:33 [INFO ]  Epoch:   43	Loss: 0.8429	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:35 [INFO ]  Epoch:   44	Loss: 0.7681	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:08:37 [INFO ]  Epoch:   45	Loss: 0.6609	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:08:38 [INFO ]  Epoch:   46	Loss: 0.7424	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:08:40 [INFO ]  Epoch:   47	Loss: 0.7073	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:08:42 [INFO ]  Epoch:   48	Loss: 0.7833	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:08:44 [INFO ]  Epoch:   49	Loss: 0.7490	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:08:45 [INFO ]  Epoch:   50	Loss: 0.6087	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:47 [INFO ]  Epoch:   51	Loss: 0.5813	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:08:49 [INFO ]  Epoch:   52	Loss: 0.6025	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:51 [INFO ]  Epoch:   53	Loss: 0.6351	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:08:53 [INFO ]  Epoch:   54	Loss: 0.6350	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:08:55 [INFO ]  Epoch:   55	Loss: 0.5966	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:08:56 [INFO ]  Epoch:   56	Loss: 0.6634	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:08:58 [INFO ]  Epoch:   57	Loss: 0.6251	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:00 [INFO ]  Epoch:   58	Loss: 0.5949	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:09:02 [INFO ]  Epoch:   59	Loss: 0.6034	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:04 [INFO ]  Epoch:   60	Loss: 0.5095	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:06 [INFO ]  Epoch:   61	Loss: 0.6851	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:09:08 [INFO ]  Epoch:   62	Loss: 0.6159	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:10 [INFO ]  Epoch:   63	Loss: 0.6738	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:11 [INFO ]  Epoch:   64	Loss: 0.6721	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:13 [INFO ]  Epoch:   65	Loss: 0.6377	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:15 [INFO ]  Epoch:   66	Loss: 0.5615	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:17 [INFO ]  Epoch:   67	Loss: 0.6469	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:19 [INFO ]  Epoch:   68	Loss: 0.5988	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:09:20 [INFO ]  Epoch:   69	Loss: 0.5835	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:22 [INFO ]  Epoch:   70	Loss: 0.5592	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:09:24 [INFO ]  Epoch:   71	Loss: 0.6585	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:09:26 [INFO ]  Epoch:   72	Loss: 0.5768	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:28 [INFO ]  Epoch:   73	Loss: 0.5709	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:30 [INFO ]  Epoch:   74	Loss: 0.6851	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:31 [INFO ]  Epoch:   75	Loss: 0.6112	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:09:33 [INFO ]  Epoch:   76	Loss: 0.5966	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:35 [INFO ]  Epoch:   77	Loss: 0.6488	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:37 [INFO ]  Epoch:   78	Loss: 0.5596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:39 [INFO ]  Epoch:   79	Loss: 0.6167	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:09:41 [INFO ]  Epoch:   80	Loss: 0.6203	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:09:43 [INFO ]  Epoch:   81	Loss: 0.6347	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:09:45 [INFO ]  Epoch:   82	Loss: 0.5898	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:46 [INFO ]  Epoch:   83	Loss: 0.5373	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:48 [INFO ]  Epoch:   84	Loss: 0.6837	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:50 [INFO ]  Epoch:   85	Loss: 0.5835	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:52 [INFO ]  Epoch:   86	Loss: 0.5274	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:54 [INFO ]  Epoch:   87	Loss: 0.6473	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:09:56 [INFO ]  Epoch:   88	Loss: 0.6012	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:09:57 [INFO ]  Epoch:   89	Loss: 0.6183	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:09:59 [INFO ]  Epoch:   90	Loss: 0.6209	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:01 [INFO ]  Epoch:   91	Loss: 0.5916	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:10:03 [INFO ]  Epoch:   92	Loss: 0.6231	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:10:05 [INFO ]  Epoch:   93	Loss: 0.6235	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:07 [INFO ]  Epoch:   94	Loss: 0.5667	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:10:09 [INFO ]  Epoch:   95	Loss: 0.5922	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:10:11 [INFO ]  Epoch:   96	Loss: 0.6874	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:13 [INFO ]  Epoch:   97	Loss: 0.5570	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:14 [INFO ]  Epoch:   98	Loss: 0.6168	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:17 [INFO ]  Epoch:   99	Loss: 0.5866	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:10:18 [INFO ]  Epoch:  100	Loss: 0.6015	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:21 [INFO ]  Epoch:  101	Loss: 0.6134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:23 [INFO ]  Epoch:  102	Loss: 0.6334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:24 [INFO ]  Epoch:  103	Loss: 0.5982	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:26 [INFO ]  Epoch:  104	Loss: 0.5366	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:28 [INFO ]  Epoch:  105	Loss: 0.6028	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:10:30 [INFO ]  Epoch:  106	Loss: 0.5927	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:32 [INFO ]  Epoch:  107	Loss: 0.5679	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:10:34 [INFO ]  Epoch:  108	Loss: 0.5525	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:35 [INFO ]  Epoch:  109	Loss: 0.5880	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:10:37 [INFO ]  Epoch:  110	Loss: 0.6032	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:10:39 [INFO ]  Epoch:  111	Loss: 0.5671	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:41 [INFO ]  Epoch:  112	Loss: 0.6045	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:10:43 [INFO ]  Epoch:  113	Loss: 0.6255	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:10:45 [INFO ]  Epoch:  114	Loss: 0.6407	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:10:47 [INFO ]  Epoch:  115	Loss: 0.6204	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:10:48 [INFO ]  Epoch:  116	Loss: 0.6529	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:51 [INFO ]  Epoch:  117	Loss: 0.6004	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:10:52 [INFO ]  Epoch:  118	Loss: 0.5362	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:54 [INFO ]  Epoch:  119	Loss: 0.6178	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:10:56 [INFO ]  Epoch:  120	Loss: 0.5960	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:10:58 [INFO ]  Epoch:  121	Loss: 0.6553	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:11:00 [INFO ]  Epoch:  122	Loss: 0.6152	Data Time: 0.17s	Train Time: 0.02s
2022-10-04 14:11:02 [INFO ]  Epoch:  123	Loss: 0.6143	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:11:03 [INFO ]  Epoch:  124	Loss: 0.5476	Data Time: 0.22s	Train Time: 0.00s
2022-10-04 14:11:05 [INFO ]  Epoch:  125	Loss: 0.5867	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:07 [INFO ]  Epoch:  126	Loss: 0.5860	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:11:09 [INFO ]  Epoch:  127	Loss: 0.6926	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:11 [INFO ]  Epoch:  128	Loss: 0.6499	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:12 [INFO ]  Epoch:  129	Loss: 0.5581	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:11:15 [INFO ]  Epoch:  130	Loss: 0.6125	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:11:16 [INFO ]  Epoch:  131	Loss: 0.5282	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:18 [INFO ]  Epoch:  132	Loss: 0.5712	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:20 [INFO ]  Epoch:  133	Loss: 0.5174	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:11:22 [INFO ]  Epoch:  134	Loss: 0.6345	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 14:11:24 [INFO ]  Epoch:  135	Loss: 0.5778	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:26 [INFO ]  Epoch:  136	Loss: 0.5643	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:28 [INFO ]  Epoch:  137	Loss: 0.6368	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:11:29 [INFO ]  Epoch:  138	Loss: 0.5925	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:11:32 [INFO ]  Epoch:  139	Loss: 0.5411	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:33 [INFO ]  Epoch:  140	Loss: 0.5561	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:11:35 [INFO ]  Epoch:  141	Loss: 0.5809	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:11:37 [INFO ]  Epoch:  142	Loss: 0.5802	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:11:39 [INFO ]  Epoch:  143	Loss: 0.5384	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:41 [INFO ]  Epoch:  144	Loss: 0.6572	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:11:43 [INFO ]  Epoch:  145	Loss: 0.6192	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:11:44 [INFO ]  Epoch:  146	Loss: 0.6218	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:11:46 [INFO ]  Epoch:  147	Loss: 0.5925	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:11:48 [INFO ]  Epoch:  148	Loss: 0.6106	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:11:50 [INFO ]  Epoch:  149	Loss: 0.6296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:51 [INFO ]  Epoch:  150	Loss: 0.5790	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:11:53 [INFO ]  Epoch:  151	Loss: 0.5517	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:11:55 [INFO ]  Epoch:  152	Loss: 0.5679	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:11:57 [INFO ]  Epoch:  153	Loss: 0.5422	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:11:59 [INFO ]  Epoch:  154	Loss: 0.5207	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:12:01 [INFO ]  Epoch:  155	Loss: 0.5616	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:02 [INFO ]  Epoch:  156	Loss: 0.5468	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:04 [INFO ]  Epoch:  157	Loss: 0.5855	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:06 [INFO ]  Epoch:  158	Loss: 0.5887	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:12:08 [INFO ]  Epoch:  159	Loss: 0.5850	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:10 [INFO ]  Epoch:  160	Loss: 0.5851	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:12 [INFO ]  Epoch:  161	Loss: 0.6094	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:14 [INFO ]  Epoch:  162	Loss: 0.6604	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:16 [INFO ]  Epoch:  163	Loss: 0.5870	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:17 [INFO ]  Epoch:  164	Loss: 0.5644	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:12:19 [INFO ]  Epoch:  165	Loss: 0.5525	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:21 [INFO ]  Epoch:  166	Loss: 0.6057	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:23 [INFO ]  Epoch:  167	Loss: 0.5374	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:12:25 [INFO ]  Epoch:  168	Loss: 0.6151	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:27 [INFO ]  Epoch:  169	Loss: 0.5736	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:29 [INFO ]  Epoch:  170	Loss: 0.5732	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:12:31 [INFO ]  Epoch:  171	Loss: 0.6052	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:33 [INFO ]  Epoch:  172	Loss: 0.5834	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:12:35 [INFO ]  Epoch:  173	Loss: 0.5896	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:36 [INFO ]  Epoch:  174	Loss: 0.6449	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:38 [INFO ]  Epoch:  175	Loss: 0.5680	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:40 [INFO ]  Epoch:  176	Loss: 0.5896	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:12:42 [INFO ]  Epoch:  177	Loss: 0.5495	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:44 [INFO ]  Epoch:  178	Loss: 0.5870	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:46 [INFO ]  Epoch:  179	Loss: 0.6272	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:48 [INFO ]  Epoch:  180	Loss: 0.6329	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:50 [INFO ]  Epoch:  181	Loss: 0.5572	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:12:52 [INFO ]  Epoch:  182	Loss: 0.5781	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:12:54 [INFO ]  Epoch:  183	Loss: 0.5705	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:55 [INFO ]  Epoch:  184	Loss: 0.5423	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:12:57 [INFO ]  Epoch:  185	Loss: 0.6004	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:12:59 [INFO ]  Epoch:  186	Loss: 0.5459	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:13:01 [INFO ]  Epoch:  187	Loss: 0.5651	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:13:03 [INFO ]  Epoch:  188	Loss: 0.5982	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:13:05 [INFO ]  Epoch:  189	Loss: 0.5570	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:13:07 [INFO ]  Epoch:  190	Loss: 0.5424	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:13:09 [INFO ]  Epoch:  191	Loss: 0.5596	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:13:10 [INFO ]  Epoch:  192	Loss: 0.5701	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:13:12 [INFO ]  Epoch:  193	Loss: 0.6040	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:13:14 [INFO ]  Epoch:  194	Loss: 0.6045	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:13:16 [INFO ]  Epoch:  195	Loss: 0.5612	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:13:18 [INFO ]  Epoch:  196	Loss: 0.6047	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:13:20 [INFO ]  Epoch:  197	Loss: 0.6397	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:13:22 [INFO ]  Epoch:  198	Loss: 0.6364	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:13:24 [INFO ]  Epoch:  199	Loss: 0.5059	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:13:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 14:13:25 [INFO ]  
2022-10-04 14:13:25 [INFO ]  Final evaluation for SVHN :
2022-10-04 14:13:29 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:13:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:13:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:13:29 [INFO ]  	   step  1 (lr=0.465228)                   82.09%                   0.6766
2022-10-04 14:13:29 [INFO ]  
2022-10-04 14:13:29 [INFO ]  
2022-10-04 14:13:29 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 14:13:32 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:13:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:13:32 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 14:13:32 [INFO ]  	   step  1 (lr=0.465228)                   15.11%                   5.8459
2022-10-04 14:13:32 [INFO ]  
2022-10-04 14:13:32 [INFO ]  CPU Time: 3.53 minutes
2022-10-04 14:19:30 [INFO ]  ======================================== 2022-10-04 14:19:30 ========================================
2022-10-04 14:19:30 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:19:30 [INFO ]  Options: 
2022-10-04 14:19:30 [INFO ]  	base_dir: null
2022-10-04 14:19:30 [INFO ]  	batch_size: 1024
2022-10-04 14:19:30 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:19:30 [INFO ]  	dataset: SVHN
2022-10-04 14:19:30 [INFO ]  	dataset_labels:
2022-10-04 14:19:30 [INFO ]  	- 0
2022-10-04 14:19:30 [INFO ]  	- 1
2022-10-04 14:19:30 [INFO ]  	- 2
2022-10-04 14:19:30 [INFO ]  	- 3
2022-10-04 14:19:30 [INFO ]  	- 4
2022-10-04 14:19:30 [INFO ]  	- 5
2022-10-04 14:19:30 [INFO ]  	- 6
2022-10-04 14:19:30 [INFO ]  	- 7
2022-10-04 14:19:30 [INFO ]  	- 8
2022-10-04 14:19:30 [INFO ]  	- 9
2022-10-04 14:19:30 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:19:30 [INFO ]  	- !!python/tuple
2022-10-04 14:19:30 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:19:30 [INFO ]  	    - 0.44398033618927
2022-10-04 14:19:30 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:19:30 [INFO ]  	- !!python/tuple
2022-10-04 14:19:30 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:19:30 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:19:30 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:19:30 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:19:30 [INFO ]  	decay_epochs: 50
2022-10-04 14:19:30 [INFO ]  	decay_factor: 0.1
2022-10-04 14:19:30 [INFO ]  	device_id: 0
2022-10-04 14:19:30 [INFO ]  	distill_epochs: 1
2022-10-04 14:19:30 [INFO ]  	distill_lr: 0.02
2022-10-04 14:19:30 [INFO ]  	distill_steps: 1
2022-10-04 14:19:30 [INFO ]  	epochs: 200
2022-10-04 14:19:30 [INFO ]  	expand_cls: false
2022-10-04 14:19:30 [INFO ]  	forgetting_dataset: null
2022-10-04 14:19:30 [INFO ]  	init: xavier
2022-10-04 14:19:30 [INFO ]  	init_param: 1.0
2022-10-04 14:19:30 [INFO ]  	input_size: 32
2022-10-04 14:19:30 [INFO ]  	ipc: 75
2022-10-04 14:19:30 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:19:30 [INFO ]  	log_interval: 100
2022-10-04 14:19:30 [INFO ]  	log_level: INFO
2022-10-04 14:19:30 [INFO ]  	lr: 0.01
2022-10-04 14:19:30 [INFO ]  	mode: distill_adapt
2022-10-04 14:19:30 [INFO ]  	nc: 3
2022-10-04 14:19:30 [INFO ]  	num_classes: 10
2022-10-04 14:19:30 [INFO ]  	num_workers: 8
2022-10-04 14:19:30 [INFO ]  	phase: train
2022-10-04 14:19:30 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:19:30 [INFO ]  	start_time: '2022-10-04 14:19:30'
2022-10-04 14:19:30 [INFO ]  	test_batch_size: 1024
2022-10-04 14:19:30 [INFO ]  	
2022-10-04 14:19:33 [INFO ]  train dataset size:	73257
2022-10-04 14:19:33 [INFO ]  test dataset size: 	26032
2022-10-04 14:19:33 [INFO ]  datasets built!
2022-10-04 14:19:33 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:19:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:19:34 [INFO ]  
2022-10-04 14:19:34 [INFO ]  Begin of epoch 0 :
2022-10-04 14:19:38 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:19:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:19:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:19:38 [INFO ]  	   step  1 (lr=0.020000)                    7.02%                   8.8538
2022-10-04 14:19:38 [INFO ]  
2022-10-04 14:19:38 [INFO ]  Epoch:    0	Loss: 8.2363	Data Time: 0.40s	Train Time: 0.07s
2022-10-04 14:19:40 [INFO ]  Epoch:    1	Loss: 3.0785	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 14:19:41 [INFO ]  Epoch:    2	Loss: 2.4963	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:19:43 [INFO ]  Epoch:    3	Loss: 2.2916	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:19:45 [INFO ]  Epoch:    4	Loss: 2.2197	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:19:47 [INFO ]  Epoch:    5	Loss: 2.1658	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:19:49 [INFO ]  Epoch:    6	Loss: 2.1458	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:19:51 [INFO ]  Epoch:    7	Loss: 2.1049	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:19:52 [INFO ]  Epoch:    8	Loss: 2.0465	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:19:54 [INFO ]  Epoch:    9	Loss: 1.9325	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:19:56 [INFO ]  Epoch:   10	Loss: 1.8030	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:19:58 [INFO ]  Epoch:   11	Loss: 1.6429	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:20:00 [INFO ]  Epoch:   12	Loss: 1.5414	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:20:02 [INFO ]  Epoch:   13	Loss: 1.4202	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:04 [INFO ]  Epoch:   14	Loss: 1.3369	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:05 [INFO ]  Epoch:   15	Loss: 1.2048	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:20:07 [INFO ]  Epoch:   16	Loss: 1.1620	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:20:09 [INFO ]  Epoch:   17	Loss: 1.0418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:11 [INFO ]  Epoch:   18	Loss: 1.0214	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:20:13 [INFO ]  Epoch:   19	Loss: 1.1110	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:15 [INFO ]  Epoch:   20	Loss: 1.0627	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:20:17 [INFO ]  Epoch:   21	Loss: 0.9683	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:19 [INFO ]  Epoch:   22	Loss: 0.9228	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:21 [INFO ]  Epoch:   23	Loss: 0.8587	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:23 [INFO ]  Epoch:   24	Loss: 0.8168	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:20:24 [INFO ]  Epoch:   25	Loss: 0.9982	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:20:26 [INFO ]  Epoch:   26	Loss: 0.8450	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:28 [INFO ]  Epoch:   27	Loss: 0.8221	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:30 [INFO ]  Epoch:   28	Loss: 0.7908	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:20:32 [INFO ]  Epoch:   29	Loss: 0.7809	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:20:34 [INFO ]  Epoch:   30	Loss: 0.8403	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:36 [INFO ]  Epoch:   31	Loss: 0.7784	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:20:38 [INFO ]  Epoch:   32	Loss: 0.7043	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:20:40 [INFO ]  Epoch:   33	Loss: 0.8027	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:20:41 [INFO ]  Epoch:   34	Loss: 0.6357	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:43 [INFO ]  Epoch:   35	Loss: 0.8338	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:20:45 [INFO ]  Epoch:   36	Loss: 0.7167	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:47 [INFO ]  Epoch:   37	Loss: 0.8172	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:20:49 [INFO ]  Epoch:   38	Loss: 0.7760	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:51 [INFO ]  Epoch:   39	Loss: 0.6628	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:52 [INFO ]  Epoch:   40	Loss: 0.6873	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:54 [INFO ]  Epoch:   41	Loss: 0.6387	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:20:56 [INFO ]  Epoch:   42	Loss: 0.6643	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:20:58 [INFO ]  Epoch:   43	Loss: 0.6711	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:21:00 [INFO ]  Epoch:   44	Loss: 0.6748	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:21:01 [INFO ]  Epoch:   45	Loss: 0.6600	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:21:03 [INFO ]  Epoch:   46	Loss: 0.6418	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:21:05 [INFO ]  Epoch:   47	Loss: 0.6470	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:21:07 [INFO ]  Epoch:   48	Loss: 0.7164	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:21:09 [INFO ]  Epoch:   49	Loss: 0.6791	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:21:11 [INFO ]  Epoch:   50	Loss: 0.5736	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:21:13 [INFO ]  Epoch:   51	Loss: 0.5494	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:14 [INFO ]  Epoch:   52	Loss: 0.5594	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:16 [INFO ]  Epoch:   53	Loss: 0.6098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:18 [INFO ]  Epoch:   54	Loss: 0.5637	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:21:20 [INFO ]  Epoch:   55	Loss: 0.5921	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:22 [INFO ]  Epoch:   56	Loss: 0.5729	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:24 [INFO ]  Epoch:   57	Loss: 0.6065	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:21:26 [INFO ]  Epoch:   58	Loss: 0.5853	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:28 [INFO ]  Epoch:   59	Loss: 0.6243	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:30 [INFO ]  Epoch:   60	Loss: 0.6162	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:21:32 [INFO ]  Epoch:   61	Loss: 0.6125	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:21:33 [INFO ]  Epoch:   62	Loss: 0.5640	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:21:35 [INFO ]  Epoch:   63	Loss: 0.6246	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:21:37 [INFO ]  Epoch:   64	Loss: 0.5555	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:21:39 [INFO ]  Epoch:   65	Loss: 0.5992	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:21:41 [INFO ]  Epoch:   66	Loss: 0.5916	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:21:43 [INFO ]  Epoch:   67	Loss: 0.5678	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:21:45 [INFO ]  Epoch:   68	Loss: 0.5441	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:21:46 [INFO ]  Epoch:   69	Loss: 0.5905	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:21:48 [INFO ]  Epoch:   70	Loss: 0.6069	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:50 [INFO ]  Epoch:   71	Loss: 0.6220	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:21:52 [INFO ]  Epoch:   72	Loss: 0.6584	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:54 [INFO ]  Epoch:   73	Loss: 0.5767	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:56 [INFO ]  Epoch:   74	Loss: 0.6339	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:21:58 [INFO ]  Epoch:   75	Loss: 0.5602	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:22:00 [INFO ]  Epoch:   76	Loss: 0.6489	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:01 [INFO ]  Epoch:   77	Loss: 0.5936	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:03 [INFO ]  Epoch:   78	Loss: 0.6098	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:05 [INFO ]  Epoch:   79	Loss: 0.6238	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:07 [INFO ]  Epoch:   80	Loss: 0.5989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:09 [INFO ]  Epoch:   81	Loss: 0.5927	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:11 [INFO ]  Epoch:   82	Loss: 0.5738	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:12 [INFO ]  Epoch:   83	Loss: 0.5959	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:14 [INFO ]  Epoch:   84	Loss: 0.5593	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:16 [INFO ]  Epoch:   85	Loss: 0.5660	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:18 [INFO ]  Epoch:   86	Loss: 0.5580	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:22:20 [INFO ]  Epoch:   87	Loss: 0.5886	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:22:22 [INFO ]  Epoch:   88	Loss: 0.5695	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:23 [INFO ]  Epoch:   89	Loss: 0.6495	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:25 [INFO ]  Epoch:   90	Loss: 0.5538	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:27 [INFO ]  Epoch:   91	Loss: 0.5428	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:22:29 [INFO ]  Epoch:   92	Loss: 0.5599	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:22:31 [INFO ]  Epoch:   93	Loss: 0.5759	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:22:33 [INFO ]  Epoch:   94	Loss: 0.6598	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:22:35 [INFO ]  Epoch:   95	Loss: 0.5517	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:22:37 [INFO ]  Epoch:   96	Loss: 0.6260	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:39 [INFO ]  Epoch:   97	Loss: 0.6439	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:41 [INFO ]  Epoch:   98	Loss: 0.6003	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:22:42 [INFO ]  Epoch:   99	Loss: 0.5791	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:44 [INFO ]  Epoch:  100	Loss: 0.4833	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:22:46 [INFO ]  Epoch:  101	Loss: 0.5376	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:22:48 [INFO ]  Epoch:  102	Loss: 0.6480	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:50 [INFO ]  Epoch:  103	Loss: 0.4911	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:22:51 [INFO ]  Epoch:  104	Loss: 0.5300	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:22:53 [INFO ]  Epoch:  105	Loss: 0.5336	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:22:55 [INFO ]  Epoch:  106	Loss: 0.5369	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:22:57 [INFO ]  Epoch:  107	Loss: 0.5269	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:22:59 [INFO ]  Epoch:  108	Loss: 0.5755	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:01 [INFO ]  Epoch:  109	Loss: 0.5691	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:23:03 [INFO ]  Epoch:  110	Loss: 0.5862	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:23:05 [INFO ]  Epoch:  111	Loss: 0.5955	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:23:07 [INFO ]  Epoch:  112	Loss: 0.5323	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:09 [INFO ]  Epoch:  113	Loss: 0.5588	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:23:10 [INFO ]  Epoch:  114	Loss: 0.5741	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:23:12 [INFO ]  Epoch:  115	Loss: 0.5207	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:23:14 [INFO ]  Epoch:  116	Loss: 0.5287	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:23:16 [INFO ]  Epoch:  117	Loss: 0.6278	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:18 [INFO ]  Epoch:  118	Loss: 0.5019	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:23:20 [INFO ]  Epoch:  119	Loss: 0.5885	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:23:22 [INFO ]  Epoch:  120	Loss: 0.5598	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:23:23 [INFO ]  Epoch:  121	Loss: 0.5622	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:25 [INFO ]  Epoch:  122	Loss: 0.5187	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:27 [INFO ]  Epoch:  123	Loss: 0.4860	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:23:29 [INFO ]  Epoch:  124	Loss: 0.5275	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:31 [INFO ]  Epoch:  125	Loss: 0.4991	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:23:33 [INFO ]  Epoch:  126	Loss: 0.5233	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:35 [INFO ]  Epoch:  127	Loss: 0.5693	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:36 [INFO ]  Epoch:  128	Loss: 0.5027	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:23:38 [INFO ]  Epoch:  129	Loss: 0.5736	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:23:40 [INFO ]  Epoch:  130	Loss: 0.5871	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:42 [INFO ]  Epoch:  131	Loss: 0.5304	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:44 [INFO ]  Epoch:  132	Loss: 0.5220	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:45 [INFO ]  Epoch:  133	Loss: 0.5727	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:47 [INFO ]  Epoch:  134	Loss: 0.5867	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:49 [INFO ]  Epoch:  135	Loss: 0.5777	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:23:51 [INFO ]  Epoch:  136	Loss: 0.5469	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:53 [INFO ]  Epoch:  137	Loss: 0.5666	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:23:55 [INFO ]  Epoch:  138	Loss: 0.6271	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:23:57 [INFO ]  Epoch:  139	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:23:59 [INFO ]  Epoch:  140	Loss: 0.5308	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:24:01 [INFO ]  Epoch:  141	Loss: 0.5520	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:03 [INFO ]  Epoch:  142	Loss: 0.5454	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:24:04 [INFO ]  Epoch:  143	Loss: 0.5306	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:24:06 [INFO ]  Epoch:  144	Loss: 0.5351	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:08 [INFO ]  Epoch:  145	Loss: 0.5635	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:24:10 [INFO ]  Epoch:  146	Loss: 0.6139	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:12 [INFO ]  Epoch:  147	Loss: 0.5707	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:13 [INFO ]  Epoch:  148	Loss: 0.5932	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:24:15 [INFO ]  Epoch:  149	Loss: 0.6163	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:17 [INFO ]  Epoch:  150	Loss: 0.5750	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:24:19 [INFO ]  Epoch:  151	Loss: 0.5772	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:21 [INFO ]  Epoch:  152	Loss: 0.5240	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:23 [INFO ]  Epoch:  153	Loss: 0.4890	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:24:25 [INFO ]  Epoch:  154	Loss: 0.4979	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:27 [INFO ]  Epoch:  155	Loss: 0.5184	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:24:29 [INFO ]  Epoch:  156	Loss: 0.5854	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:30 [INFO ]  Epoch:  157	Loss: 0.5333	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:24:32 [INFO ]  Epoch:  158	Loss: 0.5815	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:34 [INFO ]  Epoch:  159	Loss: 0.5842	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:24:36 [INFO ]  Epoch:  160	Loss: 0.5950	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:38 [INFO ]  Epoch:  161	Loss: 0.5616	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:24:40 [INFO ]  Epoch:  162	Loss: 0.5211	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:42 [INFO ]  Epoch:  163	Loss: 0.5885	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:24:43 [INFO ]  Epoch:  164	Loss: 0.5728	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:45 [INFO ]  Epoch:  165	Loss: 0.5898	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:47 [INFO ]  Epoch:  166	Loss: 0.5842	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:24:49 [INFO ]  Epoch:  167	Loss: 0.5217	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:24:51 [INFO ]  Epoch:  168	Loss: 0.5447	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:24:53 [INFO ]  Epoch:  169	Loss: 0.5109	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:24:54 [INFO ]  Epoch:  170	Loss: 0.4722	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:24:56 [INFO ]  Epoch:  171	Loss: 0.5516	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:24:58 [INFO ]  Epoch:  172	Loss: 0.5822	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:25:00 [INFO ]  Epoch:  173	Loss: 0.4997	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:02 [INFO ]  Epoch:  174	Loss: 0.6069	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:04 [INFO ]  Epoch:  175	Loss: 0.5185	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:25:05 [INFO ]  Epoch:  176	Loss: 0.5698	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:25:07 [INFO ]  Epoch:  177	Loss: 0.4871	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:25:09 [INFO ]  Epoch:  178	Loss: 0.5882	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:25:11 [INFO ]  Epoch:  179	Loss: 0.6039	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:13 [INFO ]  Epoch:  180	Loss: 0.5593	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:25:15 [INFO ]  Epoch:  181	Loss: 0.5618	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:25:17 [INFO ]  Epoch:  182	Loss: 0.5732	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:18 [INFO ]  Epoch:  183	Loss: 0.5960	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:25:20 [INFO ]  Epoch:  184	Loss: 0.5309	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:25:22 [INFO ]  Epoch:  185	Loss: 0.6024	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:24 [INFO ]  Epoch:  186	Loss: 0.4921	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:26 [INFO ]  Epoch:  187	Loss: 0.4918	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:28 [INFO ]  Epoch:  188	Loss: 0.5784	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:25:30 [INFO ]  Epoch:  189	Loss: 0.5261	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:25:31 [INFO ]  Epoch:  190	Loss: 0.5022	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:25:33 [INFO ]  Epoch:  191	Loss: 0.4601	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:25:35 [INFO ]  Epoch:  192	Loss: 0.5417	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:25:37 [INFO ]  Epoch:  193	Loss: 0.5417	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:25:39 [INFO ]  Epoch:  194	Loss: 0.5053	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:41 [INFO ]  Epoch:  195	Loss: 0.5251	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:43 [INFO ]  Epoch:  196	Loss: 0.5420	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:25:45 [INFO ]  Epoch:  197	Loss: 0.5445	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:25:46 [INFO ]  Epoch:  198	Loss: 0.5922	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:25:48 [INFO ]  Epoch:  199	Loss: 0.5730	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:25:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 14:25:50 [INFO ]  
2022-10-04 14:25:50 [INFO ]  Final evaluation for SVHN :
2022-10-04 14:25:53 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:25:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:25:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:25:53 [INFO ]  	   step  1 (lr=0.471845)                   82.67%                   0.6360
2022-10-04 14:25:53 [INFO ]  
2022-10-04 14:25:53 [INFO ]  
2022-10-04 14:25:53 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 14:25:56 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:25:56 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:25:56 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 14:25:56 [INFO ]  	   step  1 (lr=0.471845)                   14.81%                   5.9925
2022-10-04 14:25:56 [INFO ]  
2022-10-04 14:25:56 [INFO ]  CPU Time: 3.55 minutes
2022-10-04 14:26:24 [INFO ]  ======================================== 2022-10-04 14:26:24 ========================================
2022-10-04 14:26:24 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:26:24 [INFO ]  Options: 
2022-10-04 14:26:24 [INFO ]  	base_dir: null
2022-10-04 14:26:24 [INFO ]  	batch_size: 1024
2022-10-04 14:26:24 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:26:24 [INFO ]  	dataset: SVHN
2022-10-04 14:26:24 [INFO ]  	dataset_labels:
2022-10-04 14:26:24 [INFO ]  	- 0
2022-10-04 14:26:24 [INFO ]  	- 1
2022-10-04 14:26:24 [INFO ]  	- 2
2022-10-04 14:26:24 [INFO ]  	- 3
2022-10-04 14:26:24 [INFO ]  	- 4
2022-10-04 14:26:24 [INFO ]  	- 5
2022-10-04 14:26:24 [INFO ]  	- 6
2022-10-04 14:26:24 [INFO ]  	- 7
2022-10-04 14:26:24 [INFO ]  	- 8
2022-10-04 14:26:24 [INFO ]  	- 9
2022-10-04 14:26:24 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:26:24 [INFO ]  	- !!python/tuple
2022-10-04 14:26:24 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:26:24 [INFO ]  	    - 0.44398033618927
2022-10-04 14:26:24 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:26:24 [INFO ]  	- !!python/tuple
2022-10-04 14:26:24 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:26:24 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:26:24 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:26:24 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:26:24 [INFO ]  	decay_epochs: 50
2022-10-04 14:26:24 [INFO ]  	decay_factor: 0.1
2022-10-04 14:26:24 [INFO ]  	device_id: 0
2022-10-04 14:26:24 [INFO ]  	distill_epochs: 1
2022-10-04 14:26:24 [INFO ]  	distill_lr: 0.02
2022-10-04 14:26:24 [INFO ]  	distill_steps: 1
2022-10-04 14:26:24 [INFO ]  	epochs: 200
2022-10-04 14:26:24 [INFO ]  	expand_cls: false
2022-10-04 14:26:24 [INFO ]  	forgetting_dataset: null
2022-10-04 14:26:24 [INFO ]  	init: xavier
2022-10-04 14:26:24 [INFO ]  	init_param: 1.0
2022-10-04 14:26:24 [INFO ]  	input_size: 32
2022-10-04 14:26:24 [INFO ]  	ipc: 100
2022-10-04 14:26:24 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:26:24 [INFO ]  	log_interval: 100
2022-10-04 14:26:24 [INFO ]  	log_level: INFO
2022-10-04 14:26:24 [INFO ]  	lr: 0.01
2022-10-04 14:26:24 [INFO ]  	mode: distill_adapt
2022-10-04 14:26:24 [INFO ]  	nc: 3
2022-10-04 14:26:24 [INFO ]  	num_classes: 10
2022-10-04 14:26:24 [INFO ]  	num_workers: 8
2022-10-04 14:26:24 [INFO ]  	phase: train
2022-10-04 14:26:24 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:26:24 [INFO ]  	start_time: '2022-10-04 14:26:24'
2022-10-04 14:26:24 [INFO ]  	test_batch_size: 1024
2022-10-04 14:26:24 [INFO ]  	
2022-10-04 14:26:26 [INFO ]  train dataset size:	73257
2022-10-04 14:26:26 [INFO ]  test dataset size: 	26032
2022-10-04 14:26:26 [INFO ]  datasets built!
2022-10-04 14:26:26 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:26:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:26:28 [INFO ]  
2022-10-04 14:26:28 [INFO ]  Begin of epoch 0 :
2022-10-04 14:26:31 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:26:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:26:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:26:31 [INFO ]  	   step  1 (lr=0.020000)                    7.07%                   8.9413
2022-10-04 14:26:31 [INFO ]  
2022-10-04 14:26:31 [INFO ]  Epoch:    0	Loss: 8.7453	Data Time: 0.48s	Train Time: 0.08s
2022-10-04 14:26:33 [INFO ]  Epoch:    1	Loss: 3.0312	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:26:35 [INFO ]  Epoch:    2	Loss: 2.4276	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:26:37 [INFO ]  Epoch:    3	Loss: 2.2523	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:26:39 [INFO ]  Epoch:    4	Loss: 2.1936	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:26:41 [INFO ]  Epoch:    5	Loss: 2.1816	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:26:42 [INFO ]  Epoch:    6	Loss: 2.1272	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:26:44 [INFO ]  Epoch:    7	Loss: 2.0934	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:26:46 [INFO ]  Epoch:    8	Loss: 2.0370	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:26:48 [INFO ]  Epoch:    9	Loss: 1.9356	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:26:50 [INFO ]  Epoch:   10	Loss: 1.8031	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:26:52 [INFO ]  Epoch:   11	Loss: 1.7981	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:26:54 [INFO ]  Epoch:   12	Loss: 1.6439	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:26:56 [INFO ]  Epoch:   13	Loss: 1.5307	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:26:58 [INFO ]  Epoch:   14	Loss: 1.2309	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:27:00 [INFO ]  Epoch:   15	Loss: 1.3148	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:27:02 [INFO ]  Epoch:   16	Loss: 1.1625	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:04 [INFO ]  Epoch:   17	Loss: 1.1935	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:06 [INFO ]  Epoch:   18	Loss: 1.1040	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:07 [INFO ]  Epoch:   19	Loss: 1.0941	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:10 [INFO ]  Epoch:   20	Loss: 1.0512	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:27:12 [INFO ]  Epoch:   21	Loss: 0.9552	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:27:13 [INFO ]  Epoch:   22	Loss: 0.8873	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:27:15 [INFO ]  Epoch:   23	Loss: 0.8866	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:17 [INFO ]  Epoch:   24	Loss: 0.8573	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:19 [INFO ]  Epoch:   25	Loss: 0.8690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:20 [INFO ]  Epoch:   26	Loss: 0.9252	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:27:22 [INFO ]  Epoch:   27	Loss: 0.8695	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:24 [INFO ]  Epoch:   28	Loss: 0.8642	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:27:26 [INFO ]  Epoch:   29	Loss: 0.7799	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:27:28 [INFO ]  Epoch:   30	Loss: 0.8406	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:30 [INFO ]  Epoch:   31	Loss: 0.8214	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:27:31 [INFO ]  Epoch:   32	Loss: 0.7705	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:27:33 [INFO ]  Epoch:   33	Loss: 0.6651	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:35 [INFO ]  Epoch:   34	Loss: 0.7988	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:37 [INFO ]  Epoch:   35	Loss: 0.7868	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:27:39 [INFO ]  Epoch:   36	Loss: 0.6976	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:41 [INFO ]  Epoch:   37	Loss: 0.7149	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:27:43 [INFO ]  Epoch:   38	Loss: 0.8452	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:27:45 [INFO ]  Epoch:   39	Loss: 0.6665	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:27:46 [INFO ]  Epoch:   40	Loss: 0.7705	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:27:48 [INFO ]  Epoch:   41	Loss: 0.6819	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:50 [INFO ]  Epoch:   42	Loss: 0.7942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:52 [INFO ]  Epoch:   43	Loss: 0.8591	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:27:54 [INFO ]  Epoch:   44	Loss: 0.6976	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:27:56 [INFO ]  Epoch:   45	Loss: 0.6493	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:27:58 [INFO ]  Epoch:   46	Loss: 0.7249	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:28:00 [INFO ]  Epoch:   47	Loss: 0.7882	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:28:01 [INFO ]  Epoch:   48	Loss: 0.7350	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:03 [INFO ]  Epoch:   49	Loss: 0.6444	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:28:05 [INFO ]  Epoch:   50	Loss: 0.6071	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:28:07 [INFO ]  Epoch:   51	Loss: 0.5028	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:28:09 [INFO ]  Epoch:   52	Loss: 0.5541	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:11 [INFO ]  Epoch:   53	Loss: 0.6345	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:13 [INFO ]  Epoch:   54	Loss: 0.5693	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:28:15 [INFO ]  Epoch:   55	Loss: 0.5653	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:28:17 [INFO ]  Epoch:   56	Loss: 0.7133	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:19 [INFO ]  Epoch:   57	Loss: 0.6348	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:21 [INFO ]  Epoch:   58	Loss: 0.5864	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:23 [INFO ]  Epoch:   59	Loss: 0.5670	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:28:25 [INFO ]  Epoch:   60	Loss: 0.5423	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:28:26 [INFO ]  Epoch:   61	Loss: 0.6310	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:28 [INFO ]  Epoch:   62	Loss: 0.5448	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:28:30 [INFO ]  Epoch:   63	Loss: 0.5975	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:32 [INFO ]  Epoch:   64	Loss: 0.6156	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:34 [INFO ]  Epoch:   65	Loss: 0.6243	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:28:36 [INFO ]  Epoch:   66	Loss: 0.6363	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:28:38 [INFO ]  Epoch:   67	Loss: 0.6535	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:28:39 [INFO ]  Epoch:   68	Loss: 0.6345	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:28:41 [INFO ]  Epoch:   69	Loss: 0.5625	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:28:44 [INFO ]  Epoch:   70	Loss: 0.5756	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:45 [INFO ]  Epoch:   71	Loss: 0.6404	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:28:48 [INFO ]  Epoch:   72	Loss: 0.7149	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:28:50 [INFO ]  Epoch:   73	Loss: 0.6411	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:28:52 [INFO ]  Epoch:   74	Loss: 0.6345	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:28:54 [INFO ]  Epoch:   75	Loss: 0.6757	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:28:56 [INFO ]  Epoch:   76	Loss: 0.5822	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:28:58 [INFO ]  Epoch:   77	Loss: 0.6848	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:29:00 [INFO ]  Epoch:   78	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:01 [INFO ]  Epoch:   79	Loss: 0.7342	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:29:03 [INFO ]  Epoch:   80	Loss: 0.5653	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:29:06 [INFO ]  Epoch:   81	Loss: 0.6221	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:29:07 [INFO ]  Epoch:   82	Loss: 0.5475	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:29:09 [INFO ]  Epoch:   83	Loss: 0.5263	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:29:11 [INFO ]  Epoch:   84	Loss: 0.6356	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:13 [INFO ]  Epoch:   85	Loss: 0.6236	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:15 [INFO ]  Epoch:   86	Loss: 0.5379	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:16 [INFO ]  Epoch:   87	Loss: 0.5179	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:18 [INFO ]  Epoch:   88	Loss: 0.5969	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:20 [INFO ]  Epoch:   89	Loss: 0.6348	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:22 [INFO ]  Epoch:   90	Loss: 0.5828	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:24 [INFO ]  Epoch:   91	Loss: 0.5614	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:26 [INFO ]  Epoch:   92	Loss: 0.5996	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:29:28 [INFO ]  Epoch:   93	Loss: 0.5817	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:29:30 [INFO ]  Epoch:   94	Loss: 0.5989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:32 [INFO ]  Epoch:   95	Loss: 0.5405	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:34 [INFO ]  Epoch:   96	Loss: 0.5750	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:35 [INFO ]  Epoch:   97	Loss: 0.6125	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:29:37 [INFO ]  Epoch:   98	Loss: 0.6690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:39 [INFO ]  Epoch:   99	Loss: 0.5081	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:29:41 [INFO ]  Epoch:  100	Loss: 0.5549	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:43 [INFO ]  Epoch:  101	Loss: 0.6030	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:45 [INFO ]  Epoch:  102	Loss: 0.6052	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:47 [INFO ]  Epoch:  103	Loss: 0.5795	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:29:48 [INFO ]  Epoch:  104	Loss: 0.5848	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:50 [INFO ]  Epoch:  105	Loss: 0.5084	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:29:52 [INFO ]  Epoch:  106	Loss: 0.5962	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:29:54 [INFO ]  Epoch:  107	Loss: 0.6311	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:29:56 [INFO ]  Epoch:  108	Loss: 0.5460	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:29:58 [INFO ]  Epoch:  109	Loss: 0.5681	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:30:00 [INFO ]  Epoch:  110	Loss: 0.5224	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:02 [INFO ]  Epoch:  111	Loss: 0.5549	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:03 [INFO ]  Epoch:  112	Loss: 0.5033	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:30:05 [INFO ]  Epoch:  113	Loss: 0.6141	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:07 [INFO ]  Epoch:  114	Loss: 0.5942	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:09 [INFO ]  Epoch:  115	Loss: 0.6100	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:11 [INFO ]  Epoch:  116	Loss: 0.5677	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:30:13 [INFO ]  Epoch:  117	Loss: 0.5795	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:15 [INFO ]  Epoch:  118	Loss: 0.6443	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:17 [INFO ]  Epoch:  119	Loss: 0.5780	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:30:19 [INFO ]  Epoch:  120	Loss: 0.4925	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:21 [INFO ]  Epoch:  121	Loss: 0.5005	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:23 [INFO ]  Epoch:  122	Loss: 0.5962	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:25 [INFO ]  Epoch:  123	Loss: 0.6076	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:30:26 [INFO ]  Epoch:  124	Loss: 0.5367	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:30:28 [INFO ]  Epoch:  125	Loss: 0.5855	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:30 [INFO ]  Epoch:  126	Loss: 0.5764	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:32 [INFO ]  Epoch:  127	Loss: 0.6118	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:30:34 [INFO ]  Epoch:  128	Loss: 0.6358	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:30:36 [INFO ]  Epoch:  129	Loss: 0.5813	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:38 [INFO ]  Epoch:  130	Loss: 0.5157	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:30:40 [INFO ]  Epoch:  131	Loss: 0.6447	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:30:42 [INFO ]  Epoch:  132	Loss: 0.5205	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:44 [INFO ]  Epoch:  133	Loss: 0.5582	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:30:46 [INFO ]  Epoch:  134	Loss: 0.4994	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:48 [INFO ]  Epoch:  135	Loss: 0.5743	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:30:50 [INFO ]  Epoch:  136	Loss: 0.6004	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:51 [INFO ]  Epoch:  137	Loss: 0.5223	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:30:53 [INFO ]  Epoch:  138	Loss: 0.5143	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:30:55 [INFO ]  Epoch:  139	Loss: 0.5921	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:30:57 [INFO ]  Epoch:  140	Loss: 0.6539	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:30:59 [INFO ]  Epoch:  141	Loss: 0.5815	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:01 [INFO ]  Epoch:  142	Loss: 0.5733	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:31:02 [INFO ]  Epoch:  143	Loss: 0.4721	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:31:04 [INFO ]  Epoch:  144	Loss: 0.5623	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:06 [INFO ]  Epoch:  145	Loss: 0.6016	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:08 [INFO ]  Epoch:  146	Loss: 0.5271	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:31:10 [INFO ]  Epoch:  147	Loss: 0.5971	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:12 [INFO ]  Epoch:  148	Loss: 0.6083	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:14 [INFO ]  Epoch:  149	Loss: 0.5777	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:31:16 [INFO ]  Epoch:  150	Loss: 0.5188	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:18 [INFO ]  Epoch:  151	Loss: 0.5393	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:31:20 [INFO ]  Epoch:  152	Loss: 0.5360	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:21 [INFO ]  Epoch:  153	Loss: 0.5364	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:23 [INFO ]  Epoch:  154	Loss: 0.5580	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:31:25 [INFO ]  Epoch:  155	Loss: 0.5513	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:27 [INFO ]  Epoch:  156	Loss: 0.5441	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:29 [INFO ]  Epoch:  157	Loss: 0.6072	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:31:31 [INFO ]  Epoch:  158	Loss: 0.5798	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:33 [INFO ]  Epoch:  159	Loss: 0.5365	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:35 [INFO ]  Epoch:  160	Loss: 0.6389	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:37 [INFO ]  Epoch:  161	Loss: 0.5364	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:39 [INFO ]  Epoch:  162	Loss: 0.5124	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:41 [INFO ]  Epoch:  163	Loss: 0.4905	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:43 [INFO ]  Epoch:  164	Loss: 0.6034	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:44 [INFO ]  Epoch:  165	Loss: 0.5982	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:46 [INFO ]  Epoch:  166	Loss: 0.5123	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:48 [INFO ]  Epoch:  167	Loss: 0.5452	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:31:50 [INFO ]  Epoch:  168	Loss: 0.5494	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:52 [INFO ]  Epoch:  169	Loss: 0.5693	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:31:54 [INFO ]  Epoch:  170	Loss: 0.5733	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:31:56 [INFO ]  Epoch:  171	Loss: 0.6162	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:31:58 [INFO ]  Epoch:  172	Loss: 0.5672	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:32:00 [INFO ]  Epoch:  173	Loss: 0.6061	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:32:02 [INFO ]  Epoch:  174	Loss: 0.5495	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:04 [INFO ]  Epoch:  175	Loss: 0.4956	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:06 [INFO ]  Epoch:  176	Loss: 0.6116	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:08 [INFO ]  Epoch:  177	Loss: 0.5479	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:09 [INFO ]  Epoch:  178	Loss: 0.6079	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:11 [INFO ]  Epoch:  179	Loss: 0.6090	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:32:13 [INFO ]  Epoch:  180	Loss: 0.5467	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:32:15 [INFO ]  Epoch:  181	Loss: 0.6231	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:32:17 [INFO ]  Epoch:  182	Loss: 0.6050	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:32:19 [INFO ]  Epoch:  183	Loss: 0.6024	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:32:21 [INFO ]  Epoch:  184	Loss: 0.5300	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:23 [INFO ]  Epoch:  185	Loss: 0.5006	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:32:24 [INFO ]  Epoch:  186	Loss: 0.4557	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:26 [INFO ]  Epoch:  187	Loss: 0.6296	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:28 [INFO ]  Epoch:  188	Loss: 0.6031	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:30 [INFO ]  Epoch:  189	Loss: 0.6165	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:32:32 [INFO ]  Epoch:  190	Loss: 0.5470	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:34 [INFO ]  Epoch:  191	Loss: 0.5740	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:32:36 [INFO ]  Epoch:  192	Loss: 0.6025	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:32:38 [INFO ]  Epoch:  193	Loss: 0.5249	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:39 [INFO ]  Epoch:  194	Loss: 0.5077	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:32:41 [INFO ]  Epoch:  195	Loss: 0.5661	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:32:43 [INFO ]  Epoch:  196	Loss: 0.5646	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:32:45 [INFO ]  Epoch:  197	Loss: 0.5497	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:47 [INFO ]  Epoch:  198	Loss: 0.5309	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:49 [INFO ]  Epoch:  199	Loss: 0.5832	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:32:50 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 14:32:50 [INFO ]  
2022-10-04 14:32:50 [INFO ]  Final evaluation for SVHN :
2022-10-04 14:32:54 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:32:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:32:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:32:54 [INFO ]  	   step  1 (lr=0.457989)                   82.63%                   0.6404
2022-10-04 14:32:54 [INFO ]  
2022-10-04 14:32:54 [INFO ]  
2022-10-04 14:32:54 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 14:32:57 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:32:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:32:57 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 14:32:57 [INFO ]  	   step  1 (lr=0.457989)                   15.47%                   5.5606
2022-10-04 14:32:57 [INFO ]  
2022-10-04 14:32:57 [INFO ]  CPU Time: 3.62 minutes
2022-10-04 14:37:24 [INFO ]  ======================================== 2022-10-04 14:37:24 ========================================
2022-10-04 14:37:24 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:37:24 [INFO ]  Options: 
2022-10-04 14:37:24 [INFO ]  	base_dir: null
2022-10-04 14:37:24 [INFO ]  	batch_size: 1024
2022-10-04 14:37:24 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:37:24 [INFO ]  	dataset: SVHN
2022-10-04 14:37:24 [INFO ]  	dataset_labels:
2022-10-04 14:37:24 [INFO ]  	- 0
2022-10-04 14:37:24 [INFO ]  	- 1
2022-10-04 14:37:24 [INFO ]  	- 2
2022-10-04 14:37:24 [INFO ]  	- 3
2022-10-04 14:37:24 [INFO ]  	- 4
2022-10-04 14:37:24 [INFO ]  	- 5
2022-10-04 14:37:24 [INFO ]  	- 6
2022-10-04 14:37:24 [INFO ]  	- 7
2022-10-04 14:37:24 [INFO ]  	- 8
2022-10-04 14:37:24 [INFO ]  	- 9
2022-10-04 14:37:24 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:37:24 [INFO ]  	- !!python/tuple
2022-10-04 14:37:24 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:37:24 [INFO ]  	    - 0.44398033618927
2022-10-04 14:37:24 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:37:24 [INFO ]  	- !!python/tuple
2022-10-04 14:37:24 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:37:24 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:37:24 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:37:24 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:37:24 [INFO ]  	decay_epochs: 50
2022-10-04 14:37:24 [INFO ]  	decay_factor: 0.1
2022-10-04 14:37:24 [INFO ]  	device_id: 0
2022-10-04 14:37:24 [INFO ]  	distill_epochs: 1
2022-10-04 14:37:24 [INFO ]  	distill_lr: 0.02
2022-10-04 14:37:24 [INFO ]  	distill_steps: 1
2022-10-04 14:37:24 [INFO ]  	epochs: 200
2022-10-04 14:37:24 [INFO ]  	expand_cls: false
2022-10-04 14:37:24 [INFO ]  	forgetting_dataset: null
2022-10-04 14:37:24 [INFO ]  	init: xavier
2022-10-04 14:37:24 [INFO ]  	init_param: 1.0
2022-10-04 14:37:24 [INFO ]  	input_size: 32
2022-10-04 14:37:24 [INFO ]  	ipc: 100
2022-10-04 14:37:24 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:37:24 [INFO ]  	log_interval: 100
2022-10-04 14:37:24 [INFO ]  	log_level: INFO
2022-10-04 14:37:24 [INFO ]  	lr: 0.01
2022-10-04 14:37:24 [INFO ]  	mode: distill_adapt
2022-10-04 14:37:24 [INFO ]  	nc: 3
2022-10-04 14:37:24 [INFO ]  	num_classes: 10
2022-10-04 14:37:24 [INFO ]  	num_workers: 8
2022-10-04 14:37:24 [INFO ]  	phase: train
2022-10-04 14:37:24 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:37:24 [INFO ]  	start_time: '2022-10-04 14:37:24'
2022-10-04 14:37:24 [INFO ]  	test_batch_size: 1024
2022-10-04 14:37:24 [INFO ]  	
2022-10-04 14:37:26 [INFO ]  train dataset size:	73257
2022-10-04 14:37:26 [INFO ]  test dataset size: 	26032
2022-10-04 14:37:26 [INFO ]  datasets built!
2022-10-04 14:37:26 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:37:28 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:37:28 [INFO ]  
2022-10-04 14:37:28 [INFO ]  Begin of epoch 0 :
2022-10-04 14:37:31 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:37:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:37:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:37:31 [INFO ]  	   step  1 (lr=0.020000)                    6.97%                   8.8340
2022-10-04 14:37:31 [INFO ]  
2022-10-04 14:37:32 [INFO ]  Epoch:    0	Loss: 8.7687	Data Time: 0.38s	Train Time: 0.08s
2022-10-04 14:37:33 [INFO ]  Epoch:    1	Loss: 3.1024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:37:35 [INFO ]  Epoch:    2	Loss: 2.4691	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:37:37 [INFO ]  Epoch:    3	Loss: 2.2709	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:37:39 [INFO ]  Epoch:    4	Loss: 2.2414	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:37:41 [INFO ]  Epoch:    5	Loss: 2.1946	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:37:43 [INFO ]  Epoch:    6	Loss: 2.1252	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:37:45 [INFO ]  Epoch:    7	Loss: 2.1335	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:37:47 [INFO ]  Epoch:    8	Loss: 2.0528	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:37:49 [INFO ]  Epoch:    9	Loss: 1.9648	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:37:51 [INFO ]  Epoch:   10	Loss: 1.8489	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:37:52 [INFO ]  Epoch:   11	Loss: 1.7667	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:37:54 [INFO ]  Epoch:   12	Loss: 1.6219	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:37:56 [INFO ]  Epoch:   13	Loss: 1.3937	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:37:58 [INFO ]  Epoch:   14	Loss: 1.4181	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:38:00 [INFO ]  Epoch:   15	Loss: 1.2244	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:38:02 [INFO ]  Epoch:   16	Loss: 1.1601	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:38:04 [INFO ]  Epoch:   17	Loss: 1.1818	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:06 [INFO ]  Epoch:   18	Loss: 1.0153	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:38:08 [INFO ]  Epoch:   19	Loss: 0.9760	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:10 [INFO ]  Epoch:   20	Loss: 0.9343	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:38:11 [INFO ]  Epoch:   21	Loss: 0.9430	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:13 [INFO ]  Epoch:   22	Loss: 0.9897	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:38:15 [INFO ]  Epoch:   23	Loss: 1.0579	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:17 [INFO ]  Epoch:   24	Loss: 0.9509	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:38:19 [INFO ]  Epoch:   25	Loss: 0.8682	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:38:21 [INFO ]  Epoch:   26	Loss: 0.8934	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:23 [INFO ]  Epoch:   27	Loss: 0.8533	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:38:25 [INFO ]  Epoch:   28	Loss: 0.7255	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:27 [INFO ]  Epoch:   29	Loss: 0.8565	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:38:29 [INFO ]  Epoch:   30	Loss: 0.8248	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:38:30 [INFO ]  Epoch:   31	Loss: 0.8632	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:32 [INFO ]  Epoch:   32	Loss: 0.8008	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:38:34 [INFO ]  Epoch:   33	Loss: 0.7892	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:38:36 [INFO ]  Epoch:   34	Loss: 0.7403	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:38:38 [INFO ]  Epoch:   35	Loss: 0.7985	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:40 [INFO ]  Epoch:   36	Loss: 0.7659	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:42 [INFO ]  Epoch:   37	Loss: 0.6685	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:44 [INFO ]  Epoch:   38	Loss: 0.7405	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:38:46 [INFO ]  Epoch:   39	Loss: 0.7324	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:47 [INFO ]  Epoch:   40	Loss: 0.7303	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:49 [INFO ]  Epoch:   41	Loss: 0.6750	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:51 [INFO ]  Epoch:   42	Loss: 0.7633	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:53 [INFO ]  Epoch:   43	Loss: 0.6547	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:38:55 [INFO ]  Epoch:   44	Loss: 0.6471	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:38:57 [INFO ]  Epoch:   45	Loss: 0.8164	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:38:59 [INFO ]  Epoch:   46	Loss: 0.6728	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:00 [INFO ]  Epoch:   47	Loss: 0.6830	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:39:02 [INFO ]  Epoch:   48	Loss: 0.6712	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:39:04 [INFO ]  Epoch:   49	Loss: 0.6632	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:39:06 [INFO ]  Epoch:   50	Loss: 0.5641	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:08 [INFO ]  Epoch:   51	Loss: 0.6337	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:39:10 [INFO ]  Epoch:   52	Loss: 0.5411	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:39:12 [INFO ]  Epoch:   53	Loss: 0.6150	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:39:13 [INFO ]  Epoch:   54	Loss: 0.5787	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:39:15 [INFO ]  Epoch:   55	Loss: 0.6134	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:39:17 [INFO ]  Epoch:   56	Loss: 0.6640	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:39:19 [INFO ]  Epoch:   57	Loss: 0.5668	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:39:21 [INFO ]  Epoch:   58	Loss: 0.5814	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:39:22 [INFO ]  Epoch:   59	Loss: 0.6381	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:39:24 [INFO ]  Epoch:   60	Loss: 0.5839	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:26 [INFO ]  Epoch:   61	Loss: 0.5719	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:28 [INFO ]  Epoch:   62	Loss: 0.6734	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:39:30 [INFO ]  Epoch:   63	Loss: 0.5354	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:39:32 [INFO ]  Epoch:   64	Loss: 0.7000	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:39:34 [INFO ]  Epoch:   65	Loss: 0.6301	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:39:36 [INFO ]  Epoch:   66	Loss: 0.5948	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:39:38 [INFO ]  Epoch:   67	Loss: 0.5466	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:39:39 [INFO ]  Epoch:   68	Loss: 0.5898	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:39:41 [INFO ]  Epoch:   69	Loss: 0.6350	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:39:43 [INFO ]  Epoch:   70	Loss: 0.6183	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:45 [INFO ]  Epoch:   71	Loss: 0.6069	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:39:47 [INFO ]  Epoch:   72	Loss: 0.6159	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:39:49 [INFO ]  Epoch:   73	Loss: 0.6042	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:39:51 [INFO ]  Epoch:   74	Loss: 0.6427	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:39:53 [INFO ]  Epoch:   75	Loss: 0.6636	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:39:55 [INFO ]  Epoch:   76	Loss: 0.6622	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:57 [INFO ]  Epoch:   77	Loss: 0.6286	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:39:59 [INFO ]  Epoch:   78	Loss: 0.6785	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:01 [INFO ]  Epoch:   79	Loss: 0.6475	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:02 [INFO ]  Epoch:   80	Loss: 0.5769	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:04 [INFO ]  Epoch:   81	Loss: 0.5947	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:40:06 [INFO ]  Epoch:   82	Loss: 0.6575	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:40:08 [INFO ]  Epoch:   83	Loss: 0.5820	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:10 [INFO ]  Epoch:   84	Loss: 0.5492	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:40:12 [INFO ]  Epoch:   85	Loss: 0.5975	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:40:14 [INFO ]  Epoch:   86	Loss: 0.5142	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:16 [INFO ]  Epoch:   87	Loss: 0.6505	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:40:18 [INFO ]  Epoch:   88	Loss: 0.6287	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:40:19 [INFO ]  Epoch:   89	Loss: 0.5354	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:21 [INFO ]  Epoch:   90	Loss: 0.5627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:23 [INFO ]  Epoch:   91	Loss: 0.6565	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:40:25 [INFO ]  Epoch:   92	Loss: 0.6147	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:27 [INFO ]  Epoch:   93	Loss: 0.5686	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:29 [INFO ]  Epoch:   94	Loss: 0.5653	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:40:31 [INFO ]  Epoch:   95	Loss: 0.5351	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:40:33 [INFO ]  Epoch:   96	Loss: 0.5947	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:35 [INFO ]  Epoch:   97	Loss: 0.5976	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:40:36 [INFO ]  Epoch:   98	Loss: 0.6132	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:40:38 [INFO ]  Epoch:   99	Loss: 0.5639	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:40 [INFO ]  Epoch:  100	Loss: 0.6307	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:40:42 [INFO ]  Epoch:  101	Loss: 0.6278	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:40:44 [INFO ]  Epoch:  102	Loss: 0.5833	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:40:45 [INFO ]  Epoch:  103	Loss: 0.5466	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:47 [INFO ]  Epoch:  104	Loss: 0.6020	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:40:49 [INFO ]  Epoch:  105	Loss: 0.5433	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:40:51 [INFO ]  Epoch:  106	Loss: 0.5981	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:40:53 [INFO ]  Epoch:  107	Loss: 0.6083	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:40:55 [INFO ]  Epoch:  108	Loss: 0.5733	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:40:57 [INFO ]  Epoch:  109	Loss: 0.6065	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:40:58 [INFO ]  Epoch:  110	Loss: 0.5641	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:00 [INFO ]  Epoch:  111	Loss: 0.5217	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:41:02 [INFO ]  Epoch:  112	Loss: 0.6059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:04 [INFO ]  Epoch:  113	Loss: 0.6550	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:06 [INFO ]  Epoch:  114	Loss: 0.5391	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:41:08 [INFO ]  Epoch:  115	Loss: 0.4980	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:09 [INFO ]  Epoch:  116	Loss: 0.4876	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:41:11 [INFO ]  Epoch:  117	Loss: 0.5215	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:13 [INFO ]  Epoch:  118	Loss: 0.5859	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:15 [INFO ]  Epoch:  119	Loss: 0.5994	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:16 [INFO ]  Epoch:  120	Loss: 0.5801	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:19 [INFO ]  Epoch:  121	Loss: 0.5834	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:21 [INFO ]  Epoch:  122	Loss: 0.5275	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:41:22 [INFO ]  Epoch:  123	Loss: 0.5587	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 14:41:24 [INFO ]  Epoch:  124	Loss: 0.5512	Data Time: 0.29s	Train Time: 0.01s
2022-10-04 14:41:26 [INFO ]  Epoch:  125	Loss: 0.6110	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:41:28 [INFO ]  Epoch:  126	Loss: 0.5228	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:41:30 [INFO ]  Epoch:  127	Loss: 0.6290	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:41:32 [INFO ]  Epoch:  128	Loss: 0.5968	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:34 [INFO ]  Epoch:  129	Loss: 0.5597	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:36 [INFO ]  Epoch:  130	Loss: 0.4975	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:41:38 [INFO ]  Epoch:  131	Loss: 0.5693	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:41:39 [INFO ]  Epoch:  132	Loss: 0.5358	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:41:41 [INFO ]  Epoch:  133	Loss: 0.6061	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:41:43 [INFO ]  Epoch:  134	Loss: 0.5759	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:41:45 [INFO ]  Epoch:  135	Loss: 0.6096	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:41:47 [INFO ]  Epoch:  136	Loss: 0.6281	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:41:49 [INFO ]  Epoch:  137	Loss: 0.6062	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:50 [INFO ]  Epoch:  138	Loss: 0.5914	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:52 [INFO ]  Epoch:  139	Loss: 0.5090	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:54 [INFO ]  Epoch:  140	Loss: 0.5862	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:41:56 [INFO ]  Epoch:  141	Loss: 0.5623	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:41:58 [INFO ]  Epoch:  142	Loss: 0.5925	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:42:00 [INFO ]  Epoch:  143	Loss: 0.6525	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:02 [INFO ]  Epoch:  144	Loss: 0.5329	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:04 [INFO ]  Epoch:  145	Loss: 0.5926	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:06 [INFO ]  Epoch:  146	Loss: 0.5495	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:42:08 [INFO ]  Epoch:  147	Loss: 0.5071	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:10 [INFO ]  Epoch:  148	Loss: 0.5903	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:11 [INFO ]  Epoch:  149	Loss: 0.5028	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:42:13 [INFO ]  Epoch:  150	Loss: 0.5153	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:42:15 [INFO ]  Epoch:  151	Loss: 0.5833	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:17 [INFO ]  Epoch:  152	Loss: 0.5674	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:42:19 [INFO ]  Epoch:  153	Loss: 0.5413	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:42:21 [INFO ]  Epoch:  154	Loss: 0.5425	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:42:23 [INFO ]  Epoch:  155	Loss: 0.5336	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:24 [INFO ]  Epoch:  156	Loss: 0.4982	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:42:26 [INFO ]  Epoch:  157	Loss: 0.5386	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:42:28 [INFO ]  Epoch:  158	Loss: 0.5070	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:42:30 [INFO ]  Epoch:  159	Loss: 0.5697	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:42:32 [INFO ]  Epoch:  160	Loss: 0.5714	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:42:34 [INFO ]  Epoch:  161	Loss: 0.4983	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:42:36 [INFO ]  Epoch:  162	Loss: 0.6020	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:42:38 [INFO ]  Epoch:  163	Loss: 0.5714	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:42:39 [INFO ]  Epoch:  164	Loss: 0.5661	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:42:42 [INFO ]  Epoch:  165	Loss: 0.5618	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:42:43 [INFO ]  Epoch:  166	Loss: 0.5901	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:42:45 [INFO ]  Epoch:  167	Loss: 0.6070	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:42:47 [INFO ]  Epoch:  168	Loss: 0.5870	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:42:49 [INFO ]  Epoch:  169	Loss: 0.5070	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:42:51 [INFO ]  Epoch:  170	Loss: 0.5606	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:42:53 [INFO ]  Epoch:  171	Loss: 0.5506	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:42:55 [INFO ]  Epoch:  172	Loss: 0.5990	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:42:56 [INFO ]  Epoch:  173	Loss: 0.5365	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:42:58 [INFO ]  Epoch:  174	Loss: 0.5166	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:43:00 [INFO ]  Epoch:  175	Loss: 0.5631	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:43:02 [INFO ]  Epoch:  176	Loss: 0.5523	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:43:04 [INFO ]  Epoch:  177	Loss: 0.5638	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:43:06 [INFO ]  Epoch:  178	Loss: 0.5987	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:43:08 [INFO ]  Epoch:  179	Loss: 0.5692	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:43:10 [INFO ]  Epoch:  180	Loss: 0.5800	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:43:12 [INFO ]  Epoch:  181	Loss: 0.4867	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:43:14 [INFO ]  Epoch:  182	Loss: 0.5681	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:43:16 [INFO ]  Epoch:  183	Loss: 0.5185	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:43:18 [INFO ]  Epoch:  184	Loss: 0.5357	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:43:20 [INFO ]  Epoch:  185	Loss: 0.5750	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:43:22 [INFO ]  Epoch:  186	Loss: 0.5420	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:43:24 [INFO ]  Epoch:  187	Loss: 0.5601	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:43:26 [INFO ]  Epoch:  188	Loss: 0.5500	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 14:43:28 [INFO ]  Epoch:  189	Loss: 0.5868	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:43:30 [INFO ]  Epoch:  190	Loss: 0.5154	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:43:32 [INFO ]  Epoch:  191	Loss: 0.5563	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:43:33 [INFO ]  Epoch:  192	Loss: 0.5523	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:43:35 [INFO ]  Epoch:  193	Loss: 0.5289	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:43:37 [INFO ]  Epoch:  194	Loss: 0.6050	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:43:39 [INFO ]  Epoch:  195	Loss: 0.6302	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:43:41 [INFO ]  Epoch:  196	Loss: 0.6031	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:43:43 [INFO ]  Epoch:  197	Loss: 0.6064	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:43:45 [INFO ]  Epoch:  198	Loss: 0.4734	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:43:47 [INFO ]  Epoch:  199	Loss: 0.5618	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:43:48 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 14:43:48 [INFO ]  
2022-10-04 14:43:48 [INFO ]  Final evaluation for SVHN :
2022-10-04 14:43:52 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:43:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:43:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:43:52 [INFO ]  	   step  1 (lr=0.474889)                   82.96%                   0.6393
2022-10-04 14:43:52 [INFO ]  
2022-10-04 14:43:52 [INFO ]  
2022-10-04 14:43:52 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 14:43:55 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:43:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:43:55 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 14:43:55 [INFO ]  	   step  1 (lr=0.474889)                   13.60%                   5.8728
2022-10-04 14:43:55 [INFO ]  
2022-10-04 14:43:55 [INFO ]  CPU Time: 3.60 minutes
2022-10-04 14:44:34 [INFO ]  ======================================== 2022-10-04 14:44:34 ========================================
2022-10-04 14:44:34 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:44:34 [INFO ]  Options: 
2022-10-04 14:44:34 [INFO ]  	base_dir: null
2022-10-04 14:44:34 [INFO ]  	batch_size: 1024
2022-10-04 14:44:34 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:44:34 [INFO ]  	dataset: SVHN
2022-10-04 14:44:34 [INFO ]  	dataset_labels:
2022-10-04 14:44:34 [INFO ]  	- 0
2022-10-04 14:44:34 [INFO ]  	- 1
2022-10-04 14:44:34 [INFO ]  	- 2
2022-10-04 14:44:34 [INFO ]  	- 3
2022-10-04 14:44:34 [INFO ]  	- 4
2022-10-04 14:44:34 [INFO ]  	- 5
2022-10-04 14:44:34 [INFO ]  	- 6
2022-10-04 14:44:34 [INFO ]  	- 7
2022-10-04 14:44:34 [INFO ]  	- 8
2022-10-04 14:44:34 [INFO ]  	- 9
2022-10-04 14:44:34 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:44:34 [INFO ]  	- !!python/tuple
2022-10-04 14:44:34 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:44:34 [INFO ]  	    - 0.44398033618927
2022-10-04 14:44:34 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:44:34 [INFO ]  	- !!python/tuple
2022-10-04 14:44:34 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:44:34 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:44:34 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:44:34 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:44:34 [INFO ]  	decay_epochs: 50
2022-10-04 14:44:34 [INFO ]  	decay_factor: 0.1
2022-10-04 14:44:34 [INFO ]  	device_id: 0
2022-10-04 14:44:34 [INFO ]  	distill_epochs: 1
2022-10-04 14:44:34 [INFO ]  	distill_lr: 0.02
2022-10-04 14:44:34 [INFO ]  	distill_steps: 1
2022-10-04 14:44:34 [INFO ]  	epochs: 200
2022-10-04 14:44:34 [INFO ]  	expand_cls: false
2022-10-04 14:44:34 [INFO ]  	forgetting_dataset: null
2022-10-04 14:44:34 [INFO ]  	init: xavier
2022-10-04 14:44:34 [INFO ]  	init_param: 1.0
2022-10-04 14:44:34 [INFO ]  	input_size: 32
2022-10-04 14:44:34 [INFO ]  	ipc: 100
2022-10-04 14:44:34 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:44:34 [INFO ]  	log_interval: 100
2022-10-04 14:44:34 [INFO ]  	log_level: INFO
2022-10-04 14:44:34 [INFO ]  	lr: 0.01
2022-10-04 14:44:34 [INFO ]  	mode: distill_adapt
2022-10-04 14:44:34 [INFO ]  	nc: 3
2022-10-04 14:44:34 [INFO ]  	num_classes: 10
2022-10-04 14:44:34 [INFO ]  	num_workers: 8
2022-10-04 14:44:34 [INFO ]  	phase: train
2022-10-04 14:44:34 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:44:34 [INFO ]  	start_time: '2022-10-04 14:44:34'
2022-10-04 14:44:34 [INFO ]  	test_batch_size: 1024
2022-10-04 14:44:34 [INFO ]  	
2022-10-04 14:44:36 [INFO ]  train dataset size:	73257
2022-10-04 14:44:36 [INFO ]  test dataset size: 	26032
2022-10-04 14:44:36 [INFO ]  datasets built!
2022-10-04 14:44:36 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:44:38 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:44:38 [INFO ]  
2022-10-04 14:44:38 [INFO ]  Begin of epoch 0 :
2022-10-04 14:44:42 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:44:42 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:44:42 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:44:42 [INFO ]  	   step  1 (lr=0.020000)                    7.10%                   8.7452
2022-10-04 14:44:42 [INFO ]  
2022-10-04 14:44:42 [INFO ]  Epoch:    0	Loss: 9.0213	Data Time: 0.47s	Train Time: 0.08s
2022-10-04 14:44:43 [INFO ]  Epoch:    1	Loss: 2.9911	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:44:45 [INFO ]  Epoch:    2	Loss: 2.4842	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:44:47 [INFO ]  Epoch:    3	Loss: 2.2693	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:44:49 [INFO ]  Epoch:    4	Loss: 2.2263	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:44:51 [INFO ]  Epoch:    5	Loss: 2.1743	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:44:52 [INFO ]  Epoch:    6	Loss: 2.1717	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:44:54 [INFO ]  Epoch:    7	Loss: 2.1236	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:44:56 [INFO ]  Epoch:    8	Loss: 2.0416	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:44:58 [INFO ]  Epoch:    9	Loss: 1.9669	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:00 [INFO ]  Epoch:   10	Loss: 1.7829	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:45:02 [INFO ]  Epoch:   11	Loss: 1.6222	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:04 [INFO ]  Epoch:   12	Loss: 1.4655	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:45:06 [INFO ]  Epoch:   13	Loss: 1.3839	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 14:45:08 [INFO ]  Epoch:   14	Loss: 1.3716	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:45:10 [INFO ]  Epoch:   15	Loss: 1.2394	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:11 [INFO ]  Epoch:   16	Loss: 1.2346	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:13 [INFO ]  Epoch:   17	Loss: 1.2204	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:15 [INFO ]  Epoch:   18	Loss: 1.1305	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:45:17 [INFO ]  Epoch:   19	Loss: 0.9532	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:19 [INFO ]  Epoch:   20	Loss: 0.9464	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:45:21 [INFO ]  Epoch:   21	Loss: 0.9766	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:45:23 [INFO ]  Epoch:   22	Loss: 0.9851	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:45:24 [INFO ]  Epoch:   23	Loss: 0.9870	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:45:26 [INFO ]  Epoch:   24	Loss: 0.9698	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:45:28 [INFO ]  Epoch:   25	Loss: 0.8717	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:30 [INFO ]  Epoch:   26	Loss: 0.8175	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:32 [INFO ]  Epoch:   27	Loss: 0.8104	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:33 [INFO ]  Epoch:   28	Loss: 0.8880	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:45:35 [INFO ]  Epoch:   29	Loss: 0.9515	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:37 [INFO ]  Epoch:   30	Loss: 0.7633	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:45:39 [INFO ]  Epoch:   31	Loss: 0.7474	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:40 [INFO ]  Epoch:   32	Loss: 0.8302	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:45:42 [INFO ]  Epoch:   33	Loss: 0.8696	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:44 [INFO ]  Epoch:   34	Loss: 0.8067	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:46 [INFO ]  Epoch:   35	Loss: 0.7593	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:45:48 [INFO ]  Epoch:   36	Loss: 0.7740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:50 [INFO ]  Epoch:   37	Loss: 0.7906	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:45:52 [INFO ]  Epoch:   38	Loss: 0.7512	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:54 [INFO ]  Epoch:   39	Loss: 0.9743	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:45:55 [INFO ]  Epoch:   40	Loss: 0.7932	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:45:57 [INFO ]  Epoch:   41	Loss: 0.7661	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:45:59 [INFO ]  Epoch:   42	Loss: 0.8075	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:46:01 [INFO ]  Epoch:   43	Loss: 0.7880	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:03 [INFO ]  Epoch:   44	Loss: 0.7208	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:46:05 [INFO ]  Epoch:   45	Loss: 0.7030	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:07 [INFO ]  Epoch:   46	Loss: 0.6765	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:09 [INFO ]  Epoch:   47	Loss: 0.6060	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:11 [INFO ]  Epoch:   48	Loss: 0.6951	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:13 [INFO ]  Epoch:   49	Loss: 0.6861	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:46:15 [INFO ]  Epoch:   50	Loss: 0.6446	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:46:17 [INFO ]  Epoch:   51	Loss: 0.6605	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:46:19 [INFO ]  Epoch:   52	Loss: 0.5473	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:21 [INFO ]  Epoch:   53	Loss: 0.5841	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:22 [INFO ]  Epoch:   54	Loss: 0.5947	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:24 [INFO ]  Epoch:   55	Loss: 0.6242	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:46:26 [INFO ]  Epoch:   56	Loss: 0.6098	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:46:28 [INFO ]  Epoch:   57	Loss: 0.6212	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:30 [INFO ]  Epoch:   58	Loss: 0.6375	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:46:32 [INFO ]  Epoch:   59	Loss: 0.6356	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:46:34 [INFO ]  Epoch:   60	Loss: 0.6734	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:36 [INFO ]  Epoch:   61	Loss: 0.6345	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:38 [INFO ]  Epoch:   62	Loss: 0.5716	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:46:39 [INFO ]  Epoch:   63	Loss: 0.6107	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:41 [INFO ]  Epoch:   64	Loss: 0.5970	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:43 [INFO ]  Epoch:   65	Loss: 0.6253	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:45 [INFO ]  Epoch:   66	Loss: 0.6003	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:46:47 [INFO ]  Epoch:   67	Loss: 0.5928	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:46:48 [INFO ]  Epoch:   68	Loss: 0.5777	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:50 [INFO ]  Epoch:   69	Loss: 0.6432	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:46:52 [INFO ]  Epoch:   70	Loss: 0.5844	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:46:54 [INFO ]  Epoch:   71	Loss: 0.6551	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:46:56 [INFO ]  Epoch:   72	Loss: 0.6558	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:58 [INFO ]  Epoch:   73	Loss: 0.5937	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:46:59 [INFO ]  Epoch:   74	Loss: 0.5788	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:01 [INFO ]  Epoch:   75	Loss: 0.5600	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:47:03 [INFO ]  Epoch:   76	Loss: 0.6590	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:05 [INFO ]  Epoch:   77	Loss: 0.6133	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:47:07 [INFO ]  Epoch:   78	Loss: 0.5999	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:47:09 [INFO ]  Epoch:   79	Loss: 0.5918	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:47:11 [INFO ]  Epoch:   80	Loss: 0.5986	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:13 [INFO ]  Epoch:   81	Loss: 0.6424	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:47:14 [INFO ]  Epoch:   82	Loss: 0.6531	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:47:16 [INFO ]  Epoch:   83	Loss: 0.5832	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:18 [INFO ]  Epoch:   84	Loss: 0.5554	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:20 [INFO ]  Epoch:   85	Loss: 0.6864	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:22 [INFO ]  Epoch:   86	Loss: 0.6171	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:47:24 [INFO ]  Epoch:   87	Loss: 0.5679	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:26 [INFO ]  Epoch:   88	Loss: 0.5689	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:28 [INFO ]  Epoch:   89	Loss: 0.6417	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:47:30 [INFO ]  Epoch:   90	Loss: 0.6308	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:47:32 [INFO ]  Epoch:   91	Loss: 0.5445	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:47:33 [INFO ]  Epoch:   92	Loss: 0.5806	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:35 [INFO ]  Epoch:   93	Loss: 0.6217	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:47:37 [INFO ]  Epoch:   94	Loss: 0.5957	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:47:39 [INFO ]  Epoch:   95	Loss: 0.5522	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:47:41 [INFO ]  Epoch:   96	Loss: 0.5512	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:47:43 [INFO ]  Epoch:   97	Loss: 0.5580	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:47:45 [INFO ]  Epoch:   98	Loss: 0.5709	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:47 [INFO ]  Epoch:   99	Loss: 0.6002	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:48 [INFO ]  Epoch:  100	Loss: 0.6535	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:47:50 [INFO ]  Epoch:  101	Loss: 0.5993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:52 [INFO ]  Epoch:  102	Loss: 0.5248	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:47:54 [INFO ]  Epoch:  103	Loss: 0.6131	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:47:56 [INFO ]  Epoch:  104	Loss: 0.5472	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:47:58 [INFO ]  Epoch:  105	Loss: 0.5759	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:47:59 [INFO ]  Epoch:  106	Loss: 0.5395	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:01 [INFO ]  Epoch:  107	Loss: 0.5639	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:48:03 [INFO ]  Epoch:  108	Loss: 0.5845	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:48:05 [INFO ]  Epoch:  109	Loss: 0.5541	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:48:07 [INFO ]  Epoch:  110	Loss: 0.5715	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:48:09 [INFO ]  Epoch:  111	Loss: 0.5324	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:48:11 [INFO ]  Epoch:  112	Loss: 0.5196	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:13 [INFO ]  Epoch:  113	Loss: 0.5529	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:48:14 [INFO ]  Epoch:  114	Loss: 0.5736	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:48:16 [INFO ]  Epoch:  115	Loss: 0.6248	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:48:18 [INFO ]  Epoch:  116	Loss: 0.5434	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:48:20 [INFO ]  Epoch:  117	Loss: 0.6251	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:22 [INFO ]  Epoch:  118	Loss: 0.5949	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:24 [INFO ]  Epoch:  119	Loss: 0.6237	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:26 [INFO ]  Epoch:  120	Loss: 0.5145	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:48:28 [INFO ]  Epoch:  121	Loss: 0.5419	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:48:30 [INFO ]  Epoch:  122	Loss: 0.5887	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:32 [INFO ]  Epoch:  123	Loss: 0.6550	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:48:34 [INFO ]  Epoch:  124	Loss: 0.5546	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:36 [INFO ]  Epoch:  125	Loss: 0.5419	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:38 [INFO ]  Epoch:  126	Loss: 0.5401	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:48:40 [INFO ]  Epoch:  127	Loss: 0.5985	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:41 [INFO ]  Epoch:  128	Loss: 0.5361	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:44 [INFO ]  Epoch:  129	Loss: 0.5795	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:48:46 [INFO ]  Epoch:  130	Loss: 0.6153	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:48:48 [INFO ]  Epoch:  131	Loss: 0.5901	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:49 [INFO ]  Epoch:  132	Loss: 0.5724	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:48:52 [INFO ]  Epoch:  133	Loss: 0.5869	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:48:54 [INFO ]  Epoch:  134	Loss: 0.5646	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:48:56 [INFO ]  Epoch:  135	Loss: 0.5739	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:57 [INFO ]  Epoch:  136	Loss: 0.5977	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:48:59 [INFO ]  Epoch:  137	Loss: 0.5564	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:01 [INFO ]  Epoch:  138	Loss: 0.5566	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:03 [INFO ]  Epoch:  139	Loss: 0.6012	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:05 [INFO ]  Epoch:  140	Loss: 0.5622	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:07 [INFO ]  Epoch:  141	Loss: 0.5325	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:09 [INFO ]  Epoch:  142	Loss: 0.5943	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:11 [INFO ]  Epoch:  143	Loss: 0.6088	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:13 [INFO ]  Epoch:  144	Loss: 0.5877	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:49:15 [INFO ]  Epoch:  145	Loss: 0.5833	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:49:17 [INFO ]  Epoch:  146	Loss: 0.5635	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:49:18 [INFO ]  Epoch:  147	Loss: 0.5750	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:20 [INFO ]  Epoch:  148	Loss: 0.5555	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:49:22 [INFO ]  Epoch:  149	Loss: 0.5042	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:24 [INFO ]  Epoch:  150	Loss: 0.5799	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:26 [INFO ]  Epoch:  151	Loss: 0.5291	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:49:28 [INFO ]  Epoch:  152	Loss: 0.5761	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:30 [INFO ]  Epoch:  153	Loss: 0.5090	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:49:32 [INFO ]  Epoch:  154	Loss: 0.5667	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:49:34 [INFO ]  Epoch:  155	Loss: 0.5148	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:49:35 [INFO ]  Epoch:  156	Loss: 0.5773	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:37 [INFO ]  Epoch:  157	Loss: 0.6366	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:49:39 [INFO ]  Epoch:  158	Loss: 0.5712	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:41 [INFO ]  Epoch:  159	Loss: 0.5628	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:49:43 [INFO ]  Epoch:  160	Loss: 0.5918	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:49:45 [INFO ]  Epoch:  161	Loss: 0.5349	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:49:47 [INFO ]  Epoch:  162	Loss: 0.5716	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:49:49 [INFO ]  Epoch:  163	Loss: 0.5767	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:49:50 [INFO ]  Epoch:  164	Loss: 0.5509	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:49:52 [INFO ]  Epoch:  165	Loss: 0.5776	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:49:54 [INFO ]  Epoch:  166	Loss: 0.6266	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:49:56 [INFO ]  Epoch:  167	Loss: 0.5695	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:49:58 [INFO ]  Epoch:  168	Loss: 0.5646	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:50:00 [INFO ]  Epoch:  169	Loss: 0.6070	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:02 [INFO ]  Epoch:  170	Loss: 0.6378	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:50:04 [INFO ]  Epoch:  171	Loss: 0.6631	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:06 [INFO ]  Epoch:  172	Loss: 0.5678	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:08 [INFO ]  Epoch:  173	Loss: 0.6041	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:10 [INFO ]  Epoch:  174	Loss: 0.6380	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:50:12 [INFO ]  Epoch:  175	Loss: 0.6124	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:50:14 [INFO ]  Epoch:  176	Loss: 0.5510	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:16 [INFO ]  Epoch:  177	Loss: 0.5783	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:50:18 [INFO ]  Epoch:  178	Loss: 0.5462	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:20 [INFO ]  Epoch:  179	Loss: 0.5772	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:50:22 [INFO ]  Epoch:  180	Loss: 0.5986	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:50:23 [INFO ]  Epoch:  181	Loss: 0.6366	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:50:25 [INFO ]  Epoch:  182	Loss: 0.5838	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:50:27 [INFO ]  Epoch:  183	Loss: 0.5987	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:29 [INFO ]  Epoch:  184	Loss: 0.5755	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:31 [INFO ]  Epoch:  185	Loss: 0.5326	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:50:33 [INFO ]  Epoch:  186	Loss: 0.6809	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:50:35 [INFO ]  Epoch:  187	Loss: 0.6466	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:50:37 [INFO ]  Epoch:  188	Loss: 0.6113	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:50:39 [INFO ]  Epoch:  189	Loss: 0.5092	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:50:41 [INFO ]  Epoch:  190	Loss: 0.5885	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:43 [INFO ]  Epoch:  191	Loss: 0.6290	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:50:45 [INFO ]  Epoch:  192	Loss: 0.5774	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:50:47 [INFO ]  Epoch:  193	Loss: 0.6201	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:50:48 [INFO ]  Epoch:  194	Loss: 0.5864	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:50:50 [INFO ]  Epoch:  195	Loss: 0.5534	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:50:52 [INFO ]  Epoch:  196	Loss: 0.5269	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:50:54 [INFO ]  Epoch:  197	Loss: 0.5353	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 14:50:56 [INFO ]  Epoch:  198	Loss: 0.5617	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:50:58 [INFO ]  Epoch:  199	Loss: 0.4856	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:51:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 14:51:00 [INFO ]  
2022-10-04 14:51:00 [INFO ]  Final evaluation for SVHN :
2022-10-04 14:51:03 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:51:03 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:51:03 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:51:03 [INFO ]  	   step  1 (lr=0.473770)                   82.43%                   0.6555
2022-10-04 14:51:03 [INFO ]  
2022-10-04 14:51:03 [INFO ]  
2022-10-04 14:51:03 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 14:51:06 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:51:06 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:51:06 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 14:51:06 [INFO ]  	   step  1 (lr=0.473770)                   14.05%                   5.6263
2022-10-04 14:51:06 [INFO ]  
2022-10-04 14:51:06 [INFO ]  CPU Time: 3.63 minutes
2022-10-04 14:55:12 [INFO ]  ======================================== 2022-10-04 14:55:12 ========================================
2022-10-04 14:55:12 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 14:55:12 [INFO ]  Options: 
2022-10-04 14:55:12 [INFO ]  	base_dir: null
2022-10-04 14:55:12 [INFO ]  	batch_size: 1024
2022-10-04 14:55:12 [INFO ]  	checkpoint_interval: 300
2022-10-04 14:55:12 [INFO ]  	dataset: SVHN
2022-10-04 14:55:12 [INFO ]  	dataset_labels:
2022-10-04 14:55:12 [INFO ]  	- 0
2022-10-04 14:55:12 [INFO ]  	- 1
2022-10-04 14:55:12 [INFO ]  	- 2
2022-10-04 14:55:12 [INFO ]  	- 3
2022-10-04 14:55:12 [INFO ]  	- 4
2022-10-04 14:55:12 [INFO ]  	- 5
2022-10-04 14:55:12 [INFO ]  	- 6
2022-10-04 14:55:12 [INFO ]  	- 7
2022-10-04 14:55:12 [INFO ]  	- 8
2022-10-04 14:55:12 [INFO ]  	- 9
2022-10-04 14:55:12 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 14:55:12 [INFO ]  	- !!python/tuple
2022-10-04 14:55:12 [INFO ]  	    - 0.4379104971885681
2022-10-04 14:55:12 [INFO ]  	    - 0.44398033618927
2022-10-04 14:55:12 [INFO ]  	    - 0.4729299545288086
2022-10-04 14:55:12 [INFO ]  	- !!python/tuple
2022-10-04 14:55:12 [INFO ]  	    - 0.19803012907505035
2022-10-04 14:55:12 [INFO ]  	    - 0.2010156363248825
2022-10-04 14:55:12 [INFO ]  	    - 0.19703614711761475
2022-10-04 14:55:12 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 14:55:12 [INFO ]  	decay_epochs: 50
2022-10-04 14:55:12 [INFO ]  	decay_factor: 0.1
2022-10-04 14:55:12 [INFO ]  	device_id: 0
2022-10-04 14:55:12 [INFO ]  	distill_epochs: 1
2022-10-04 14:55:12 [INFO ]  	distill_lr: 0.02
2022-10-04 14:55:12 [INFO ]  	distill_steps: 1
2022-10-04 14:55:12 [INFO ]  	epochs: 200
2022-10-04 14:55:12 [INFO ]  	expand_cls: false
2022-10-04 14:55:12 [INFO ]  	forgetting_dataset: null
2022-10-04 14:55:12 [INFO ]  	init: xavier
2022-10-04 14:55:12 [INFO ]  	init_param: 1.0
2022-10-04 14:55:12 [INFO ]  	input_size: 32
2022-10-04 14:55:12 [INFO ]  	ipc: 100
2022-10-04 14:55:12 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 14:55:12 [INFO ]  	log_interval: 100
2022-10-04 14:55:12 [INFO ]  	log_level: INFO
2022-10-04 14:55:12 [INFO ]  	lr: 0.01
2022-10-04 14:55:12 [INFO ]  	mode: distill_adapt
2022-10-04 14:55:12 [INFO ]  	nc: 3
2022-10-04 14:55:12 [INFO ]  	num_classes: 10
2022-10-04 14:55:12 [INFO ]  	num_workers: 8
2022-10-04 14:55:12 [INFO ]  	phase: train
2022-10-04 14:55:12 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 14:55:12 [INFO ]  	start_time: '2022-10-04 14:55:12'
2022-10-04 14:55:12 [INFO ]  	test_batch_size: 1024
2022-10-04 14:55:12 [INFO ]  	
2022-10-04 14:55:14 [INFO ]  train dataset size:	73257
2022-10-04 14:55:14 [INFO ]  test dataset size: 	26032
2022-10-04 14:55:14 [INFO ]  datasets built!
2022-10-04 14:55:14 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 14:55:16 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 14:55:16 [INFO ]  
2022-10-04 14:55:16 [INFO ]  Begin of epoch 0 :
2022-10-04 14:55:20 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 14:55:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 14:55:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 14:55:20 [INFO ]  	   step  1 (lr=0.020000)                    7.00%                   8.9592
2022-10-04 14:55:20 [INFO ]  
2022-10-04 14:55:20 [INFO ]  Epoch:    0	Loss: 8.8842	Data Time: 0.44s	Train Time: 0.08s
2022-10-04 14:55:22 [INFO ]  Epoch:    1	Loss: 3.0277	Data Time: 0.13s	Train Time: 0.01s
2022-10-04 14:55:23 [INFO ]  Epoch:    2	Loss: 2.4735	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:25 [INFO ]  Epoch:    3	Loss: 2.2888	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:27 [INFO ]  Epoch:    4	Loss: 2.2109	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:55:29 [INFO ]  Epoch:    5	Loss: 2.2098	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:55:31 [INFO ]  Epoch:    6	Loss: 2.1548	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:55:33 [INFO ]  Epoch:    7	Loss: 2.1042	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:55:35 [INFO ]  Epoch:    8	Loss: 2.0479	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:55:36 [INFO ]  Epoch:    9	Loss: 1.9678	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:38 [INFO ]  Epoch:   10	Loss: 1.8150	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:55:40 [INFO ]  Epoch:   11	Loss: 1.6989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:42 [INFO ]  Epoch:   12	Loss: 1.6632	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:55:44 [INFO ]  Epoch:   13	Loss: 1.3930	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:46 [INFO ]  Epoch:   14	Loss: 1.4848	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:55:48 [INFO ]  Epoch:   15	Loss: 1.2474	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:55:50 [INFO ]  Epoch:   16	Loss: 1.1531	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:55:51 [INFO ]  Epoch:   17	Loss: 1.0881	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:55:53 [INFO ]  Epoch:   18	Loss: 1.1745	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:55:55 [INFO ]  Epoch:   19	Loss: 1.0154	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:55:57 [INFO ]  Epoch:   20	Loss: 1.0415	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:55:59 [INFO ]  Epoch:   21	Loss: 0.9538	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:56:01 [INFO ]  Epoch:   22	Loss: 0.9153	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:56:03 [INFO ]  Epoch:   23	Loss: 0.9209	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:05 [INFO ]  Epoch:   24	Loss: 0.9090	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 14:56:06 [INFO ]  Epoch:   25	Loss: 0.8506	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:56:08 [INFO ]  Epoch:   26	Loss: 0.7796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:10 [INFO ]  Epoch:   27	Loss: 0.9160	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:12 [INFO ]  Epoch:   28	Loss: 0.8031	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:14 [INFO ]  Epoch:   29	Loss: 0.8348	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 14:56:15 [INFO ]  Epoch:   30	Loss: 0.7969	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:18 [INFO ]  Epoch:   31	Loss: 0.8522	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:56:19 [INFO ]  Epoch:   32	Loss: 0.8709	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:21 [INFO ]  Epoch:   33	Loss: 0.8529	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:23 [INFO ]  Epoch:   34	Loss: 0.7952	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:25 [INFO ]  Epoch:   35	Loss: 0.9134	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:56:27 [INFO ]  Epoch:   36	Loss: 0.8403	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:28 [INFO ]  Epoch:   37	Loss: 0.8261	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:56:30 [INFO ]  Epoch:   38	Loss: 0.7207	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:56:32 [INFO ]  Epoch:   39	Loss: 0.7071	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:56:34 [INFO ]  Epoch:   40	Loss: 0.6742	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:56:36 [INFO ]  Epoch:   41	Loss: 0.7965	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:56:38 [INFO ]  Epoch:   42	Loss: 0.6831	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:40 [INFO ]  Epoch:   43	Loss: 0.7336	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:56:41 [INFO ]  Epoch:   44	Loss: 0.7126	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:56:43 [INFO ]  Epoch:   45	Loss: 0.7234	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:45 [INFO ]  Epoch:   46	Loss: 0.7574	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:56:47 [INFO ]  Epoch:   47	Loss: 0.6994	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:56:49 [INFO ]  Epoch:   48	Loss: 0.7834	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:51 [INFO ]  Epoch:   49	Loss: 0.5921	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:56:53 [INFO ]  Epoch:   50	Loss: 0.6489	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:56:54 [INFO ]  Epoch:   51	Loss: 0.5900	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:56:56 [INFO ]  Epoch:   52	Loss: 0.6437	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:56:58 [INFO ]  Epoch:   53	Loss: 0.6787	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:57:00 [INFO ]  Epoch:   54	Loss: 0.6191	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:02 [INFO ]  Epoch:   55	Loss: 0.6091	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:57:04 [INFO ]  Epoch:   56	Loss: 0.5957	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:06 [INFO ]  Epoch:   57	Loss: 0.5974	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:57:08 [INFO ]  Epoch:   58	Loss: 0.6350	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:57:10 [INFO ]  Epoch:   59	Loss: 0.5487	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:11 [INFO ]  Epoch:   60	Loss: 0.6344	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:57:13 [INFO ]  Epoch:   61	Loss: 0.6065	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:15 [INFO ]  Epoch:   62	Loss: 0.6334	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:57:17 [INFO ]  Epoch:   63	Loss: 0.5894	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:19 [INFO ]  Epoch:   64	Loss: 0.5736	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:57:21 [INFO ]  Epoch:   65	Loss: 0.6040	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:57:23 [INFO ]  Epoch:   66	Loss: 0.7227	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:57:25 [INFO ]  Epoch:   67	Loss: 0.6110	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:57:27 [INFO ]  Epoch:   68	Loss: 0.6391	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:28 [INFO ]  Epoch:   69	Loss: 0.6330	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:31 [INFO ]  Epoch:   70	Loss: 0.6670	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:32 [INFO ]  Epoch:   71	Loss: 0.6608	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:57:34 [INFO ]  Epoch:   72	Loss: 0.6347	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:57:36 [INFO ]  Epoch:   73	Loss: 0.5990	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:57:38 [INFO ]  Epoch:   74	Loss: 0.6519	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:57:40 [INFO ]  Epoch:   75	Loss: 0.6334	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:57:41 [INFO ]  Epoch:   76	Loss: 0.5993	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:57:43 [INFO ]  Epoch:   77	Loss: 0.5861	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:45 [INFO ]  Epoch:   78	Loss: 0.6077	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:57:47 [INFO ]  Epoch:   79	Loss: 0.6578	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:57:49 [INFO ]  Epoch:   80	Loss: 0.5515	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:51 [INFO ]  Epoch:   81	Loss: 0.6671	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:57:53 [INFO ]  Epoch:   82	Loss: 0.5531	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:57:55 [INFO ]  Epoch:   83	Loss: 0.6211	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:57:57 [INFO ]  Epoch:   84	Loss: 0.6937	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:57:59 [INFO ]  Epoch:   85	Loss: 0.5999	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:00 [INFO ]  Epoch:   86	Loss: 0.6161	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:02 [INFO ]  Epoch:   87	Loss: 0.6174	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:04 [INFO ]  Epoch:   88	Loss: 0.5982	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:58:06 [INFO ]  Epoch:   89	Loss: 0.6242	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:08 [INFO ]  Epoch:   90	Loss: 0.6561	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:58:09 [INFO ]  Epoch:   91	Loss: 0.5574	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:11 [INFO ]  Epoch:   92	Loss: 0.5601	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:13 [INFO ]  Epoch:   93	Loss: 0.6334	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:15 [INFO ]  Epoch:   94	Loss: 0.6017	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:58:17 [INFO ]  Epoch:   95	Loss: 0.5984	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:19 [INFO ]  Epoch:   96	Loss: 0.5507	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:21 [INFO ]  Epoch:   97	Loss: 0.6431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:23 [INFO ]  Epoch:   98	Loss: 0.5689	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:24 [INFO ]  Epoch:   99	Loss: 0.5881	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:26 [INFO ]  Epoch:  100	Loss: 0.5424	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:28 [INFO ]  Epoch:  101	Loss: 0.5496	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:30 [INFO ]  Epoch:  102	Loss: 0.6012	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:58:32 [INFO ]  Epoch:  103	Loss: 0.6280	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 14:58:34 [INFO ]  Epoch:  104	Loss: 0.6115	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:58:35 [INFO ]  Epoch:  105	Loss: 0.5852	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:37 [INFO ]  Epoch:  106	Loss: 0.5735	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:58:39 [INFO ]  Epoch:  107	Loss: 0.5308	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:41 [INFO ]  Epoch:  108	Loss: 0.5296	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:58:43 [INFO ]  Epoch:  109	Loss: 0.5483	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:45 [INFO ]  Epoch:  110	Loss: 0.5235	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:47 [INFO ]  Epoch:  111	Loss: 0.6015	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:58:48 [INFO ]  Epoch:  112	Loss: 0.5632	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:50 [INFO ]  Epoch:  113	Loss: 0.5790	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:58:52 [INFO ]  Epoch:  114	Loss: 0.5320	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:54 [INFO ]  Epoch:  115	Loss: 0.5408	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:58:56 [INFO ]  Epoch:  116	Loss: 0.6049	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:58:58 [INFO ]  Epoch:  117	Loss: 0.5300	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 14:59:00 [INFO ]  Epoch:  118	Loss: 0.5563	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:02 [INFO ]  Epoch:  119	Loss: 0.5828	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:59:04 [INFO ]  Epoch:  120	Loss: 0.5962	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:59:06 [INFO ]  Epoch:  121	Loss: 0.6116	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:59:07 [INFO ]  Epoch:  122	Loss: 0.5746	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:59:09 [INFO ]  Epoch:  123	Loss: 0.5649	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:59:11 [INFO ]  Epoch:  124	Loss: 0.5204	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:59:13 [INFO ]  Epoch:  125	Loss: 0.5850	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:59:15 [INFO ]  Epoch:  126	Loss: 0.6109	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:17 [INFO ]  Epoch:  127	Loss: 0.5934	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:19 [INFO ]  Epoch:  128	Loss: 0.6205	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:59:21 [INFO ]  Epoch:  129	Loss: 0.5625	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:59:22 [INFO ]  Epoch:  130	Loss: 0.5763	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:24 [INFO ]  Epoch:  131	Loss: 0.6163	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:59:26 [INFO ]  Epoch:  132	Loss: 0.5570	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:59:28 [INFO ]  Epoch:  133	Loss: 0.5857	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 14:59:30 [INFO ]  Epoch:  134	Loss: 0.5791	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:32 [INFO ]  Epoch:  135	Loss: 0.6222	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:59:34 [INFO ]  Epoch:  136	Loss: 0.5228	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:59:36 [INFO ]  Epoch:  137	Loss: 0.5876	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 14:59:37 [INFO ]  Epoch:  138	Loss: 0.5618	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:39 [INFO ]  Epoch:  139	Loss: 0.5366	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:41 [INFO ]  Epoch:  140	Loss: 0.5668	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:43 [INFO ]  Epoch:  141	Loss: 0.5599	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:45 [INFO ]  Epoch:  142	Loss: 0.6146	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:47 [INFO ]  Epoch:  143	Loss: 0.5987	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:59:48 [INFO ]  Epoch:  144	Loss: 0.5552	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 14:59:50 [INFO ]  Epoch:  145	Loss: 0.5985	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 14:59:52 [INFO ]  Epoch:  146	Loss: 0.6144	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 14:59:54 [INFO ]  Epoch:  147	Loss: 0.5759	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 14:59:56 [INFO ]  Epoch:  148	Loss: 0.5727	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 14:59:58 [INFO ]  Epoch:  149	Loss: 0.5688	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:00 [INFO ]  Epoch:  150	Loss: 0.6497	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:00:01 [INFO ]  Epoch:  151	Loss: 0.5533	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:00:03 [INFO ]  Epoch:  152	Loss: 0.5464	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:00:05 [INFO ]  Epoch:  153	Loss: 0.5456	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:07 [INFO ]  Epoch:  154	Loss: 0.5490	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:09 [INFO ]  Epoch:  155	Loss: 0.5463	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:00:11 [INFO ]  Epoch:  156	Loss: 0.6490	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:00:13 [INFO ]  Epoch:  157	Loss: 0.5430	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:15 [INFO ]  Epoch:  158	Loss: 0.5329	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:00:17 [INFO ]  Epoch:  159	Loss: 0.6142	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:00:19 [INFO ]  Epoch:  160	Loss: 0.5801	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:21 [INFO ]  Epoch:  161	Loss: 0.6350	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:00:23 [INFO ]  Epoch:  162	Loss: 0.5997	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:00:25 [INFO ]  Epoch:  163	Loss: 0.5770	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:00:26 [INFO ]  Epoch:  164	Loss: 0.5607	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:00:28 [INFO ]  Epoch:  165	Loss: 0.6018	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:00:30 [INFO ]  Epoch:  166	Loss: 0.5986	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:00:32 [INFO ]  Epoch:  167	Loss: 0.6058	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:34 [INFO ]  Epoch:  168	Loss: 0.5605	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:36 [INFO ]  Epoch:  169	Loss: 0.5978	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:38 [INFO ]  Epoch:  170	Loss: 0.6024	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:00:40 [INFO ]  Epoch:  171	Loss: 0.6186	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:00:42 [INFO ]  Epoch:  172	Loss: 0.5419	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:00:43 [INFO ]  Epoch:  173	Loss: 0.5583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:45 [INFO ]  Epoch:  174	Loss: 0.5673	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:47 [INFO ]  Epoch:  175	Loss: 0.5601	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:49 [INFO ]  Epoch:  176	Loss: 0.6089	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:51 [INFO ]  Epoch:  177	Loss: 0.5280	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:53 [INFO ]  Epoch:  178	Loss: 0.6295	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:00:55 [INFO ]  Epoch:  179	Loss: 0.6185	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:57 [INFO ]  Epoch:  180	Loss: 0.6775	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:00:59 [INFO ]  Epoch:  181	Loss: 0.5986	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:00 [INFO ]  Epoch:  182	Loss: 0.5542	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:02 [INFO ]  Epoch:  183	Loss: 0.5624	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:01:04 [INFO ]  Epoch:  184	Loss: 0.5904	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:06 [INFO ]  Epoch:  185	Loss: 0.5670	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:01:08 [INFO ]  Epoch:  186	Loss: 0.6422	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:01:10 [INFO ]  Epoch:  187	Loss: 0.5804	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:01:12 [INFO ]  Epoch:  188	Loss: 0.6048	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:14 [INFO ]  Epoch:  189	Loss: 0.4994	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:01:16 [INFO ]  Epoch:  190	Loss: 0.5883	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:01:17 [INFO ]  Epoch:  191	Loss: 0.6268	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:01:19 [INFO ]  Epoch:  192	Loss: 0.5849	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:21 [INFO ]  Epoch:  193	Loss: 0.5712	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:01:23 [INFO ]  Epoch:  194	Loss: 0.5386	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:01:25 [INFO ]  Epoch:  195	Loss: 0.5783	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:01:27 [INFO ]  Epoch:  196	Loss: 0.5593	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:29 [INFO ]  Epoch:  197	Loss: 0.5056	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:01:31 [INFO ]  Epoch:  198	Loss: 0.5307	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:33 [INFO ]  Epoch:  199	Loss: 0.5511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:01:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 15:01:35 [INFO ]  
2022-10-04 15:01:35 [INFO ]  Final evaluation for SVHN :
2022-10-04 15:01:38 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:01:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:01:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:01:38 [INFO ]  	   step  1 (lr=0.471923)                   82.24%                   0.6691
2022-10-04 15:01:38 [INFO ]  
2022-10-04 15:01:38 [INFO ]  
2022-10-04 15:01:38 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 15:01:41 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:01:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:01:41 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 15:01:41 [INFO ]  	   step  1 (lr=0.471923)                   14.64%                   5.5193
2022-10-04 15:01:41 [INFO ]  
2022-10-04 15:01:41 [INFO ]  CPU Time: 3.60 minutes
2022-10-04 15:05:52 [INFO ]  ======================================== 2022-10-04 15:05:52 ========================================
2022-10-04 15:05:52 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 15:05:52 [INFO ]  Options: 
2022-10-04 15:05:52 [INFO ]  	base_dir: null
2022-10-04 15:05:52 [INFO ]  	batch_size: 1024
2022-10-04 15:05:52 [INFO ]  	checkpoint_interval: 300
2022-10-04 15:05:52 [INFO ]  	dataset: SVHN
2022-10-04 15:05:52 [INFO ]  	dataset_labels:
2022-10-04 15:05:52 [INFO ]  	- 0
2022-10-04 15:05:52 [INFO ]  	- 1
2022-10-04 15:05:52 [INFO ]  	- 2
2022-10-04 15:05:52 [INFO ]  	- 3
2022-10-04 15:05:52 [INFO ]  	- 4
2022-10-04 15:05:52 [INFO ]  	- 5
2022-10-04 15:05:52 [INFO ]  	- 6
2022-10-04 15:05:52 [INFO ]  	- 7
2022-10-04 15:05:52 [INFO ]  	- 8
2022-10-04 15:05:52 [INFO ]  	- 9
2022-10-04 15:05:52 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 15:05:52 [INFO ]  	- !!python/tuple
2022-10-04 15:05:52 [INFO ]  	    - 0.4379104971885681
2022-10-04 15:05:52 [INFO ]  	    - 0.44398033618927
2022-10-04 15:05:52 [INFO ]  	    - 0.4729299545288086
2022-10-04 15:05:52 [INFO ]  	- !!python/tuple
2022-10-04 15:05:52 [INFO ]  	    - 0.19803012907505035
2022-10-04 15:05:52 [INFO ]  	    - 0.2010156363248825
2022-10-04 15:05:52 [INFO ]  	    - 0.19703614711761475
2022-10-04 15:05:52 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 15:05:52 [INFO ]  	decay_epochs: 50
2022-10-04 15:05:52 [INFO ]  	decay_factor: 0.1
2022-10-04 15:05:52 [INFO ]  	device_id: 0
2022-10-04 15:05:52 [INFO ]  	distill_epochs: 1
2022-10-04 15:05:52 [INFO ]  	distill_lr: 0.02
2022-10-04 15:05:52 [INFO ]  	distill_steps: 1
2022-10-04 15:05:52 [INFO ]  	epochs: 200
2022-10-04 15:05:52 [INFO ]  	expand_cls: false
2022-10-04 15:05:52 [INFO ]  	forgetting_dataset: null
2022-10-04 15:05:52 [INFO ]  	init: xavier
2022-10-04 15:05:52 [INFO ]  	init_param: 1.0
2022-10-04 15:05:52 [INFO ]  	input_size: 32
2022-10-04 15:05:52 [INFO ]  	ipc: 100
2022-10-04 15:05:52 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 15:05:52 [INFO ]  	log_interval: 100
2022-10-04 15:05:52 [INFO ]  	log_level: INFO
2022-10-04 15:05:52 [INFO ]  	lr: 0.01
2022-10-04 15:05:52 [INFO ]  	mode: distill_adapt
2022-10-04 15:05:52 [INFO ]  	nc: 3
2022-10-04 15:05:52 [INFO ]  	num_classes: 10
2022-10-04 15:05:52 [INFO ]  	num_workers: 8
2022-10-04 15:05:52 [INFO ]  	phase: train
2022-10-04 15:05:52 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 15:05:52 [INFO ]  	start_time: '2022-10-04 15:05:52'
2022-10-04 15:05:52 [INFO ]  	test_batch_size: 1024
2022-10-04 15:05:52 [INFO ]  	
2022-10-04 15:05:54 [INFO ]  train dataset size:	73257
2022-10-04 15:05:54 [INFO ]  test dataset size: 	26032
2022-10-04 15:05:54 [INFO ]  datasets built!
2022-10-04 15:05:54 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 15:05:56 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 15:05:56 [INFO ]  
2022-10-04 15:05:56 [INFO ]  Begin of epoch 0 :
2022-10-04 15:06:00 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:06:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:06:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:06:00 [INFO ]  	   step  1 (lr=0.020000)                    7.08%                   8.9382
2022-10-04 15:06:00 [INFO ]  
2022-10-04 15:06:00 [INFO ]  Epoch:    0	Loss: 8.8786	Data Time: 0.39s	Train Time: 0.08s
2022-10-04 15:06:02 [INFO ]  Epoch:    1	Loss: 3.0465	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:06:03 [INFO ]  Epoch:    2	Loss: 2.5227	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:06:05 [INFO ]  Epoch:    3	Loss: 2.2657	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:06:07 [INFO ]  Epoch:    4	Loss: 2.1991	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:06:09 [INFO ]  Epoch:    5	Loss: 2.1600	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:11 [INFO ]  Epoch:    6	Loss: 2.1503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:12 [INFO ]  Epoch:    7	Loss: 2.0793	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:06:15 [INFO ]  Epoch:    8	Loss: 2.0412	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:06:16 [INFO ]  Epoch:    9	Loss: 1.9596	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:06:18 [INFO ]  Epoch:   10	Loss: 1.8215	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:06:20 [INFO ]  Epoch:   11	Loss: 1.6890	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:06:22 [INFO ]  Epoch:   12	Loss: 1.5601	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:06:24 [INFO ]  Epoch:   13	Loss: 1.4940	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:26 [INFO ]  Epoch:   14	Loss: 1.3388	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:06:27 [INFO ]  Epoch:   15	Loss: 1.1549	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:29 [INFO ]  Epoch:   16	Loss: 1.2703	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:06:31 [INFO ]  Epoch:   17	Loss: 1.1782	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:33 [INFO ]  Epoch:   18	Loss: 1.0622	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:06:35 [INFO ]  Epoch:   19	Loss: 1.0830	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:06:37 [INFO ]  Epoch:   20	Loss: 1.1172	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:06:39 [INFO ]  Epoch:   21	Loss: 0.9453	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:41 [INFO ]  Epoch:   22	Loss: 0.9430	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:06:43 [INFO ]  Epoch:   23	Loss: 0.9947	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:06:44 [INFO ]  Epoch:   24	Loss: 0.9322	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:46 [INFO ]  Epoch:   25	Loss: 1.0112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:48 [INFO ]  Epoch:   26	Loss: 0.8677	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:06:50 [INFO ]  Epoch:   27	Loss: 0.8007	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:06:52 [INFO ]  Epoch:   28	Loss: 0.8390	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:06:54 [INFO ]  Epoch:   29	Loss: 0.9111	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:06:56 [INFO ]  Epoch:   30	Loss: 0.8090	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:06:58 [INFO ]  Epoch:   31	Loss: 0.8194	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:07:00 [INFO ]  Epoch:   32	Loss: 0.7563	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:07:02 [INFO ]  Epoch:   33	Loss: 0.8543	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:07:04 [INFO ]  Epoch:   34	Loss: 0.8900	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:07:05 [INFO ]  Epoch:   35	Loss: 0.6909	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:07:07 [INFO ]  Epoch:   36	Loss: 0.7966	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:09 [INFO ]  Epoch:   37	Loss: 0.7440	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:07:11 [INFO ]  Epoch:   38	Loss: 0.7256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:07:13 [INFO ]  Epoch:   39	Loss: 0.8879	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:07:14 [INFO ]  Epoch:   40	Loss: 0.7089	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:07:16 [INFO ]  Epoch:   41	Loss: 0.6799	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:18 [INFO ]  Epoch:   42	Loss: 0.7029	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:07:20 [INFO ]  Epoch:   43	Loss: 0.7961	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:07:22 [INFO ]  Epoch:   44	Loss: 0.7148	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:07:24 [INFO ]  Epoch:   45	Loss: 0.7426	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:26 [INFO ]  Epoch:   46	Loss: 0.6954	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:07:27 [INFO ]  Epoch:   47	Loss: 0.7028	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:07:29 [INFO ]  Epoch:   48	Loss: 0.7325	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:31 [INFO ]  Epoch:   49	Loss: 0.6790	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:07:33 [INFO ]  Epoch:   50	Loss: 0.5521	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:07:35 [INFO ]  Epoch:   51	Loss: 0.6513	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:07:37 [INFO ]  Epoch:   52	Loss: 0.6062	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:07:38 [INFO ]  Epoch:   53	Loss: 0.6653	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:40 [INFO ]  Epoch:   54	Loss: 0.6013	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:07:42 [INFO ]  Epoch:   55	Loss: 0.5685	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:44 [INFO ]  Epoch:   56	Loss: 0.5904	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:07:46 [INFO ]  Epoch:   57	Loss: 0.5442	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:07:48 [INFO ]  Epoch:   58	Loss: 0.5747	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:49 [INFO ]  Epoch:   59	Loss: 0.6394	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:07:51 [INFO ]  Epoch:   60	Loss: 0.5762	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:07:53 [INFO ]  Epoch:   61	Loss: 0.6043	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:55 [INFO ]  Epoch:   62	Loss: 0.6111	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:57 [INFO ]  Epoch:   63	Loss: 0.5782	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:07:59 [INFO ]  Epoch:   64	Loss: 0.6471	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:01 [INFO ]  Epoch:   65	Loss: 0.6066	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:08:03 [INFO ]  Epoch:   66	Loss: 0.6561	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:05 [INFO ]  Epoch:   67	Loss: 0.6050	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:08:07 [INFO ]  Epoch:   68	Loss: 0.6306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:09 [INFO ]  Epoch:   69	Loss: 0.6870	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:08:10 [INFO ]  Epoch:   70	Loss: 0.5911	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:08:12 [INFO ]  Epoch:   71	Loss: 0.6429	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:08:14 [INFO ]  Epoch:   72	Loss: 0.6580	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:08:16 [INFO ]  Epoch:   73	Loss: 0.5226	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:08:18 [INFO ]  Epoch:   74	Loss: 0.5656	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:08:20 [INFO ]  Epoch:   75	Loss: 0.6521	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:08:22 [INFO ]  Epoch:   76	Loss: 0.5614	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:24 [INFO ]  Epoch:   77	Loss: 0.6640	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:26 [INFO ]  Epoch:   78	Loss: 0.5977	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:08:27 [INFO ]  Epoch:   79	Loss: 0.6159	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:29 [INFO ]  Epoch:   80	Loss: 0.5586	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:31 [INFO ]  Epoch:   81	Loss: 0.5960	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:33 [INFO ]  Epoch:   82	Loss: 0.6395	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:35 [INFO ]  Epoch:   83	Loss: 0.5196	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:37 [INFO ]  Epoch:   84	Loss: 0.6528	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:39 [INFO ]  Epoch:   85	Loss: 0.6808	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:41 [INFO ]  Epoch:   86	Loss: 0.5837	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 15:08:43 [INFO ]  Epoch:   87	Loss: 0.6539	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:44 [INFO ]  Epoch:   88	Loss: 0.5967	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:46 [INFO ]  Epoch:   89	Loss: 0.6085	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:48 [INFO ]  Epoch:   90	Loss: 0.6253	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:50 [INFO ]  Epoch:   91	Loss: 0.6722	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:52 [INFO ]  Epoch:   92	Loss: 0.5998	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:08:54 [INFO ]  Epoch:   93	Loss: 0.7100	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:08:56 [INFO ]  Epoch:   94	Loss: 0.6297	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:08:58 [INFO ]  Epoch:   95	Loss: 0.6208	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:00 [INFO ]  Epoch:   96	Loss: 0.5319	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:09:02 [INFO ]  Epoch:   97	Loss: 0.5353	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:04 [INFO ]  Epoch:   98	Loss: 0.6459	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:09:05 [INFO ]  Epoch:   99	Loss: 0.5818	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:09:07 [INFO ]  Epoch:  100	Loss: 0.6269	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:09:09 [INFO ]  Epoch:  101	Loss: 0.6262	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:11 [INFO ]  Epoch:  102	Loss: 0.5137	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:09:13 [INFO ]  Epoch:  103	Loss: 0.5145	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:09:14 [INFO ]  Epoch:  104	Loss: 0.5516	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:16 [INFO ]  Epoch:  105	Loss: 0.5635	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:18 [INFO ]  Epoch:  106	Loss: 0.5168	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:20 [INFO ]  Epoch:  107	Loss: 0.5438	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:22 [INFO ]  Epoch:  108	Loss: 0.5582	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:24 [INFO ]  Epoch:  109	Loss: 0.6507	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:09:26 [INFO ]  Epoch:  110	Loss: 0.5961	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:28 [INFO ]  Epoch:  111	Loss: 0.5125	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:09:30 [INFO ]  Epoch:  112	Loss: 0.6336	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:09:32 [INFO ]  Epoch:  113	Loss: 0.5751	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:09:34 [INFO ]  Epoch:  114	Loss: 0.5647	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:09:35 [INFO ]  Epoch:  115	Loss: 0.5099	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:09:37 [INFO ]  Epoch:  116	Loss: 0.5909	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:09:39 [INFO ]  Epoch:  117	Loss: 0.6646	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:09:41 [INFO ]  Epoch:  118	Loss: 0.5516	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:09:43 [INFO ]  Epoch:  119	Loss: 0.5676	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:09:45 [INFO ]  Epoch:  120	Loss: 0.5462	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:47 [INFO ]  Epoch:  121	Loss: 0.6005	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:09:49 [INFO ]  Epoch:  122	Loss: 0.5408	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:09:51 [INFO ]  Epoch:  123	Loss: 0.5097	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:52 [INFO ]  Epoch:  124	Loss: 0.5324	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:09:54 [INFO ]  Epoch:  125	Loss: 0.6023	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:09:56 [INFO ]  Epoch:  126	Loss: 0.6316	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:09:58 [INFO ]  Epoch:  127	Loss: 0.6494	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:00 [INFO ]  Epoch:  128	Loss: 0.5919	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:10:02 [INFO ]  Epoch:  129	Loss: 0.5096	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:10:03 [INFO ]  Epoch:  130	Loss: 0.5930	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:10:05 [INFO ]  Epoch:  131	Loss: 0.5633	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:10:07 [INFO ]  Epoch:  132	Loss: 0.5860	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:09 [INFO ]  Epoch:  133	Loss: 0.5673	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:11 [INFO ]  Epoch:  134	Loss: 0.5482	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:13 [INFO ]  Epoch:  135	Loss: 0.5322	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:10:14 [INFO ]  Epoch:  136	Loss: 0.5774	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:10:16 [INFO ]  Epoch:  137	Loss: 0.5239	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:10:18 [INFO ]  Epoch:  138	Loss: 0.5994	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:10:20 [INFO ]  Epoch:  139	Loss: 0.5357	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:22 [INFO ]  Epoch:  140	Loss: 0.6025	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:24 [INFO ]  Epoch:  141	Loss: 0.5530	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:10:26 [INFO ]  Epoch:  142	Loss: 0.5858	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:10:28 [INFO ]  Epoch:  143	Loss: 0.5477	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:10:30 [INFO ]  Epoch:  144	Loss: 0.5272	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:32 [INFO ]  Epoch:  145	Loss: 0.5138	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:10:34 [INFO ]  Epoch:  146	Loss: 0.6035	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:10:36 [INFO ]  Epoch:  147	Loss: 0.5142	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:10:38 [INFO ]  Epoch:  148	Loss: 0.5639	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:40 [INFO ]  Epoch:  149	Loss: 0.5741	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:42 [INFO ]  Epoch:  150	Loss: 0.5783	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:43 [INFO ]  Epoch:  151	Loss: 0.5659	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:46 [INFO ]  Epoch:  152	Loss: 0.5674	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:10:47 [INFO ]  Epoch:  153	Loss: 0.5747	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:49 [INFO ]  Epoch:  154	Loss: 0.5106	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:51 [INFO ]  Epoch:  155	Loss: 0.6242	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:10:53 [INFO ]  Epoch:  156	Loss: 0.5338	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:55 [INFO ]  Epoch:  157	Loss: 0.6319	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:10:57 [INFO ]  Epoch:  158	Loss: 0.5749	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:10:59 [INFO ]  Epoch:  159	Loss: 0.6485	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:11:00 [INFO ]  Epoch:  160	Loss: 0.5096	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:11:02 [INFO ]  Epoch:  161	Loss: 0.5536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:04 [INFO ]  Epoch:  162	Loss: 0.5769	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:06 [INFO ]  Epoch:  163	Loss: 0.5709	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:11:08 [INFO ]  Epoch:  164	Loss: 0.5325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:09 [INFO ]  Epoch:  165	Loss: 0.5295	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:11:11 [INFO ]  Epoch:  166	Loss: 0.5404	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:11:13 [INFO ]  Epoch:  167	Loss: 0.5800	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:15 [INFO ]  Epoch:  168	Loss: 0.5521	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:11:17 [INFO ]  Epoch:  169	Loss: 0.5859	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:11:19 [INFO ]  Epoch:  170	Loss: 0.6191	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:11:21 [INFO ]  Epoch:  171	Loss: 0.5784	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:23 [INFO ]  Epoch:  172	Loss: 0.5460	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:25 [INFO ]  Epoch:  173	Loss: 0.5160	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:27 [INFO ]  Epoch:  174	Loss: 0.5227	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:11:29 [INFO ]  Epoch:  175	Loss: 0.5314	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:11:30 [INFO ]  Epoch:  176	Loss: 0.5978	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:32 [INFO ]  Epoch:  177	Loss: 0.6260	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:11:34 [INFO ]  Epoch:  178	Loss: 0.5050	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:36 [INFO ]  Epoch:  179	Loss: 0.5233	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:38 [INFO ]  Epoch:  180	Loss: 0.5573	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:40 [INFO ]  Epoch:  181	Loss: 0.5599	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:11:41 [INFO ]  Epoch:  182	Loss: 0.5947	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:44 [INFO ]  Epoch:  183	Loss: 0.5469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:45 [INFO ]  Epoch:  184	Loss: 0.6294	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:11:47 [INFO ]  Epoch:  185	Loss: 0.5071	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:11:49 [INFO ]  Epoch:  186	Loss: 0.5537	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:11:51 [INFO ]  Epoch:  187	Loss: 0.5715	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:11:53 [INFO ]  Epoch:  188	Loss: 0.5161	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:55 [INFO ]  Epoch:  189	Loss: 0.5892	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:11:57 [INFO ]  Epoch:  190	Loss: 0.5528	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:11:59 [INFO ]  Epoch:  191	Loss: 0.5905	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:12:01 [INFO ]  Epoch:  192	Loss: 0.6037	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:12:03 [INFO ]  Epoch:  193	Loss: 0.5781	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:12:04 [INFO ]  Epoch:  194	Loss: 0.5966	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:12:06 [INFO ]  Epoch:  195	Loss: 0.5440	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:12:08 [INFO ]  Epoch:  196	Loss: 0.6036	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:12:10 [INFO ]  Epoch:  197	Loss: 0.5515	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:12:12 [INFO ]  Epoch:  198	Loss: 0.6051	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:12:14 [INFO ]  Epoch:  199	Loss: 0.4993	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:12:15 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 15:12:15 [INFO ]  
2022-10-04 15:12:15 [INFO ]  Final evaluation for SVHN :
2022-10-04 15:12:19 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:12:19 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:12:19 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:12:19 [INFO ]  	   step  1 (lr=0.466959)                   82.53%                   0.6498
2022-10-04 15:12:19 [INFO ]  
2022-10-04 15:12:19 [INFO ]  
2022-10-04 15:12:19 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 15:12:22 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:12:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:12:22 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 15:12:22 [INFO ]  	   step  1 (lr=0.466959)                   14.82%                   5.6032
2022-10-04 15:12:22 [INFO ]  
2022-10-04 15:12:22 [INFO ]  CPU Time: 3.61 minutes
2022-10-04 15:14:01 [INFO ]  ======================================== 2022-10-04 15:14:01 ========================================
2022-10-04 15:14:01 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 15:14:01 [INFO ]  Options: 
2022-10-04 15:14:01 [INFO ]  	base_dir: null
2022-10-04 15:14:01 [INFO ]  	batch_size: 1024
2022-10-04 15:14:01 [INFO ]  	checkpoint_interval: 300
2022-10-04 15:14:01 [INFO ]  	dataset: SVHN
2022-10-04 15:14:01 [INFO ]  	dataset_labels:
2022-10-04 15:14:01 [INFO ]  	- 0
2022-10-04 15:14:01 [INFO ]  	- 1
2022-10-04 15:14:01 [INFO ]  	- 2
2022-10-04 15:14:01 [INFO ]  	- 3
2022-10-04 15:14:01 [INFO ]  	- 4
2022-10-04 15:14:01 [INFO ]  	- 5
2022-10-04 15:14:01 [INFO ]  	- 6
2022-10-04 15:14:01 [INFO ]  	- 7
2022-10-04 15:14:01 [INFO ]  	- 8
2022-10-04 15:14:01 [INFO ]  	- 9
2022-10-04 15:14:01 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 15:14:01 [INFO ]  	- !!python/tuple
2022-10-04 15:14:01 [INFO ]  	    - 0.4379104971885681
2022-10-04 15:14:01 [INFO ]  	    - 0.44398033618927
2022-10-04 15:14:01 [INFO ]  	    - 0.4729299545288086
2022-10-04 15:14:01 [INFO ]  	- !!python/tuple
2022-10-04 15:14:01 [INFO ]  	    - 0.19803012907505035
2022-10-04 15:14:01 [INFO ]  	    - 0.2010156363248825
2022-10-04 15:14:01 [INFO ]  	    - 0.19703614711761475
2022-10-04 15:14:01 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 15:14:01 [INFO ]  	decay_epochs: 50
2022-10-04 15:14:01 [INFO ]  	decay_factor: 0.1
2022-10-04 15:14:01 [INFO ]  	device_id: 0
2022-10-04 15:14:01 [INFO ]  	distill_epochs: 1
2022-10-04 15:14:01 [INFO ]  	distill_lr: 0.02
2022-10-04 15:14:01 [INFO ]  	distill_steps: 1
2022-10-04 15:14:01 [INFO ]  	epochs: 200
2022-10-04 15:14:01 [INFO ]  	expand_cls: false
2022-10-04 15:14:01 [INFO ]  	forgetting_dataset: null
2022-10-04 15:14:01 [INFO ]  	init: xavier
2022-10-04 15:14:01 [INFO ]  	init_param: 1.0
2022-10-04 15:14:01 [INFO ]  	input_size: 32
2022-10-04 15:14:01 [INFO ]  	ipc: 1
2022-10-04 15:14:01 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 15:14:01 [INFO ]  	log_interval: 100
2022-10-04 15:14:01 [INFO ]  	log_level: INFO
2022-10-04 15:14:01 [INFO ]  	lr: 0.01
2022-10-04 15:14:01 [INFO ]  	mode: distill_adapt
2022-10-04 15:14:01 [INFO ]  	nc: 3
2022-10-04 15:14:01 [INFO ]  	num_classes: 10
2022-10-04 15:14:01 [INFO ]  	num_workers: 8
2022-10-04 15:14:01 [INFO ]  	phase: train
2022-10-04 15:14:01 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 15:14:01 [INFO ]  	start_time: '2022-10-04 15:14:01'
2022-10-04 15:14:01 [INFO ]  	test_batch_size: 1024
2022-10-04 15:14:01 [INFO ]  	
2022-10-04 15:14:03 [INFO ]  train dataset size:	73257
2022-10-04 15:14:03 [INFO ]  test dataset size: 	26032
2022-10-04 15:14:03 [INFO ]  datasets built!
2022-10-04 15:14:03 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 15:14:05 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 15:14:05 [INFO ]  
2022-10-04 15:14:05 [INFO ]  Begin of epoch 0 :
2022-10-04 15:14:08 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:14:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:14:08 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:14:08 [INFO ]  	   step  1 (lr=0.020000)                    7.13%                  10.6237
2022-10-04 15:14:08 [INFO ]  
2022-10-04 15:14:08 [INFO ]  Epoch:    0	Loss: 10.4719	Data Time: 0.39s	Train Time: 0.03s
2022-10-04 15:14:10 [INFO ]  Epoch:    1	Loss: 3.6273	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:14:12 [INFO ]  Epoch:    2	Loss: 2.8370	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:14:14 [INFO ]  Epoch:    3	Loss: 2.5340	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:14:16 [INFO ]  Epoch:    4	Loss: 2.3513	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:14:18 [INFO ]  Epoch:    5	Loss: 2.2900	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:14:20 [INFO ]  Epoch:    6	Loss: 2.2780	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:14:22 [INFO ]  Epoch:    7	Loss: 2.2535	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:14:24 [INFO ]  Epoch:    8	Loss: 2.2079	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:14:26 [INFO ]  Epoch:    9	Loss: 2.2385	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:14:27 [INFO ]  Epoch:   10	Loss: 2.1760	Data Time: 0.16s	Train Time: 0.00s
2022-10-04 15:14:29 [INFO ]  Epoch:   11	Loss: 2.1564	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:14:31 [INFO ]  Epoch:   12	Loss: 2.1082	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:14:33 [INFO ]  Epoch:   13	Loss: 2.1047	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:14:35 [INFO ]  Epoch:   14	Loss: 2.0748	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:14:37 [INFO ]  Epoch:   15	Loss: 2.0097	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:14:39 [INFO ]  Epoch:   16	Loss: 1.9541	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:14:41 [INFO ]  Epoch:   17	Loss: 1.8503	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:14:43 [INFO ]  Epoch:   18	Loss: 1.9519	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:14:45 [INFO ]  Epoch:   19	Loss: 1.7594	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:14:47 [INFO ]  Epoch:   20	Loss: 2.3819	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:14:48 [INFO ]  Epoch:   21	Loss: 1.8275	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:14:50 [INFO ]  Epoch:   22	Loss: 1.7235	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:14:52 [INFO ]  Epoch:   23	Loss: 2.6581	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:14:54 [INFO ]  Epoch:   24	Loss: 1.6950	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:14:56 [INFO ]  Epoch:   25	Loss: 1.7012	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:14:58 [INFO ]  Epoch:   26	Loss: 1.6858	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:15:00 [INFO ]  Epoch:   27	Loss: 1.6924	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:15:02 [INFO ]  Epoch:   28	Loss: 1.6552	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:04 [INFO ]  Epoch:   29	Loss: 1.7835	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:15:06 [INFO ]  Epoch:   30	Loss: 1.4497	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:07 [INFO ]  Epoch:   31	Loss: 1.4591	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:09 [INFO ]  Epoch:   32	Loss: 1.4881	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:11 [INFO ]  Epoch:   33	Loss: 1.3206	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:15:13 [INFO ]  Epoch:   34	Loss: 1.4095	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:15 [INFO ]  Epoch:   35	Loss: 1.3795	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:15:17 [INFO ]  Epoch:   36	Loss: 1.2965	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:15:19 [INFO ]  Epoch:   37	Loss: 1.4117	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:15:20 [INFO ]  Epoch:   38	Loss: 1.4999	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:22 [INFO ]  Epoch:   39	Loss: 1.4269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:24 [INFO ]  Epoch:   40	Loss: 1.3583	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:15:26 [INFO ]  Epoch:   41	Loss: 1.4272	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:28 [INFO ]  Epoch:   42	Loss: 1.3499	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:15:30 [INFO ]  Epoch:   43	Loss: 1.5104	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:15:31 [INFO ]  Epoch:   44	Loss: 1.3879	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:33 [INFO ]  Epoch:   45	Loss: 1.4516	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:35 [INFO ]  Epoch:   46	Loss: 1.2396	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:15:37 [INFO ]  Epoch:   47	Loss: 1.2010	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:15:39 [INFO ]  Epoch:   48	Loss: 1.3553	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:15:41 [INFO ]  Epoch:   49	Loss: 1.6274	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:43 [INFO ]  Epoch:   50	Loss: 1.2686	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:15:45 [INFO ]  Epoch:   51	Loss: 1.1758	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:46 [INFO ]  Epoch:   52	Loss: 1.2164	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:15:48 [INFO ]  Epoch:   53	Loss: 1.2686	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:15:50 [INFO ]  Epoch:   54	Loss: 1.2809	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:15:52 [INFO ]  Epoch:   55	Loss: 1.2003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:54 [INFO ]  Epoch:   56	Loss: 1.1799	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:15:56 [INFO ]  Epoch:   57	Loss: 1.2329	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:15:57 [INFO ]  Epoch:   58	Loss: 1.1761	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:15:59 [INFO ]  Epoch:   59	Loss: 1.1604	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:16:01 [INFO ]  Epoch:   60	Loss: 1.2510	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:03 [INFO ]  Epoch:   61	Loss: 1.2023	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:16:05 [INFO ]  Epoch:   62	Loss: 1.2058	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:16:07 [INFO ]  Epoch:   63	Loss: 1.1263	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:09 [INFO ]  Epoch:   64	Loss: 1.2273	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:10 [INFO ]  Epoch:   65	Loss: 1.2136	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:12 [INFO ]  Epoch:   66	Loss: 1.1724	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:16:14 [INFO ]  Epoch:   67	Loss: 1.0949	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:16:16 [INFO ]  Epoch:   68	Loss: 1.1494	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:16:18 [INFO ]  Epoch:   69	Loss: 1.1538	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:16:20 [INFO ]  Epoch:   70	Loss: 1.3091	Data Time: 0.22s	Train Time: 0.00s
2022-10-04 15:16:22 [INFO ]  Epoch:   71	Loss: 1.2313	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:16:23 [INFO ]  Epoch:   72	Loss: 1.2404	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:16:25 [INFO ]  Epoch:   73	Loss: 1.1743	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:16:27 [INFO ]  Epoch:   74	Loss: 1.1081	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:16:29 [INFO ]  Epoch:   75	Loss: 1.2853	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:16:31 [INFO ]  Epoch:   76	Loss: 1.2851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:33 [INFO ]  Epoch:   77	Loss: 1.0969	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:16:34 [INFO ]  Epoch:   78	Loss: 1.1724	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:36 [INFO ]  Epoch:   79	Loss: 1.0987	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:16:38 [INFO ]  Epoch:   80	Loss: 1.1393	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:16:40 [INFO ]  Epoch:   81	Loss: 1.0942	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:16:42 [INFO ]  Epoch:   82	Loss: 1.1054	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:16:44 [INFO ]  Epoch:   83	Loss: 1.1363	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:16:45 [INFO ]  Epoch:   84	Loss: 1.0885	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:16:47 [INFO ]  Epoch:   85	Loss: 1.3577	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:16:49 [INFO ]  Epoch:   86	Loss: 1.1360	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:16:51 [INFO ]  Epoch:   87	Loss: 1.2265	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:16:53 [INFO ]  Epoch:   88	Loss: 1.1279	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:16:55 [INFO ]  Epoch:   89	Loss: 1.1054	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:16:56 [INFO ]  Epoch:   90	Loss: 1.0225	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:16:58 [INFO ]  Epoch:   91	Loss: 1.1308	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:17:00 [INFO ]  Epoch:   92	Loss: 1.2176	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:17:02 [INFO ]  Epoch:   93	Loss: 1.1828	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:17:04 [INFO ]  Epoch:   94	Loss: 1.1490	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:17:06 [INFO ]  Epoch:   95	Loss: 1.1271	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:17:07 [INFO ]  Epoch:   96	Loss: 1.1816	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:09 [INFO ]  Epoch:   97	Loss: 1.0446	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:11 [INFO ]  Epoch:   98	Loss: 1.1114	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:13 [INFO ]  Epoch:   99	Loss: 1.3260	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:17:16 [INFO ]  Epoch:  100	Loss: 1.2320	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:17:18 [INFO ]  Epoch:  101	Loss: 1.2240	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:17:20 [INFO ]  Epoch:  102	Loss: 1.1271	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:17:21 [INFO ]  Epoch:  103	Loss: 1.0985	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:17:23 [INFO ]  Epoch:  104	Loss: 1.1550	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:25 [INFO ]  Epoch:  105	Loss: 1.1110	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:27 [INFO ]  Epoch:  106	Loss: 1.2375	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:17:29 [INFO ]  Epoch:  107	Loss: 1.0440	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:31 [INFO ]  Epoch:  108	Loss: 1.1515	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:33 [INFO ]  Epoch:  109	Loss: 1.2314	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:17:34 [INFO ]  Epoch:  110	Loss: 1.1636	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:17:36 [INFO ]  Epoch:  111	Loss: 1.1034	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:38 [INFO ]  Epoch:  112	Loss: 1.1898	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:17:40 [INFO ]  Epoch:  113	Loss: 1.0690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:42 [INFO ]  Epoch:  114	Loss: 1.1107	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:17:44 [INFO ]  Epoch:  115	Loss: 1.1422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:46 [INFO ]  Epoch:  116	Loss: 1.0971	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:17:48 [INFO ]  Epoch:  117	Loss: 1.1368	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:17:49 [INFO ]  Epoch:  118	Loss: 1.1710	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:51 [INFO ]  Epoch:  119	Loss: 1.3724	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:53 [INFO ]  Epoch:  120	Loss: 1.1385	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:55 [INFO ]  Epoch:  121	Loss: 1.1699	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:17:57 [INFO ]  Epoch:  122	Loss: 1.1696	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:17:59 [INFO ]  Epoch:  123	Loss: 1.2537	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:18:01 [INFO ]  Epoch:  124	Loss: 1.1033	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:18:03 [INFO ]  Epoch:  125	Loss: 1.2826	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:18:04 [INFO ]  Epoch:  126	Loss: 1.1687	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:18:06 [INFO ]  Epoch:  127	Loss: 1.1182	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:18:08 [INFO ]  Epoch:  128	Loss: 1.2404	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:18:10 [INFO ]  Epoch:  129	Loss: 1.2256	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:18:12 [INFO ]  Epoch:  130	Loss: 1.0531	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:18:14 [INFO ]  Epoch:  131	Loss: 1.1585	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:16 [INFO ]  Epoch:  132	Loss: 1.3683	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:18:18 [INFO ]  Epoch:  133	Loss: 1.1148	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:18:20 [INFO ]  Epoch:  134	Loss: 1.0998	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:18:22 [INFO ]  Epoch:  135	Loss: 1.1379	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:18:23 [INFO ]  Epoch:  136	Loss: 1.0711	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:18:25 [INFO ]  Epoch:  137	Loss: 1.0969	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:27 [INFO ]  Epoch:  138	Loss: 1.0820	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:18:29 [INFO ]  Epoch:  139	Loss: 1.1049	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:31 [INFO ]  Epoch:  140	Loss: 1.1161	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:18:33 [INFO ]  Epoch:  141	Loss: 1.2036	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:18:35 [INFO ]  Epoch:  142	Loss: 1.4321	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:37 [INFO ]  Epoch:  143	Loss: 1.1348	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:18:39 [INFO ]  Epoch:  144	Loss: 1.2103	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:18:41 [INFO ]  Epoch:  145	Loss: 1.1180	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:43 [INFO ]  Epoch:  146	Loss: 1.0859	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:44 [INFO ]  Epoch:  147	Loss: 1.2733	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:18:46 [INFO ]  Epoch:  148	Loss: 1.0049	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:18:48 [INFO ]  Epoch:  149	Loss: 1.1308	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:50 [INFO ]  Epoch:  150	Loss: 1.2854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:18:52 [INFO ]  Epoch:  151	Loss: 1.1597	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:18:54 [INFO ]  Epoch:  152	Loss: 1.1168	Data Time: 0.20s	Train Time: 0.00s
2022-10-04 15:18:56 [INFO ]  Epoch:  153	Loss: 1.1537	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:18:58 [INFO ]  Epoch:  154	Loss: 1.1481	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:19:00 [INFO ]  Epoch:  155	Loss: 1.2177	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:01 [INFO ]  Epoch:  156	Loss: 1.1856	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:03 [INFO ]  Epoch:  157	Loss: 1.0852	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:05 [INFO ]  Epoch:  158	Loss: 1.2477	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:19:07 [INFO ]  Epoch:  159	Loss: 1.1014	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:09 [INFO ]  Epoch:  160	Loss: 1.1061	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:19:11 [INFO ]  Epoch:  161	Loss: 1.1200	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:19:13 [INFO ]  Epoch:  162	Loss: 1.1518	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:15 [INFO ]  Epoch:  163	Loss: 1.0815	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:17 [INFO ]  Epoch:  164	Loss: 1.1736	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:19 [INFO ]  Epoch:  165	Loss: 1.1121	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:21 [INFO ]  Epoch:  166	Loss: 1.1358	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:19:22 [INFO ]  Epoch:  167	Loss: 1.0863	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:24 [INFO ]  Epoch:  168	Loss: 1.0927	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:19:26 [INFO ]  Epoch:  169	Loss: 1.0772	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:28 [INFO ]  Epoch:  170	Loss: 1.1169	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:19:30 [INFO ]  Epoch:  171	Loss: 1.1662	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:19:32 [INFO ]  Epoch:  172	Loss: 1.1885	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:19:34 [INFO ]  Epoch:  173	Loss: 1.1463	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:19:36 [INFO ]  Epoch:  174	Loss: 1.0859	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:38 [INFO ]  Epoch:  175	Loss: 1.2595	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:19:40 [INFO ]  Epoch:  176	Loss: 1.1940	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:19:42 [INFO ]  Epoch:  177	Loss: 1.1096	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:44 [INFO ]  Epoch:  178	Loss: 1.2120	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:19:46 [INFO ]  Epoch:  179	Loss: 1.1358	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:47 [INFO ]  Epoch:  180	Loss: 1.1605	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:19:49 [INFO ]  Epoch:  181	Loss: 1.1568	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:19:51 [INFO ]  Epoch:  182	Loss: 1.1910	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:53 [INFO ]  Epoch:  183	Loss: 1.0936	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:19:55 [INFO ]  Epoch:  184	Loss: 1.1579	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:19:57 [INFO ]  Epoch:  185	Loss: 1.1626	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:19:59 [INFO ]  Epoch:  186	Loss: 1.1550	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:20:00 [INFO ]  Epoch:  187	Loss: 1.0818	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:20:02 [INFO ]  Epoch:  188	Loss: 1.1074	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:20:04 [INFO ]  Epoch:  189	Loss: 1.1771	Data Time: 0.17s	Train Time: 0.02s
2022-10-04 15:20:06 [INFO ]  Epoch:  190	Loss: 1.1143	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:20:08 [INFO ]  Epoch:  191	Loss: 1.1588	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:20:10 [INFO ]  Epoch:  192	Loss: 1.1927	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:20:12 [INFO ]  Epoch:  193	Loss: 1.1232	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:20:14 [INFO ]  Epoch:  194	Loss: 1.1597	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:20:16 [INFO ]  Epoch:  195	Loss: 1.1067	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:20:18 [INFO ]  Epoch:  196	Loss: 1.1419	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:20:19 [INFO ]  Epoch:  197	Loss: 1.1874	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:20:21 [INFO ]  Epoch:  198	Loss: 1.0965	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:20:23 [INFO ]  Epoch:  199	Loss: 1.0427	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:20:25 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 15:20:25 [INFO ]  
2022-10-04 15:20:25 [INFO ]  Final evaluation for SVHN :
2022-10-04 15:20:28 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:20:28 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:20:28 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:20:28 [INFO ]  	   step  1 (lr=0.231997)                   66.62%                   1.1587
2022-10-04 15:20:28 [INFO ]  
2022-10-04 15:20:28 [INFO ]  
2022-10-04 15:20:28 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 15:20:31 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:20:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:20:31 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 15:20:31 [INFO ]  	   step  1 (lr=0.231997)                   20.96%                   5.9218
2022-10-04 15:20:31 [INFO ]  
2022-10-04 15:20:31 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 15:20:42 [INFO ]  ======================================== 2022-10-04 15:20:42 ========================================
2022-10-04 15:20:42 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 15:20:42 [INFO ]  Options: 
2022-10-04 15:20:42 [INFO ]  	base_dir: null
2022-10-04 15:20:42 [INFO ]  	batch_size: 1024
2022-10-04 15:20:42 [INFO ]  	checkpoint_interval: 300
2022-10-04 15:20:42 [INFO ]  	dataset: SVHN
2022-10-04 15:20:42 [INFO ]  	dataset_labels:
2022-10-04 15:20:42 [INFO ]  	- 0
2022-10-04 15:20:42 [INFO ]  	- 1
2022-10-04 15:20:42 [INFO ]  	- 2
2022-10-04 15:20:42 [INFO ]  	- 3
2022-10-04 15:20:42 [INFO ]  	- 4
2022-10-04 15:20:42 [INFO ]  	- 5
2022-10-04 15:20:42 [INFO ]  	- 6
2022-10-04 15:20:42 [INFO ]  	- 7
2022-10-04 15:20:42 [INFO ]  	- 8
2022-10-04 15:20:42 [INFO ]  	- 9
2022-10-04 15:20:42 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 15:20:42 [INFO ]  	- !!python/tuple
2022-10-04 15:20:42 [INFO ]  	    - 0.4379104971885681
2022-10-04 15:20:42 [INFO ]  	    - 0.44398033618927
2022-10-04 15:20:42 [INFO ]  	    - 0.4729299545288086
2022-10-04 15:20:42 [INFO ]  	- !!python/tuple
2022-10-04 15:20:42 [INFO ]  	    - 0.19803012907505035
2022-10-04 15:20:42 [INFO ]  	    - 0.2010156363248825
2022-10-04 15:20:42 [INFO ]  	    - 0.19703614711761475
2022-10-04 15:20:42 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 15:20:42 [INFO ]  	decay_epochs: 50
2022-10-04 15:20:42 [INFO ]  	decay_factor: 0.1
2022-10-04 15:20:42 [INFO ]  	device_id: 0
2022-10-04 15:20:42 [INFO ]  	distill_epochs: 1
2022-10-04 15:20:42 [INFO ]  	distill_lr: 0.02
2022-10-04 15:20:42 [INFO ]  	distill_steps: 1
2022-10-04 15:20:42 [INFO ]  	epochs: 200
2022-10-04 15:20:42 [INFO ]  	expand_cls: false
2022-10-04 15:20:42 [INFO ]  	forgetting_dataset: null
2022-10-04 15:20:42 [INFO ]  	init: xavier
2022-10-04 15:20:42 [INFO ]  	init_param: 1.0
2022-10-04 15:20:42 [INFO ]  	input_size: 32
2022-10-04 15:20:42 [INFO ]  	ipc: 1
2022-10-04 15:20:42 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 15:20:42 [INFO ]  	log_interval: 100
2022-10-04 15:20:42 [INFO ]  	log_level: INFO
2022-10-04 15:20:42 [INFO ]  	lr: 0.01
2022-10-04 15:20:42 [INFO ]  	mode: distill_adapt
2022-10-04 15:20:42 [INFO ]  	nc: 3
2022-10-04 15:20:42 [INFO ]  	num_classes: 10
2022-10-04 15:20:42 [INFO ]  	num_workers: 8
2022-10-04 15:20:42 [INFO ]  	phase: train
2022-10-04 15:20:42 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 15:20:42 [INFO ]  	start_time: '2022-10-04 15:20:42'
2022-10-04 15:20:42 [INFO ]  	test_batch_size: 1024
2022-10-04 15:20:42 [INFO ]  	
2022-10-04 15:20:44 [INFO ]  train dataset size:	73257
2022-10-04 15:20:44 [INFO ]  test dataset size: 	26032
2022-10-04 15:20:44 [INFO ]  datasets built!
2022-10-04 15:20:44 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 15:20:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 15:20:46 [INFO ]  
2022-10-04 15:20:46 [INFO ]  Begin of epoch 0 :
2022-10-04 15:20:50 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:20:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:20:50 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:20:50 [INFO ]  	   step  1 (lr=0.020000)                    6.84%                  10.8170
2022-10-04 15:20:50 [INFO ]  
2022-10-04 15:20:50 [INFO ]  Epoch:    0	Loss: 11.4539	Data Time: 0.39s	Train Time: 0.03s
2022-10-04 15:20:51 [INFO ]  Epoch:    1	Loss: 3.3047	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:20:53 [INFO ]  Epoch:    2	Loss: 2.7763	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:20:55 [INFO ]  Epoch:    3	Loss: 2.5187	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:20:57 [INFO ]  Epoch:    4	Loss: 2.3601	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:20:59 [INFO ]  Epoch:    5	Loss: 2.3309	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:21:00 [INFO ]  Epoch:    6	Loss: 2.1942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:02 [INFO ]  Epoch:    7	Loss: 2.1703	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:21:04 [INFO ]  Epoch:    8	Loss: 2.1534	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:21:06 [INFO ]  Epoch:    9	Loss: 2.1351	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:21:08 [INFO ]  Epoch:   10	Loss: 2.1074	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:21:10 [INFO ]  Epoch:   11	Loss: 2.1033	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:21:11 [INFO ]  Epoch:   12	Loss: 2.0226	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:13 [INFO ]  Epoch:   13	Loss: 1.9991	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:21:15 [INFO ]  Epoch:   14	Loss: 2.0008	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:21:17 [INFO ]  Epoch:   15	Loss: 1.8818	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:21:19 [INFO ]  Epoch:   16	Loss: 1.8542	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:21:21 [INFO ]  Epoch:   17	Loss: 1.9154	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:21:23 [INFO ]  Epoch:   18	Loss: 1.7046	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:21:25 [INFO ]  Epoch:   19	Loss: 1.7255	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:21:26 [INFO ]  Epoch:   20	Loss: 1.8637	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:21:28 [INFO ]  Epoch:   21	Loss: 1.5510	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:21:30 [INFO ]  Epoch:   22	Loss: 1.5683	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:32 [INFO ]  Epoch:   23	Loss: 1.6184	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:21:34 [INFO ]  Epoch:   24	Loss: 1.7220	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:36 [INFO ]  Epoch:   25	Loss: 1.6849	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:37 [INFO ]  Epoch:   26	Loss: 1.5604	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:39 [INFO ]  Epoch:   27	Loss: 1.4332	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:21:41 [INFO ]  Epoch:   28	Loss: 1.4373	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:21:43 [INFO ]  Epoch:   29	Loss: 1.3548	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:21:45 [INFO ]  Epoch:   30	Loss: 1.3854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:47 [INFO ]  Epoch:   31	Loss: 1.4086	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:21:49 [INFO ]  Epoch:   32	Loss: 1.3395	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:51 [INFO ]  Epoch:   33	Loss: 1.3829	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:21:52 [INFO ]  Epoch:   34	Loss: 1.3966	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:21:54 [INFO ]  Epoch:   35	Loss: 1.2899	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:21:56 [INFO ]  Epoch:   36	Loss: 1.3586	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:21:58 [INFO ]  Epoch:   37	Loss: 1.1866	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:00 [INFO ]  Epoch:   38	Loss: 1.3948	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:22:02 [INFO ]  Epoch:   39	Loss: 1.6055	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:03 [INFO ]  Epoch:   40	Loss: 1.3558	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:22:05 [INFO ]  Epoch:   41	Loss: 1.3581	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:07 [INFO ]  Epoch:   42	Loss: 1.2327	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:22:09 [INFO ]  Epoch:   43	Loss: 1.5053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:11 [INFO ]  Epoch:   44	Loss: 1.3142	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:22:13 [INFO ]  Epoch:   45	Loss: 1.1721	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:15 [INFO ]  Epoch:   46	Loss: 1.2945	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:17 [INFO ]  Epoch:   47	Loss: 1.2129	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:18 [INFO ]  Epoch:   48	Loss: 1.1228	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:22:20 [INFO ]  Epoch:   49	Loss: 1.1554	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:22 [INFO ]  Epoch:   50	Loss: 1.0933	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:24 [INFO ]  Epoch:   51	Loss: 1.0395	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:26 [INFO ]  Epoch:   52	Loss: 1.0077	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:22:28 [INFO ]  Epoch:   53	Loss: 1.0269	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:30 [INFO ]  Epoch:   54	Loss: 1.0037	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:32 [INFO ]  Epoch:   55	Loss: 1.0702	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:34 [INFO ]  Epoch:   56	Loss: 1.2014	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:36 [INFO ]  Epoch:   57	Loss: 1.1078	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:37 [INFO ]  Epoch:   58	Loss: 1.1343	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:22:39 [INFO ]  Epoch:   59	Loss: 1.1217	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:22:42 [INFO ]  Epoch:   60	Loss: 1.0859	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:22:43 [INFO ]  Epoch:   61	Loss: 0.9931	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:22:45 [INFO ]  Epoch:   62	Loss: 1.1567	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:47 [INFO ]  Epoch:   63	Loss: 1.0258	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:22:49 [INFO ]  Epoch:   64	Loss: 0.9974	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:51 [INFO ]  Epoch:   65	Loss: 1.0714	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:53 [INFO ]  Epoch:   66	Loss: 1.0423	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:22:55 [INFO ]  Epoch:   67	Loss: 1.0535	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:22:57 [INFO ]  Epoch:   68	Loss: 1.0774	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:22:58 [INFO ]  Epoch:   69	Loss: 1.0755	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:23:00 [INFO ]  Epoch:   70	Loss: 1.0375	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 15:23:02 [INFO ]  Epoch:   71	Loss: 0.9941	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:23:04 [INFO ]  Epoch:   72	Loss: 0.9655	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:06 [INFO ]  Epoch:   73	Loss: 1.0541	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:23:08 [INFO ]  Epoch:   74	Loss: 1.0013	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:23:10 [INFO ]  Epoch:   75	Loss: 1.0776	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:11 [INFO ]  Epoch:   76	Loss: 0.9892	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:23:13 [INFO ]  Epoch:   77	Loss: 0.9848	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:23:15 [INFO ]  Epoch:   78	Loss: 0.9475	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:17 [INFO ]  Epoch:   79	Loss: 1.0869	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:19 [INFO ]  Epoch:   80	Loss: 1.0913	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:21 [INFO ]  Epoch:   81	Loss: 1.0596	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:23 [INFO ]  Epoch:   82	Loss: 1.0382	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:23:25 [INFO ]  Epoch:   83	Loss: 0.9363	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:23:27 [INFO ]  Epoch:   84	Loss: 0.9137	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:23:29 [INFO ]  Epoch:   85	Loss: 1.0249	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:23:31 [INFO ]  Epoch:   86	Loss: 1.0169	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:23:32 [INFO ]  Epoch:   87	Loss: 0.9901	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:23:34 [INFO ]  Epoch:   88	Loss: 0.9062	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:36 [INFO ]  Epoch:   89	Loss: 0.8843	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:23:38 [INFO ]  Epoch:   90	Loss: 0.9600	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:23:40 [INFO ]  Epoch:   91	Loss: 0.9477	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:42 [INFO ]  Epoch:   92	Loss: 0.9765	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:44 [INFO ]  Epoch:   93	Loss: 0.9307	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:46 [INFO ]  Epoch:   94	Loss: 1.2903	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:23:47 [INFO ]  Epoch:   95	Loss: 0.9927	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:49 [INFO ]  Epoch:   96	Loss: 1.0364	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:23:52 [INFO ]  Epoch:   97	Loss: 0.9568	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:53 [INFO ]  Epoch:   98	Loss: 1.0122	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:55 [INFO ]  Epoch:   99	Loss: 0.9782	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:23:57 [INFO ]  Epoch:  100	Loss: 0.9755	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:23:59 [INFO ]  Epoch:  101	Loss: 1.0053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:24:01 [INFO ]  Epoch:  102	Loss: 0.9815	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:24:03 [INFO ]  Epoch:  103	Loss: 1.0340	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:24:05 [INFO ]  Epoch:  104	Loss: 0.9778	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:07 [INFO ]  Epoch:  105	Loss: 1.0012	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:24:09 [INFO ]  Epoch:  106	Loss: 0.9505	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:11 [INFO ]  Epoch:  107	Loss: 1.0198	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:24:13 [INFO ]  Epoch:  108	Loss: 0.9149	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:24:15 [INFO ]  Epoch:  109	Loss: 1.0311	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:17 [INFO ]  Epoch:  110	Loss: 0.9300	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:18 [INFO ]  Epoch:  111	Loss: 0.9585	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:24:20 [INFO ]  Epoch:  112	Loss: 1.1439	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:24:22 [INFO ]  Epoch:  113	Loss: 1.0270	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:24:24 [INFO ]  Epoch:  114	Loss: 1.0386	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:26 [INFO ]  Epoch:  115	Loss: 1.2753	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:28 [INFO ]  Epoch:  116	Loss: 1.0014	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:30 [INFO ]  Epoch:  117	Loss: 0.9954	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:24:32 [INFO ]  Epoch:  118	Loss: 1.0079	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:24:34 [INFO ]  Epoch:  119	Loss: 0.9215	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:35 [INFO ]  Epoch:  120	Loss: 0.9288	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:24:38 [INFO ]  Epoch:  121	Loss: 0.9820	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:40 [INFO ]  Epoch:  122	Loss: 0.9193	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:41 [INFO ]  Epoch:  123	Loss: 0.8743	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:24:43 [INFO ]  Epoch:  124	Loss: 0.9472	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:24:45 [INFO ]  Epoch:  125	Loss: 0.9743	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:24:47 [INFO ]  Epoch:  126	Loss: 0.9052	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:49 [INFO ]  Epoch:  127	Loss: 0.8521	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:24:50 [INFO ]  Epoch:  128	Loss: 0.9116	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:24:52 [INFO ]  Epoch:  129	Loss: 0.9256	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:24:54 [INFO ]  Epoch:  130	Loss: 1.1691	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:24:56 [INFO ]  Epoch:  131	Loss: 1.4852	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 15:24:58 [INFO ]  Epoch:  132	Loss: 1.2353	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:00 [INFO ]  Epoch:  133	Loss: 1.0337	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:02 [INFO ]  Epoch:  134	Loss: 1.0433	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:25:04 [INFO ]  Epoch:  135	Loss: 1.1052	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:25:06 [INFO ]  Epoch:  136	Loss: 0.9399	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:07 [INFO ]  Epoch:  137	Loss: 1.0430	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:09 [INFO ]  Epoch:  138	Loss: 0.9456	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 15:25:11 [INFO ]  Epoch:  139	Loss: 0.9780	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:13 [INFO ]  Epoch:  140	Loss: 0.9926	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:25:15 [INFO ]  Epoch:  141	Loss: 1.1445	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:17 [INFO ]  Epoch:  142	Loss: 0.9782	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:25:19 [INFO ]  Epoch:  143	Loss: 0.9603	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:25:21 [INFO ]  Epoch:  144	Loss: 0.9982	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:25:23 [INFO ]  Epoch:  145	Loss: 1.0312	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:25:25 [INFO ]  Epoch:  146	Loss: 0.9480	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:25:26 [INFO ]  Epoch:  147	Loss: 1.0629	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:25:28 [INFO ]  Epoch:  148	Loss: 0.9278	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:30 [INFO ]  Epoch:  149	Loss: 0.9817	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:32 [INFO ]  Epoch:  150	Loss: 0.9699	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:34 [INFO ]  Epoch:  151	Loss: 0.9485	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:36 [INFO ]  Epoch:  152	Loss: 0.9905	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:25:38 [INFO ]  Epoch:  153	Loss: 0.9984	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:40 [INFO ]  Epoch:  154	Loss: 0.9306	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:25:42 [INFO ]  Epoch:  155	Loss: 0.9153	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 15:25:44 [INFO ]  Epoch:  156	Loss: 0.9736	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:25:46 [INFO ]  Epoch:  157	Loss: 0.9942	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:47 [INFO ]  Epoch:  158	Loss: 0.9926	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:49 [INFO ]  Epoch:  159	Loss: 0.9470	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:25:51 [INFO ]  Epoch:  160	Loss: 0.9569	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:25:53 [INFO ]  Epoch:  161	Loss: 0.9765	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 15:25:55 [INFO ]  Epoch:  162	Loss: 0.9793	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:25:56 [INFO ]  Epoch:  163	Loss: 1.0720	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:25:58 [INFO ]  Epoch:  164	Loss: 0.9486	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:00 [INFO ]  Epoch:  165	Loss: 1.0188	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:02 [INFO ]  Epoch:  166	Loss: 0.9726	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:04 [INFO ]  Epoch:  167	Loss: 1.0071	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:06 [INFO ]  Epoch:  168	Loss: 1.0355	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:26:08 [INFO ]  Epoch:  169	Loss: 0.9358	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:10 [INFO ]  Epoch:  170	Loss: 0.9995	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 15:26:12 [INFO ]  Epoch:  171	Loss: 1.0196	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:14 [INFO ]  Epoch:  172	Loss: 1.0115	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:26:16 [INFO ]  Epoch:  173	Loss: 0.9186	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:26:17 [INFO ]  Epoch:  174	Loss: 0.9398	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:19 [INFO ]  Epoch:  175	Loss: 1.0948	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:21 [INFO ]  Epoch:  176	Loss: 1.1062	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:26:23 [INFO ]  Epoch:  177	Loss: 1.0643	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:25 [INFO ]  Epoch:  178	Loss: 1.0490	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:27 [INFO ]  Epoch:  179	Loss: 1.0041	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 15:26:29 [INFO ]  Epoch:  180	Loss: 1.0101	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:31 [INFO ]  Epoch:  181	Loss: 0.9929	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:26:33 [INFO ]  Epoch:  182	Loss: 1.0073	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:26:35 [INFO ]  Epoch:  183	Loss: 0.9896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:26:37 [INFO ]  Epoch:  184	Loss: 0.9612	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:39 [INFO ]  Epoch:  185	Loss: 1.0505	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 15:26:40 [INFO ]  Epoch:  186	Loss: 0.9872	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 15:26:42 [INFO ]  Epoch:  187	Loss: 0.9103	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:26:44 [INFO ]  Epoch:  188	Loss: 1.0520	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 15:26:46 [INFO ]  Epoch:  189	Loss: 0.9826	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:48 [INFO ]  Epoch:  190	Loss: 1.0021	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:50 [INFO ]  Epoch:  191	Loss: 1.0340	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:26:52 [INFO ]  Epoch:  192	Loss: 0.9440	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 15:26:54 [INFO ]  Epoch:  193	Loss: 1.0013	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:26:55 [INFO ]  Epoch:  194	Loss: 0.9913	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:26:57 [INFO ]  Epoch:  195	Loss: 0.8998	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 15:26:59 [INFO ]  Epoch:  196	Loss: 0.9811	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:27:01 [INFO ]  Epoch:  197	Loss: 0.9582	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 15:27:03 [INFO ]  Epoch:  198	Loss: 0.9715	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 15:27:05 [INFO ]  Epoch:  199	Loss: 1.0039	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 15:27:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 15:27:06 [INFO ]  
2022-10-04 15:27:06 [INFO ]  Final evaluation for SVHN :
2022-10-04 15:27:10 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:27:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:27:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 15:27:10 [INFO ]  	   step  1 (lr=0.235845)                   71.99%                   0.9897
2022-10-04 15:27:10 [INFO ]  
2022-10-04 15:27:10 [INFO ]  
2022-10-04 15:27:10 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 15:27:13 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 15:27:13 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 15:27:13 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 15:27:13 [INFO ]  	   step  1 (lr=0.235845)                   15.98%                   4.9181
2022-10-04 15:27:13 [INFO ]  
2022-10-04 15:27:13 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 16:56:51 [INFO ]  ======================================== 2022-10-04 16:56:51 ========================================
2022-10-04 16:56:51 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 16:56:51 [INFO ]  Options: 
2022-10-04 16:56:51 [INFO ]  	base_dir: null
2022-10-04 16:56:51 [INFO ]  	batch_size: 1024
2022-10-04 16:56:51 [INFO ]  	checkpoint_interval: 300
2022-10-04 16:56:51 [INFO ]  	dataset: SVHN
2022-10-04 16:56:51 [INFO ]  	dataset_labels:
2022-10-04 16:56:51 [INFO ]  	- 0
2022-10-04 16:56:51 [INFO ]  	- 1
2022-10-04 16:56:51 [INFO ]  	- 2
2022-10-04 16:56:51 [INFO ]  	- 3
2022-10-04 16:56:51 [INFO ]  	- 4
2022-10-04 16:56:51 [INFO ]  	- 5
2022-10-04 16:56:51 [INFO ]  	- 6
2022-10-04 16:56:51 [INFO ]  	- 7
2022-10-04 16:56:51 [INFO ]  	- 8
2022-10-04 16:56:51 [INFO ]  	- 9
2022-10-04 16:56:51 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 16:56:51 [INFO ]  	- !!python/tuple
2022-10-04 16:56:51 [INFO ]  	    - 0.4379104971885681
2022-10-04 16:56:51 [INFO ]  	    - 0.44398033618927
2022-10-04 16:56:51 [INFO ]  	    - 0.4729299545288086
2022-10-04 16:56:51 [INFO ]  	- !!python/tuple
2022-10-04 16:56:51 [INFO ]  	    - 0.19803012907505035
2022-10-04 16:56:51 [INFO ]  	    - 0.2010156363248825
2022-10-04 16:56:51 [INFO ]  	    - 0.19703614711761475
2022-10-04 16:56:51 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 16:56:51 [INFO ]  	decay_epochs: 50
2022-10-04 16:56:51 [INFO ]  	decay_factor: 0.1
2022-10-04 16:56:51 [INFO ]  	device_id: 0
2022-10-04 16:56:51 [INFO ]  	distill_epochs: 1
2022-10-04 16:56:51 [INFO ]  	distill_lr: 0.02
2022-10-04 16:56:51 [INFO ]  	distill_steps: 1
2022-10-04 16:56:51 [INFO ]  	epochs: 200
2022-10-04 16:56:51 [INFO ]  	expand_cls: false
2022-10-04 16:56:51 [INFO ]  	forgetting_dataset: null
2022-10-04 16:56:51 [INFO ]  	init: xavier
2022-10-04 16:56:51 [INFO ]  	init_param: 1.0
2022-10-04 16:56:51 [INFO ]  	input_size: 32
2022-10-04 16:56:51 [INFO ]  	ipc: 1
2022-10-04 16:56:51 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 16:56:51 [INFO ]  	log_interval: 100
2022-10-04 16:56:51 [INFO ]  	log_level: INFO
2022-10-04 16:56:51 [INFO ]  	lr: 0.01
2022-10-04 16:56:51 [INFO ]  	mode: distill_adapt
2022-10-04 16:56:51 [INFO ]  	nc: 3
2022-10-04 16:56:51 [INFO ]  	num_classes: 10
2022-10-04 16:56:51 [INFO ]  	num_workers: 8
2022-10-04 16:56:51 [INFO ]  	phase: train
2022-10-04 16:56:51 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 16:56:51 [INFO ]  	start_time: '2022-10-04 16:56:51'
2022-10-04 16:56:51 [INFO ]  	test_batch_size: 1024
2022-10-04 16:56:51 [INFO ]  	
2022-10-04 16:56:53 [INFO ]  train dataset size:	73257
2022-10-04 16:56:53 [INFO ]  test dataset size: 	26032
2022-10-04 16:56:53 [INFO ]  datasets built!
2022-10-04 16:56:53 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 16:56:54 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 16:56:54 [INFO ]  
2022-10-04 16:56:54 [INFO ]  Begin of epoch 0 :
2022-10-04 16:56:58 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 16:56:58 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 16:56:58 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 16:56:58 [INFO ]  	   step  1 (lr=0.020000)                    6.81%                  10.7597
2022-10-04 16:56:58 [INFO ]  
2022-10-04 16:56:58 [INFO ]  Epoch:    0	Loss: 11.0662	Data Time: 0.40s	Train Time: 0.03s
2022-10-04 16:56:59 [INFO ]  Epoch:    1	Loss: 3.2656	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 16:57:01 [INFO ]  Epoch:    2	Loss: 2.7862	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:03 [INFO ]  Epoch:    3	Loss: 2.4993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:04 [INFO ]  Epoch:    4	Loss: 2.2668	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:06 [INFO ]  Epoch:    5	Loss: 2.2615	Data Time: 0.17s	Train Time: 0.00s
2022-10-04 16:57:08 [INFO ]  Epoch:    6	Loss: 2.2687	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:10 [INFO ]  Epoch:    7	Loss: 2.2140	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:12 [INFO ]  Epoch:    8	Loss: 2.2093	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:57:14 [INFO ]  Epoch:    9	Loss: 2.2427	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 16:57:15 [INFO ]  Epoch:   10	Loss: 2.1673	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 16:57:17 [INFO ]  Epoch:   11	Loss: 2.1260	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:19 [INFO ]  Epoch:   12	Loss: 2.0561	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:57:21 [INFO ]  Epoch:   13	Loss: 2.0519	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:57:23 [INFO ]  Epoch:   14	Loss: 2.1943	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:57:24 [INFO ]  Epoch:   15	Loss: 2.0185	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:26 [INFO ]  Epoch:   16	Loss: 2.0082	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 16:57:28 [INFO ]  Epoch:   17	Loss: 1.9907	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 16:57:30 [INFO ]  Epoch:   18	Loss: 1.8795	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:32 [INFO ]  Epoch:   19	Loss: 1.8284	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:33 [INFO ]  Epoch:   20	Loss: 1.8412	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:35 [INFO ]  Epoch:   21	Loss: 2.0226	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:37 [INFO ]  Epoch:   22	Loss: 1.9748	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:39 [INFO ]  Epoch:   23	Loss: 1.7868	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 16:57:41 [INFO ]  Epoch:   24	Loss: 1.8194	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 16:57:42 [INFO ]  Epoch:   25	Loss: 1.9126	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 16:57:44 [INFO ]  Epoch:   26	Loss: 1.8416	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:46 [INFO ]  Epoch:   27	Loss: 1.7945	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:57:48 [INFO ]  Epoch:   28	Loss: 1.8338	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:50 [INFO ]  Epoch:   29	Loss: 1.8740	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 16:57:52 [INFO ]  Epoch:   30	Loss: 1.6724	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 16:57:53 [INFO ]  Epoch:   31	Loss: 1.6818	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:57:55 [INFO ]  Epoch:   32	Loss: 1.7985	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:57 [INFO ]  Epoch:   33	Loss: 1.6794	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:57:59 [INFO ]  Epoch:   34	Loss: 1.6520	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 16:58:01 [INFO ]  Epoch:   35	Loss: 1.7230	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:58:03 [INFO ]  Epoch:   36	Loss: 1.7549	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:05 [INFO ]  Epoch:   37	Loss: 1.7955	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:06 [INFO ]  Epoch:   38	Loss: 1.8895	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:08 [INFO ]  Epoch:   39	Loss: 10.4567	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:10 [INFO ]  Epoch:   40	Loss: 1.7922	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 16:58:12 [INFO ]  Epoch:   41	Loss: 1.6769	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:14 [INFO ]  Epoch:   42	Loss: 1.6948	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:58:16 [INFO ]  Epoch:   43	Loss: 1.7486	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:17 [INFO ]  Epoch:   44	Loss: 1.8108	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:19 [INFO ]  Epoch:   45	Loss: 1.6804	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:21 [INFO ]  Epoch:   46	Loss: 1.7354	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:23 [INFO ]  Epoch:   47	Loss: 1.5556	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:25 [INFO ]  Epoch:   48	Loss: 1.5265	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:58:26 [INFO ]  Epoch:   49	Loss: 1.5555	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:28 [INFO ]  Epoch:   50	Loss: 1.5079	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 16:58:30 [INFO ]  Epoch:   51	Loss: 1.5352	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:32 [INFO ]  Epoch:   52	Loss: 1.5142	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 16:58:33 [INFO ]  Epoch:   53	Loss: 1.4880	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:58:35 [INFO ]  Epoch:   54	Loss: 1.5322	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:58:37 [INFO ]  Epoch:   55	Loss: 1.5516	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:58:39 [INFO ]  Epoch:   56	Loss: 1.6536	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:58:41 [INFO ]  Epoch:   57	Loss: 1.5568	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:58:43 [INFO ]  Epoch:   58	Loss: 1.6776	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 16:58:44 [INFO ]  Epoch:   59	Loss: 1.5092	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:46 [INFO ]  Epoch:   60	Loss: 1.4829	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:58:48 [INFO ]  Epoch:   61	Loss: 1.5238	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:58:50 [INFO ]  Epoch:   62	Loss: 1.5653	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:58:52 [INFO ]  Epoch:   63	Loss: 1.5029	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:58:54 [INFO ]  Epoch:   64	Loss: 1.4862	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:58:55 [INFO ]  Epoch:   65	Loss: 1.4983	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:58:57 [INFO ]  Epoch:   66	Loss: 1.5563	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:58:59 [INFO ]  Epoch:   67	Loss: 1.4947	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:59:01 [INFO ]  Epoch:   68	Loss: 1.4660	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:03 [INFO ]  Epoch:   69	Loss: 1.5152	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 16:59:04 [INFO ]  Epoch:   70	Loss: 1.5071	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:06 [INFO ]  Epoch:   71	Loss: 1.4645	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:59:08 [INFO ]  Epoch:   72	Loss: 1.5381	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 16:59:10 [INFO ]  Epoch:   73	Loss: 1.5028	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:59:12 [INFO ]  Epoch:   74	Loss: 1.4605	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:14 [INFO ]  Epoch:   75	Loss: 1.5592	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:59:15 [INFO ]  Epoch:   76	Loss: 1.4472	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:59:17 [INFO ]  Epoch:   77	Loss: 1.4806	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:59:19 [INFO ]  Epoch:   78	Loss: 1.4147	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 16:59:21 [INFO ]  Epoch:   79	Loss: 1.4484	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 16:59:23 [INFO ]  Epoch:   80	Loss: 1.4816	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:59:25 [INFO ]  Epoch:   81	Loss: 1.5203	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 16:59:26 [INFO ]  Epoch:   82	Loss: 1.4410	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:28 [INFO ]  Epoch:   83	Loss: 1.4624	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:59:30 [INFO ]  Epoch:   84	Loss: 1.4553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:32 [INFO ]  Epoch:   85	Loss: 1.5278	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:34 [INFO ]  Epoch:   86	Loss: 1.5121	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:35 [INFO ]  Epoch:   87	Loss: 1.4766	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:59:37 [INFO ]  Epoch:   88	Loss: 1.4750	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:59:39 [INFO ]  Epoch:   89	Loss: 1.5456	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:41 [INFO ]  Epoch:   90	Loss: 1.5183	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 16:59:43 [INFO ]  Epoch:   91	Loss: 1.4985	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:44 [INFO ]  Epoch:   92	Loss: 1.4170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:46 [INFO ]  Epoch:   93	Loss: 1.4215	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 16:59:48 [INFO ]  Epoch:   94	Loss: 1.4461	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 16:59:50 [INFO ]  Epoch:   95	Loss: 1.3616	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:52 [INFO ]  Epoch:   96	Loss: 1.4470	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 16:59:53 [INFO ]  Epoch:   97	Loss: 1.4986	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 16:59:55 [INFO ]  Epoch:   98	Loss: 1.4208	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 16:59:57 [INFO ]  Epoch:   99	Loss: 1.4821	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 16:59:59 [INFO ]  Epoch:  100	Loss: 1.5050	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:00:01 [INFO ]  Epoch:  101	Loss: 1.4222	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:00:03 [INFO ]  Epoch:  102	Loss: 1.4400	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:00:04 [INFO ]  Epoch:  103	Loss: 1.5126	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:00:06 [INFO ]  Epoch:  104	Loss: 1.5009	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:08 [INFO ]  Epoch:  105	Loss: 1.4324	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:00:10 [INFO ]  Epoch:  106	Loss: 1.5247	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:00:12 [INFO ]  Epoch:  107	Loss: 1.5028	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:14 [INFO ]  Epoch:  108	Loss: 1.4797	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:00:15 [INFO ]  Epoch:  109	Loss: 1.4148	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:00:17 [INFO ]  Epoch:  110	Loss: 1.4365	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:19 [INFO ]  Epoch:  111	Loss: 1.4105	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:21 [INFO ]  Epoch:  112	Loss: 1.4435	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:00:22 [INFO ]  Epoch:  113	Loss: 1.4384	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:00:24 [INFO ]  Epoch:  114	Loss: 1.4057	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:00:26 [INFO ]  Epoch:  115	Loss: 1.4277	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:28 [INFO ]  Epoch:  116	Loss: 1.4400	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:00:30 [INFO ]  Epoch:  117	Loss: 1.5183	Data Time: 0.16s	Train Time: 0.00s
2022-10-04 17:00:32 [INFO ]  Epoch:  118	Loss: 1.4900	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:00:34 [INFO ]  Epoch:  119	Loss: 1.4386	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:00:35 [INFO ]  Epoch:  120	Loss: 1.4855	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:37 [INFO ]  Epoch:  121	Loss: 1.4382	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:00:39 [INFO ]  Epoch:  122	Loss: 1.3750	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:00:41 [INFO ]  Epoch:  123	Loss: 1.4335	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:00:43 [INFO ]  Epoch:  124	Loss: 1.4540	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:45 [INFO ]  Epoch:  125	Loss: 1.4479	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:00:47 [INFO ]  Epoch:  126	Loss: 1.4207	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:00:49 [INFO ]  Epoch:  127	Loss: 1.4204	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:00:51 [INFO ]  Epoch:  128	Loss: 1.4446	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:00:53 [INFO ]  Epoch:  129	Loss: 1.4926	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:00:54 [INFO ]  Epoch:  130	Loss: 1.4572	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:00:56 [INFO ]  Epoch:  131	Loss: 1.4424	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:00:58 [INFO ]  Epoch:  132	Loss: 1.3982	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:01:00 [INFO ]  Epoch:  133	Loss: 1.4679	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:01 [INFO ]  Epoch:  134	Loss: 1.3622	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:01:03 [INFO ]  Epoch:  135	Loss: 1.3990	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:01:05 [INFO ]  Epoch:  136	Loss: 1.3861	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:01:07 [INFO ]  Epoch:  137	Loss: 1.4037	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:09 [INFO ]  Epoch:  138	Loss: 1.4035	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:10 [INFO ]  Epoch:  139	Loss: 1.4936	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:01:12 [INFO ]  Epoch:  140	Loss: 1.3968	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:14 [INFO ]  Epoch:  141	Loss: 1.4261	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:01:16 [INFO ]  Epoch:  142	Loss: 1.3675	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:01:18 [INFO ]  Epoch:  143	Loss: 1.4047	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:19 [INFO ]  Epoch:  144	Loss: 1.4427	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:21 [INFO ]  Epoch:  145	Loss: 1.4602	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:23 [INFO ]  Epoch:  146	Loss: 1.5451	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:01:25 [INFO ]  Epoch:  147	Loss: 1.4711	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:27 [INFO ]  Epoch:  148	Loss: 1.4371	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:29 [INFO ]  Epoch:  149	Loss: 1.3648	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:31 [INFO ]  Epoch:  150	Loss: 1.3971	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:01:32 [INFO ]  Epoch:  151	Loss: 1.4182	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:34 [INFO ]  Epoch:  152	Loss: 1.4888	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:01:36 [INFO ]  Epoch:  153	Loss: 1.4279	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:01:38 [INFO ]  Epoch:  154	Loss: 1.4329	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:01:39 [INFO ]  Epoch:  155	Loss: 1.3799	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:01:41 [INFO ]  Epoch:  156	Loss: 1.5003	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:43 [INFO ]  Epoch:  157	Loss: 1.4314	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:45 [INFO ]  Epoch:  158	Loss: 1.3825	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:47 [INFO ]  Epoch:  159	Loss: 1.4887	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:01:48 [INFO ]  Epoch:  160	Loss: 1.4367	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 17:01:50 [INFO ]  Epoch:  161	Loss: 1.3925	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:01:52 [INFO ]  Epoch:  162	Loss: 1.4155	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:54 [INFO ]  Epoch:  163	Loss: 1.4678	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:01:55 [INFO ]  Epoch:  164	Loss: 1.4074	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:01:57 [INFO ]  Epoch:  165	Loss: 1.3690	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:01:59 [INFO ]  Epoch:  166	Loss: 1.3600	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:01 [INFO ]  Epoch:  167	Loss: 2.1168	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:02:03 [INFO ]  Epoch:  168	Loss: 1.9417	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:02:04 [INFO ]  Epoch:  169	Loss: 1.4137	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:06 [INFO ]  Epoch:  170	Loss: 1.8644	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:08 [INFO ]  Epoch:  171	Loss: 1.4876	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:02:10 [INFO ]  Epoch:  172	Loss: 1.9589	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:12 [INFO ]  Epoch:  173	Loss: 1.9762	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:02:14 [INFO ]  Epoch:  174	Loss: 1.4646	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:02:16 [INFO ]  Epoch:  175	Loss: 1.3601	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:02:18 [INFO ]  Epoch:  176	Loss: 1.7840	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:02:20 [INFO ]  Epoch:  177	Loss: 2.0039	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:02:22 [INFO ]  Epoch:  178	Loss: 1.9134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:23 [INFO ]  Epoch:  179	Loss: 1.7733	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:25 [INFO ]  Epoch:  180	Loss: 1.7915	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:02:27 [INFO ]  Epoch:  181	Loss: 1.7158	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:29 [INFO ]  Epoch:  182	Loss: 1.7424	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:02:31 [INFO ]  Epoch:  183	Loss: 1.7781	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:02:33 [INFO ]  Epoch:  184	Loss: 1.6176	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:02:35 [INFO ]  Epoch:  185	Loss: 1.5967	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:02:36 [INFO ]  Epoch:  186	Loss: 1.5305	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:02:38 [INFO ]  Epoch:  187	Loss: 1.6205	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:02:40 [INFO ]  Epoch:  188	Loss: 1.5409	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:42 [INFO ]  Epoch:  189	Loss: 1.4326	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:44 [INFO ]  Epoch:  190	Loss: 1.5081	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:02:45 [INFO ]  Epoch:  191	Loss: 1.5287	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:02:47 [INFO ]  Epoch:  192	Loss: 1.4356	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:02:49 [INFO ]  Epoch:  193	Loss: 1.5545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:51 [INFO ]  Epoch:  194	Loss: 1.8973	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:02:53 [INFO ]  Epoch:  195	Loss: 1.5160	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:02:55 [INFO ]  Epoch:  196	Loss: 1.5509	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:02:56 [INFO ]  Epoch:  197	Loss: 1.7212	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:02:58 [INFO ]  Epoch:  198	Loss: 1.5010	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:00 [INFO ]  Epoch:  199	Loss: 1.5420	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:03:02 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:03:02 [INFO ]  
2022-10-04 17:03:02 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:03:05 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:03:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:03:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:03:05 [INFO ]  	   step  1 (lr=0.166908)                   45.62%                   1.7587
2022-10-04 17:03:05 [INFO ]  
2022-10-04 17:03:05 [INFO ]  
2022-10-04 17:03:05 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:03:08 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:03:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:03:08 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:03:08 [INFO ]  	   step  1 (lr=0.166908)                   20.74%                   4.2896
2022-10-04 17:03:08 [INFO ]  
2022-10-04 17:03:08 [INFO ]  CPU Time: 3.38 minutes
2022-10-04 17:03:29 [INFO ]  ======================================== 2022-10-04 17:03:29 ========================================
2022-10-04 17:03:29 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:03:29 [INFO ]  Options: 
2022-10-04 17:03:29 [INFO ]  	base_dir: null
2022-10-04 17:03:29 [INFO ]  	batch_size: 1024
2022-10-04 17:03:29 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:03:29 [INFO ]  	dataset: SVHN
2022-10-04 17:03:29 [INFO ]  	dataset_labels:
2022-10-04 17:03:29 [INFO ]  	- 0
2022-10-04 17:03:29 [INFO ]  	- 1
2022-10-04 17:03:29 [INFO ]  	- 2
2022-10-04 17:03:29 [INFO ]  	- 3
2022-10-04 17:03:29 [INFO ]  	- 4
2022-10-04 17:03:29 [INFO ]  	- 5
2022-10-04 17:03:29 [INFO ]  	- 6
2022-10-04 17:03:29 [INFO ]  	- 7
2022-10-04 17:03:29 [INFO ]  	- 8
2022-10-04 17:03:29 [INFO ]  	- 9
2022-10-04 17:03:29 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:03:29 [INFO ]  	- !!python/tuple
2022-10-04 17:03:29 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:03:29 [INFO ]  	    - 0.44398033618927
2022-10-04 17:03:29 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:03:29 [INFO ]  	- !!python/tuple
2022-10-04 17:03:29 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:03:29 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:03:29 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:03:29 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:03:29 [INFO ]  	decay_epochs: 50
2022-10-04 17:03:29 [INFO ]  	decay_factor: 0.1
2022-10-04 17:03:29 [INFO ]  	device_id: 0
2022-10-04 17:03:29 [INFO ]  	distill_epochs: 1
2022-10-04 17:03:29 [INFO ]  	distill_lr: 0.02
2022-10-04 17:03:29 [INFO ]  	distill_steps: 1
2022-10-04 17:03:29 [INFO ]  	epochs: 200
2022-10-04 17:03:29 [INFO ]  	expand_cls: false
2022-10-04 17:03:29 [INFO ]  	forgetting_dataset: null
2022-10-04 17:03:29 [INFO ]  	init: xavier
2022-10-04 17:03:29 [INFO ]  	init_param: 1.0
2022-10-04 17:03:29 [INFO ]  	input_size: 32
2022-10-04 17:03:29 [INFO ]  	ipc: 1
2022-10-04 17:03:29 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:03:29 [INFO ]  	log_interval: 100
2022-10-04 17:03:29 [INFO ]  	log_level: INFO
2022-10-04 17:03:29 [INFO ]  	lr: 0.01
2022-10-04 17:03:29 [INFO ]  	mode: distill_adapt
2022-10-04 17:03:29 [INFO ]  	nc: 3
2022-10-04 17:03:29 [INFO ]  	num_classes: 10
2022-10-04 17:03:29 [INFO ]  	num_workers: 8
2022-10-04 17:03:29 [INFO ]  	phase: train
2022-10-04 17:03:29 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:03:29 [INFO ]  	start_time: '2022-10-04 17:03:29'
2022-10-04 17:03:29 [INFO ]  	test_batch_size: 1024
2022-10-04 17:03:29 [INFO ]  	
2022-10-04 17:03:31 [INFO ]  train dataset size:	73257
2022-10-04 17:03:31 [INFO ]  test dataset size: 	26032
2022-10-04 17:03:31 [INFO ]  datasets built!
2022-10-04 17:03:31 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:03:33 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:03:33 [INFO ]  
2022-10-04 17:03:33 [INFO ]  Begin of epoch 0 :
2022-10-04 17:03:36 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:03:36 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:03:36 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:03:36 [INFO ]  	   step  1 (lr=0.020000)                    7.10%                   8.3886
2022-10-04 17:03:36 [INFO ]  
2022-10-04 17:03:37 [INFO ]  Epoch:    0	Loss: 7.9594	Data Time: 0.38s	Train Time: 0.03s
2022-10-04 17:03:38 [INFO ]  Epoch:    1	Loss: 3.5131	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 17:03:40 [INFO ]  Epoch:    2	Loss: 2.9377	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:03:42 [INFO ]  Epoch:    3	Loss: 2.5498	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:44 [INFO ]  Epoch:    4	Loss: 2.3387	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:46 [INFO ]  Epoch:    5	Loss: 2.2946	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:03:47 [INFO ]  Epoch:    6	Loss: 2.2682	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:03:49 [INFO ]  Epoch:    7	Loss: 2.2163	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:03:51 [INFO ]  Epoch:    8	Loss: 2.2137	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:53 [INFO ]  Epoch:    9	Loss: 2.2327	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:55 [INFO ]  Epoch:   10	Loss: 2.1475	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:57 [INFO ]  Epoch:   11	Loss: 2.2155	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:03:58 [INFO ]  Epoch:   12	Loss: 2.0666	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:00 [INFO ]  Epoch:   13	Loss: 2.1089	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:04:02 [INFO ]  Epoch:   14	Loss: 2.0672	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:04:04 [INFO ]  Epoch:   15	Loss: 2.0181	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:06 [INFO ]  Epoch:   16	Loss: 1.9573	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:04:08 [INFO ]  Epoch:   17	Loss: 1.9690	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:04:10 [INFO ]  Epoch:   18	Loss: 2.1602	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:12 [INFO ]  Epoch:   19	Loss: 1.9283	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:14 [INFO ]  Epoch:   20	Loss: 1.9348	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:04:15 [INFO ]  Epoch:   21	Loss: 1.8697	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:17 [INFO ]  Epoch:   22	Loss: 1.8306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:19 [INFO ]  Epoch:   23	Loss: 1.8578	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:04:21 [INFO ]  Epoch:   24	Loss: 1.7583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:23 [INFO ]  Epoch:   25	Loss: 1.8275	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:04:25 [INFO ]  Epoch:   26	Loss: 1.8569	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:26 [INFO ]  Epoch:   27	Loss: 1.9005	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:28 [INFO ]  Epoch:   28	Loss: 1.7021	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:04:30 [INFO ]  Epoch:   29	Loss: 1.6007	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:32 [INFO ]  Epoch:   30	Loss: 1.7053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:34 [INFO ]  Epoch:   31	Loss: 1.6203	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:36 [INFO ]  Epoch:   32	Loss: 1.6483	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:04:38 [INFO ]  Epoch:   33	Loss: 1.6109	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:40 [INFO ]  Epoch:   34	Loss: 1.8652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:42 [INFO ]  Epoch:   35	Loss: 2.0916	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:04:43 [INFO ]  Epoch:   36	Loss: 1.5776	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:45 [INFO ]  Epoch:   37	Loss: 1.6428	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:04:47 [INFO ]  Epoch:   38	Loss: 1.5038	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:04:49 [INFO ]  Epoch:   39	Loss: 1.5813	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:04:51 [INFO ]  Epoch:   40	Loss: 1.4373	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 17:04:53 [INFO ]  Epoch:   41	Loss: 1.6302	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:04:55 [INFO ]  Epoch:   42	Loss: 1.5474	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:56 [INFO ]  Epoch:   43	Loss: 1.4074	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:04:58 [INFO ]  Epoch:   44	Loss: 1.5087	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:00 [INFO ]  Epoch:   45	Loss: 1.5007	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:05:02 [INFO ]  Epoch:   46	Loss: 1.4538	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:05:04 [INFO ]  Epoch:   47	Loss: 1.4172	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:05 [INFO ]  Epoch:   48	Loss: 1.5570	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:07 [INFO ]  Epoch:   49	Loss: 1.4488	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:09 [INFO ]  Epoch:   50	Loss: 1.4003	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:05:11 [INFO ]  Epoch:   51	Loss: 1.3881	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:13 [INFO ]  Epoch:   52	Loss: 1.3358	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:05:15 [INFO ]  Epoch:   53	Loss: 1.3203	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:05:17 [INFO ]  Epoch:   54	Loss: 1.2504	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:19 [INFO ]  Epoch:   55	Loss: 1.3079	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:20 [INFO ]  Epoch:   56	Loss: 1.3955	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:05:22 [INFO ]  Epoch:   57	Loss: 1.3973	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:24 [INFO ]  Epoch:   58	Loss: 1.3071	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:26 [INFO ]  Epoch:   59	Loss: 1.3585	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:05:28 [INFO ]  Epoch:   60	Loss: 1.2493	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:30 [INFO ]  Epoch:   61	Loss: 1.3421	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:05:31 [INFO ]  Epoch:   62	Loss: 1.3864	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:05:33 [INFO ]  Epoch:   63	Loss: 1.3825	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:35 [INFO ]  Epoch:   64	Loss: 1.4182	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:05:37 [INFO ]  Epoch:   65	Loss: 1.3464	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:39 [INFO ]  Epoch:   66	Loss: 1.2949	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:41 [INFO ]  Epoch:   67	Loss: 1.2599	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:05:42 [INFO ]  Epoch:   68	Loss: 1.2949	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:44 [INFO ]  Epoch:   69	Loss: 1.3236	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:46 [INFO ]  Epoch:   70	Loss: 1.3089	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:05:48 [INFO ]  Epoch:   71	Loss: 1.2626	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:49 [INFO ]  Epoch:   72	Loss: 1.2016	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:51 [INFO ]  Epoch:   73	Loss: 1.2501	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:53 [INFO ]  Epoch:   74	Loss: 1.2902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:05:55 [INFO ]  Epoch:   75	Loss: 1.2088	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:05:57 [INFO ]  Epoch:   76	Loss: 1.2098	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:05:58 [INFO ]  Epoch:   77	Loss: 1.2120	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:06:00 [INFO ]  Epoch:   78	Loss: 1.1880	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:02 [INFO ]  Epoch:   79	Loss: 1.1819	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:04 [INFO ]  Epoch:   80	Loss: 1.2622	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:06:05 [INFO ]  Epoch:   81	Loss: 1.2247	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:07 [INFO ]  Epoch:   82	Loss: 1.2185	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:06:09 [INFO ]  Epoch:   83	Loss: 1.1936	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:06:11 [INFO ]  Epoch:   84	Loss: 1.1644	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:06:13 [INFO ]  Epoch:   85	Loss: 1.1914	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:15 [INFO ]  Epoch:   86	Loss: 1.1723	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:06:17 [INFO ]  Epoch:   87	Loss: 1.1302	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:06:19 [INFO ]  Epoch:   88	Loss: 1.1566	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:20 [INFO ]  Epoch:   89	Loss: 1.2292	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:06:22 [INFO ]  Epoch:   90	Loss: 1.2101	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:06:24 [INFO ]  Epoch:   91	Loss: 1.3913	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:06:26 [INFO ]  Epoch:   92	Loss: 1.2688	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:28 [INFO ]  Epoch:   93	Loss: 1.2032	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:06:29 [INFO ]  Epoch:   94	Loss: 1.1632	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:06:31 [INFO ]  Epoch:   95	Loss: 1.2045	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:33 [INFO ]  Epoch:   96	Loss: 1.2722	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:35 [INFO ]  Epoch:   97	Loss: 1.1217	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:06:37 [INFO ]  Epoch:   98	Loss: 1.1343	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:39 [INFO ]  Epoch:   99	Loss: 1.1964	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:06:41 [INFO ]  Epoch:  100	Loss: 1.1887	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:06:43 [INFO ]  Epoch:  101	Loss: 1.2226	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:06:45 [INFO ]  Epoch:  102	Loss: 1.1776	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:06:46 [INFO ]  Epoch:  103	Loss: 1.1413	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:06:48 [INFO ]  Epoch:  104	Loss: 1.1690	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:06:50 [INFO ]  Epoch:  105	Loss: 1.1867	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:06:52 [INFO ]  Epoch:  106	Loss: 1.1446	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:06:54 [INFO ]  Epoch:  107	Loss: 1.1932	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:06:56 [INFO ]  Epoch:  108	Loss: 1.0914	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:06:57 [INFO ]  Epoch:  109	Loss: 1.2003	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:06:59 [INFO ]  Epoch:  110	Loss: 1.0926	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:01 [INFO ]  Epoch:  111	Loss: 1.2320	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:07:03 [INFO ]  Epoch:  112	Loss: 1.2079	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:07:05 [INFO ]  Epoch:  113	Loss: 1.2133	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:07 [INFO ]  Epoch:  114	Loss: 1.1063	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:07:08 [INFO ]  Epoch:  115	Loss: 1.2381	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:07:10 [INFO ]  Epoch:  116	Loss: 1.2484	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:12 [INFO ]  Epoch:  117	Loss: 1.2847	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:14 [INFO ]  Epoch:  118	Loss: 1.2149	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:07:16 [INFO ]  Epoch:  119	Loss: 1.2985	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:07:17 [INFO ]  Epoch:  120	Loss: 1.1943	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:19 [INFO ]  Epoch:  121	Loss: 1.2289	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:07:21 [INFO ]  Epoch:  122	Loss: 1.2023	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:07:23 [INFO ]  Epoch:  123	Loss: 1.1827	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:25 [INFO ]  Epoch:  124	Loss: 1.1782	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:07:27 [INFO ]  Epoch:  125	Loss: 1.3152	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:07:29 [INFO ]  Epoch:  126	Loss: 1.3002	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:07:30 [INFO ]  Epoch:  127	Loss: 1.2734	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:07:32 [INFO ]  Epoch:  128	Loss: 1.3212	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:34 [INFO ]  Epoch:  129	Loss: 1.3371	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:07:36 [INFO ]  Epoch:  130	Loss: 1.2714	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:38 [INFO ]  Epoch:  131	Loss: 1.3754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:07:40 [INFO ]  Epoch:  132	Loss: 1.2205	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:42 [INFO ]  Epoch:  133	Loss: 1.2193	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:07:44 [INFO ]  Epoch:  134	Loss: 1.2216	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:46 [INFO ]  Epoch:  135	Loss: 1.1734	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:07:48 [INFO ]  Epoch:  136	Loss: 1.2428	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:07:49 [INFO ]  Epoch:  137	Loss: 1.1774	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:07:52 [INFO ]  Epoch:  138	Loss: 1.2414	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:07:54 [INFO ]  Epoch:  139	Loss: 1.1409	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:07:56 [INFO ]  Epoch:  140	Loss: 1.2759	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:07:57 [INFO ]  Epoch:  141	Loss: 1.2214	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:07:59 [INFO ]  Epoch:  142	Loss: 1.2002	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:08:01 [INFO ]  Epoch:  143	Loss: 1.2170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:03 [INFO ]  Epoch:  144	Loss: 1.2010	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:08:05 [INFO ]  Epoch:  145	Loss: 1.1434	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:08:07 [INFO ]  Epoch:  146	Loss: 1.1420	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:08:09 [INFO ]  Epoch:  147	Loss: 1.1212	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:08:11 [INFO ]  Epoch:  148	Loss: 1.1819	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:08:13 [INFO ]  Epoch:  149	Loss: 1.2247	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:08:15 [INFO ]  Epoch:  150	Loss: 1.2658	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:08:17 [INFO ]  Epoch:  151	Loss: 1.1283	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:08:19 [INFO ]  Epoch:  152	Loss: 1.2823	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:21 [INFO ]  Epoch:  153	Loss: 1.3159	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:08:22 [INFO ]  Epoch:  154	Loss: 1.1685	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:08:24 [INFO ]  Epoch:  155	Loss: 1.3343	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:26 [INFO ]  Epoch:  156	Loss: 1.1921	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:08:28 [INFO ]  Epoch:  157	Loss: 1.2563	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:08:30 [INFO ]  Epoch:  158	Loss: 1.1010	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:08:32 [INFO ]  Epoch:  159	Loss: 1.2545	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:08:33 [INFO ]  Epoch:  160	Loss: 1.2818	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:08:35 [INFO ]  Epoch:  161	Loss: 1.4665	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:08:37 [INFO ]  Epoch:  162	Loss: 1.4326	Data Time: 0.16s	Train Time: 0.00s
2022-10-04 17:08:39 [INFO ]  Epoch:  163	Loss: 1.3012	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:08:41 [INFO ]  Epoch:  164	Loss: 1.3744	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:08:42 [INFO ]  Epoch:  165	Loss: 1.2236	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:08:44 [INFO ]  Epoch:  166	Loss: 1.2611	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:08:46 [INFO ]  Epoch:  167	Loss: 1.2683	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:48 [INFO ]  Epoch:  168	Loss: 1.2302	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:08:50 [INFO ]  Epoch:  169	Loss: 1.2719	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:08:52 [INFO ]  Epoch:  170	Loss: 1.2355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:54 [INFO ]  Epoch:  171	Loss: 1.3004	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:08:55 [INFO ]  Epoch:  172	Loss: 1.2329	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:08:57 [INFO ]  Epoch:  173	Loss: 1.1438	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:08:59 [INFO ]  Epoch:  174	Loss: 1.1993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:01 [INFO ]  Epoch:  175	Loss: 1.3018	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:09:03 [INFO ]  Epoch:  176	Loss: 1.2601	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:05 [INFO ]  Epoch:  177	Loss: 1.2576	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:06 [INFO ]  Epoch:  178	Loss: 1.2272	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:09:08 [INFO ]  Epoch:  179	Loss: 1.3154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:09:10 [INFO ]  Epoch:  180	Loss: 1.3177	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:12 [INFO ]  Epoch:  181	Loss: 1.2126	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:14 [INFO ]  Epoch:  182	Loss: 1.1900	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:16 [INFO ]  Epoch:  183	Loss: 1.2721	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:09:17 [INFO ]  Epoch:  184	Loss: 1.1201	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:19 [INFO ]  Epoch:  185	Loss: 1.1823	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:21 [INFO ]  Epoch:  186	Loss: 1.2189	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:09:23 [INFO ]  Epoch:  187	Loss: 1.1376	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:24 [INFO ]  Epoch:  188	Loss: 1.1633	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:09:26 [INFO ]  Epoch:  189	Loss: 1.2002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:28 [INFO ]  Epoch:  190	Loss: 1.1776	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:09:30 [INFO ]  Epoch:  191	Loss: 1.2633	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:32 [INFO ]  Epoch:  192	Loss: 1.1690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:34 [INFO ]  Epoch:  193	Loss: 1.2124	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:09:36 [INFO ]  Epoch:  194	Loss: 1.2174	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:37 [INFO ]  Epoch:  195	Loss: 1.2684	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:09:39 [INFO ]  Epoch:  196	Loss: 1.2169	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:41 [INFO ]  Epoch:  197	Loss: 1.2463	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:09:43 [INFO ]  Epoch:  198	Loss: 1.2134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:09:45 [INFO ]  Epoch:  199	Loss: 1.1715	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:09:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:09:46 [INFO ]  
2022-10-04 17:09:46 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:09:49 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:09:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:09:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:09:49 [INFO ]  	   step  1 (lr=0.259905)                   62.64%                   1.2293
2022-10-04 17:09:49 [INFO ]  
2022-10-04 17:09:49 [INFO ]  
2022-10-04 17:09:49 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:09:52 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:09:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:09:52 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:09:52 [INFO ]  	   step  1 (lr=0.259905)                   16.39%                   5.7558
2022-10-04 17:09:52 [INFO ]  
2022-10-04 17:09:52 [INFO ]  CPU Time: 3.45 minutes
2022-10-04 17:10:08 [INFO ]  ======================================== 2022-10-04 17:10:08 ========================================
2022-10-04 17:10:08 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:10:08 [INFO ]  Options: 
2022-10-04 17:10:08 [INFO ]  	base_dir: null
2022-10-04 17:10:08 [INFO ]  	batch_size: 1024
2022-10-04 17:10:08 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:10:08 [INFO ]  	dataset: SVHN
2022-10-04 17:10:08 [INFO ]  	dataset_labels:
2022-10-04 17:10:08 [INFO ]  	- 0
2022-10-04 17:10:08 [INFO ]  	- 1
2022-10-04 17:10:08 [INFO ]  	- 2
2022-10-04 17:10:08 [INFO ]  	- 3
2022-10-04 17:10:08 [INFO ]  	- 4
2022-10-04 17:10:08 [INFO ]  	- 5
2022-10-04 17:10:08 [INFO ]  	- 6
2022-10-04 17:10:08 [INFO ]  	- 7
2022-10-04 17:10:08 [INFO ]  	- 8
2022-10-04 17:10:08 [INFO ]  	- 9
2022-10-04 17:10:08 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:10:08 [INFO ]  	- !!python/tuple
2022-10-04 17:10:08 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:10:08 [INFO ]  	    - 0.44398033618927
2022-10-04 17:10:08 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:10:08 [INFO ]  	- !!python/tuple
2022-10-04 17:10:08 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:10:08 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:10:08 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:10:08 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:10:08 [INFO ]  	decay_epochs: 50
2022-10-04 17:10:08 [INFO ]  	decay_factor: 0.1
2022-10-04 17:10:08 [INFO ]  	device_id: 0
2022-10-04 17:10:08 [INFO ]  	distill_epochs: 1
2022-10-04 17:10:08 [INFO ]  	distill_lr: 0.02
2022-10-04 17:10:08 [INFO ]  	distill_steps: 1
2022-10-04 17:10:08 [INFO ]  	epochs: 200
2022-10-04 17:10:08 [INFO ]  	expand_cls: false
2022-10-04 17:10:08 [INFO ]  	forgetting_dataset: null
2022-10-04 17:10:08 [INFO ]  	init: xavier
2022-10-04 17:10:08 [INFO ]  	init_param: 1.0
2022-10-04 17:10:08 [INFO ]  	input_size: 32
2022-10-04 17:10:08 [INFO ]  	ipc: 2
2022-10-04 17:10:08 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:10:08 [INFO ]  	log_interval: 100
2022-10-04 17:10:08 [INFO ]  	log_level: INFO
2022-10-04 17:10:08 [INFO ]  	lr: 0.01
2022-10-04 17:10:08 [INFO ]  	mode: distill_adapt
2022-10-04 17:10:08 [INFO ]  	nc: 3
2022-10-04 17:10:08 [INFO ]  	num_classes: 10
2022-10-04 17:10:08 [INFO ]  	num_workers: 8
2022-10-04 17:10:08 [INFO ]  	phase: train
2022-10-04 17:10:08 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:10:08 [INFO ]  	start_time: '2022-10-04 17:10:08'
2022-10-04 17:10:08 [INFO ]  	test_batch_size: 1024
2022-10-04 17:10:08 [INFO ]  	
2022-10-04 17:10:10 [INFO ]  train dataset size:	73257
2022-10-04 17:10:10 [INFO ]  test dataset size: 	26032
2022-10-04 17:10:10 [INFO ]  datasets built!
2022-10-04 17:10:10 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:10:12 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:10:12 [INFO ]  
2022-10-04 17:10:12 [INFO ]  Begin of epoch 0 :
2022-10-04 17:10:16 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:10:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:10:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:10:16 [INFO ]  	   step  1 (lr=0.020000)                    6.78%                   9.5542
2022-10-04 17:10:16 [INFO ]  
2022-10-04 17:10:16 [INFO ]  Epoch:    0	Loss: 8.7349	Data Time: 0.39s	Train Time: 0.04s
2022-10-04 17:10:17 [INFO ]  Epoch:    1	Loss: 2.9721	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:10:19 [INFO ]  Epoch:    2	Loss: 2.6634	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:21 [INFO ]  Epoch:    3	Loss: 2.3480	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:10:23 [INFO ]  Epoch:    4	Loss: 2.2695	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:10:25 [INFO ]  Epoch:    5	Loss: 2.2246	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:27 [INFO ]  Epoch:    6	Loss: 2.2249	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:29 [INFO ]  Epoch:    7	Loss: 2.1367	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:30 [INFO ]  Epoch:    8	Loss: 2.1265	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:10:32 [INFO ]  Epoch:    9	Loss: 2.1248	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:10:35 [INFO ]  Epoch:   10	Loss: 2.0685	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:10:36 [INFO ]  Epoch:   11	Loss: 2.0315	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:10:38 [INFO ]  Epoch:   12	Loss: 2.0217	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:40 [INFO ]  Epoch:   13	Loss: 1.8355	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:42 [INFO ]  Epoch:   14	Loss: 1.8523	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:10:44 [INFO ]  Epoch:   15	Loss: 1.7876	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:46 [INFO ]  Epoch:   16	Loss: 2.2187	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:10:48 [INFO ]  Epoch:   17	Loss: 1.6328	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:10:49 [INFO ]  Epoch:   18	Loss: 2.1527	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:10:51 [INFO ]  Epoch:   19	Loss: 1.5923	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:10:53 [INFO ]  Epoch:   20	Loss: 1.4475	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:10:55 [INFO ]  Epoch:   21	Loss: 1.5600	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:10:57 [INFO ]  Epoch:   22	Loss: 1.5680	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:10:59 [INFO ]  Epoch:   23	Loss: 1.4370	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:00 [INFO ]  Epoch:   24	Loss: 1.3836	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:11:02 [INFO ]  Epoch:   25	Loss: 1.7904	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:04 [INFO ]  Epoch:   26	Loss: 1.5277	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:06 [INFO ]  Epoch:   27	Loss: 1.4228	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:08 [INFO ]  Epoch:   28	Loss: 1.3780	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:11:10 [INFO ]  Epoch:   29	Loss: 1.3809	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:11:12 [INFO ]  Epoch:   30	Loss: 1.4400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:11:14 [INFO ]  Epoch:   31	Loss: 1.4451	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:11:16 [INFO ]  Epoch:   32	Loss: 1.2279	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:17 [INFO ]  Epoch:   33	Loss: 1.3340	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:19 [INFO ]  Epoch:   34	Loss: 1.1442	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:11:21 [INFO ]  Epoch:   35	Loss: 1.0985	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:11:23 [INFO ]  Epoch:   36	Loss: 1.1676	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:25 [INFO ]  Epoch:   37	Loss: 1.1725	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:11:27 [INFO ]  Epoch:   38	Loss: 1.2274	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:11:29 [INFO ]  Epoch:   39	Loss: 1.1419	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:11:31 [INFO ]  Epoch:   40	Loss: 1.5467	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:33 [INFO ]  Epoch:   41	Loss: 1.0589	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:11:34 [INFO ]  Epoch:   42	Loss: 1.1032	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:36 [INFO ]  Epoch:   43	Loss: 1.2115	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:38 [INFO ]  Epoch:   44	Loss: 1.2863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:40 [INFO ]  Epoch:   45	Loss: 1.3691	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:42 [INFO ]  Epoch:   46	Loss: 1.1197	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:44 [INFO ]  Epoch:   47	Loss: 1.1671	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:11:45 [INFO ]  Epoch:   48	Loss: 1.2064	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:11:47 [INFO ]  Epoch:   49	Loss: 0.9800	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:11:49 [INFO ]  Epoch:   50	Loss: 1.0109	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:51 [INFO ]  Epoch:   51	Loss: 0.9612	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:11:53 [INFO ]  Epoch:   52	Loss: 1.6752	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:11:55 [INFO ]  Epoch:   53	Loss: 1.1077	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:11:57 [INFO ]  Epoch:   54	Loss: 1.0300	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:11:58 [INFO ]  Epoch:   55	Loss: 1.1775	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:00 [INFO ]  Epoch:   56	Loss: 1.0504	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:02 [INFO ]  Epoch:   57	Loss: 0.9738	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:04 [INFO ]  Epoch:   58	Loss: 1.0770	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:06 [INFO ]  Epoch:   59	Loss: 1.3757	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:08 [INFO ]  Epoch:   60	Loss: 1.2715	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:10 [INFO ]  Epoch:   61	Loss: 1.0899	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:12 [INFO ]  Epoch:   62	Loss: 0.9050	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:14 [INFO ]  Epoch:   63	Loss: 0.9754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:15 [INFO ]  Epoch:   64	Loss: 0.9300	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:12:17 [INFO ]  Epoch:   65	Loss: 0.9565	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:19 [INFO ]  Epoch:   66	Loss: 1.0205	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:21 [INFO ]  Epoch:   67	Loss: 1.2309	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:23 [INFO ]  Epoch:   68	Loss: 1.0568	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:25 [INFO ]  Epoch:   69	Loss: 0.9787	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:12:27 [INFO ]  Epoch:   70	Loss: 0.9798	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:28 [INFO ]  Epoch:   71	Loss: 0.9748	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:30 [INFO ]  Epoch:   72	Loss: 0.9532	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:32 [INFO ]  Epoch:   73	Loss: 0.9328	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:12:34 [INFO ]  Epoch:   74	Loss: 0.9732	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:36 [INFO ]  Epoch:   75	Loss: 1.2012	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:38 [INFO ]  Epoch:   76	Loss: 1.1061	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:40 [INFO ]  Epoch:   77	Loss: 0.9164	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:12:42 [INFO ]  Epoch:   78	Loss: 0.9541	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:12:44 [INFO ]  Epoch:   79	Loss: 0.8979	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:46 [INFO ]  Epoch:   80	Loss: 1.3827	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:48 [INFO ]  Epoch:   81	Loss: 0.9323	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:50 [INFO ]  Epoch:   82	Loss: 0.9905	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:52 [INFO ]  Epoch:   83	Loss: 0.9736	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:54 [INFO ]  Epoch:   84	Loss: 1.1099	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:12:55 [INFO ]  Epoch:   85	Loss: 0.9120	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:12:57 [INFO ]  Epoch:   86	Loss: 1.0676	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:12:59 [INFO ]  Epoch:   87	Loss: 1.0200	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:01 [INFO ]  Epoch:   88	Loss: 0.9969	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:13:03 [INFO ]  Epoch:   89	Loss: 0.9986	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:13:05 [INFO ]  Epoch:   90	Loss: 0.9011	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:07 [INFO ]  Epoch:   91	Loss: 0.8441	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:13:09 [INFO ]  Epoch:   92	Loss: 1.0238	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:13:11 [INFO ]  Epoch:   93	Loss: 0.9369	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:13:12 [INFO ]  Epoch:   94	Loss: 0.9637	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:15 [INFO ]  Epoch:   95	Loss: 0.8461	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:13:16 [INFO ]  Epoch:   96	Loss: 0.9779	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:13:18 [INFO ]  Epoch:   97	Loss: 0.9206	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:20 [INFO ]  Epoch:   98	Loss: 0.9024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:22 [INFO ]  Epoch:   99	Loss: 0.8843	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:24 [INFO ]  Epoch:  100	Loss: 0.9267	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:13:26 [INFO ]  Epoch:  101	Loss: 0.8560	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:28 [INFO ]  Epoch:  102	Loss: 0.8391	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:13:30 [INFO ]  Epoch:  103	Loss: 1.2257	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:13:31 [INFO ]  Epoch:  104	Loss: 0.8392	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:13:33 [INFO ]  Epoch:  105	Loss: 0.8407	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:35 [INFO ]  Epoch:  106	Loss: 0.8882	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:37 [INFO ]  Epoch:  107	Loss: 0.9666	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:13:39 [INFO ]  Epoch:  108	Loss: 0.9652	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:13:41 [INFO ]  Epoch:  109	Loss: 0.8702	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:43 [INFO ]  Epoch:  110	Loss: 0.8983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:13:45 [INFO ]  Epoch:  111	Loss: 0.9255	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:47 [INFO ]  Epoch:  112	Loss: 0.8552	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:49 [INFO ]  Epoch:  113	Loss: 0.8064	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:13:50 [INFO ]  Epoch:  114	Loss: 1.1003	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:52 [INFO ]  Epoch:  115	Loss: 0.7729	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:13:54 [INFO ]  Epoch:  116	Loss: 0.8047	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:13:56 [INFO ]  Epoch:  117	Loss: 0.9280	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:13:58 [INFO ]  Epoch:  118	Loss: 0.9075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:00 [INFO ]  Epoch:  119	Loss: 0.8486	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:02 [INFO ]  Epoch:  120	Loss: 1.0601	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:03 [INFO ]  Epoch:  121	Loss: 0.8876	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:14:05 [INFO ]  Epoch:  122	Loss: 0.9644	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:07 [INFO ]  Epoch:  123	Loss: 0.9019	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:09 [INFO ]  Epoch:  124	Loss: 0.9468	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:14:11 [INFO ]  Epoch:  125	Loss: 1.1338	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:14:13 [INFO ]  Epoch:  126	Loss: 0.9221	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:14:15 [INFO ]  Epoch:  127	Loss: 0.8759	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:14:16 [INFO ]  Epoch:  128	Loss: 0.9349	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:18 [INFO ]  Epoch:  129	Loss: 0.9650	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:20 [INFO ]  Epoch:  130	Loss: 0.8891	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:22 [INFO ]  Epoch:  131	Loss: 0.8914	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:14:24 [INFO ]  Epoch:  132	Loss: 0.9373	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:26 [INFO ]  Epoch:  133	Loss: 0.9394	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:28 [INFO ]  Epoch:  134	Loss: 0.9109	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:14:29 [INFO ]  Epoch:  135	Loss: 0.9218	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:31 [INFO ]  Epoch:  136	Loss: 0.8088	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:14:33 [INFO ]  Epoch:  137	Loss: 0.8988	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:35 [INFO ]  Epoch:  138	Loss: 0.8765	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:37 [INFO ]  Epoch:  139	Loss: 0.9236	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:14:39 [INFO ]  Epoch:  140	Loss: 0.9127	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:14:41 [INFO ]  Epoch:  141	Loss: 0.8664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:43 [INFO ]  Epoch:  142	Loss: 0.8380	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:14:44 [INFO ]  Epoch:  143	Loss: 0.9365	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:46 [INFO ]  Epoch:  144	Loss: 0.8794	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:14:48 [INFO ]  Epoch:  145	Loss: 0.8457	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:14:50 [INFO ]  Epoch:  146	Loss: 0.8997	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:14:52 [INFO ]  Epoch:  147	Loss: 0.8777	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:14:54 [INFO ]  Epoch:  148	Loss: 0.9714	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:14:56 [INFO ]  Epoch:  149	Loss: 0.8956	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:14:58 [INFO ]  Epoch:  150	Loss: 0.8346	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:14:59 [INFO ]  Epoch:  151	Loss: 0.8731	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:15:01 [INFO ]  Epoch:  152	Loss: 0.8390	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:15:03 [INFO ]  Epoch:  153	Loss: 0.8582	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:15:05 [INFO ]  Epoch:  154	Loss: 0.9412	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:15:07 [INFO ]  Epoch:  155	Loss: 0.8873	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:15:09 [INFO ]  Epoch:  156	Loss: 0.9103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:11 [INFO ]  Epoch:  157	Loss: 0.9714	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:15:13 [INFO ]  Epoch:  158	Loss: 0.9475	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:15:15 [INFO ]  Epoch:  159	Loss: 1.0973	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:15:17 [INFO ]  Epoch:  160	Loss: 0.8662	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:19 [INFO ]  Epoch:  161	Loss: 0.9730	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:21 [INFO ]  Epoch:  162	Loss: 0.8659	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:15:22 [INFO ]  Epoch:  163	Loss: 0.8801	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:15:24 [INFO ]  Epoch:  164	Loss: 0.9345	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:15:26 [INFO ]  Epoch:  165	Loss: 0.9105	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:15:28 [INFO ]  Epoch:  166	Loss: 1.0339	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:30 [INFO ]  Epoch:  167	Loss: 0.8701	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:32 [INFO ]  Epoch:  168	Loss: 0.8432	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:15:33 [INFO ]  Epoch:  169	Loss: 0.8795	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:15:35 [INFO ]  Epoch:  170	Loss: 0.8160	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:37 [INFO ]  Epoch:  171	Loss: 0.9233	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:39 [INFO ]  Epoch:  172	Loss: 0.9332	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:15:41 [INFO ]  Epoch:  173	Loss: 0.7945	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:15:43 [INFO ]  Epoch:  174	Loss: 0.8842	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:15:45 [INFO ]  Epoch:  175	Loss: 0.8818	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:15:46 [INFO ]  Epoch:  176	Loss: 0.9393	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:48 [INFO ]  Epoch:  177	Loss: 1.0020	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:15:51 [INFO ]  Epoch:  178	Loss: 0.9271	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:15:52 [INFO ]  Epoch:  179	Loss: 0.8880	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:15:54 [INFO ]  Epoch:  180	Loss: 1.0490	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:15:56 [INFO ]  Epoch:  181	Loss: 0.9506	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:15:58 [INFO ]  Epoch:  182	Loss: 0.9189	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:16:00 [INFO ]  Epoch:  183	Loss: 0.9250	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:16:02 [INFO ]  Epoch:  184	Loss: 0.9567	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:16:04 [INFO ]  Epoch:  185	Loss: 0.9397	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:16:06 [INFO ]  Epoch:  186	Loss: 0.9141	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:16:08 [INFO ]  Epoch:  187	Loss: 0.8413	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:16:10 [INFO ]  Epoch:  188	Loss: 0.8579	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:16:12 [INFO ]  Epoch:  189	Loss: 1.1507	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:16:14 [INFO ]  Epoch:  190	Loss: 0.8155	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:16:15 [INFO ]  Epoch:  191	Loss: 0.9018	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:16:17 [INFO ]  Epoch:  192	Loss: 0.9082	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:16:19 [INFO ]  Epoch:  193	Loss: 0.9729	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:16:21 [INFO ]  Epoch:  194	Loss: 0.9896	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:16:23 [INFO ]  Epoch:  195	Loss: 0.8979	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:16:25 [INFO ]  Epoch:  196	Loss: 0.8919	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:16:27 [INFO ]  Epoch:  197	Loss: 0.9663	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:16:29 [INFO ]  Epoch:  198	Loss: 1.1224	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:16:30 [INFO ]  Epoch:  199	Loss: 1.0976	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:16:32 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:16:32 [INFO ]  
2022-10-04 17:16:32 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:16:35 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:16:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:16:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:16:35 [INFO ]  	   step  1 (lr=0.291132)                   73.37%                   0.9333
2022-10-04 17:16:35 [INFO ]  
2022-10-04 17:16:35 [INFO ]  
2022-10-04 17:16:35 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:16:38 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:16:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:16:38 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:16:38 [INFO ]  	   step  1 (lr=0.291132)                   21.24%                   4.8382
2022-10-04 17:16:38 [INFO ]  
2022-10-04 17:16:38 [INFO ]  CPU Time: 3.45 minutes
2022-10-04 17:19:09 [INFO ]  ======================================== 2022-10-04 17:19:09 ========================================
2022-10-04 17:19:09 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:19:09 [INFO ]  Options: 
2022-10-04 17:19:09 [INFO ]  	base_dir: null
2022-10-04 17:19:09 [INFO ]  	batch_size: 1024
2022-10-04 17:19:09 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:19:09 [INFO ]  	dataset: SVHN
2022-10-04 17:19:09 [INFO ]  	dataset_labels:
2022-10-04 17:19:09 [INFO ]  	- 0
2022-10-04 17:19:09 [INFO ]  	- 1
2022-10-04 17:19:09 [INFO ]  	- 2
2022-10-04 17:19:09 [INFO ]  	- 3
2022-10-04 17:19:09 [INFO ]  	- 4
2022-10-04 17:19:09 [INFO ]  	- 5
2022-10-04 17:19:09 [INFO ]  	- 6
2022-10-04 17:19:09 [INFO ]  	- 7
2022-10-04 17:19:09 [INFO ]  	- 8
2022-10-04 17:19:09 [INFO ]  	- 9
2022-10-04 17:19:09 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:19:09 [INFO ]  	- !!python/tuple
2022-10-04 17:19:09 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:19:09 [INFO ]  	    - 0.44398033618927
2022-10-04 17:19:09 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:19:09 [INFO ]  	- !!python/tuple
2022-10-04 17:19:09 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:19:09 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:19:09 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:19:09 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:19:09 [INFO ]  	decay_epochs: 50
2022-10-04 17:19:09 [INFO ]  	decay_factor: 0.1
2022-10-04 17:19:09 [INFO ]  	device_id: 0
2022-10-04 17:19:09 [INFO ]  	distill_epochs: 1
2022-10-04 17:19:09 [INFO ]  	distill_lr: 0.02
2022-10-04 17:19:09 [INFO ]  	distill_steps: 1
2022-10-04 17:19:09 [INFO ]  	epochs: 200
2022-10-04 17:19:09 [INFO ]  	expand_cls: false
2022-10-04 17:19:09 [INFO ]  	forgetting_dataset: null
2022-10-04 17:19:09 [INFO ]  	init: xavier
2022-10-04 17:19:09 [INFO ]  	init_param: 1.0
2022-10-04 17:19:09 [INFO ]  	input_size: 32
2022-10-04 17:19:09 [INFO ]  	ipc: 2
2022-10-04 17:19:09 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:19:09 [INFO ]  	log_interval: 100
2022-10-04 17:19:09 [INFO ]  	log_level: INFO
2022-10-04 17:19:09 [INFO ]  	lr: 0.01
2022-10-04 17:19:09 [INFO ]  	mode: distill_adapt
2022-10-04 17:19:09 [INFO ]  	nc: 3
2022-10-04 17:19:09 [INFO ]  	num_classes: 10
2022-10-04 17:19:09 [INFO ]  	num_workers: 8
2022-10-04 17:19:09 [INFO ]  	phase: train
2022-10-04 17:19:09 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:19:09 [INFO ]  	start_time: '2022-10-04 17:19:09'
2022-10-04 17:19:09 [INFO ]  	test_batch_size: 1024
2022-10-04 17:19:09 [INFO ]  	
2022-10-04 17:19:11 [INFO ]  train dataset size:	73257
2022-10-04 17:19:11 [INFO ]  test dataset size: 	26032
2022-10-04 17:19:11 [INFO ]  datasets built!
2022-10-04 17:19:11 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:19:13 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:19:13 [INFO ]  
2022-10-04 17:19:13 [INFO ]  Begin of epoch 0 :
2022-10-04 17:19:16 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:19:16 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:19:16 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:19:16 [INFO ]  	   step  1 (lr=0.020000)                    8.56%                   7.8372
2022-10-04 17:19:16 [INFO ]  
2022-10-04 17:19:16 [INFO ]  Epoch:    0	Loss: 7.6599	Data Time: 0.40s	Train Time: 0.04s
2022-10-04 17:19:18 [INFO ]  Epoch:    1	Loss: 3.0444	Data Time: 0.17s	Train Time: 0.00s
2022-10-04 17:19:20 [INFO ]  Epoch:    2	Loss: 2.6498	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:19:22 [INFO ]  Epoch:    3	Loss: 2.3663	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:19:24 [INFO ]  Epoch:    4	Loss: 2.2143	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:19:25 [INFO ]  Epoch:    5	Loss: 2.1674	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:19:27 [INFO ]  Epoch:    6	Loss: 2.1810	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:19:29 [INFO ]  Epoch:    7	Loss: 2.1614	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:19:31 [INFO ]  Epoch:    8	Loss: 2.0867	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:19:33 [INFO ]  Epoch:    9	Loss: 2.0145	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:19:35 [INFO ]  Epoch:   10	Loss: 1.9716	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:19:37 [INFO ]  Epoch:   11	Loss: 1.9162	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:19:38 [INFO ]  Epoch:   12	Loss: 1.8903	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:19:40 [INFO ]  Epoch:   13	Loss: 1.6681	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:19:42 [INFO ]  Epoch:   14	Loss: 1.6187	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:19:44 [INFO ]  Epoch:   15	Loss: 1.5645	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:19:46 [INFO ]  Epoch:   16	Loss: 1.5337	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:19:48 [INFO ]  Epoch:   17	Loss: 1.4425	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:19:50 [INFO ]  Epoch:   18	Loss: 1.4818	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:19:52 [INFO ]  Epoch:   19	Loss: 1.4410	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:19:53 [INFO ]  Epoch:   20	Loss: 1.4627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:19:55 [INFO ]  Epoch:   21	Loss: 1.3164	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:19:57 [INFO ]  Epoch:   22	Loss: 1.3122	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:19:59 [INFO ]  Epoch:   23	Loss: 1.2831	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:20:01 [INFO ]  Epoch:   24	Loss: 1.3135	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:03 [INFO ]  Epoch:   25	Loss: 1.4127	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:20:05 [INFO ]  Epoch:   26	Loss: 1.3315	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:20:07 [INFO ]  Epoch:   27	Loss: 1.1937	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:20:09 [INFO ]  Epoch:   28	Loss: 1.3201	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:20:11 [INFO ]  Epoch:   29	Loss: 1.1700	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:20:12 [INFO ]  Epoch:   30	Loss: 1.2127	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:14 [INFO ]  Epoch:   31	Loss: 1.3184	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:20:16 [INFO ]  Epoch:   32	Loss: 1.4151	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:20:18 [INFO ]  Epoch:   33	Loss: 1.2182	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:19 [INFO ]  Epoch:   34	Loss: 1.1429	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:21 [INFO ]  Epoch:   35	Loss: 1.1397	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:23 [INFO ]  Epoch:   36	Loss: 1.1764	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:20:25 [INFO ]  Epoch:   37	Loss: 1.1621	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:20:27 [INFO ]  Epoch:   38	Loss: 1.1408	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:20:29 [INFO ]  Epoch:   39	Loss: 1.2278	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:30 [INFO ]  Epoch:   40	Loss: 1.3020	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:32 [INFO ]  Epoch:   41	Loss: 1.1794	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:20:34 [INFO ]  Epoch:   42	Loss: 1.0995	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:20:36 [INFO ]  Epoch:   43	Loss: 1.2077	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:38 [INFO ]  Epoch:   44	Loss: 1.1319	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:20:40 [INFO ]  Epoch:   45	Loss: 1.1228	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:20:41 [INFO ]  Epoch:   46	Loss: 1.2343	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:20:44 [INFO ]  Epoch:   47	Loss: 1.0801	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:20:45 [INFO ]  Epoch:   48	Loss: 1.1302	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:47 [INFO ]  Epoch:   49	Loss: 1.0794	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:20:49 [INFO ]  Epoch:   50	Loss: 0.9108	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:51 [INFO ]  Epoch:   51	Loss: 0.9869	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:20:53 [INFO ]  Epoch:   52	Loss: 1.0253	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:20:55 [INFO ]  Epoch:   53	Loss: 0.9570	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:20:56 [INFO ]  Epoch:   54	Loss: 0.8914	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:20:58 [INFO ]  Epoch:   55	Loss: 1.0017	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:21:00 [INFO ]  Epoch:   56	Loss: 0.9272	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:21:02 [INFO ]  Epoch:   57	Loss: 0.9186	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:21:04 [INFO ]  Epoch:   58	Loss: 0.9431	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:21:05 [INFO ]  Epoch:   59	Loss: 0.9390	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:07 [INFO ]  Epoch:   60	Loss: 0.9969	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:21:09 [INFO ]  Epoch:   61	Loss: 0.9422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:11 [INFO ]  Epoch:   62	Loss: 1.0148	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:13 [INFO ]  Epoch:   63	Loss: 0.9523	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:21:15 [INFO ]  Epoch:   64	Loss: 1.0608	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:17 [INFO ]  Epoch:   65	Loss: 0.9479	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:18 [INFO ]  Epoch:   66	Loss: 0.8796	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:21:20 [INFO ]  Epoch:   67	Loss: 0.8509	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:22 [INFO ]  Epoch:   68	Loss: 0.8745	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:21:24 [INFO ]  Epoch:   69	Loss: 0.9291	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:26 [INFO ]  Epoch:   70	Loss: 0.9739	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:28 [INFO ]  Epoch:   71	Loss: 0.8936	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:21:30 [INFO ]  Epoch:   72	Loss: 0.8704	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:32 [INFO ]  Epoch:   73	Loss: 0.8986	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:21:34 [INFO ]  Epoch:   74	Loss: 0.9923	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:21:36 [INFO ]  Epoch:   75	Loss: 0.8763	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:21:38 [INFO ]  Epoch:   76	Loss: 0.8921	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:40 [INFO ]  Epoch:   77	Loss: 0.8747	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:42 [INFO ]  Epoch:   78	Loss: 0.8788	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:44 [INFO ]  Epoch:   79	Loss: 0.8932	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:45 [INFO ]  Epoch:   80	Loss: 0.9305	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:21:47 [INFO ]  Epoch:   81	Loss: 0.9396	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:21:49 [INFO ]  Epoch:   82	Loss: 0.9892	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:51 [INFO ]  Epoch:   83	Loss: 0.8969	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:21:53 [INFO ]  Epoch:   84	Loss: 0.8805	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:21:54 [INFO ]  Epoch:   85	Loss: 0.8235	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:21:56 [INFO ]  Epoch:   86	Loss: 0.9470	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:21:58 [INFO ]  Epoch:   87	Loss: 0.8855	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:22:00 [INFO ]  Epoch:   88	Loss: 0.8006	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:22:02 [INFO ]  Epoch:   89	Loss: 0.8832	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:22:04 [INFO ]  Epoch:   90	Loss: 0.8588	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:06 [INFO ]  Epoch:   91	Loss: 0.9017	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:08 [INFO ]  Epoch:   92	Loss: 1.0002	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:22:10 [INFO ]  Epoch:   93	Loss: 0.7980	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:22:12 [INFO ]  Epoch:   94	Loss: 0.8425	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:22:13 [INFO ]  Epoch:   95	Loss: 0.8146	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:15 [INFO ]  Epoch:   96	Loss: 0.8858	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:22:17 [INFO ]  Epoch:   97	Loss: 0.8523	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:22:19 [INFO ]  Epoch:   98	Loss: 0.8699	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:21 [INFO ]  Epoch:   99	Loss: 0.8422	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:23 [INFO ]  Epoch:  100	Loss: 0.9560	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:25 [INFO ]  Epoch:  101	Loss: 0.9096	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:27 [INFO ]  Epoch:  102	Loss: 0.9369	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:22:29 [INFO ]  Epoch:  103	Loss: 0.8817	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 17:22:31 [INFO ]  Epoch:  104	Loss: 0.9718	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:33 [INFO ]  Epoch:  105	Loss: 0.9135	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:35 [INFO ]  Epoch:  106	Loss: 0.8715	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:36 [INFO ]  Epoch:  107	Loss: 0.8533	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:38 [INFO ]  Epoch:  108	Loss: 0.9331	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:40 [INFO ]  Epoch:  109	Loss: 0.8122	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:22:42 [INFO ]  Epoch:  110	Loss: 0.8102	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:44 [INFO ]  Epoch:  111	Loss: 0.7862	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:46 [INFO ]  Epoch:  112	Loss: 0.8858	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:22:48 [INFO ]  Epoch:  113	Loss: 0.9309	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:22:50 [INFO ]  Epoch:  114	Loss: 0.8667	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:22:52 [INFO ]  Epoch:  115	Loss: 0.8690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:22:53 [INFO ]  Epoch:  116	Loss: 0.9832	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:22:55 [INFO ]  Epoch:  117	Loss: 0.8954	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:22:57 [INFO ]  Epoch:  118	Loss: 0.7729	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:22:59 [INFO ]  Epoch:  119	Loss: 0.7951	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:23:01 [INFO ]  Epoch:  120	Loss: 0.8228	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:23:03 [INFO ]  Epoch:  121	Loss: 0.7979	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:05 [INFO ]  Epoch:  122	Loss: 0.8185	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:07 [INFO ]  Epoch:  123	Loss: 0.7990	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:23:08 [INFO ]  Epoch:  124	Loss: 0.9040	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:10 [INFO ]  Epoch:  125	Loss: 0.8467	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:23:12 [INFO ]  Epoch:  126	Loss: 0.9160	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:14 [INFO ]  Epoch:  127	Loss: 0.8675	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:16 [INFO ]  Epoch:  128	Loss: 0.8292	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:18 [INFO ]  Epoch:  129	Loss: 0.8287	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:23:19 [INFO ]  Epoch:  130	Loss: 0.8460	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:23:21 [INFO ]  Epoch:  131	Loss: 0.8519	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:23:23 [INFO ]  Epoch:  132	Loss: 0.8592	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:23:25 [INFO ]  Epoch:  133	Loss: 0.9229	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:23:27 [INFO ]  Epoch:  134	Loss: 0.9016	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:23:29 [INFO ]  Epoch:  135	Loss: 0.8425	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:31 [INFO ]  Epoch:  136	Loss: 0.8298	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:23:32 [INFO ]  Epoch:  137	Loss: 0.8492	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:23:34 [INFO ]  Epoch:  138	Loss: 0.8512	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:36 [INFO ]  Epoch:  139	Loss: 0.8081	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:38 [INFO ]  Epoch:  140	Loss: 0.7697	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:23:40 [INFO ]  Epoch:  141	Loss: 0.8435	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:23:42 [INFO ]  Epoch:  142	Loss: 0.7503	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:23:43 [INFO ]  Epoch:  143	Loss: 0.7323	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:45 [INFO ]  Epoch:  144	Loss: 0.8616	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:47 [INFO ]  Epoch:  145	Loss: 0.8213	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:49 [INFO ]  Epoch:  146	Loss: 0.8459	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:51 [INFO ]  Epoch:  147	Loss: 0.8075	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:53 [INFO ]  Epoch:  148	Loss: 0.7958	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:23:55 [INFO ]  Epoch:  149	Loss: 0.7822	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:23:56 [INFO ]  Epoch:  150	Loss: 0.8291	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:23:58 [INFO ]  Epoch:  151	Loss: 0.9118	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:00 [INFO ]  Epoch:  152	Loss: 0.8713	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:02 [INFO ]  Epoch:  153	Loss: 0.7861	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:24:04 [INFO ]  Epoch:  154	Loss: 0.8274	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:24:05 [INFO ]  Epoch:  155	Loss: 0.8519	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:24:07 [INFO ]  Epoch:  156	Loss: 0.8449	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:24:09 [INFO ]  Epoch:  157	Loss: 0.8573	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:24:11 [INFO ]  Epoch:  158	Loss: 0.8467	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:24:13 [INFO ]  Epoch:  159	Loss: 0.8588	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:24:15 [INFO ]  Epoch:  160	Loss: 0.8237	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:17 [INFO ]  Epoch:  161	Loss: 0.8299	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:19 [INFO ]  Epoch:  162	Loss: 0.8358	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:24:21 [INFO ]  Epoch:  163	Loss: 0.7830	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:22 [INFO ]  Epoch:  164	Loss: 0.8458	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:24:24 [INFO ]  Epoch:  165	Loss: 1.0334	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:24:26 [INFO ]  Epoch:  166	Loss: 0.8396	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:24:28 [INFO ]  Epoch:  167	Loss: 0.8707	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:30 [INFO ]  Epoch:  168	Loss: 0.8653	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:24:32 [INFO ]  Epoch:  169	Loss: 0.9815	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:34 [INFO ]  Epoch:  170	Loss: 0.8476	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:24:36 [INFO ]  Epoch:  171	Loss: 0.8784	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:24:38 [INFO ]  Epoch:  172	Loss: 0.8191	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:24:40 [INFO ]  Epoch:  173	Loss: 0.7892	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:42 [INFO ]  Epoch:  174	Loss: 0.8416	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:44 [INFO ]  Epoch:  175	Loss: 0.8804	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:24:45 [INFO ]  Epoch:  176	Loss: 0.8645	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:47 [INFO ]  Epoch:  177	Loss: 0.8093	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:24:49 [INFO ]  Epoch:  178	Loss: 0.8024	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:24:51 [INFO ]  Epoch:  179	Loss: 0.8765	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:24:53 [INFO ]  Epoch:  180	Loss: 0.7743	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:24:55 [INFO ]  Epoch:  181	Loss: 0.7597	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:24:57 [INFO ]  Epoch:  182	Loss: 0.7371	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:24:59 [INFO ]  Epoch:  183	Loss: 0.8384	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:00 [INFO ]  Epoch:  184	Loss: 0.8035	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:25:02 [INFO ]  Epoch:  185	Loss: 0.8752	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:25:04 [INFO ]  Epoch:  186	Loss: 0.8174	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:25:06 [INFO ]  Epoch:  187	Loss: 0.8552	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:25:08 [INFO ]  Epoch:  188	Loss: 0.8135	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:25:10 [INFO ]  Epoch:  189	Loss: 0.8349	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:25:12 [INFO ]  Epoch:  190	Loss: 0.8576	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:14 [INFO ]  Epoch:  191	Loss: 0.7725	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:25:16 [INFO ]  Epoch:  192	Loss: 0.8508	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:25:18 [INFO ]  Epoch:  193	Loss: 0.9042	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:25:20 [INFO ]  Epoch:  194	Loss: 0.7807	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:22 [INFO ]  Epoch:  195	Loss: 0.7894	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:24 [INFO ]  Epoch:  196	Loss: 0.8066	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:25 [INFO ]  Epoch:  197	Loss: 0.8551	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:25:27 [INFO ]  Epoch:  198	Loss: 0.7629	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:25:29 [INFO ]  Epoch:  199	Loss: 0.7891	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:25:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:25:31 [INFO ]  
2022-10-04 17:25:31 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:25:34 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:25:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:25:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:25:34 [INFO ]  	   step  1 (lr=0.318131)                   75.45%                   0.8895
2022-10-04 17:25:34 [INFO ]  
2022-10-04 17:25:34 [INFO ]  
2022-10-04 17:25:34 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:25:37 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:25:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:25:37 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:25:37 [INFO ]  	   step  1 (lr=0.318131)                   21.48%                   4.6841
2022-10-04 17:25:37 [INFO ]  
2022-10-04 17:25:37 [INFO ]  CPU Time: 3.45 minutes
2022-10-04 17:25:47 [INFO ]  ======================================== 2022-10-04 17:25:47 ========================================
2022-10-04 17:25:47 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:25:47 [INFO ]  Options: 
2022-10-04 17:25:47 [INFO ]  	base_dir: null
2022-10-04 17:25:47 [INFO ]  	batch_size: 1024
2022-10-04 17:25:47 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:25:47 [INFO ]  	dataset: SVHN
2022-10-04 17:25:47 [INFO ]  	dataset_labels:
2022-10-04 17:25:47 [INFO ]  	- 0
2022-10-04 17:25:47 [INFO ]  	- 1
2022-10-04 17:25:47 [INFO ]  	- 2
2022-10-04 17:25:47 [INFO ]  	- 3
2022-10-04 17:25:47 [INFO ]  	- 4
2022-10-04 17:25:47 [INFO ]  	- 5
2022-10-04 17:25:47 [INFO ]  	- 6
2022-10-04 17:25:47 [INFO ]  	- 7
2022-10-04 17:25:47 [INFO ]  	- 8
2022-10-04 17:25:47 [INFO ]  	- 9
2022-10-04 17:25:47 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:25:47 [INFO ]  	- !!python/tuple
2022-10-04 17:25:47 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:25:47 [INFO ]  	    - 0.44398033618927
2022-10-04 17:25:47 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:25:47 [INFO ]  	- !!python/tuple
2022-10-04 17:25:47 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:25:47 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:25:47 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:25:47 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:25:47 [INFO ]  	decay_epochs: 50
2022-10-04 17:25:47 [INFO ]  	decay_factor: 0.1
2022-10-04 17:25:47 [INFO ]  	device_id: 0
2022-10-04 17:25:47 [INFO ]  	distill_epochs: 1
2022-10-04 17:25:47 [INFO ]  	distill_lr: 0.02
2022-10-04 17:25:47 [INFO ]  	distill_steps: 1
2022-10-04 17:25:47 [INFO ]  	epochs: 200
2022-10-04 17:25:47 [INFO ]  	expand_cls: false
2022-10-04 17:25:47 [INFO ]  	forgetting_dataset: null
2022-10-04 17:25:47 [INFO ]  	init: xavier
2022-10-04 17:25:47 [INFO ]  	init_param: 1.0
2022-10-04 17:25:47 [INFO ]  	input_size: 32
2022-10-04 17:25:47 [INFO ]  	ipc: 2
2022-10-04 17:25:47 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:25:47 [INFO ]  	log_interval: 100
2022-10-04 17:25:47 [INFO ]  	log_level: INFO
2022-10-04 17:25:47 [INFO ]  	lr: 0.01
2022-10-04 17:25:47 [INFO ]  	mode: distill_adapt
2022-10-04 17:25:47 [INFO ]  	nc: 3
2022-10-04 17:25:47 [INFO ]  	num_classes: 10
2022-10-04 17:25:47 [INFO ]  	num_workers: 8
2022-10-04 17:25:47 [INFO ]  	phase: train
2022-10-04 17:25:47 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:25:47 [INFO ]  	start_time: '2022-10-04 17:25:47'
2022-10-04 17:25:47 [INFO ]  	test_batch_size: 1024
2022-10-04 17:25:47 [INFO ]  	
2022-10-04 17:25:49 [INFO ]  train dataset size:	73257
2022-10-04 17:25:49 [INFO ]  test dataset size: 	26032
2022-10-04 17:25:49 [INFO ]  datasets built!
2022-10-04 17:25:49 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:25:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:25:51 [INFO ]  
2022-10-04 17:25:51 [INFO ]  Begin of epoch 0 :
2022-10-04 17:25:54 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:25:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:25:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:25:54 [INFO ]  	   step  1 (lr=0.020000)                    7.29%                   8.6770
2022-10-04 17:25:54 [INFO ]  
2022-10-04 17:25:54 [INFO ]  Epoch:    0	Loss: 8.1792	Data Time: 0.47s	Train Time: 0.04s
2022-10-04 17:25:56 [INFO ]  Epoch:    1	Loss: 3.1621	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:25:58 [INFO ]  Epoch:    2	Loss: 2.5122	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:25:59 [INFO ]  Epoch:    3	Loss: 2.2896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:01 [INFO ]  Epoch:    4	Loss: 2.2363	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:26:03 [INFO ]  Epoch:    5	Loss: 2.1855	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:26:05 [INFO ]  Epoch:    6	Loss: 2.2145	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:26:07 [INFO ]  Epoch:    7	Loss: 2.1619	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:26:09 [INFO ]  Epoch:    8	Loss: 2.1743	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:11 [INFO ]  Epoch:    9	Loss: 2.0907	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:26:12 [INFO ]  Epoch:   10	Loss: 2.0726	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:14 [INFO ]  Epoch:   11	Loss: 2.0188	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:16 [INFO ]  Epoch:   12	Loss: 1.8881	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:26:18 [INFO ]  Epoch:   13	Loss: 1.7895	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:26:20 [INFO ]  Epoch:   14	Loss: 1.8361	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:26:22 [INFO ]  Epoch:   15	Loss: 1.6899	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:24 [INFO ]  Epoch:   16	Loss: 1.6394	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:26 [INFO ]  Epoch:   17	Loss: 1.7784	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:26:28 [INFO ]  Epoch:   18	Loss: 1.5305	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:26:30 [INFO ]  Epoch:   19	Loss: 1.6220	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:26:31 [INFO ]  Epoch:   20	Loss: 1.5465	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:33 [INFO ]  Epoch:   21	Loss: 1.4653	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:26:35 [INFO ]  Epoch:   22	Loss: 1.4660	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:26:37 [INFO ]  Epoch:   23	Loss: 1.4530	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:26:38 [INFO ]  Epoch:   24	Loss: 1.3538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:40 [INFO ]  Epoch:   25	Loss: 1.3363	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:26:42 [INFO ]  Epoch:   26	Loss: 1.3053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:44 [INFO ]  Epoch:   27	Loss: 1.2429	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:26:46 [INFO ]  Epoch:   28	Loss: 1.2352	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:26:48 [INFO ]  Epoch:   29	Loss: 1.1950	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:26:50 [INFO ]  Epoch:   30	Loss: 1.2122	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:52 [INFO ]  Epoch:   31	Loss: 1.2156	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:26:54 [INFO ]  Epoch:   32	Loss: 1.1829	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:26:56 [INFO ]  Epoch:   33	Loss: 1.1416	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:26:58 [INFO ]  Epoch:   34	Loss: 1.1467	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:27:00 [INFO ]  Epoch:   35	Loss: 1.2705	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:01 [INFO ]  Epoch:   36	Loss: 1.1329	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:03 [INFO ]  Epoch:   37	Loss: 1.2686	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:27:05 [INFO ]  Epoch:   38	Loss: 1.3082	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:27:07 [INFO ]  Epoch:   39	Loss: 1.2256	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:09 [INFO ]  Epoch:   40	Loss: 1.1908	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:27:11 [INFO ]  Epoch:   41	Loss: 1.0937	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:27:13 [INFO ]  Epoch:   42	Loss: 1.1672	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:27:15 [INFO ]  Epoch:   43	Loss: 1.0767	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:16 [INFO ]  Epoch:   44	Loss: 1.0875	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:18 [INFO ]  Epoch:   45	Loss: 1.2475	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:20 [INFO ]  Epoch:   46	Loss: 1.0122	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:22 [INFO ]  Epoch:   47	Loss: 1.0334	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:24 [INFO ]  Epoch:   48	Loss: 1.0986	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:25 [INFO ]  Epoch:   49	Loss: 1.0378	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:27 [INFO ]  Epoch:   50	Loss: 0.9343	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:27:29 [INFO ]  Epoch:   51	Loss: 1.0442	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:31 [INFO ]  Epoch:   52	Loss: 0.9905	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:27:33 [INFO ]  Epoch:   53	Loss: 1.0518	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:27:35 [INFO ]  Epoch:   54	Loss: 1.0300	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:27:37 [INFO ]  Epoch:   55	Loss: 1.1321	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:39 [INFO ]  Epoch:   56	Loss: 1.0165	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:41 [INFO ]  Epoch:   57	Loss: 0.9208	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:27:42 [INFO ]  Epoch:   58	Loss: 1.0435	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:27:44 [INFO ]  Epoch:   59	Loss: 0.9532	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:46 [INFO ]  Epoch:   60	Loss: 0.9299	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:48 [INFO ]  Epoch:   61	Loss: 1.0836	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:27:50 [INFO ]  Epoch:   62	Loss: 0.9523	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:51 [INFO ]  Epoch:   63	Loss: 0.9829	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:27:53 [INFO ]  Epoch:   64	Loss: 1.0243	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:55 [INFO ]  Epoch:   65	Loss: 0.9301	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:27:57 [INFO ]  Epoch:   66	Loss: 1.1294	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:27:59 [INFO ]  Epoch:   67	Loss: 0.8974	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:00 [INFO ]  Epoch:   68	Loss: 0.9796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:02 [INFO ]  Epoch:   69	Loss: 0.9355	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:28:04 [INFO ]  Epoch:   70	Loss: 1.1571	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:28:06 [INFO ]  Epoch:   71	Loss: 1.1165	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:28:08 [INFO ]  Epoch:   72	Loss: 0.9242	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:28:10 [INFO ]  Epoch:   73	Loss: 0.9430	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:12 [INFO ]  Epoch:   74	Loss: 0.9897	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:14 [INFO ]  Epoch:   75	Loss: 0.9435	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:16 [INFO ]  Epoch:   76	Loss: 0.9606	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:18 [INFO ]  Epoch:   77	Loss: 0.9712	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:28:19 [INFO ]  Epoch:   78	Loss: 0.9347	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:28:21 [INFO ]  Epoch:   79	Loss: 0.9003	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:28:23 [INFO ]  Epoch:   80	Loss: 1.0242	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:28:25 [INFO ]  Epoch:   81	Loss: 0.8707	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:28:27 [INFO ]  Epoch:   82	Loss: 1.0493	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:29 [INFO ]  Epoch:   83	Loss: 1.0680	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:31 [INFO ]  Epoch:   84	Loss: 1.2254	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:28:32 [INFO ]  Epoch:   85	Loss: 0.9803	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:34 [INFO ]  Epoch:   86	Loss: 0.9345	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:28:36 [INFO ]  Epoch:   87	Loss: 1.0436	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:38 [INFO ]  Epoch:   88	Loss: 0.9678	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:28:40 [INFO ]  Epoch:   89	Loss: 1.0506	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:42 [INFO ]  Epoch:   90	Loss: 0.9718	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:28:43 [INFO ]  Epoch:   91	Loss: 0.9375	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:45 [INFO ]  Epoch:   92	Loss: 0.8836	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:28:47 [INFO ]  Epoch:   93	Loss: 0.9240	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:28:49 [INFO ]  Epoch:   94	Loss: 0.9992	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:28:51 [INFO ]  Epoch:   95	Loss: 0.8515	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:28:53 [INFO ]  Epoch:   96	Loss: 0.8985	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:28:54 [INFO ]  Epoch:   97	Loss: 0.9746	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:28:56 [INFO ]  Epoch:   98	Loss: 1.0456	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:28:58 [INFO ]  Epoch:   99	Loss: 0.9605	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:00 [INFO ]  Epoch:  100	Loss: 0.9597	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:02 [INFO ]  Epoch:  101	Loss: 0.9220	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:29:04 [INFO ]  Epoch:  102	Loss: 1.0950	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:29:06 [INFO ]  Epoch:  103	Loss: 0.9346	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:29:07 [INFO ]  Epoch:  104	Loss: 0.9231	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:09 [INFO ]  Epoch:  105	Loss: 0.8664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:11 [INFO ]  Epoch:  106	Loss: 0.8845	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:29:13 [INFO ]  Epoch:  107	Loss: 0.9644	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:15 [INFO ]  Epoch:  108	Loss: 0.8619	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:16 [INFO ]  Epoch:  109	Loss: 0.8830	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:18 [INFO ]  Epoch:  110	Loss: 0.9085	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:29:20 [INFO ]  Epoch:  111	Loss: 0.8590	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:29:22 [INFO ]  Epoch:  112	Loss: 0.9042	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:24 [INFO ]  Epoch:  113	Loss: 0.9388	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:26 [INFO ]  Epoch:  114	Loss: 0.9465	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:29:28 [INFO ]  Epoch:  115	Loss: 0.8319	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:29 [INFO ]  Epoch:  116	Loss: 0.9261	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:31 [INFO ]  Epoch:  117	Loss: 0.8703	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:33 [INFO ]  Epoch:  118	Loss: 0.8784	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:35 [INFO ]  Epoch:  119	Loss: 0.9299	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:29:37 [INFO ]  Epoch:  120	Loss: 0.8211	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:38 [INFO ]  Epoch:  121	Loss: 0.9379	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:40 [INFO ]  Epoch:  122	Loss: 0.8281	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:42 [INFO ]  Epoch:  123	Loss: 0.9493	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:29:44 [INFO ]  Epoch:  124	Loss: 1.0672	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:46 [INFO ]  Epoch:  125	Loss: 0.8734	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:29:48 [INFO ]  Epoch:  126	Loss: 0.9877	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:50 [INFO ]  Epoch:  127	Loss: 0.8954	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:52 [INFO ]  Epoch:  128	Loss: 0.8963	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:29:54 [INFO ]  Epoch:  129	Loss: 0.8908	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:29:56 [INFO ]  Epoch:  130	Loss: 1.0031	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:29:58 [INFO ]  Epoch:  131	Loss: 0.9095	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:30:00 [INFO ]  Epoch:  132	Loss: 0.8701	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:01 [INFO ]  Epoch:  133	Loss: 0.8247	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:30:03 [INFO ]  Epoch:  134	Loss: 0.9542	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:30:05 [INFO ]  Epoch:  135	Loss: 0.8749	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:07 [INFO ]  Epoch:  136	Loss: 0.9319	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:30:09 [INFO ]  Epoch:  137	Loss: 0.9409	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:11 [INFO ]  Epoch:  138	Loss: 0.8852	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:30:13 [INFO ]  Epoch:  139	Loss: 0.8614	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:30:14 [INFO ]  Epoch:  140	Loss: 0.9215	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:17 [INFO ]  Epoch:  141	Loss: 0.9309	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:30:18 [INFO ]  Epoch:  142	Loss: 0.9182	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:20 [INFO ]  Epoch:  143	Loss: 1.0102	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:22 [INFO ]  Epoch:  144	Loss: 0.9903	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:24 [INFO ]  Epoch:  145	Loss: 0.8714	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:30:25 [INFO ]  Epoch:  146	Loss: 0.9531	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:30:27 [INFO ]  Epoch:  147	Loss: 0.8674	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:29 [INFO ]  Epoch:  148	Loss: 0.8689	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:31 [INFO ]  Epoch:  149	Loss: 0.9051	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:33 [INFO ]  Epoch:  150	Loss: 0.8020	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:35 [INFO ]  Epoch:  151	Loss: 0.8545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:36 [INFO ]  Epoch:  152	Loss: 0.9812	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:30:38 [INFO ]  Epoch:  153	Loss: 0.9496	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:40 [INFO ]  Epoch:  154	Loss: 0.8677	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:30:42 [INFO ]  Epoch:  155	Loss: 0.8667	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:30:44 [INFO ]  Epoch:  156	Loss: 0.8650	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:30:46 [INFO ]  Epoch:  157	Loss: 0.8402	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:30:47 [INFO ]  Epoch:  158	Loss: 0.9257	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:30:49 [INFO ]  Epoch:  159	Loss: 0.9240	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:51 [INFO ]  Epoch:  160	Loss: 1.0007	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:53 [INFO ]  Epoch:  161	Loss: 0.9173	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:55 [INFO ]  Epoch:  162	Loss: 0.8955	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:30:57 [INFO ]  Epoch:  163	Loss: 0.9151	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:30:59 [INFO ]  Epoch:  164	Loss: 0.7950	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:31:01 [INFO ]  Epoch:  165	Loss: 0.8403	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:31:02 [INFO ]  Epoch:  166	Loss: 0.9676	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:04 [INFO ]  Epoch:  167	Loss: 0.8291	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:06 [INFO ]  Epoch:  168	Loss: 0.8782	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:31:08 [INFO ]  Epoch:  169	Loss: 0.8333	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:31:10 [INFO ]  Epoch:  170	Loss: 0.8615	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:31:12 [INFO ]  Epoch:  171	Loss: 0.8913	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:14 [INFO ]  Epoch:  172	Loss: 0.9885	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:16 [INFO ]  Epoch:  173	Loss: 1.0782	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:31:18 [INFO ]  Epoch:  174	Loss: 0.9604	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:31:20 [INFO ]  Epoch:  175	Loss: 1.0304	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:31:22 [INFO ]  Epoch:  176	Loss: 0.9013	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:31:24 [INFO ]  Epoch:  177	Loss: 0.9041	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:26 [INFO ]  Epoch:  178	Loss: 0.9305	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:28 [INFO ]  Epoch:  179	Loss: 0.8539	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:29 [INFO ]  Epoch:  180	Loss: 0.8648	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:31 [INFO ]  Epoch:  181	Loss: 0.8526	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:33 [INFO ]  Epoch:  182	Loss: 0.9813	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:31:35 [INFO ]  Epoch:  183	Loss: 0.8839	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:31:37 [INFO ]  Epoch:  184	Loss: 1.0146	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:31:39 [INFO ]  Epoch:  185	Loss: 0.9024	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:41 [INFO ]  Epoch:  186	Loss: 0.8427	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:31:42 [INFO ]  Epoch:  187	Loss: 0.9529	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:31:44 [INFO ]  Epoch:  188	Loss: 0.8334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:46 [INFO ]  Epoch:  189	Loss: 0.8393	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:31:48 [INFO ]  Epoch:  190	Loss: 0.9075	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:31:50 [INFO ]  Epoch:  191	Loss: 0.9373	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:31:52 [INFO ]  Epoch:  192	Loss: 1.0155	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:31:53 [INFO ]  Epoch:  193	Loss: 0.9967	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:31:55 [INFO ]  Epoch:  194	Loss: 0.9321	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:31:57 [INFO ]  Epoch:  195	Loss: 0.9398	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:31:59 [INFO ]  Epoch:  196	Loss: 0.9213	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:32:01 [INFO ]  Epoch:  197	Loss: 0.8523	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:32:03 [INFO ]  Epoch:  198	Loss: 0.8461	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:04 [INFO ]  Epoch:  199	Loss: 0.8698	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:32:06 [INFO ]  
2022-10-04 17:32:06 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:32:09 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:32:09 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:32:09 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:32:09 [INFO ]  	   step  1 (lr=0.292495)                   73.12%                   0.9585
2022-10-04 17:32:09 [INFO ]  
2022-10-04 17:32:09 [INFO ]  
2022-10-04 17:32:09 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:32:12 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:32:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:32:12 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:32:12 [INFO ]  	   step  1 (lr=0.292495)                   19.19%                   4.7451
2022-10-04 17:32:12 [INFO ]  
2022-10-04 17:32:12 [INFO ]  CPU Time: 3.47 minutes
2022-10-04 17:32:26 [INFO ]  ======================================== 2022-10-04 17:32:26 ========================================
2022-10-04 17:32:26 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:32:26 [INFO ]  Options: 
2022-10-04 17:32:26 [INFO ]  	base_dir: null
2022-10-04 17:32:26 [INFO ]  	batch_size: 1024
2022-10-04 17:32:26 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:32:26 [INFO ]  	dataset: SVHN
2022-10-04 17:32:26 [INFO ]  	dataset_labels:
2022-10-04 17:32:26 [INFO ]  	- 0
2022-10-04 17:32:26 [INFO ]  	- 1
2022-10-04 17:32:26 [INFO ]  	- 2
2022-10-04 17:32:26 [INFO ]  	- 3
2022-10-04 17:32:26 [INFO ]  	- 4
2022-10-04 17:32:26 [INFO ]  	- 5
2022-10-04 17:32:26 [INFO ]  	- 6
2022-10-04 17:32:26 [INFO ]  	- 7
2022-10-04 17:32:26 [INFO ]  	- 8
2022-10-04 17:32:26 [INFO ]  	- 9
2022-10-04 17:32:26 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:32:26 [INFO ]  	- !!python/tuple
2022-10-04 17:32:26 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:32:26 [INFO ]  	    - 0.44398033618927
2022-10-04 17:32:26 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:32:26 [INFO ]  	- !!python/tuple
2022-10-04 17:32:26 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:32:26 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:32:26 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:32:26 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:32:26 [INFO ]  	decay_epochs: 50
2022-10-04 17:32:26 [INFO ]  	decay_factor: 0.1
2022-10-04 17:32:26 [INFO ]  	device_id: 0
2022-10-04 17:32:26 [INFO ]  	distill_epochs: 1
2022-10-04 17:32:26 [INFO ]  	distill_lr: 0.02
2022-10-04 17:32:26 [INFO ]  	distill_steps: 1
2022-10-04 17:32:26 [INFO ]  	epochs: 200
2022-10-04 17:32:26 [INFO ]  	expand_cls: false
2022-10-04 17:32:26 [INFO ]  	forgetting_dataset: null
2022-10-04 17:32:26 [INFO ]  	init: xavier
2022-10-04 17:32:26 [INFO ]  	init_param: 1.0
2022-10-04 17:32:26 [INFO ]  	input_size: 32
2022-10-04 17:32:26 [INFO ]  	ipc: 2
2022-10-04 17:32:26 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:32:26 [INFO ]  	log_interval: 100
2022-10-04 17:32:26 [INFO ]  	log_level: INFO
2022-10-04 17:32:26 [INFO ]  	lr: 0.01
2022-10-04 17:32:26 [INFO ]  	mode: distill_adapt
2022-10-04 17:32:26 [INFO ]  	nc: 3
2022-10-04 17:32:26 [INFO ]  	num_classes: 10
2022-10-04 17:32:26 [INFO ]  	num_workers: 8
2022-10-04 17:32:26 [INFO ]  	phase: train
2022-10-04 17:32:26 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:32:26 [INFO ]  	start_time: '2022-10-04 17:32:26'
2022-10-04 17:32:26 [INFO ]  	test_batch_size: 1024
2022-10-04 17:32:26 [INFO ]  	
2022-10-04 17:32:28 [INFO ]  train dataset size:	73257
2022-10-04 17:32:28 [INFO ]  test dataset size: 	26032
2022-10-04 17:32:28 [INFO ]  datasets built!
2022-10-04 17:32:28 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:32:30 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:32:30 [INFO ]  
2022-10-04 17:32:30 [INFO ]  Begin of epoch 0 :
2022-10-04 17:32:34 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:32:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:32:34 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:32:34 [INFO ]  	   step  1 (lr=0.020000)                    8.52%                   7.3912
2022-10-04 17:32:34 [INFO ]  
2022-10-04 17:32:34 [INFO ]  Epoch:    0	Loss: 7.5350	Data Time: 0.39s	Train Time: 0.03s
2022-10-04 17:32:35 [INFO ]  Epoch:    1	Loss: 3.0062	Data Time: 0.13s	Train Time: 0.01s
2022-10-04 17:32:37 [INFO ]  Epoch:    2	Loss: 2.5567	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:32:39 [INFO ]  Epoch:    3	Loss: 2.3405	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:32:41 [INFO ]  Epoch:    4	Loss: 2.2474	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:43 [INFO ]  Epoch:    5	Loss: 2.1838	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:32:45 [INFO ]  Epoch:    6	Loss: 2.2033	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:47 [INFO ]  Epoch:    7	Loss: 2.1571	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:32:48 [INFO ]  Epoch:    8	Loss: 2.1225	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:50 [INFO ]  Epoch:    9	Loss: 2.1085	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:52 [INFO ]  Epoch:   10	Loss: 2.0453	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:54 [INFO ]  Epoch:   11	Loss: 1.9482	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:32:56 [INFO ]  Epoch:   12	Loss: 2.0404	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:32:58 [INFO ]  Epoch:   13	Loss: 1.8386	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:32:59 [INFO ]  Epoch:   14	Loss: 1.8510	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:33:01 [INFO ]  Epoch:   15	Loss: 1.8679	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:03 [INFO ]  Epoch:   16	Loss: 1.6844	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:05 [INFO ]  Epoch:   17	Loss: 1.5354	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:33:07 [INFO ]  Epoch:   18	Loss: 1.5958	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:09 [INFO ]  Epoch:   19	Loss: 1.7024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:10 [INFO ]  Epoch:   20	Loss: 1.4901	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:33:12 [INFO ]  Epoch:   21	Loss: 1.4784	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:33:14 [INFO ]  Epoch:   22	Loss: 1.5478	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:33:16 [INFO ]  Epoch:   23	Loss: 1.3612	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:18 [INFO ]  Epoch:   24	Loss: 1.3922	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:33:20 [INFO ]  Epoch:   25	Loss: 1.4357	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:22 [INFO ]  Epoch:   26	Loss: 1.2418	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:33:24 [INFO ]  Epoch:   27	Loss: 1.2502	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:33:25 [INFO ]  Epoch:   28	Loss: 1.3744	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:27 [INFO ]  Epoch:   29	Loss: 1.3262	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:29 [INFO ]  Epoch:   30	Loss: 1.1886	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:33:31 [INFO ]  Epoch:   31	Loss: 1.2219	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:33:33 [INFO ]  Epoch:   32	Loss: 1.2227	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:33:35 [INFO ]  Epoch:   33	Loss: 1.2533	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:37 [INFO ]  Epoch:   34	Loss: 1.1796	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:39 [INFO ]  Epoch:   35	Loss: 1.2861	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:33:41 [INFO ]  Epoch:   36	Loss: 1.2353	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:42 [INFO ]  Epoch:   37	Loss: 1.1355	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:33:44 [INFO ]  Epoch:   38	Loss: 1.3677	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:33:46 [INFO ]  Epoch:   39	Loss: 1.1604	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:33:48 [INFO ]  Epoch:   40	Loss: 1.1294	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:33:50 [INFO ]  Epoch:   41	Loss: 1.0997	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:52 [INFO ]  Epoch:   42	Loss: 1.1622	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:54 [INFO ]  Epoch:   43	Loss: 0.9818	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:33:56 [INFO ]  Epoch:   44	Loss: 1.5951	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:33:58 [INFO ]  Epoch:   45	Loss: 1.0736	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:00 [INFO ]  Epoch:   46	Loss: 1.0022	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:34:02 [INFO ]  Epoch:   47	Loss: 1.0166	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:34:04 [INFO ]  Epoch:   48	Loss: 0.9891	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:06 [INFO ]  Epoch:   49	Loss: 1.3032	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:34:07 [INFO ]  Epoch:   50	Loss: 0.9620	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:34:09 [INFO ]  Epoch:   51	Loss: 0.9147	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:11 [INFO ]  Epoch:   52	Loss: 0.8384	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:13 [INFO ]  Epoch:   53	Loss: 0.9654	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:15 [INFO ]  Epoch:   54	Loss: 0.8656	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:16 [INFO ]  Epoch:   55	Loss: 0.9545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:18 [INFO ]  Epoch:   56	Loss: 0.8798	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:20 [INFO ]  Epoch:   57	Loss: 0.9151	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:34:22 [INFO ]  Epoch:   58	Loss: 0.9375	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:34:24 [INFO ]  Epoch:   59	Loss: 0.8988	Data Time: 0.24s	Train Time: 0.00s
2022-10-04 17:34:26 [INFO ]  Epoch:   60	Loss: 0.9713	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:34:28 [INFO ]  Epoch:   61	Loss: 0.9034	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:30 [INFO ]  Epoch:   62	Loss: 0.9286	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:34:32 [INFO ]  Epoch:   63	Loss: 1.0008	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:34:33 [INFO ]  Epoch:   64	Loss: 0.9019	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:34:35 [INFO ]  Epoch:   65	Loss: 0.8786	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:34:37 [INFO ]  Epoch:   66	Loss: 0.9313	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:34:39 [INFO ]  Epoch:   67	Loss: 0.9052	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:34:41 [INFO ]  Epoch:   68	Loss: 0.9583	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:34:42 [INFO ]  Epoch:   69	Loss: 0.9024	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:44 [INFO ]  Epoch:   70	Loss: 0.8798	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:34:46 [INFO ]  Epoch:   71	Loss: 0.9495	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:48 [INFO ]  Epoch:   72	Loss: 0.7965	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:50 [INFO ]  Epoch:   73	Loss: 0.9126	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:34:52 [INFO ]  Epoch:   74	Loss: 0.8918	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:34:53 [INFO ]  Epoch:   75	Loss: 1.0753	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:34:55 [INFO ]  Epoch:   76	Loss: 0.8490	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:34:57 [INFO ]  Epoch:   77	Loss: 0.8754	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:34:59 [INFO ]  Epoch:   78	Loss: 0.9647	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:01 [INFO ]  Epoch:   79	Loss: 0.9989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:03 [INFO ]  Epoch:   80	Loss: 0.8282	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:05 [INFO ]  Epoch:   81	Loss: 0.9237	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:35:07 [INFO ]  Epoch:   82	Loss: 0.9075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:09 [INFO ]  Epoch:   83	Loss: 0.8624	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:10 [INFO ]  Epoch:   84	Loss: 0.8560	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:12 [INFO ]  Epoch:   85	Loss: 1.0176	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:35:14 [INFO ]  Epoch:   86	Loss: 0.7724	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:35:16 [INFO ]  Epoch:   87	Loss: 0.8822	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:18 [INFO ]  Epoch:   88	Loss: 0.8276	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:35:19 [INFO ]  Epoch:   89	Loss: 0.9129	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:21 [INFO ]  Epoch:   90	Loss: 0.8350	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:23 [INFO ]  Epoch:   91	Loss: 0.9754	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:25 [INFO ]  Epoch:   92	Loss: 0.8487	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:35:27 [INFO ]  Epoch:   93	Loss: 0.9802	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:29 [INFO ]  Epoch:   94	Loss: 0.9556	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:31 [INFO ]  Epoch:   95	Loss: 1.1170	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:33 [INFO ]  Epoch:   96	Loss: 0.8035	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:35:35 [INFO ]  Epoch:   97	Loss: 0.9410	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:35:37 [INFO ]  Epoch:   98	Loss: 0.8628	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:35:39 [INFO ]  Epoch:   99	Loss: 0.8889	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:41 [INFO ]  Epoch:  100	Loss: 0.8415	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:42 [INFO ]  Epoch:  101	Loss: 1.0286	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:35:44 [INFO ]  Epoch:  102	Loss: 0.9795	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:46 [INFO ]  Epoch:  103	Loss: 0.8404	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:35:48 [INFO ]  Epoch:  104	Loss: 0.8172	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:35:50 [INFO ]  Epoch:  105	Loss: 0.8840	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:35:52 [INFO ]  Epoch:  106	Loss: 0.9527	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:53 [INFO ]  Epoch:  107	Loss: 0.8636	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:55 [INFO ]  Epoch:  108	Loss: 0.8851	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:35:57 [INFO ]  Epoch:  109	Loss: 0.8378	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:35:59 [INFO ]  Epoch:  110	Loss: 0.8862	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:36:01 [INFO ]  Epoch:  111	Loss: 0.8745	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:36:03 [INFO ]  Epoch:  112	Loss: 0.8372	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:36:05 [INFO ]  Epoch:  113	Loss: 0.8315	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:36:07 [INFO ]  Epoch:  114	Loss: 0.8333	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:36:08 [INFO ]  Epoch:  115	Loss: 0.8240	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:10 [INFO ]  Epoch:  116	Loss: 0.8574	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:36:12 [INFO ]  Epoch:  117	Loss: 0.8255	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:36:14 [INFO ]  Epoch:  118	Loss: 0.8764	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:36:16 [INFO ]  Epoch:  119	Loss: 0.8741	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:18 [INFO ]  Epoch:  120	Loss: 0.8596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:19 [INFO ]  Epoch:  121	Loss: 0.9586	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:21 [INFO ]  Epoch:  122	Loss: 0.8247	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:36:23 [INFO ]  Epoch:  123	Loss: 0.8724	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:25 [INFO ]  Epoch:  124	Loss: 0.8206	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:27 [INFO ]  Epoch:  125	Loss: 0.8440	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:36:28 [INFO ]  Epoch:  126	Loss: 0.9290	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:30 [INFO ]  Epoch:  127	Loss: 0.8385	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:32 [INFO ]  Epoch:  128	Loss: 0.8836	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:34 [INFO ]  Epoch:  129	Loss: 0.8576	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:36:36 [INFO ]  Epoch:  130	Loss: 0.8756	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:37 [INFO ]  Epoch:  131	Loss: 0.8591	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:36:39 [INFO ]  Epoch:  132	Loss: 0.9081	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:41 [INFO ]  Epoch:  133	Loss: 0.8185	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:43 [INFO ]  Epoch:  134	Loss: 0.8534	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:36:45 [INFO ]  Epoch:  135	Loss: 0.7927	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:36:47 [INFO ]  Epoch:  136	Loss: 0.8633	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:49 [INFO ]  Epoch:  137	Loss: 0.8599	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:36:50 [INFO ]  Epoch:  138	Loss: 1.0788	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:36:52 [INFO ]  Epoch:  139	Loss: 0.8822	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:36:54 [INFO ]  Epoch:  140	Loss: 0.8323	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:36:56 [INFO ]  Epoch:  141	Loss: 0.9414	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:36:58 [INFO ]  Epoch:  142	Loss: 0.9894	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:37:00 [INFO ]  Epoch:  143	Loss: 0.8338	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:02 [INFO ]  Epoch:  144	Loss: 0.8495	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:03 [INFO ]  Epoch:  145	Loss: 0.9361	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:37:05 [INFO ]  Epoch:  146	Loss: 0.8486	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:37:07 [INFO ]  Epoch:  147	Loss: 0.8541	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:37:09 [INFO ]  Epoch:  148	Loss: 0.9443	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:37:11 [INFO ]  Epoch:  149	Loss: 0.8705	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:37:13 [INFO ]  Epoch:  150	Loss: 0.8823	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 17:37:15 [INFO ]  Epoch:  151	Loss: 0.9447	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:17 [INFO ]  Epoch:  152	Loss: 0.8894	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:37:19 [INFO ]  Epoch:  153	Loss: 0.8315	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:37:20 [INFO ]  Epoch:  154	Loss: 0.8368	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:22 [INFO ]  Epoch:  155	Loss: 0.9181	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:24 [INFO ]  Epoch:  156	Loss: 0.9086	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:37:26 [INFO ]  Epoch:  157	Loss: 0.8938	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:28 [INFO ]  Epoch:  158	Loss: 0.9165	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:29 [INFO ]  Epoch:  159	Loss: 0.9325	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:37:31 [INFO ]  Epoch:  160	Loss: 0.9026	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:37:33 [INFO ]  Epoch:  161	Loss: 0.9425	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:37:35 [INFO ]  Epoch:  162	Loss: 0.9234	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:37 [INFO ]  Epoch:  163	Loss: 0.8340	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:37:39 [INFO ]  Epoch:  164	Loss: 0.8851	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:37:41 [INFO ]  Epoch:  165	Loss: 1.2291	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:43 [INFO ]  Epoch:  166	Loss: 1.0090	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:44 [INFO ]  Epoch:  167	Loss: 0.9252	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:46 [INFO ]  Epoch:  168	Loss: 0.9673	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:48 [INFO ]  Epoch:  169	Loss: 0.9372	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:37:50 [INFO ]  Epoch:  170	Loss: 0.9508	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:52 [INFO ]  Epoch:  171	Loss: 0.8768	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:54 [INFO ]  Epoch:  172	Loss: 0.9622	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:37:55 [INFO ]  Epoch:  173	Loss: 0.9209	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:37:57 [INFO ]  Epoch:  174	Loss: 0.9389	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:37:59 [INFO ]  Epoch:  175	Loss: 0.9695	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:01 [INFO ]  Epoch:  176	Loss: 1.0061	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:38:03 [INFO ]  Epoch:  177	Loss: 0.9162	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:38:05 [INFO ]  Epoch:  178	Loss: 0.9263	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:38:07 [INFO ]  Epoch:  179	Loss: 0.8420	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:38:09 [INFO ]  Epoch:  180	Loss: 0.8767	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:38:11 [INFO ]  Epoch:  181	Loss: 0.9140	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:38:12 [INFO ]  Epoch:  182	Loss: 0.9556	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:38:14 [INFO ]  Epoch:  183	Loss: 0.9151	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:38:16 [INFO ]  Epoch:  184	Loss: 0.9458	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:38:18 [INFO ]  Epoch:  185	Loss: 0.9134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:38:20 [INFO ]  Epoch:  186	Loss: 0.8254	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:38:22 [INFO ]  Epoch:  187	Loss: 0.9115	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:38:24 [INFO ]  Epoch:  188	Loss: 0.8533	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:38:26 [INFO ]  Epoch:  189	Loss: 0.8647	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:38:28 [INFO ]  Epoch:  190	Loss: 0.8413	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:38:29 [INFO ]  Epoch:  191	Loss: 0.8047	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:31 [INFO ]  Epoch:  192	Loss: 0.8813	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:33 [INFO ]  Epoch:  193	Loss: 0.8533	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:38:35 [INFO ]  Epoch:  194	Loss: 0.8190	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:37 [INFO ]  Epoch:  195	Loss: 0.8336	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:39 [INFO ]  Epoch:  196	Loss: 0.9332	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:38:41 [INFO ]  Epoch:  197	Loss: 0.9130	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:42 [INFO ]  Epoch:  198	Loss: 0.8879	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:38:44 [INFO ]  Epoch:  199	Loss: 0.8990	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:38:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:38:46 [INFO ]  
2022-10-04 17:38:46 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:38:49 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:38:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:38:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:38:49 [INFO ]  	   step  1 (lr=0.283297)                   72.93%                   0.9482
2022-10-04 17:38:49 [INFO ]  
2022-10-04 17:38:49 [INFO ]  
2022-10-04 17:38:49 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:38:52 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:38:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:38:52 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:38:52 [INFO ]  	   step  1 (lr=0.283297)                   17.58%                   4.1310
2022-10-04 17:38:52 [INFO ]  
2022-10-04 17:38:52 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 17:39:10 [INFO ]  ======================================== 2022-10-04 17:39:10 ========================================
2022-10-04 17:39:10 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:39:10 [INFO ]  Options: 
2022-10-04 17:39:10 [INFO ]  	base_dir: null
2022-10-04 17:39:10 [INFO ]  	batch_size: 1024
2022-10-04 17:39:10 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:39:10 [INFO ]  	dataset: SVHN
2022-10-04 17:39:10 [INFO ]  	dataset_labels:
2022-10-04 17:39:10 [INFO ]  	- 0
2022-10-04 17:39:10 [INFO ]  	- 1
2022-10-04 17:39:10 [INFO ]  	- 2
2022-10-04 17:39:10 [INFO ]  	- 3
2022-10-04 17:39:10 [INFO ]  	- 4
2022-10-04 17:39:10 [INFO ]  	- 5
2022-10-04 17:39:10 [INFO ]  	- 6
2022-10-04 17:39:10 [INFO ]  	- 7
2022-10-04 17:39:10 [INFO ]  	- 8
2022-10-04 17:39:10 [INFO ]  	- 9
2022-10-04 17:39:10 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:39:10 [INFO ]  	- !!python/tuple
2022-10-04 17:39:10 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:39:10 [INFO ]  	    - 0.44398033618927
2022-10-04 17:39:10 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:39:10 [INFO ]  	- !!python/tuple
2022-10-04 17:39:10 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:39:10 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:39:10 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:39:10 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:39:10 [INFO ]  	decay_epochs: 50
2022-10-04 17:39:10 [INFO ]  	decay_factor: 0.1
2022-10-04 17:39:10 [INFO ]  	device_id: 0
2022-10-04 17:39:10 [INFO ]  	distill_epochs: 1
2022-10-04 17:39:10 [INFO ]  	distill_lr: 0.02
2022-10-04 17:39:10 [INFO ]  	distill_steps: 1
2022-10-04 17:39:10 [INFO ]  	epochs: 200
2022-10-04 17:39:10 [INFO ]  	expand_cls: false
2022-10-04 17:39:10 [INFO ]  	forgetting_dataset: null
2022-10-04 17:39:10 [INFO ]  	init: xavier
2022-10-04 17:39:10 [INFO ]  	init_param: 1.0
2022-10-04 17:39:10 [INFO ]  	input_size: 32
2022-10-04 17:39:10 [INFO ]  	ipc: 5
2022-10-04 17:39:10 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:39:10 [INFO ]  	log_interval: 100
2022-10-04 17:39:10 [INFO ]  	log_level: INFO
2022-10-04 17:39:10 [INFO ]  	lr: 0.01
2022-10-04 17:39:10 [INFO ]  	mode: distill_adapt
2022-10-04 17:39:10 [INFO ]  	nc: 3
2022-10-04 17:39:10 [INFO ]  	num_classes: 10
2022-10-04 17:39:10 [INFO ]  	num_workers: 8
2022-10-04 17:39:10 [INFO ]  	phase: train
2022-10-04 17:39:10 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:39:10 [INFO ]  	start_time: '2022-10-04 17:39:10'
2022-10-04 17:39:10 [INFO ]  	test_batch_size: 1024
2022-10-04 17:39:10 [INFO ]  	
2022-10-04 17:39:12 [INFO ]  train dataset size:	73257
2022-10-04 17:39:12 [INFO ]  test dataset size: 	26032
2022-10-04 17:39:12 [INFO ]  datasets built!
2022-10-04 17:39:12 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:39:14 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:39:14 [INFO ]  
2022-10-04 17:39:14 [INFO ]  Begin of epoch 0 :
2022-10-04 17:39:17 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:39:17 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:39:17 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:39:17 [INFO ]  	   step  1 (lr=0.020000)                    6.79%                   9.8712
2022-10-04 17:39:17 [INFO ]  
2022-10-04 17:39:17 [INFO ]  Epoch:    0	Loss: 10.1722	Data Time: 0.42s	Train Time: 0.04s
2022-10-04 17:39:19 [INFO ]  Epoch:    1	Loss: 3.0112	Data Time: 0.13s	Train Time: 0.01s
2022-10-04 17:39:21 [INFO ]  Epoch:    2	Loss: 2.4756	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:22 [INFO ]  Epoch:    3	Loss: 2.3373	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:39:24 [INFO ]  Epoch:    4	Loss: 2.2708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:39:26 [INFO ]  Epoch:    5	Loss: 2.1962	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:39:27 [INFO ]  Epoch:    6	Loss: 2.1824	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:39:29 [INFO ]  Epoch:    7	Loss: 2.1592	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:31 [INFO ]  Epoch:    8	Loss: 2.1355	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:39:33 [INFO ]  Epoch:    9	Loss: 2.0783	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:35 [INFO ]  Epoch:   10	Loss: 1.9803	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:39:36 [INFO ]  Epoch:   11	Loss: 1.9230	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:38 [INFO ]  Epoch:   12	Loss: 1.8273	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:40 [INFO ]  Epoch:   13	Loss: 1.6599	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:39:42 [INFO ]  Epoch:   14	Loss: 1.6837	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:39:44 [INFO ]  Epoch:   15	Loss: 1.6859	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:39:46 [INFO ]  Epoch:   16	Loss: 1.4292	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:39:47 [INFO ]  Epoch:   17	Loss: 1.3224	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:39:49 [INFO ]  Epoch:   18	Loss: 1.3270	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:39:51 [INFO ]  Epoch:   19	Loss: 1.3199	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:39:53 [INFO ]  Epoch:   20	Loss: 1.2079	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:39:55 [INFO ]  Epoch:   21	Loss: 1.2410	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:39:57 [INFO ]  Epoch:   22	Loss: 1.2923	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:39:58 [INFO ]  Epoch:   23	Loss: 1.2541	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:00 [INFO ]  Epoch:   24	Loss: 1.1336	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:02 [INFO ]  Epoch:   25	Loss: 1.1424	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:04 [INFO ]  Epoch:   26	Loss: 1.0222	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:40:06 [INFO ]  Epoch:   27	Loss: 1.0911	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:40:07 [INFO ]  Epoch:   28	Loss: 1.1005	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:40:09 [INFO ]  Epoch:   29	Loss: 1.1134	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:11 [INFO ]  Epoch:   30	Loss: 0.9389	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:13 [INFO ]  Epoch:   31	Loss: 0.9808	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:14 [INFO ]  Epoch:   32	Loss: 0.9071	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:40:16 [INFO ]  Epoch:   33	Loss: 1.0479	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:18 [INFO ]  Epoch:   34	Loss: 0.9700	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:20 [INFO ]  Epoch:   35	Loss: 0.9002	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:40:22 [INFO ]  Epoch:   36	Loss: 0.8961	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:24 [INFO ]  Epoch:   37	Loss: 1.0871	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:26 [INFO ]  Epoch:   38	Loss: 0.8599	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:40:28 [INFO ]  Epoch:   39	Loss: 1.0016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:29 [INFO ]  Epoch:   40	Loss: 0.8908	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:31 [INFO ]  Epoch:   41	Loss: 0.8805	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:33 [INFO ]  Epoch:   42	Loss: 0.9386	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:35 [INFO ]  Epoch:   43	Loss: 0.8397	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:40:37 [INFO ]  Epoch:   44	Loss: 0.8258	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:39 [INFO ]  Epoch:   45	Loss: 0.8733	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:40 [INFO ]  Epoch:   46	Loss: 0.8914	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:42 [INFO ]  Epoch:   47	Loss: 0.8522	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:40:44 [INFO ]  Epoch:   48	Loss: 0.8498	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:40:46 [INFO ]  Epoch:   49	Loss: 0.8423	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:40:48 [INFO ]  Epoch:   50	Loss: 0.6822	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:49 [INFO ]  Epoch:   51	Loss: 0.7940	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:51 [INFO ]  Epoch:   52	Loss: 0.7888	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:53 [INFO ]  Epoch:   53	Loss: 0.6969	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:40:55 [INFO ]  Epoch:   54	Loss: 0.8006	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:40:57 [INFO ]  Epoch:   55	Loss: 0.7301	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:40:59 [INFO ]  Epoch:   56	Loss: 0.7186	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:41:01 [INFO ]  Epoch:   57	Loss: 0.6576	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:03 [INFO ]  Epoch:   58	Loss: 0.6692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:04 [INFO ]  Epoch:   59	Loss: 0.7529	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:06 [INFO ]  Epoch:   60	Loss: 0.7790	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:08 [INFO ]  Epoch:   61	Loss: 0.7463	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:10 [INFO ]  Epoch:   62	Loss: 0.7949	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:12 [INFO ]  Epoch:   63	Loss: 0.7709	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:41:14 [INFO ]  Epoch:   64	Loss: 0.6812	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:15 [INFO ]  Epoch:   65	Loss: 0.7512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:17 [INFO ]  Epoch:   66	Loss: 0.7306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:19 [INFO ]  Epoch:   67	Loss: 0.6995	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:21 [INFO ]  Epoch:   68	Loss: 0.6806	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:41:23 [INFO ]  Epoch:   69	Loss: 0.6730	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:25 [INFO ]  Epoch:   70	Loss: 0.8317	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:41:27 [INFO ]  Epoch:   71	Loss: 0.7089	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:28 [INFO ]  Epoch:   72	Loss: 0.8157	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:30 [INFO ]  Epoch:   73	Loss: 0.7056	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:41:32 [INFO ]  Epoch:   74	Loss: 0.6529	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:41:34 [INFO ]  Epoch:   75	Loss: 0.6657	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:36 [INFO ]  Epoch:   76	Loss: 0.7614	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:38 [INFO ]  Epoch:   77	Loss: 0.8514	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:39 [INFO ]  Epoch:   78	Loss: 0.7206	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:41:41 [INFO ]  Epoch:   79	Loss: 0.7608	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:41:43 [INFO ]  Epoch:   80	Loss: 0.7413	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:41:45 [INFO ]  Epoch:   81	Loss: 0.7023	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:47 [INFO ]  Epoch:   82	Loss: 0.7706	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:41:49 [INFO ]  Epoch:   83	Loss: 0.6784	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:41:51 [INFO ]  Epoch:   84	Loss: 0.6759	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:41:52 [INFO ]  Epoch:   85	Loss: 0.8095	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:54 [INFO ]  Epoch:   86	Loss: 0.6215	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:41:56 [INFO ]  Epoch:   87	Loss: 0.7105	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:41:58 [INFO ]  Epoch:   88	Loss: 0.6554	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:42:00 [INFO ]  Epoch:   89	Loss: 0.6847	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:42:01 [INFO ]  Epoch:   90	Loss: 0.6570	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:42:03 [INFO ]  Epoch:   91	Loss: 0.6613	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:42:05 [INFO ]  Epoch:   92	Loss: 0.6370	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:42:07 [INFO ]  Epoch:   93	Loss: 0.6597	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:09 [INFO ]  Epoch:   94	Loss: 0.6322	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:42:10 [INFO ]  Epoch:   95	Loss: 0.6562	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:12 [INFO ]  Epoch:   96	Loss: 0.7383	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:42:14 [INFO ]  Epoch:   97	Loss: 0.7557	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:42:16 [INFO ]  Epoch:   98	Loss: 0.6199	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:42:17 [INFO ]  Epoch:   99	Loss: 0.6478	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:19 [INFO ]  Epoch:  100	Loss: 0.6722	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:21 [INFO ]  Epoch:  101	Loss: 0.6112	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:42:23 [INFO ]  Epoch:  102	Loss: 0.6659	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:42:25 [INFO ]  Epoch:  103	Loss: 0.6785	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:42:27 [INFO ]  Epoch:  104	Loss: 0.6622	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:42:29 [INFO ]  Epoch:  105	Loss: 0.6460	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:42:31 [INFO ]  Epoch:  106	Loss: 0.6888	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:42:33 [INFO ]  Epoch:  107	Loss: 0.6351	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:42:35 [INFO ]  Epoch:  108	Loss: 0.6422	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:42:37 [INFO ]  Epoch:  109	Loss: 0.7084	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:42:39 [INFO ]  Epoch:  110	Loss: 0.6346	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:42:41 [INFO ]  Epoch:  111	Loss: 0.6070	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:42:43 [INFO ]  Epoch:  112	Loss: 0.6693	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:42:45 [INFO ]  Epoch:  113	Loss: 0.6575	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:42:47 [INFO ]  Epoch:  114	Loss: 0.6596	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:42:49 [INFO ]  Epoch:  115	Loss: 0.6543	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:42:50 [INFO ]  Epoch:  116	Loss: 0.6823	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:52 [INFO ]  Epoch:  117	Loss: 0.6907	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:54 [INFO ]  Epoch:  118	Loss: 0.6806	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:42:56 [INFO ]  Epoch:  119	Loss: 0.6928	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:42:58 [INFO ]  Epoch:  120	Loss: 0.7256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:00 [INFO ]  Epoch:  121	Loss: 0.7219	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:43:02 [INFO ]  Epoch:  122	Loss: 0.6510	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:03 [INFO ]  Epoch:  123	Loss: 0.6148	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:05 [INFO ]  Epoch:  124	Loss: 0.6426	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:07 [INFO ]  Epoch:  125	Loss: 0.7041	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:09 [INFO ]  Epoch:  126	Loss: 0.6445	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:43:11 [INFO ]  Epoch:  127	Loss: 0.6618	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:13 [INFO ]  Epoch:  128	Loss: 0.7195	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:15 [INFO ]  Epoch:  129	Loss: 0.6703	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:17 [INFO ]  Epoch:  130	Loss: 0.7190	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:43:18 [INFO ]  Epoch:  131	Loss: 0.7164	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:43:20 [INFO ]  Epoch:  132	Loss: 0.6770	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:22 [INFO ]  Epoch:  133	Loss: 0.6456	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:24 [INFO ]  Epoch:  134	Loss: 0.6560	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:26 [INFO ]  Epoch:  135	Loss: 0.7217	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:28 [INFO ]  Epoch:  136	Loss: 0.7015	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:43:30 [INFO ]  Epoch:  137	Loss: 0.6325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:32 [INFO ]  Epoch:  138	Loss: 0.7053	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:43:33 [INFO ]  Epoch:  139	Loss: 0.7050	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:35 [INFO ]  Epoch:  140	Loss: 0.6456	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:37 [INFO ]  Epoch:  141	Loss: 0.6721	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:39 [INFO ]  Epoch:  142	Loss: 0.7176	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:41 [INFO ]  Epoch:  143	Loss: 0.7465	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:43 [INFO ]  Epoch:  144	Loss: 0.6537	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:45 [INFO ]  Epoch:  145	Loss: 0.7033	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:47 [INFO ]  Epoch:  146	Loss: 0.5674	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:49 [INFO ]  Epoch:  147	Loss: 0.6433	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:43:50 [INFO ]  Epoch:  148	Loss: 0.6150	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:43:52 [INFO ]  Epoch:  149	Loss: 0.6224	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:43:54 [INFO ]  Epoch:  150	Loss: 0.5972	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:43:56 [INFO ]  Epoch:  151	Loss: 0.6346	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:43:58 [INFO ]  Epoch:  152	Loss: 0.6188	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:43:59 [INFO ]  Epoch:  153	Loss: 0.6729	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:01 [INFO ]  Epoch:  154	Loss: 0.6428	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:03 [INFO ]  Epoch:  155	Loss: 0.7186	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:05 [INFO ]  Epoch:  156	Loss: 0.7059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:07 [INFO ]  Epoch:  157	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:09 [INFO ]  Epoch:  158	Loss: 0.6855	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:11 [INFO ]  Epoch:  159	Loss: 0.6366	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:44:12 [INFO ]  Epoch:  160	Loss: 0.6666	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:14 [INFO ]  Epoch:  161	Loss: 0.6915	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:44:16 [INFO ]  Epoch:  162	Loss: 0.6225	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:44:18 [INFO ]  Epoch:  163	Loss: 0.7395	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:44:20 [INFO ]  Epoch:  164	Loss: 0.7121	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:22 [INFO ]  Epoch:  165	Loss: 0.6523	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:24 [INFO ]  Epoch:  166	Loss: 0.6959	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:26 [INFO ]  Epoch:  167	Loss: 0.6694	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:44:28 [INFO ]  Epoch:  168	Loss: 0.6408	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:30 [INFO ]  Epoch:  169	Loss: 0.6763	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:31 [INFO ]  Epoch:  170	Loss: 0.6871	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:44:33 [INFO ]  Epoch:  171	Loss: 0.6233	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:44:35 [INFO ]  Epoch:  172	Loss: 0.7237	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:44:37 [INFO ]  Epoch:  173	Loss: 0.7395	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:44:39 [INFO ]  Epoch:  174	Loss: 0.7043	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:41 [INFO ]  Epoch:  175	Loss: 0.7156	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:44:43 [INFO ]  Epoch:  176	Loss: 0.6653	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:44:45 [INFO ]  Epoch:  177	Loss: 0.7358	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:44:47 [INFO ]  Epoch:  178	Loss: 0.6321	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:44:49 [INFO ]  Epoch:  179	Loss: 0.5484	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:44:50 [INFO ]  Epoch:  180	Loss: 0.7134	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:44:52 [INFO ]  Epoch:  181	Loss: 0.6412	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:44:54 [INFO ]  Epoch:  182	Loss: 0.7309	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:44:56 [INFO ]  Epoch:  183	Loss: 0.6492	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:44:58 [INFO ]  Epoch:  184	Loss: 0.6339	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:00 [INFO ]  Epoch:  185	Loss: 0.6423	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:02 [INFO ]  Epoch:  186	Loss: 0.6857	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:04 [INFO ]  Epoch:  187	Loss: 0.7029	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:05 [INFO ]  Epoch:  188	Loss: 0.6296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:07 [INFO ]  Epoch:  189	Loss: 0.6503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:09 [INFO ]  Epoch:  190	Loss: 0.6337	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:11 [INFO ]  Epoch:  191	Loss: 0.7360	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:45:13 [INFO ]  Epoch:  192	Loss: 0.6688	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:45:15 [INFO ]  Epoch:  193	Loss: 0.6461	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:45:17 [INFO ]  Epoch:  194	Loss: 0.6514	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 17:45:19 [INFO ]  Epoch:  195	Loss: 0.6536	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:45:21 [INFO ]  Epoch:  196	Loss: 0.6949	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:45:22 [INFO ]  Epoch:  197	Loss: 0.6490	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:45:24 [INFO ]  Epoch:  198	Loss: 0.6245	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:45:26 [INFO ]  Epoch:  199	Loss: 0.6272	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:45:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 17:45:27 [INFO ]  
2022-10-04 17:45:27 [INFO ]  Final evaluation for SVHN :
2022-10-04 17:45:30 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:45:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:45:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:45:30 [INFO ]  	   step  1 (lr=0.361303)                   80.06%                   0.7357
2022-10-04 17:45:30 [INFO ]  
2022-10-04 17:45:30 [INFO ]  
2022-10-04 17:45:30 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 17:45:33 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:45:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:45:33 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 17:45:33 [INFO ]  	   step  1 (lr=0.361303)                   18.00%                   4.7876
2022-10-04 17:45:33 [INFO ]  
2022-10-04 17:45:33 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 17:58:04 [INFO ]  ======================================== 2022-10-04 17:58:04 ========================================
2022-10-04 17:58:04 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 17:58:04 [INFO ]  Options: 
2022-10-04 17:58:04 [INFO ]  	base_dir: null
2022-10-04 17:58:04 [INFO ]  	batch_size: 1024
2022-10-04 17:58:04 [INFO ]  	checkpoint_interval: 300
2022-10-04 17:58:04 [INFO ]  	dataset: SVHN
2022-10-04 17:58:04 [INFO ]  	dataset_labels:
2022-10-04 17:58:04 [INFO ]  	- 0
2022-10-04 17:58:04 [INFO ]  	- 1
2022-10-04 17:58:04 [INFO ]  	- 2
2022-10-04 17:58:04 [INFO ]  	- 3
2022-10-04 17:58:04 [INFO ]  	- 4
2022-10-04 17:58:04 [INFO ]  	- 5
2022-10-04 17:58:04 [INFO ]  	- 6
2022-10-04 17:58:04 [INFO ]  	- 7
2022-10-04 17:58:04 [INFO ]  	- 8
2022-10-04 17:58:04 [INFO ]  	- 9
2022-10-04 17:58:04 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 17:58:04 [INFO ]  	- !!python/tuple
2022-10-04 17:58:04 [INFO ]  	    - 0.4379104971885681
2022-10-04 17:58:04 [INFO ]  	    - 0.44398033618927
2022-10-04 17:58:04 [INFO ]  	    - 0.4729299545288086
2022-10-04 17:58:04 [INFO ]  	- !!python/tuple
2022-10-04 17:58:04 [INFO ]  	    - 0.19803012907505035
2022-10-04 17:58:04 [INFO ]  	    - 0.2010156363248825
2022-10-04 17:58:04 [INFO ]  	    - 0.19703614711761475
2022-10-04 17:58:04 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 17:58:04 [INFO ]  	decay_epochs: 50
2022-10-04 17:58:04 [INFO ]  	decay_factor: 0.1
2022-10-04 17:58:04 [INFO ]  	device_id: 0
2022-10-04 17:58:04 [INFO ]  	distill_epochs: 1
2022-10-04 17:58:04 [INFO ]  	distill_lr: 0.02
2022-10-04 17:58:04 [INFO ]  	distill_steps: 1
2022-10-04 17:58:04 [INFO ]  	epochs: 200
2022-10-04 17:58:04 [INFO ]  	expand_cls: false
2022-10-04 17:58:04 [INFO ]  	forgetting_dataset: null
2022-10-04 17:58:04 [INFO ]  	init: xavier
2022-10-04 17:58:04 [INFO ]  	init_param: 1.0
2022-10-04 17:58:04 [INFO ]  	input_size: 32
2022-10-04 17:58:04 [INFO ]  	ipc: 5
2022-10-04 17:58:04 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 17:58:04 [INFO ]  	log_interval: 100
2022-10-04 17:58:04 [INFO ]  	log_level: INFO
2022-10-04 17:58:04 [INFO ]  	lr: 0.01
2022-10-04 17:58:04 [INFO ]  	mode: distill_adapt
2022-10-04 17:58:04 [INFO ]  	nc: 3
2022-10-04 17:58:04 [INFO ]  	num_classes: 10
2022-10-04 17:58:04 [INFO ]  	num_workers: 8
2022-10-04 17:58:04 [INFO ]  	phase: train
2022-10-04 17:58:04 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 17:58:04 [INFO ]  	start_time: '2022-10-04 17:58:04'
2022-10-04 17:58:04 [INFO ]  	test_batch_size: 1024
2022-10-04 17:58:04 [INFO ]  	
2022-10-04 17:58:06 [INFO ]  train dataset size:	73257
2022-10-04 17:58:06 [INFO ]  test dataset size: 	26032
2022-10-04 17:58:06 [INFO ]  datasets built!
2022-10-04 17:58:06 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 17:58:07 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 17:58:07 [INFO ]  
2022-10-04 17:58:07 [INFO ]  Begin of epoch 0 :
2022-10-04 17:58:11 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 17:58:11 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 17:58:11 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 17:58:11 [INFO ]  	   step  1 (lr=0.020000)                    6.94%                   8.6476
2022-10-04 17:58:11 [INFO ]  
2022-10-04 17:58:11 [INFO ]  Epoch:    0	Loss: 8.5121	Data Time: 0.38s	Train Time: 0.04s
2022-10-04 17:58:12 [INFO ]  Epoch:    1	Loss: 2.9625	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 17:58:14 [INFO ]  Epoch:    2	Loss: 2.5112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:16 [INFO ]  Epoch:    3	Loss: 2.2857	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:58:18 [INFO ]  Epoch:    4	Loss: 2.2286	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:58:20 [INFO ]  Epoch:    5	Loss: 2.1961	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:58:21 [INFO ]  Epoch:    6	Loss: 2.1691	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:58:23 [INFO ]  Epoch:    7	Loss: 2.1429	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:25 [INFO ]  Epoch:    8	Loss: 2.0675	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:27 [INFO ]  Epoch:    9	Loss: 2.0196	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:28 [INFO ]  Epoch:   10	Loss: 1.9418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:30 [INFO ]  Epoch:   11	Loss: 1.8724	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:58:32 [INFO ]  Epoch:   12	Loss: 1.6786	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:34 [INFO ]  Epoch:   13	Loss: 1.6469	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:58:36 [INFO ]  Epoch:   14	Loss: 1.5741	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:58:38 [INFO ]  Epoch:   15	Loss: 1.4582	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:58:40 [INFO ]  Epoch:   16	Loss: 1.5616	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:58:41 [INFO ]  Epoch:   17	Loss: 1.4790	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:58:43 [INFO ]  Epoch:   18	Loss: 1.3808	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 17:58:45 [INFO ]  Epoch:   19	Loss: 1.2350	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:58:47 [INFO ]  Epoch:   20	Loss: 1.1740	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:58:49 [INFO ]  Epoch:   21	Loss: 1.2460	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:58:50 [INFO ]  Epoch:   22	Loss: 1.1440	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:58:52 [INFO ]  Epoch:   23	Loss: 1.1241	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 17:58:54 [INFO ]  Epoch:   24	Loss: 1.1162	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:58:56 [INFO ]  Epoch:   25	Loss: 1.3374	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:58:58 [INFO ]  Epoch:   26	Loss: 1.0344	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:00 [INFO ]  Epoch:   27	Loss: 0.9664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:02 [INFO ]  Epoch:   28	Loss: 0.8983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:03 [INFO ]  Epoch:   29	Loss: 1.0096	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:05 [INFO ]  Epoch:   30	Loss: 0.9843	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:07 [INFO ]  Epoch:   31	Loss: 0.9299	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:09 [INFO ]  Epoch:   32	Loss: 0.9641	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:11 [INFO ]  Epoch:   33	Loss: 0.9299	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:13 [INFO ]  Epoch:   34	Loss: 1.0951	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:15 [INFO ]  Epoch:   35	Loss: 0.9356	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 17:59:17 [INFO ]  Epoch:   36	Loss: 0.8679	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:59:18 [INFO ]  Epoch:   37	Loss: 0.8190	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:20 [INFO ]  Epoch:   38	Loss: 0.9133	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:59:22 [INFO ]  Epoch:   39	Loss: 0.8865	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:24 [INFO ]  Epoch:   40	Loss: 0.9076	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:26 [INFO ]  Epoch:   41	Loss: 0.9236	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 17:59:27 [INFO ]  Epoch:   42	Loss: 0.7995	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:29 [INFO ]  Epoch:   43	Loss: 0.8702	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:31 [INFO ]  Epoch:   44	Loss: 0.8360	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:33 [INFO ]  Epoch:   45	Loss: 0.9015	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:59:35 [INFO ]  Epoch:   46	Loss: 0.8884	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:36 [INFO ]  Epoch:   47	Loss: 0.8897	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:59:38 [INFO ]  Epoch:   48	Loss: 0.8690	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:59:40 [INFO ]  Epoch:   49	Loss: 0.8132	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:42 [INFO ]  Epoch:   50	Loss: 0.7471	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:59:44 [INFO ]  Epoch:   51	Loss: 0.7978	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 17:59:46 [INFO ]  Epoch:   52	Loss: 0.7155	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 17:59:48 [INFO ]  Epoch:   53	Loss: 0.7874	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 17:59:49 [INFO ]  Epoch:   54	Loss: 0.8211	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 17:59:51 [INFO ]  Epoch:   55	Loss: 0.7870	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:53 [INFO ]  Epoch:   56	Loss: 0.8163	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 17:59:55 [INFO ]  Epoch:   57	Loss: 0.7467	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 17:59:56 [INFO ]  Epoch:   58	Loss: 0.7558	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 17:59:59 [INFO ]  Epoch:   59	Loss: 0.7676	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:00:00 [INFO ]  Epoch:   60	Loss: 0.7627	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:00:02 [INFO ]  Epoch:   61	Loss: 0.7954	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:04 [INFO ]  Epoch:   62	Loss: 0.7694	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:00:06 [INFO ]  Epoch:   63	Loss: 0.7769	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:08 [INFO ]  Epoch:   64	Loss: 0.7569	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:09 [INFO ]  Epoch:   65	Loss: 0.6644	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:00:11 [INFO ]  Epoch:   66	Loss: 0.7783	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:13 [INFO ]  Epoch:   67	Loss: 0.9014	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:15 [INFO ]  Epoch:   68	Loss: 0.8941	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:17 [INFO ]  Epoch:   69	Loss: 0.6904	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:00:18 [INFO ]  Epoch:   70	Loss: 0.7756	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:20 [INFO ]  Epoch:   71	Loss: 0.7740	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:00:22 [INFO ]  Epoch:   72	Loss: 0.8398	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:00:24 [INFO ]  Epoch:   73	Loss: 0.6832	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:00:26 [INFO ]  Epoch:   74	Loss: 0.7921	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:00:27 [INFO ]  Epoch:   75	Loss: 0.7517	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:30 [INFO ]  Epoch:   76	Loss: 0.7282	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:31 [INFO ]  Epoch:   77	Loss: 0.7829	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:33 [INFO ]  Epoch:   78	Loss: 0.7549	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:35 [INFO ]  Epoch:   79	Loss: 0.7636	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:00:37 [INFO ]  Epoch:   80	Loss: 0.6909	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:39 [INFO ]  Epoch:   81	Loss: 0.7556	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:41 [INFO ]  Epoch:   82	Loss: 0.7712	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:00:43 [INFO ]  Epoch:   83	Loss: 0.7791	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:00:44 [INFO ]  Epoch:   84	Loss: 0.7366	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:46 [INFO ]  Epoch:   85	Loss: 0.7936	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:48 [INFO ]  Epoch:   86	Loss: 0.7446	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:50 [INFO ]  Epoch:   87	Loss: 0.6863	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:52 [INFO ]  Epoch:   88	Loss: 0.8154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:54 [INFO ]  Epoch:   89	Loss: 0.7168	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:00:55 [INFO ]  Epoch:   90	Loss: 0.8083	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:00:57 [INFO ]  Epoch:   91	Loss: 0.7565	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:00:59 [INFO ]  Epoch:   92	Loss: 0.7702	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:01 [INFO ]  Epoch:   93	Loss: 0.8145	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:01:03 [INFO ]  Epoch:   94	Loss: 0.7902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:05 [INFO ]  Epoch:   95	Loss: 0.8194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:07 [INFO ]  Epoch:   96	Loss: 0.7046	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:09 [INFO ]  Epoch:   97	Loss: 0.8536	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:01:10 [INFO ]  Epoch:   98	Loss: 0.8086	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:12 [INFO ]  Epoch:   99	Loss: 0.7770	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:01:14 [INFO ]  Epoch:  100	Loss: 0.7527	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:01:16 [INFO ]  Epoch:  101	Loss: 0.7551	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:18 [INFO ]  Epoch:  102	Loss: 0.7074	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:01:20 [INFO ]  Epoch:  103	Loss: 0.6897	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:01:22 [INFO ]  Epoch:  104	Loss: 0.8310	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:23 [INFO ]  Epoch:  105	Loss: 0.7627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:25 [INFO ]  Epoch:  106	Loss: 0.7914	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:27 [INFO ]  Epoch:  107	Loss: 0.6867	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:01:29 [INFO ]  Epoch:  108	Loss: 0.6833	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:01:31 [INFO ]  Epoch:  109	Loss: 0.7187	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:01:33 [INFO ]  Epoch:  110	Loss: 0.7037	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:01:34 [INFO ]  Epoch:  111	Loss: 0.6944	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:36 [INFO ]  Epoch:  112	Loss: 0.7821	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:38 [INFO ]  Epoch:  113	Loss: 0.6540	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:01:40 [INFO ]  Epoch:  114	Loss: 0.8668	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:01:42 [INFO ]  Epoch:  115	Loss: 0.7051	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:01:44 [INFO ]  Epoch:  116	Loss: 0.7406	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:46 [INFO ]  Epoch:  117	Loss: 0.8127	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:01:47 [INFO ]  Epoch:  118	Loss: 0.6952	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:01:49 [INFO ]  Epoch:  119	Loss: 0.6504	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:51 [INFO ]  Epoch:  120	Loss: 0.7043	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:53 [INFO ]  Epoch:  121	Loss: 0.6828	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:01:55 [INFO ]  Epoch:  122	Loss: 0.8100	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:01:56 [INFO ]  Epoch:  123	Loss: 0.7306	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:01:58 [INFO ]  Epoch:  124	Loss: 0.7338	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:02:00 [INFO ]  Epoch:  125	Loss: 0.7347	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:02:02 [INFO ]  Epoch:  126	Loss: 0.6471	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:02:04 [INFO ]  Epoch:  127	Loss: 0.7070	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:02:05 [INFO ]  Epoch:  128	Loss: 0.7701	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:07 [INFO ]  Epoch:  129	Loss: 0.7079	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:09 [INFO ]  Epoch:  130	Loss: 0.7866	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:02:11 [INFO ]  Epoch:  131	Loss: 0.7451	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:02:13 [INFO ]  Epoch:  132	Loss: 0.6902	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:02:15 [INFO ]  Epoch:  133	Loss: 0.8415	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:17 [INFO ]  Epoch:  134	Loss: 0.7209	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:02:18 [INFO ]  Epoch:  135	Loss: 0.7277	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:02:20 [INFO ]  Epoch:  136	Loss: 0.7272	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:22 [INFO ]  Epoch:  137	Loss: 0.6844	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:02:24 [INFO ]  Epoch:  138	Loss: 0.7269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:26 [INFO ]  Epoch:  139	Loss: 0.7419	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:02:27 [INFO ]  Epoch:  140	Loss: 0.7117	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:02:29 [INFO ]  Epoch:  141	Loss: 0.7608	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:02:31 [INFO ]  Epoch:  142	Loss: 0.7226	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:02:33 [INFO ]  Epoch:  143	Loss: 0.6744	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:35 [INFO ]  Epoch:  144	Loss: 0.7897	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:02:37 [INFO ]  Epoch:  145	Loss: 0.7516	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:38 [INFO ]  Epoch:  146	Loss: 0.6776	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:02:40 [INFO ]  Epoch:  147	Loss: 0.6672	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:42 [INFO ]  Epoch:  148	Loss: 0.7207	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:02:44 [INFO ]  Epoch:  149	Loss: 0.7767	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:02:46 [INFO ]  Epoch:  150	Loss: 0.7279	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:02:47 [INFO ]  Epoch:  151	Loss: 0.6432	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:02:49 [INFO ]  Epoch:  152	Loss: 0.6513	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:02:51 [INFO ]  Epoch:  153	Loss: 0.7390	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:02:53 [INFO ]  Epoch:  154	Loss: 0.6711	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:02:55 [INFO ]  Epoch:  155	Loss: 0.6963	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:02:57 [INFO ]  Epoch:  156	Loss: 0.6634	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:02:59 [INFO ]  Epoch:  157	Loss: 0.6531	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:03:01 [INFO ]  Epoch:  158	Loss: 0.6567	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:03:03 [INFO ]  Epoch:  159	Loss: 0.6982	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:04 [INFO ]  Epoch:  160	Loss: 0.7155	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:06 [INFO ]  Epoch:  161	Loss: 0.7242	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:08 [INFO ]  Epoch:  162	Loss: 0.6626	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:10 [INFO ]  Epoch:  163	Loss: 0.7235	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:03:12 [INFO ]  Epoch:  164	Loss: 0.6627	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:03:14 [INFO ]  Epoch:  165	Loss: 0.6925	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:16 [INFO ]  Epoch:  166	Loss: 0.6759	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:17 [INFO ]  Epoch:  167	Loss: 0.7703	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:19 [INFO ]  Epoch:  168	Loss: 0.7564	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:21 [INFO ]  Epoch:  169	Loss: 0.6180	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:23 [INFO ]  Epoch:  170	Loss: 0.8010	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:25 [INFO ]  Epoch:  171	Loss: 0.7623	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:27 [INFO ]  Epoch:  172	Loss: 0.7911	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:03:29 [INFO ]  Epoch:  173	Loss: 0.6816	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:31 [INFO ]  Epoch:  174	Loss: 0.8835	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:03:33 [INFO ]  Epoch:  175	Loss: 0.7698	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:03:34 [INFO ]  Epoch:  176	Loss: 0.7273	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:36 [INFO ]  Epoch:  177	Loss: 0.7016	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:03:38 [INFO ]  Epoch:  178	Loss: 0.8075	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:03:40 [INFO ]  Epoch:  179	Loss: 0.7377	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:03:42 [INFO ]  Epoch:  180	Loss: 0.7983	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:44 [INFO ]  Epoch:  181	Loss: 0.6929	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:45 [INFO ]  Epoch:  182	Loss: 0.6862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:47 [INFO ]  Epoch:  183	Loss: 0.6711	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:49 [INFO ]  Epoch:  184	Loss: 0.6657	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:03:51 [INFO ]  Epoch:  185	Loss: 0.6582	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:03:53 [INFO ]  Epoch:  186	Loss: 0.7137	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:03:54 [INFO ]  Epoch:  187	Loss: 0.6200	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:03:56 [INFO ]  Epoch:  188	Loss: 0.7435	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:03:58 [INFO ]  Epoch:  189	Loss: 0.8425	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:04:00 [INFO ]  Epoch:  190	Loss: 0.6596	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:04:02 [INFO ]  Epoch:  191	Loss: 0.7536	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:04:04 [INFO ]  Epoch:  192	Loss: 0.8139	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:04:05 [INFO ]  Epoch:  193	Loss: 0.7073	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:08 [INFO ]  Epoch:  194	Loss: 0.7506	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:09 [INFO ]  Epoch:  195	Loss: 0.8231	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:11 [INFO ]  Epoch:  196	Loss: 0.7026	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:04:13 [INFO ]  Epoch:  197	Loss: 0.7887	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:04:15 [INFO ]  Epoch:  198	Loss: 0.7163	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:17 [INFO ]  Epoch:  199	Loss: 0.7265	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:04:18 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:04:18 [INFO ]  
2022-10-04 18:04:18 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:04:22 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:04:22 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:04:22 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:04:22 [INFO ]  	   step  1 (lr=0.318298)                   78.05%                   0.8120
2022-10-04 18:04:22 [INFO ]  
2022-10-04 18:04:22 [INFO ]  
2022-10-04 18:04:22 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:04:25 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:04:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:04:25 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:04:25 [INFO ]  	   step  1 (lr=0.318298)                   18.93%                   5.3453
2022-10-04 18:04:25 [INFO ]  
2022-10-04 18:04:25 [INFO ]  CPU Time: 3.47 minutes
2022-10-04 18:04:31 [INFO ]  ======================================== 2022-10-04 18:04:31 ========================================
2022-10-04 18:04:31 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:04:31 [INFO ]  Options: 
2022-10-04 18:04:31 [INFO ]  	base_dir: null
2022-10-04 18:04:31 [INFO ]  	batch_size: 1024
2022-10-04 18:04:31 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:04:31 [INFO ]  	dataset: SVHN
2022-10-04 18:04:31 [INFO ]  	dataset_labels:
2022-10-04 18:04:31 [INFO ]  	- 0
2022-10-04 18:04:31 [INFO ]  	- 1
2022-10-04 18:04:31 [INFO ]  	- 2
2022-10-04 18:04:31 [INFO ]  	- 3
2022-10-04 18:04:31 [INFO ]  	- 4
2022-10-04 18:04:31 [INFO ]  	- 5
2022-10-04 18:04:31 [INFO ]  	- 6
2022-10-04 18:04:31 [INFO ]  	- 7
2022-10-04 18:04:31 [INFO ]  	- 8
2022-10-04 18:04:31 [INFO ]  	- 9
2022-10-04 18:04:31 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:04:31 [INFO ]  	- !!python/tuple
2022-10-04 18:04:31 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:04:31 [INFO ]  	    - 0.44398033618927
2022-10-04 18:04:31 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:04:31 [INFO ]  	- !!python/tuple
2022-10-04 18:04:31 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:04:31 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:04:31 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:04:31 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:04:31 [INFO ]  	decay_epochs: 50
2022-10-04 18:04:31 [INFO ]  	decay_factor: 0.1
2022-10-04 18:04:31 [INFO ]  	device_id: 0
2022-10-04 18:04:31 [INFO ]  	distill_epochs: 1
2022-10-04 18:04:31 [INFO ]  	distill_lr: 0.02
2022-10-04 18:04:31 [INFO ]  	distill_steps: 1
2022-10-04 18:04:31 [INFO ]  	epochs: 200
2022-10-04 18:04:31 [INFO ]  	expand_cls: false
2022-10-04 18:04:31 [INFO ]  	forgetting_dataset: null
2022-10-04 18:04:31 [INFO ]  	init: xavier
2022-10-04 18:04:31 [INFO ]  	init_param: 1.0
2022-10-04 18:04:31 [INFO ]  	input_size: 32
2022-10-04 18:04:31 [INFO ]  	ipc: 5
2022-10-04 18:04:31 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:04:31 [INFO ]  	log_interval: 100
2022-10-04 18:04:31 [INFO ]  	log_level: INFO
2022-10-04 18:04:31 [INFO ]  	lr: 0.01
2022-10-04 18:04:31 [INFO ]  	mode: distill_adapt
2022-10-04 18:04:31 [INFO ]  	nc: 3
2022-10-04 18:04:31 [INFO ]  	num_classes: 10
2022-10-04 18:04:31 [INFO ]  	num_workers: 8
2022-10-04 18:04:31 [INFO ]  	phase: train
2022-10-04 18:04:31 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:04:31 [INFO ]  	start_time: '2022-10-04 18:04:31'
2022-10-04 18:04:31 [INFO ]  	test_batch_size: 1024
2022-10-04 18:04:31 [INFO ]  	
2022-10-04 18:04:34 [INFO ]  train dataset size:	73257
2022-10-04 18:04:34 [INFO ]  test dataset size: 	26032
2022-10-04 18:04:34 [INFO ]  datasets built!
2022-10-04 18:04:34 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:04:35 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:04:35 [INFO ]  
2022-10-04 18:04:35 [INFO ]  Begin of epoch 0 :
2022-10-04 18:04:39 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:04:39 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:04:39 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:04:39 [INFO ]  	   step  1 (lr=0.020000)                    8.33%                   7.8247
2022-10-04 18:04:39 [INFO ]  
2022-10-04 18:04:39 [INFO ]  Epoch:    0	Loss: 7.9327	Data Time: 0.44s	Train Time: 0.03s
2022-10-04 18:04:41 [INFO ]  Epoch:    1	Loss: 3.0233	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:04:42 [INFO ]  Epoch:    2	Loss: 2.5301	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:04:44 [INFO ]  Epoch:    3	Loss: 2.3053	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:46 [INFO ]  Epoch:    4	Loss: 2.2305	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:48 [INFO ]  Epoch:    5	Loss: 2.2097	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:04:50 [INFO ]  Epoch:    6	Loss: 2.1452	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:04:52 [INFO ]  Epoch:    7	Loss: 2.1309	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:04:54 [INFO ]  Epoch:    8	Loss: 2.0721	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:04:55 [INFO ]  Epoch:    9	Loss: 1.9543	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:04:57 [INFO ]  Epoch:   10	Loss: 1.8990	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:04:59 [INFO ]  Epoch:   11	Loss: 1.8210	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:05:01 [INFO ]  Epoch:   12	Loss: 1.6174	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:05:03 [INFO ]  Epoch:   13	Loss: 1.4423	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:04 [INFO ]  Epoch:   14	Loss: 1.4082	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:05:06 [INFO ]  Epoch:   15	Loss: 1.2746	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:08 [INFO ]  Epoch:   16	Loss: 1.2348	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:05:10 [INFO ]  Epoch:   17	Loss: 1.1937	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:05:11 [INFO ]  Epoch:   18	Loss: 1.1528	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:13 [INFO ]  Epoch:   19	Loss: 1.1697	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:15 [INFO ]  Epoch:   20	Loss: 1.1663	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:05:17 [INFO ]  Epoch:   21	Loss: 1.1442	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:05:19 [INFO ]  Epoch:   22	Loss: 1.0826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:21 [INFO ]  Epoch:   23	Loss: 1.0065	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:22 [INFO ]  Epoch:   24	Loss: 1.0567	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:24 [INFO ]  Epoch:   25	Loss: 1.0499	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:05:26 [INFO ]  Epoch:   26	Loss: 1.0472	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:05:28 [INFO ]  Epoch:   27	Loss: 1.0265	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:05:30 [INFO ]  Epoch:   28	Loss: 1.0244	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:05:31 [INFO ]  Epoch:   29	Loss: 1.0122	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:05:33 [INFO ]  Epoch:   30	Loss: 1.0389	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:05:35 [INFO ]  Epoch:   31	Loss: 1.0784	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:37 [INFO ]  Epoch:   32	Loss: 0.8975	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:05:39 [INFO ]  Epoch:   33	Loss: 1.0532	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:40 [INFO ]  Epoch:   34	Loss: 0.8710	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:05:42 [INFO ]  Epoch:   35	Loss: 0.8281	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:44 [INFO ]  Epoch:   36	Loss: 0.8123	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:46 [INFO ]  Epoch:   37	Loss: 0.8181	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:48 [INFO ]  Epoch:   38	Loss: 0.7995	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:05:50 [INFO ]  Epoch:   39	Loss: 0.7204	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:52 [INFO ]  Epoch:   40	Loss: 0.7169	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 18:05:53 [INFO ]  Epoch:   41	Loss: 0.7894	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:05:56 [INFO ]  Epoch:   42	Loss: 0.8182	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:05:57 [INFO ]  Epoch:   43	Loss: 0.7218	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:05:59 [INFO ]  Epoch:   44	Loss: 0.7363	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:06:01 [INFO ]  Epoch:   45	Loss: 0.7395	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:06:03 [INFO ]  Epoch:   46	Loss: 0.7583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:05 [INFO ]  Epoch:   47	Loss: 0.8098	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:06:06 [INFO ]  Epoch:   48	Loss: 0.7570	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:08 [INFO ]  Epoch:   49	Loss: 0.7083	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:10 [INFO ]  Epoch:   50	Loss: 0.6701	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:12 [INFO ]  Epoch:   51	Loss: 0.6715	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:06:13 [INFO ]  Epoch:   52	Loss: 0.5978	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:15 [INFO ]  Epoch:   53	Loss: 0.6896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:17 [INFO ]  Epoch:   54	Loss: 0.6443	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:06:19 [INFO ]  Epoch:   55	Loss: 0.7292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:21 [INFO ]  Epoch:   56	Loss: 0.6918	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:22 [INFO ]  Epoch:   57	Loss: 0.7759	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:24 [INFO ]  Epoch:   58	Loss: 0.7150	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:06:26 [INFO ]  Epoch:   59	Loss: 0.7313	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 18:06:28 [INFO ]  Epoch:   60	Loss: 0.6850	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:06:30 [INFO ]  Epoch:   61	Loss: 0.6724	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:32 [INFO ]  Epoch:   62	Loss: 0.6895	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:34 [INFO ]  Epoch:   63	Loss: 0.6630	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:36 [INFO ]  Epoch:   64	Loss: 0.7093	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:06:37 [INFO ]  Epoch:   65	Loss: 0.7367	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:39 [INFO ]  Epoch:   66	Loss: 0.6820	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:06:41 [INFO ]  Epoch:   67	Loss: 0.6141	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:06:43 [INFO ]  Epoch:   68	Loss: 0.6916	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:06:45 [INFO ]  Epoch:   69	Loss: 0.7307	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:47 [INFO ]  Epoch:   70	Loss: 0.7003	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:06:49 [INFO ]  Epoch:   71	Loss: 0.6232	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:51 [INFO ]  Epoch:   72	Loss: 0.6693	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:06:52 [INFO ]  Epoch:   73	Loss: 0.6336	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:06:54 [INFO ]  Epoch:   74	Loss: 0.6902	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:06:56 [INFO ]  Epoch:   75	Loss: 0.6295	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:06:58 [INFO ]  Epoch:   76	Loss: 0.6695	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:00 [INFO ]  Epoch:   77	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:02 [INFO ]  Epoch:   78	Loss: 0.6351	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:04 [INFO ]  Epoch:   79	Loss: 0.6471	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:06 [INFO ]  Epoch:   80	Loss: 0.6945	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:08 [INFO ]  Epoch:   81	Loss: 0.6239	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:10 [INFO ]  Epoch:   82	Loss: 0.6812	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:07:12 [INFO ]  Epoch:   83	Loss: 0.6374	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:14 [INFO ]  Epoch:   84	Loss: 0.6766	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:07:15 [INFO ]  Epoch:   85	Loss: 0.6992	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:17 [INFO ]  Epoch:   86	Loss: 0.6522	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:07:19 [INFO ]  Epoch:   87	Loss: 0.6371	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:07:21 [INFO ]  Epoch:   88	Loss: 0.6847	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:23 [INFO ]  Epoch:   89	Loss: 0.6945	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:24 [INFO ]  Epoch:   90	Loss: 0.7731	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:07:26 [INFO ]  Epoch:   91	Loss: 0.7187	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:28 [INFO ]  Epoch:   92	Loss: 0.6794	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:07:30 [INFO ]  Epoch:   93	Loss: 0.7179	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:31 [INFO ]  Epoch:   94	Loss: 0.6137	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:07:33 [INFO ]  Epoch:   95	Loss: 0.6834	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:35 [INFO ]  Epoch:   96	Loss: 0.6503	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:37 [INFO ]  Epoch:   97	Loss: 0.7263	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:07:39 [INFO ]  Epoch:   98	Loss: 0.6331	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:07:41 [INFO ]  Epoch:   99	Loss: 0.7072	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:07:43 [INFO ]  Epoch:  100	Loss: 0.6884	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:44 [INFO ]  Epoch:  101	Loss: 0.6552	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:07:46 [INFO ]  Epoch:  102	Loss: 0.6666	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:07:48 [INFO ]  Epoch:  103	Loss: 0.6628	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:07:50 [INFO ]  Epoch:  104	Loss: 0.7072	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:07:52 [INFO ]  Epoch:  105	Loss: 0.6015	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:07:53 [INFO ]  Epoch:  106	Loss: 0.5923	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:07:55 [INFO ]  Epoch:  107	Loss: 0.6908	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:07:57 [INFO ]  Epoch:  108	Loss: 0.5967	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:07:59 [INFO ]  Epoch:  109	Loss: 0.5929	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:01 [INFO ]  Epoch:  110	Loss: 0.6264	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:03 [INFO ]  Epoch:  111	Loss: 0.7298	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:04 [INFO ]  Epoch:  112	Loss: 0.6296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:07 [INFO ]  Epoch:  113	Loss: 0.7222	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:08 [INFO ]  Epoch:  114	Loss: 0.5826	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:08:10 [INFO ]  Epoch:  115	Loss: 0.6708	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:08:12 [INFO ]  Epoch:  116	Loss: 0.6545	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:14 [INFO ]  Epoch:  117	Loss: 0.6483	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:16 [INFO ]  Epoch:  118	Loss: 0.6430	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:08:18 [INFO ]  Epoch:  119	Loss: 0.6054	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:08:19 [INFO ]  Epoch:  120	Loss: 0.6976	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:08:21 [INFO ]  Epoch:  121	Loss: 0.7047	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:23 [INFO ]  Epoch:  122	Loss: 0.6193	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:08:25 [INFO ]  Epoch:  123	Loss: 0.6321	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:08:27 [INFO ]  Epoch:  124	Loss: 0.7587	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:29 [INFO ]  Epoch:  125	Loss: 0.6523	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:31 [INFO ]  Epoch:  126	Loss: 0.6977	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:08:33 [INFO ]  Epoch:  127	Loss: 0.6989	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:08:34 [INFO ]  Epoch:  128	Loss: 0.6321	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:36 [INFO ]  Epoch:  129	Loss: 0.6410	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:38 [INFO ]  Epoch:  130	Loss: 0.5909	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:08:40 [INFO ]  Epoch:  131	Loss: 0.6573	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:08:41 [INFO ]  Epoch:  132	Loss: 0.7399	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:43 [INFO ]  Epoch:  133	Loss: 0.6649	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:08:45 [INFO ]  Epoch:  134	Loss: 0.6200	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:08:47 [INFO ]  Epoch:  135	Loss: 0.6253	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:08:49 [INFO ]  Epoch:  136	Loss: 0.6684	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:51 [INFO ]  Epoch:  137	Loss: 0.6742	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:08:52 [INFO ]  Epoch:  138	Loss: 0.6064	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:08:54 [INFO ]  Epoch:  139	Loss: 0.6181	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:08:56 [INFO ]  Epoch:  140	Loss: 0.6703	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:08:58 [INFO ]  Epoch:  141	Loss: 0.6551	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:00 [INFO ]  Epoch:  142	Loss: 0.5810	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:09:02 [INFO ]  Epoch:  143	Loss: 0.6194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:03 [INFO ]  Epoch:  144	Loss: 0.5933	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:09:05 [INFO ]  Epoch:  145	Loss: 0.6187	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:07 [INFO ]  Epoch:  146	Loss: 0.6119	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:09:09 [INFO ]  Epoch:  147	Loss: 0.7068	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:09:11 [INFO ]  Epoch:  148	Loss: 0.6204	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:09:13 [INFO ]  Epoch:  149	Loss: 0.6214	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:15 [INFO ]  Epoch:  150	Loss: 0.6684	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:16 [INFO ]  Epoch:  151	Loss: 0.6388	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:09:18 [INFO ]  Epoch:  152	Loss: 0.6995	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:09:20 [INFO ]  Epoch:  153	Loss: 0.6855	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:09:22 [INFO ]  Epoch:  154	Loss: 0.5815	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:23 [INFO ]  Epoch:  155	Loss: 0.6669	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:25 [INFO ]  Epoch:  156	Loss: 0.6998	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:09:27 [INFO ]  Epoch:  157	Loss: 0.6093	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 18:09:29 [INFO ]  Epoch:  158	Loss: 0.6553	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:31 [INFO ]  Epoch:  159	Loss: 0.6251	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:09:33 [INFO ]  Epoch:  160	Loss: 0.6417	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:35 [INFO ]  Epoch:  161	Loss: 0.6544	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:36 [INFO ]  Epoch:  162	Loss: 0.6331	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:38 [INFO ]  Epoch:  163	Loss: 0.6269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:40 [INFO ]  Epoch:  164	Loss: 0.6507	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:09:42 [INFO ]  Epoch:  165	Loss: 0.5935	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:43 [INFO ]  Epoch:  166	Loss: 0.6960	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:09:45 [INFO ]  Epoch:  167	Loss: 0.6118	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:47 [INFO ]  Epoch:  168	Loss: 0.6794	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:09:49 [INFO ]  Epoch:  169	Loss: 0.6054	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:09:51 [INFO ]  Epoch:  170	Loss: 0.7162	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:09:53 [INFO ]  Epoch:  171	Loss: 0.6302	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:09:54 [INFO ]  Epoch:  172	Loss: 0.6415	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:09:56 [INFO ]  Epoch:  173	Loss: 0.6497	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:09:58 [INFO ]  Epoch:  174	Loss: 0.6241	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:00 [INFO ]  Epoch:  175	Loss: 0.6408	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:02 [INFO ]  Epoch:  176	Loss: 0.7007	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:10:03 [INFO ]  Epoch:  177	Loss: 0.5638	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:10:05 [INFO ]  Epoch:  178	Loss: 0.5726	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:10:07 [INFO ]  Epoch:  179	Loss: 0.7289	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:10:09 [INFO ]  Epoch:  180	Loss: 0.5907	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:10:11 [INFO ]  Epoch:  181	Loss: 0.6444	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:10:13 [INFO ]  Epoch:  182	Loss: 0.6548	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:10:15 [INFO ]  Epoch:  183	Loss: 0.6576	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:10:16 [INFO ]  Epoch:  184	Loss: 0.6000	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:10:18 [INFO ]  Epoch:  185	Loss: 0.6440	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:10:20 [INFO ]  Epoch:  186	Loss: 0.5665	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:10:22 [INFO ]  Epoch:  187	Loss: 0.5719	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:10:24 [INFO ]  Epoch:  188	Loss: 0.6440	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:10:26 [INFO ]  Epoch:  189	Loss: 0.6395	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:10:28 [INFO ]  Epoch:  190	Loss: 0.5937	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:10:30 [INFO ]  Epoch:  191	Loss: 0.6690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:31 [INFO ]  Epoch:  192	Loss: 0.6514	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:10:33 [INFO ]  Epoch:  193	Loss: 0.6584	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:10:35 [INFO ]  Epoch:  194	Loss: 0.5885	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:37 [INFO ]  Epoch:  195	Loss: 0.6443	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:10:39 [INFO ]  Epoch:  196	Loss: 0.5891	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:10:41 [INFO ]  Epoch:  197	Loss: 0.7059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:42 [INFO ]  Epoch:  198	Loss: 0.7376	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:10:44 [INFO ]  Epoch:  199	Loss: 0.6389	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:10:46 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:10:46 [INFO ]  
2022-10-04 18:10:46 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:10:49 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:10:49 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:10:49 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:10:49 [INFO ]  	   step  1 (lr=0.349950)                   80.70%                   0.7106
2022-10-04 18:10:49 [INFO ]  
2022-10-04 18:10:49 [INFO ]  
2022-10-04 18:10:49 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:10:52 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:10:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:10:52 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:10:52 [INFO ]  	   step  1 (lr=0.349950)                   18.49%                   5.0754
2022-10-04 18:10:52 [INFO ]  
2022-10-04 18:10:52 [INFO ]  CPU Time: 3.46 minutes
2022-10-04 18:11:07 [INFO ]  ======================================== 2022-10-04 18:11:07 ========================================
2022-10-04 18:11:07 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:11:07 [INFO ]  Options: 
2022-10-04 18:11:07 [INFO ]  	base_dir: null
2022-10-04 18:11:07 [INFO ]  	batch_size: 1024
2022-10-04 18:11:07 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:11:07 [INFO ]  	dataset: SVHN
2022-10-04 18:11:07 [INFO ]  	dataset_labels:
2022-10-04 18:11:07 [INFO ]  	- 0
2022-10-04 18:11:07 [INFO ]  	- 1
2022-10-04 18:11:07 [INFO ]  	- 2
2022-10-04 18:11:07 [INFO ]  	- 3
2022-10-04 18:11:07 [INFO ]  	- 4
2022-10-04 18:11:07 [INFO ]  	- 5
2022-10-04 18:11:07 [INFO ]  	- 6
2022-10-04 18:11:07 [INFO ]  	- 7
2022-10-04 18:11:07 [INFO ]  	- 8
2022-10-04 18:11:07 [INFO ]  	- 9
2022-10-04 18:11:07 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:11:07 [INFO ]  	- !!python/tuple
2022-10-04 18:11:07 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:11:07 [INFO ]  	    - 0.44398033618927
2022-10-04 18:11:07 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:11:07 [INFO ]  	- !!python/tuple
2022-10-04 18:11:07 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:11:07 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:11:07 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:11:07 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:11:07 [INFO ]  	decay_epochs: 50
2022-10-04 18:11:07 [INFO ]  	decay_factor: 0.1
2022-10-04 18:11:07 [INFO ]  	device_id: 0
2022-10-04 18:11:07 [INFO ]  	distill_epochs: 1
2022-10-04 18:11:07 [INFO ]  	distill_lr: 0.02
2022-10-04 18:11:07 [INFO ]  	distill_steps: 1
2022-10-04 18:11:07 [INFO ]  	epochs: 200
2022-10-04 18:11:07 [INFO ]  	expand_cls: false
2022-10-04 18:11:07 [INFO ]  	forgetting_dataset: null
2022-10-04 18:11:07 [INFO ]  	init: xavier
2022-10-04 18:11:07 [INFO ]  	init_param: 1.0
2022-10-04 18:11:07 [INFO ]  	input_size: 32
2022-10-04 18:11:07 [INFO ]  	ipc: 5
2022-10-04 18:11:07 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:11:07 [INFO ]  	log_interval: 100
2022-10-04 18:11:07 [INFO ]  	log_level: INFO
2022-10-04 18:11:07 [INFO ]  	lr: 0.01
2022-10-04 18:11:07 [INFO ]  	mode: distill_adapt
2022-10-04 18:11:07 [INFO ]  	nc: 3
2022-10-04 18:11:07 [INFO ]  	num_classes: 10
2022-10-04 18:11:07 [INFO ]  	num_workers: 8
2022-10-04 18:11:07 [INFO ]  	phase: train
2022-10-04 18:11:07 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:11:07 [INFO ]  	start_time: '2022-10-04 18:11:07'
2022-10-04 18:11:07 [INFO ]  	test_batch_size: 1024
2022-10-04 18:11:07 [INFO ]  	
2022-10-04 18:11:09 [INFO ]  train dataset size:	73257
2022-10-04 18:11:09 [INFO ]  test dataset size: 	26032
2022-10-04 18:11:09 [INFO ]  datasets built!
2022-10-04 18:11:09 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:11:11 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:11:11 [INFO ]  
2022-10-04 18:11:11 [INFO ]  Begin of epoch 0 :
2022-10-04 18:11:14 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:11:14 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:11:14 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:11:14 [INFO ]  	   step  1 (lr=0.020000)                    8.00%                   8.5376
2022-10-04 18:11:14 [INFO ]  
2022-10-04 18:11:14 [INFO ]  Epoch:    0	Loss: 8.3454	Data Time: 0.41s	Train Time: 0.03s
2022-10-04 18:11:16 [INFO ]  Epoch:    1	Loss: 3.0096	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 18:11:18 [INFO ]  Epoch:    2	Loss: 2.5631	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:11:20 [INFO ]  Epoch:    3	Loss: 2.3176	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:11:22 [INFO ]  Epoch:    4	Loss: 2.2317	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:23 [INFO ]  Epoch:    5	Loss: 2.1862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:25 [INFO ]  Epoch:    6	Loss: 2.1540	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:11:27 [INFO ]  Epoch:    7	Loss: 2.1317	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:11:29 [INFO ]  Epoch:    8	Loss: 2.0308	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:11:31 [INFO ]  Epoch:    9	Loss: 1.9545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:11:33 [INFO ]  Epoch:   10	Loss: 1.8141	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:11:35 [INFO ]  Epoch:   11	Loss: 1.7387	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:11:37 [INFO ]  Epoch:   12	Loss: 1.6554	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:11:39 [INFO ]  Epoch:   13	Loss: 1.5639	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:11:41 [INFO ]  Epoch:   14	Loss: 1.4193	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:43 [INFO ]  Epoch:   15	Loss: 1.3295	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:11:44 [INFO ]  Epoch:   16	Loss: 1.3471	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:11:46 [INFO ]  Epoch:   17	Loss: 1.2879	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:48 [INFO ]  Epoch:   18	Loss: 1.3667	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:50 [INFO ]  Epoch:   19	Loss: 1.2922	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:11:52 [INFO ]  Epoch:   20	Loss: 1.2221	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:54 [INFO ]  Epoch:   21	Loss: 1.1376	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:11:56 [INFO ]  Epoch:   22	Loss: 1.1075	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:11:58 [INFO ]  Epoch:   23	Loss: 1.0366	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:12:00 [INFO ]  Epoch:   24	Loss: 1.0847	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:12:01 [INFO ]  Epoch:   25	Loss: 1.0268	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:12:03 [INFO ]  Epoch:   26	Loss: 1.0508	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:05 [INFO ]  Epoch:   27	Loss: 1.1480	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:07 [INFO ]  Epoch:   28	Loss: 0.9856	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:09 [INFO ]  Epoch:   29	Loss: 1.0590	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:12:11 [INFO ]  Epoch:   30	Loss: 1.0521	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:13 [INFO ]  Epoch:   31	Loss: 0.9323	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:15 [INFO ]  Epoch:   32	Loss: 1.1638	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:17 [INFO ]  Epoch:   33	Loss: 0.8882	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:18 [INFO ]  Epoch:   34	Loss: 1.0198	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:12:20 [INFO ]  Epoch:   35	Loss: 0.9902	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:22 [INFO ]  Epoch:   36	Loss: 0.8492	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:12:24 [INFO ]  Epoch:   37	Loss: 0.8932	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:12:26 [INFO ]  Epoch:   38	Loss: 0.8509	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:12:28 [INFO ]  Epoch:   39	Loss: 0.9819	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 18:12:30 [INFO ]  Epoch:   40	Loss: 0.8498	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:32 [INFO ]  Epoch:   41	Loss: 0.9459	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:12:34 [INFO ]  Epoch:   42	Loss: 0.8774	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:12:36 [INFO ]  Epoch:   43	Loss: 0.7808	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:12:38 [INFO ]  Epoch:   44	Loss: 0.9070	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:40 [INFO ]  Epoch:   45	Loss: 0.7766	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:42 [INFO ]  Epoch:   46	Loss: 0.7827	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:12:43 [INFO ]  Epoch:   47	Loss: 0.8545	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:12:45 [INFO ]  Epoch:   48	Loss: 0.7977	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:47 [INFO ]  Epoch:   49	Loss: 0.7964	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:12:49 [INFO ]  Epoch:   50	Loss: 0.7544	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:12:51 [INFO ]  Epoch:   51	Loss: 0.7656	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:12:53 [INFO ]  Epoch:   52	Loss: 0.8111	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:55 [INFO ]  Epoch:   53	Loss: 0.6429	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:12:56 [INFO ]  Epoch:   54	Loss: 0.7472	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:12:58 [INFO ]  Epoch:   55	Loss: 0.7610	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:00 [INFO ]  Epoch:   56	Loss: 0.6870	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:02 [INFO ]  Epoch:   57	Loss: 0.7304	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:04 [INFO ]  Epoch:   58	Loss: 0.8151	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:13:06 [INFO ]  Epoch:   59	Loss: 0.7561	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:13:08 [INFO ]  Epoch:   60	Loss: 0.7017	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:10 [INFO ]  Epoch:   61	Loss: 0.7143	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:13:12 [INFO ]  Epoch:   62	Loss: 0.7283	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:13:14 [INFO ]  Epoch:   63	Loss: 0.7299	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:16 [INFO ]  Epoch:   64	Loss: 0.7718	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:13:17 [INFO ]  Epoch:   65	Loss: 0.8260	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:19 [INFO ]  Epoch:   66	Loss: 0.6830	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:13:21 [INFO ]  Epoch:   67	Loss: 0.7350	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:23 [INFO ]  Epoch:   68	Loss: 0.7374	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:25 [INFO ]  Epoch:   69	Loss: 0.6543	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:27 [INFO ]  Epoch:   70	Loss: 0.7436	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:13:28 [INFO ]  Epoch:   71	Loss: 0.6967	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:13:30 [INFO ]  Epoch:   72	Loss: 0.7200	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:32 [INFO ]  Epoch:   73	Loss: 0.7763	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:34 [INFO ]  Epoch:   74	Loss: 0.7772	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:13:36 [INFO ]  Epoch:   75	Loss: 0.7003	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:13:38 [INFO ]  Epoch:   76	Loss: 0.7057	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:40 [INFO ]  Epoch:   77	Loss: 0.6952	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:13:41 [INFO ]  Epoch:   78	Loss: 0.7415	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:13:43 [INFO ]  Epoch:   79	Loss: 0.6470	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:45 [INFO ]  Epoch:   80	Loss: 0.7524	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:13:47 [INFO ]  Epoch:   81	Loss: 0.6715	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:13:49 [INFO ]  Epoch:   82	Loss: 0.7378	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:51 [INFO ]  Epoch:   83	Loss: 0.6524	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:13:53 [INFO ]  Epoch:   84	Loss: 0.7163	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:13:55 [INFO ]  Epoch:   85	Loss: 0.7218	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:13:57 [INFO ]  Epoch:   86	Loss: 0.7449	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:13:58 [INFO ]  Epoch:   87	Loss: 0.7035	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:14:00 [INFO ]  Epoch:   88	Loss: 0.7052	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:14:02 [INFO ]  Epoch:   89	Loss: 0.5921	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:14:04 [INFO ]  Epoch:   90	Loss: 0.7298	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:06 [INFO ]  Epoch:   91	Loss: 0.6939	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:08 [INFO ]  Epoch:   92	Loss: 0.7098	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:14:09 [INFO ]  Epoch:   93	Loss: 0.6959	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:14:11 [INFO ]  Epoch:   94	Loss: 0.6991	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:13 [INFO ]  Epoch:   95	Loss: 0.7394	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:14:15 [INFO ]  Epoch:   96	Loss: 0.7025	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:17 [INFO ]  Epoch:   97	Loss: 0.6887	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:14:19 [INFO ]  Epoch:   98	Loss: 0.7801	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:14:21 [INFO ]  Epoch:   99	Loss: 0.7582	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:23 [INFO ]  Epoch:  100	Loss: 0.6803	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:14:25 [INFO ]  Epoch:  101	Loss: 0.6800	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:14:26 [INFO ]  Epoch:  102	Loss: 0.7119	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:14:28 [INFO ]  Epoch:  103	Loss: 0.7051	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:14:30 [INFO ]  Epoch:  104	Loss: 0.7697	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:32 [INFO ]  Epoch:  105	Loss: 0.6972	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:34 [INFO ]  Epoch:  106	Loss: 0.6242	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:36 [INFO ]  Epoch:  107	Loss: 0.8371	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:38 [INFO ]  Epoch:  108	Loss: 0.6556	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:40 [INFO ]  Epoch:  109	Loss: 0.6435	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:14:42 [INFO ]  Epoch:  110	Loss: 0.7480	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:44 [INFO ]  Epoch:  111	Loss: 0.6479	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:14:46 [INFO ]  Epoch:  112	Loss: 0.6810	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:14:48 [INFO ]  Epoch:  113	Loss: 0.6855	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:14:49 [INFO ]  Epoch:  114	Loss: 0.6406	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:14:51 [INFO ]  Epoch:  115	Loss: 0.6529	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:53 [INFO ]  Epoch:  116	Loss: 0.7095	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:14:55 [INFO ]  Epoch:  117	Loss: 0.6555	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:14:57 [INFO ]  Epoch:  118	Loss: 0.6271	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:14:59 [INFO ]  Epoch:  119	Loss: 0.7078	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:15:01 [INFO ]  Epoch:  120	Loss: 0.7418	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:03 [INFO ]  Epoch:  121	Loss: 0.6834	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:15:05 [INFO ]  Epoch:  122	Loss: 0.7658	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:15:07 [INFO ]  Epoch:  123	Loss: 0.6915	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:15:09 [INFO ]  Epoch:  124	Loss: 0.6965	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:15:11 [INFO ]  Epoch:  125	Loss: 0.6663	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:15:12 [INFO ]  Epoch:  126	Loss: 0.7811	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:15:14 [INFO ]  Epoch:  127	Loss: 0.7038	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:16 [INFO ]  Epoch:  128	Loss: 0.7312	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:15:18 [INFO ]  Epoch:  129	Loss: 0.6256	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:15:20 [INFO ]  Epoch:  130	Loss: 0.6647	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:15:22 [INFO ]  Epoch:  131	Loss: 0.6127	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:24 [INFO ]  Epoch:  132	Loss: 0.7324	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:15:25 [INFO ]  Epoch:  133	Loss: 0.6705	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:15:27 [INFO ]  Epoch:  134	Loss: 0.7129	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:15:29 [INFO ]  Epoch:  135	Loss: 0.6424	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:15:31 [INFO ]  Epoch:  136	Loss: 0.6930	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:33 [INFO ]  Epoch:  137	Loss: 0.7193	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:35 [INFO ]  Epoch:  138	Loss: 0.6217	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:15:36 [INFO ]  Epoch:  139	Loss: 0.6319	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:15:38 [INFO ]  Epoch:  140	Loss: 0.5968	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:40 [INFO ]  Epoch:  141	Loss: 0.7189	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:15:42 [INFO ]  Epoch:  142	Loss: 0.6921	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:44 [INFO ]  Epoch:  143	Loss: 0.7681	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:15:46 [INFO ]  Epoch:  144	Loss: 0.7100	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:15:47 [INFO ]  Epoch:  145	Loss: 0.6672	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:49 [INFO ]  Epoch:  146	Loss: 0.6331	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:15:51 [INFO ]  Epoch:  147	Loss: 0.7079	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:15:53 [INFO ]  Epoch:  148	Loss: 0.7300	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:15:55 [INFO ]  Epoch:  149	Loss: 0.7079	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:15:57 [INFO ]  Epoch:  150	Loss: 0.7108	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:15:59 [INFO ]  Epoch:  151	Loss: 0.6626	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:01 [INFO ]  Epoch:  152	Loss: 0.6869	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:16:03 [INFO ]  Epoch:  153	Loss: 0.7034	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:16:05 [INFO ]  Epoch:  154	Loss: 0.6282	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:16:06 [INFO ]  Epoch:  155	Loss: 0.6886	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:16:08 [INFO ]  Epoch:  156	Loss: 0.7642	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:10 [INFO ]  Epoch:  157	Loss: 0.6568	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:16:12 [INFO ]  Epoch:  158	Loss: 0.7471	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:16:14 [INFO ]  Epoch:  159	Loss: 0.6858	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:16:16 [INFO ]  Epoch:  160	Loss: 0.7020	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:16:18 [INFO ]  Epoch:  161	Loss: 0.6175	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:16:20 [INFO ]  Epoch:  162	Loss: 0.7153	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:16:22 [INFO ]  Epoch:  163	Loss: 0.6792	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:16:23 [INFO ]  Epoch:  164	Loss: 0.7290	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:25 [INFO ]  Epoch:  165	Loss: 0.6487	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:16:27 [INFO ]  Epoch:  166	Loss: 0.7002	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:16:29 [INFO ]  Epoch:  167	Loss: 0.6454	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:31 [INFO ]  Epoch:  168	Loss: 0.7127	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:33 [INFO ]  Epoch:  169	Loss: 0.6893	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:35 [INFO ]  Epoch:  170	Loss: 0.7585	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:16:37 [INFO ]  Epoch:  171	Loss: 0.7090	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:39 [INFO ]  Epoch:  172	Loss: 0.6590	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:40 [INFO ]  Epoch:  173	Loss: 0.7101	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:16:42 [INFO ]  Epoch:  174	Loss: 0.6698	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:44 [INFO ]  Epoch:  175	Loss: 0.6261	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:16:46 [INFO ]  Epoch:  176	Loss: 0.7214	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:48 [INFO ]  Epoch:  177	Loss: 0.7300	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:16:50 [INFO ]  Epoch:  178	Loss: 0.6982	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:16:52 [INFO ]  Epoch:  179	Loss: 0.6749	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:16:54 [INFO ]  Epoch:  180	Loss: 0.6910	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:16:55 [INFO ]  Epoch:  181	Loss: 0.6704	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:16:57 [INFO ]  Epoch:  182	Loss: 0.6599	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:16:59 [INFO ]  Epoch:  183	Loss: 0.6689	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:17:01 [INFO ]  Epoch:  184	Loss: 0.7027	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:03 [INFO ]  Epoch:  185	Loss: 0.6701	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:05 [INFO ]  Epoch:  186	Loss: 0.6753	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:17:07 [INFO ]  Epoch:  187	Loss: 0.7359	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:17:09 [INFO ]  Epoch:  188	Loss: 0.7140	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:17:11 [INFO ]  Epoch:  189	Loss: 0.7062	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:17:13 [INFO ]  Epoch:  190	Loss: 0.6518	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:17:15 [INFO ]  Epoch:  191	Loss: 0.7196	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:17 [INFO ]  Epoch:  192	Loss: 0.6661	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:18 [INFO ]  Epoch:  193	Loss: 0.7264	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:20 [INFO ]  Epoch:  194	Loss: 0.6777	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:17:22 [INFO ]  Epoch:  195	Loss: 0.7562	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:24 [INFO ]  Epoch:  196	Loss: 0.6305	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:17:26 [INFO ]  Epoch:  197	Loss: 0.6560	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:17:28 [INFO ]  Epoch:  198	Loss: 0.7264	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:17:30 [INFO ]  Epoch:  199	Loss: 0.6625	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:17:31 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:17:31 [INFO ]  
2022-10-04 18:17:31 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:17:35 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:17:35 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:17:35 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:17:35 [INFO ]  	   step  1 (lr=0.351762)                   79.45%                   0.7563
2022-10-04 18:17:35 [INFO ]  
2022-10-04 18:17:35 [INFO ]  
2022-10-04 18:17:35 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:17:38 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:17:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:17:38 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:17:38 [INFO ]  	   step  1 (lr=0.351762)                   16.45%                   5.1599
2022-10-04 18:17:38 [INFO ]  
2022-10-04 18:17:38 [INFO ]  CPU Time: 3.49 minutes
2022-10-04 18:18:02 [INFO ]  ======================================== 2022-10-04 18:18:02 ========================================
2022-10-04 18:18:02 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:18:02 [INFO ]  Options: 
2022-10-04 18:18:02 [INFO ]  	base_dir: null
2022-10-04 18:18:02 [INFO ]  	batch_size: 1024
2022-10-04 18:18:02 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:18:02 [INFO ]  	dataset: SVHN
2022-10-04 18:18:02 [INFO ]  	dataset_labels:
2022-10-04 18:18:02 [INFO ]  	- 0
2022-10-04 18:18:02 [INFO ]  	- 1
2022-10-04 18:18:02 [INFO ]  	- 2
2022-10-04 18:18:02 [INFO ]  	- 3
2022-10-04 18:18:02 [INFO ]  	- 4
2022-10-04 18:18:02 [INFO ]  	- 5
2022-10-04 18:18:02 [INFO ]  	- 6
2022-10-04 18:18:02 [INFO ]  	- 7
2022-10-04 18:18:02 [INFO ]  	- 8
2022-10-04 18:18:02 [INFO ]  	- 9
2022-10-04 18:18:02 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:18:02 [INFO ]  	- !!python/tuple
2022-10-04 18:18:02 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:18:02 [INFO ]  	    - 0.44398033618927
2022-10-04 18:18:02 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:18:02 [INFO ]  	- !!python/tuple
2022-10-04 18:18:02 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:18:02 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:18:02 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:18:02 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:18:02 [INFO ]  	decay_epochs: 50
2022-10-04 18:18:02 [INFO ]  	decay_factor: 0.1
2022-10-04 18:18:02 [INFO ]  	device_id: 0
2022-10-04 18:18:02 [INFO ]  	distill_epochs: 1
2022-10-04 18:18:02 [INFO ]  	distill_lr: 0.02
2022-10-04 18:18:02 [INFO ]  	distill_steps: 1
2022-10-04 18:18:02 [INFO ]  	epochs: 200
2022-10-04 18:18:02 [INFO ]  	expand_cls: false
2022-10-04 18:18:02 [INFO ]  	forgetting_dataset: null
2022-10-04 18:18:02 [INFO ]  	init: xavier
2022-10-04 18:18:02 [INFO ]  	init_param: 1.0
2022-10-04 18:18:02 [INFO ]  	input_size: 32
2022-10-04 18:18:02 [INFO ]  	ipc: 10
2022-10-04 18:18:02 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:18:02 [INFO ]  	log_interval: 100
2022-10-04 18:18:02 [INFO ]  	log_level: INFO
2022-10-04 18:18:02 [INFO ]  	lr: 0.01
2022-10-04 18:18:02 [INFO ]  	mode: distill_adapt
2022-10-04 18:18:02 [INFO ]  	nc: 3
2022-10-04 18:18:02 [INFO ]  	num_classes: 10
2022-10-04 18:18:02 [INFO ]  	num_workers: 8
2022-10-04 18:18:02 [INFO ]  	phase: train
2022-10-04 18:18:02 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:18:02 [INFO ]  	start_time: '2022-10-04 18:18:02'
2022-10-04 18:18:02 [INFO ]  	test_batch_size: 1024
2022-10-04 18:18:02 [INFO ]  	
2022-10-04 18:18:05 [INFO ]  train dataset size:	73257
2022-10-04 18:18:05 [INFO ]  test dataset size: 	26032
2022-10-04 18:18:05 [INFO ]  datasets built!
2022-10-04 18:18:05 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:18:06 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:18:06 [INFO ]  
2022-10-04 18:18:06 [INFO ]  Begin of epoch 0 :
2022-10-04 18:18:10 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:18:10 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:18:10 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:18:10 [INFO ]  	   step  1 (lr=0.020000)                    7.75%                   8.1511
2022-10-04 18:18:10 [INFO ]  
2022-10-04 18:18:10 [INFO ]  Epoch:    0	Loss: 8.1333	Data Time: 0.41s	Train Time: 0.04s
2022-10-04 18:18:11 [INFO ]  Epoch:    1	Loss: 2.9347	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 18:18:13 [INFO ]  Epoch:    2	Loss: 2.4388	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:18:15 [INFO ]  Epoch:    3	Loss: 2.2762	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:18:17 [INFO ]  Epoch:    4	Loss: 2.2121	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:19 [INFO ]  Epoch:    5	Loss: 2.2002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:21 [INFO ]  Epoch:    6	Loss: 2.1376	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:18:23 [INFO ]  Epoch:    7	Loss: 2.1031	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:25 [INFO ]  Epoch:    8	Loss: 2.0552	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:27 [INFO ]  Epoch:    9	Loss: 1.9933	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:29 [INFO ]  Epoch:   10	Loss: 1.8152	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:18:30 [INFO ]  Epoch:   11	Loss: 1.6664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:32 [INFO ]  Epoch:   12	Loss: 1.5941	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:34 [INFO ]  Epoch:   13	Loss: 1.6178	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:18:36 [INFO ]  Epoch:   14	Loss: 1.3172	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:38 [INFO ]  Epoch:   15	Loss: 1.4085	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:18:40 [INFO ]  Epoch:   16	Loss: 1.3211	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:42 [INFO ]  Epoch:   17	Loss: 1.2326	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:18:44 [INFO ]  Epoch:   18	Loss: 1.0970	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:18:46 [INFO ]  Epoch:   19	Loss: 1.1741	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:18:47 [INFO ]  Epoch:   20	Loss: 1.1275	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:18:49 [INFO ]  Epoch:   21	Loss: 1.2068	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:18:51 [INFO ]  Epoch:   22	Loss: 0.9692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:18:53 [INFO ]  Epoch:   23	Loss: 0.9926	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:18:55 [INFO ]  Epoch:   24	Loss: 0.9717	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:18:57 [INFO ]  Epoch:   25	Loss: 0.9600	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:18:59 [INFO ]  Epoch:   26	Loss: 0.9125	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:01 [INFO ]  Epoch:   27	Loss: 0.9043	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:03 [INFO ]  Epoch:   28	Loss: 0.8492	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:05 [INFO ]  Epoch:   29	Loss: 0.9055	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:06 [INFO ]  Epoch:   30	Loss: 1.1512	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:08 [INFO ]  Epoch:   31	Loss: 0.8160	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:10 [INFO ]  Epoch:   32	Loss: 0.8694	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:19:12 [INFO ]  Epoch:   33	Loss: 0.7982	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:19:14 [INFO ]  Epoch:   34	Loss: 0.7840	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:19:16 [INFO ]  Epoch:   35	Loss: 0.8017	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:19:18 [INFO ]  Epoch:   36	Loss: 0.8762	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:19 [INFO ]  Epoch:   37	Loss: 0.7352	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:21 [INFO ]  Epoch:   38	Loss: 0.8161	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:19:23 [INFO ]  Epoch:   39	Loss: 0.7630	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:25 [INFO ]  Epoch:   40	Loss: 0.7761	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:19:27 [INFO ]  Epoch:   41	Loss: 0.7531	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:19:29 [INFO ]  Epoch:   42	Loss: 0.7654	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:30 [INFO ]  Epoch:   43	Loss: 0.9645	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:19:32 [INFO ]  Epoch:   44	Loss: 0.7335	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:34 [INFO ]  Epoch:   45	Loss: 0.7791	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:36 [INFO ]  Epoch:   46	Loss: 0.7946	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:19:38 [INFO ]  Epoch:   47	Loss: 0.7879	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:40 [INFO ]  Epoch:   48	Loss: 0.8120	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:19:42 [INFO ]  Epoch:   49	Loss: 0.7671	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:19:44 [INFO ]  Epoch:   50	Loss: 0.6460	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:19:46 [INFO ]  Epoch:   51	Loss: 0.7108	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:19:48 [INFO ]  Epoch:   52	Loss: 0.7217	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:49 [INFO ]  Epoch:   53	Loss: 0.7546	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:19:51 [INFO ]  Epoch:   54	Loss: 0.7310	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:19:53 [INFO ]  Epoch:   55	Loss: 0.6371	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:19:56 [INFO ]  Epoch:   56	Loss: 0.6164	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:19:57 [INFO ]  Epoch:   57	Loss: 0.6340	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:19:59 [INFO ]  Epoch:   58	Loss: 0.7067	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:20:01 [INFO ]  Epoch:   59	Loss: 0.6740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:03 [INFO ]  Epoch:   60	Loss: 0.7086	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:05 [INFO ]  Epoch:   61	Loss: 0.6582	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:07 [INFO ]  Epoch:   62	Loss: 0.7029	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:20:09 [INFO ]  Epoch:   63	Loss: 0.6625	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:10 [INFO ]  Epoch:   64	Loss: 0.6718	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:12 [INFO ]  Epoch:   65	Loss: 0.6697	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:14 [INFO ]  Epoch:   66	Loss: 0.7272	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:16 [INFO ]  Epoch:   67	Loss: 0.6348	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:20:18 [INFO ]  Epoch:   68	Loss: 0.6575	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:20 [INFO ]  Epoch:   69	Loss: 0.6562	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:22 [INFO ]  Epoch:   70	Loss: 0.7261	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:20:24 [INFO ]  Epoch:   71	Loss: 0.6569	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:20:26 [INFO ]  Epoch:   72	Loss: 0.6603	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:20:27 [INFO ]  Epoch:   73	Loss: 0.7188	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:29 [INFO ]  Epoch:   74	Loss: 0.6265	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:20:31 [INFO ]  Epoch:   75	Loss: 0.6315	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:20:33 [INFO ]  Epoch:   76	Loss: 0.5898	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:35 [INFO ]  Epoch:   77	Loss: 0.6152	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:20:37 [INFO ]  Epoch:   78	Loss: 0.6419	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:20:38 [INFO ]  Epoch:   79	Loss: 0.6460	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:41 [INFO ]  Epoch:   80	Loss: 0.6406	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:42 [INFO ]  Epoch:   81	Loss: 0.6156	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:20:44 [INFO ]  Epoch:   82	Loss: 0.6614	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:20:46 [INFO ]  Epoch:   83	Loss: 0.6736	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:20:48 [INFO ]  Epoch:   84	Loss: 0.6551	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:50 [INFO ]  Epoch:   85	Loss: 0.6286	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:20:52 [INFO ]  Epoch:   86	Loss: 0.5916	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:20:54 [INFO ]  Epoch:   87	Loss: 0.6056	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:20:56 [INFO ]  Epoch:   88	Loss: 0.7634	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:20:57 [INFO ]  Epoch:   89	Loss: 0.6649	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:20:59 [INFO ]  Epoch:   90	Loss: 0.6551	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:21:01 [INFO ]  Epoch:   91	Loss: 0.5960	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:03 [INFO ]  Epoch:   92	Loss: 0.6289	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:05 [INFO ]  Epoch:   93	Loss: 0.6317	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:07 [INFO ]  Epoch:   94	Loss: 0.6461	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:21:09 [INFO ]  Epoch:   95	Loss: 0.6542	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:11 [INFO ]  Epoch:   96	Loss: 0.6368	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:13 [INFO ]  Epoch:   97	Loss: 0.6438	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:15 [INFO ]  Epoch:   98	Loss: 0.6408	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:21:16 [INFO ]  Epoch:   99	Loss: 0.6254	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:18 [INFO ]  Epoch:  100	Loss: 0.5952	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:20 [INFO ]  Epoch:  101	Loss: 0.6132	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:21:22 [INFO ]  Epoch:  102	Loss: 0.6216	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:24 [INFO ]  Epoch:  103	Loss: 0.6315	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:26 [INFO ]  Epoch:  104	Loss: 0.5784	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:28 [INFO ]  Epoch:  105	Loss: 0.6299	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:30 [INFO ]  Epoch:  106	Loss: 0.5944	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:32 [INFO ]  Epoch:  107	Loss: 0.7120	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:21:34 [INFO ]  Epoch:  108	Loss: 0.5930	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:36 [INFO ]  Epoch:  109	Loss: 0.6219	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:21:38 [INFO ]  Epoch:  110	Loss: 0.6806	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:21:40 [INFO ]  Epoch:  111	Loss: 0.6408	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:42 [INFO ]  Epoch:  112	Loss: 0.6734	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:44 [INFO ]  Epoch:  113	Loss: 0.6107	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:21:45 [INFO ]  Epoch:  114	Loss: 0.5635	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:47 [INFO ]  Epoch:  115	Loss: 0.5760	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:21:49 [INFO ]  Epoch:  116	Loss: 0.6866	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:21:51 [INFO ]  Epoch:  117	Loss: 0.6342	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:21:53 [INFO ]  Epoch:  118	Loss: 0.6330	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:55 [INFO ]  Epoch:  119	Loss: 0.6297	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:21:57 [INFO ]  Epoch:  120	Loss: 0.6311	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:21:59 [INFO ]  Epoch:  121	Loss: 0.6168	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:01 [INFO ]  Epoch:  122	Loss: 0.6098	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:22:02 [INFO ]  Epoch:  123	Loss: 0.5784	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:04 [INFO ]  Epoch:  124	Loss: 0.6265	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:22:06 [INFO ]  Epoch:  125	Loss: 0.6637	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:08 [INFO ]  Epoch:  126	Loss: 0.6215	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:10 [INFO ]  Epoch:  127	Loss: 0.5864	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:22:11 [INFO ]  Epoch:  128	Loss: 0.7202	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:13 [INFO ]  Epoch:  129	Loss: 0.6221	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:15 [INFO ]  Epoch:  130	Loss: 0.6830	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:17 [INFO ]  Epoch:  131	Loss: 0.6351	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:19 [INFO ]  Epoch:  132	Loss: 0.5948	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:21 [INFO ]  Epoch:  133	Loss: 0.7273	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:23 [INFO ]  Epoch:  134	Loss: 0.6247	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:25 [INFO ]  Epoch:  135	Loss: 0.5651	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:22:26 [INFO ]  Epoch:  136	Loss: 0.6725	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:28 [INFO ]  Epoch:  137	Loss: 0.6468	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:30 [INFO ]  Epoch:  138	Loss: 0.6676	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:32 [INFO ]  Epoch:  139	Loss: 0.6155	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:22:34 [INFO ]  Epoch:  140	Loss: 0.6255	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:22:36 [INFO ]  Epoch:  141	Loss: 0.6410	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:22:38 [INFO ]  Epoch:  142	Loss: 0.6448	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:40 [INFO ]  Epoch:  143	Loss: 0.6984	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:22:42 [INFO ]  Epoch:  144	Loss: 0.6715	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:44 [INFO ]  Epoch:  145	Loss: 0.6115	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:22:46 [INFO ]  Epoch:  146	Loss: 0.5894	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:48 [INFO ]  Epoch:  147	Loss: 0.7022	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:22:50 [INFO ]  Epoch:  148	Loss: 0.6354	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:22:52 [INFO ]  Epoch:  149	Loss: 0.6265	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:22:53 [INFO ]  Epoch:  150	Loss: 0.6300	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:22:56 [INFO ]  Epoch:  151	Loss: 0.6252	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:22:57 [INFO ]  Epoch:  152	Loss: 0.6116	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:22:59 [INFO ]  Epoch:  153	Loss: 0.6255	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:01 [INFO ]  Epoch:  154	Loss: 0.6141	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:03 [INFO ]  Epoch:  155	Loss: 0.6409	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:05 [INFO ]  Epoch:  156	Loss: 0.5808	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:23:07 [INFO ]  Epoch:  157	Loss: 0.6941	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 18:23:09 [INFO ]  Epoch:  158	Loss: 0.6220	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:23:10 [INFO ]  Epoch:  159	Loss: 0.5634	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:23:12 [INFO ]  Epoch:  160	Loss: 0.6049	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:23:14 [INFO ]  Epoch:  161	Loss: 0.6349	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:23:16 [INFO ]  Epoch:  162	Loss: 0.6515	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:23:18 [INFO ]  Epoch:  163	Loss: 0.6073	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:23:20 [INFO ]  Epoch:  164	Loss: 0.5249	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:23:22 [INFO ]  Epoch:  165	Loss: 0.7421	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:23:24 [INFO ]  Epoch:  166	Loss: 0.5710	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:23:26 [INFO ]  Epoch:  167	Loss: 0.6660	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:28 [INFO ]  Epoch:  168	Loss: 0.5976	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:23:29 [INFO ]  Epoch:  169	Loss: 0.6062	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:31 [INFO ]  Epoch:  170	Loss: 0.5758	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:33 [INFO ]  Epoch:  171	Loss: 0.6708	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:35 [INFO ]  Epoch:  172	Loss: 0.6832	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:23:37 [INFO ]  Epoch:  173	Loss: 0.6285	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:39 [INFO ]  Epoch:  174	Loss: 0.6634	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:23:41 [INFO ]  Epoch:  175	Loss: 0.6960	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:23:43 [INFO ]  Epoch:  176	Loss: 0.5986	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:23:45 [INFO ]  Epoch:  177	Loss: 0.6129	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:23:46 [INFO ]  Epoch:  178	Loss: 0.5640	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:49 [INFO ]  Epoch:  179	Loss: 0.5985	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:23:50 [INFO ]  Epoch:  180	Loss: 0.5872	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:23:52 [INFO ]  Epoch:  181	Loss: 0.6355	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:23:54 [INFO ]  Epoch:  182	Loss: 0.5652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:23:56 [INFO ]  Epoch:  183	Loss: 0.6146	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:23:58 [INFO ]  Epoch:  184	Loss: 0.6182	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:24:00 [INFO ]  Epoch:  185	Loss: 0.6552	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:24:02 [INFO ]  Epoch:  186	Loss: 0.5779	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:24:04 [INFO ]  Epoch:  187	Loss: 0.6070	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:06 [INFO ]  Epoch:  188	Loss: 0.6157	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:08 [INFO ]  Epoch:  189	Loss: 0.5930	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:10 [INFO ]  Epoch:  190	Loss: 0.6092	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:24:11 [INFO ]  Epoch:  191	Loss: 0.5841	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:13 [INFO ]  Epoch:  192	Loss: 0.6599	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:24:15 [INFO ]  Epoch:  193	Loss: 0.6158	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:17 [INFO ]  Epoch:  194	Loss: 0.6351	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:19 [INFO ]  Epoch:  195	Loss: 0.6986	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:24:21 [INFO ]  Epoch:  196	Loss: 0.6462	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:24:22 [INFO ]  Epoch:  197	Loss: 0.6570	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:24:24 [INFO ]  Epoch:  198	Loss: 0.7182	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:24:26 [INFO ]  Epoch:  199	Loss: 0.6042	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:24:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:24:27 [INFO ]  
2022-10-04 18:24:27 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:24:31 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:24:31 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:24:31 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:24:31 [INFO ]  	   step  1 (lr=0.374902)                   81.31%                   0.6926
2022-10-04 18:24:31 [INFO ]  
2022-10-04 18:24:31 [INFO ]  
2022-10-04 18:24:31 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:24:34 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:24:34 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:24:34 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:24:34 [INFO ]  	   step  1 (lr=0.374902)                   17.19%                   5.3181
2022-10-04 18:24:34 [INFO ]  
2022-10-04 18:24:34 [INFO ]  CPU Time: 3.50 minutes
2022-10-04 18:31:53 [INFO ]  ======================================== 2022-10-04 18:31:53 ========================================
2022-10-04 18:31:53 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:31:53 [INFO ]  Options: 
2022-10-04 18:31:53 [INFO ]  	base_dir: null
2022-10-04 18:31:53 [INFO ]  	batch_size: 1024
2022-10-04 18:31:53 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:31:53 [INFO ]  	dataset: SVHN
2022-10-04 18:31:53 [INFO ]  	dataset_labels:
2022-10-04 18:31:53 [INFO ]  	- 0
2022-10-04 18:31:53 [INFO ]  	- 1
2022-10-04 18:31:53 [INFO ]  	- 2
2022-10-04 18:31:53 [INFO ]  	- 3
2022-10-04 18:31:53 [INFO ]  	- 4
2022-10-04 18:31:53 [INFO ]  	- 5
2022-10-04 18:31:53 [INFO ]  	- 6
2022-10-04 18:31:53 [INFO ]  	- 7
2022-10-04 18:31:53 [INFO ]  	- 8
2022-10-04 18:31:53 [INFO ]  	- 9
2022-10-04 18:31:53 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:31:53 [INFO ]  	- !!python/tuple
2022-10-04 18:31:53 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:31:53 [INFO ]  	    - 0.44398033618927
2022-10-04 18:31:53 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:31:53 [INFO ]  	- !!python/tuple
2022-10-04 18:31:53 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:31:53 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:31:53 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:31:53 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:31:53 [INFO ]  	decay_epochs: 50
2022-10-04 18:31:53 [INFO ]  	decay_factor: 0.1
2022-10-04 18:31:53 [INFO ]  	device_id: 0
2022-10-04 18:31:53 [INFO ]  	distill_epochs: 1
2022-10-04 18:31:53 [INFO ]  	distill_lr: 0.02
2022-10-04 18:31:53 [INFO ]  	distill_steps: 1
2022-10-04 18:31:53 [INFO ]  	epochs: 200
2022-10-04 18:31:53 [INFO ]  	expand_cls: false
2022-10-04 18:31:53 [INFO ]  	forgetting_dataset: null
2022-10-04 18:31:53 [INFO ]  	init: xavier
2022-10-04 18:31:53 [INFO ]  	init_param: 1.0
2022-10-04 18:31:53 [INFO ]  	input_size: 32
2022-10-04 18:31:53 [INFO ]  	ipc: 10
2022-10-04 18:31:53 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:31:53 [INFO ]  	log_interval: 100
2022-10-04 18:31:53 [INFO ]  	log_level: INFO
2022-10-04 18:31:53 [INFO ]  	lr: 0.01
2022-10-04 18:31:53 [INFO ]  	mode: distill_adapt
2022-10-04 18:31:53 [INFO ]  	nc: 3
2022-10-04 18:31:53 [INFO ]  	num_classes: 10
2022-10-04 18:31:53 [INFO ]  	num_workers: 8
2022-10-04 18:31:53 [INFO ]  	phase: train
2022-10-04 18:31:53 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:31:53 [INFO ]  	start_time: '2022-10-04 18:31:53'
2022-10-04 18:31:53 [INFO ]  	test_batch_size: 1024
2022-10-04 18:31:53 [INFO ]  	
2022-10-04 18:31:55 [INFO ]  train dataset size:	73257
2022-10-04 18:31:55 [INFO ]  test dataset size: 	26032
2022-10-04 18:31:55 [INFO ]  datasets built!
2022-10-04 18:31:55 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:31:57 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:31:57 [INFO ]  
2022-10-04 18:31:57 [INFO ]  Begin of epoch 0 :
2022-10-04 18:32:00 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:32:00 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:32:00 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:32:00 [INFO ]  	   step  1 (lr=0.020000)                    6.85%                   9.1004
2022-10-04 18:32:00 [INFO ]  
2022-10-04 18:32:00 [INFO ]  Epoch:    0	Loss: 9.2987	Data Time: 0.45s	Train Time: 0.03s
2022-10-04 18:32:02 [INFO ]  Epoch:    1	Loss: 2.9180	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:32:04 [INFO ]  Epoch:    2	Loss: 2.5074	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:32:06 [INFO ]  Epoch:    3	Loss: 2.2787	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:32:07 [INFO ]  Epoch:    4	Loss: 2.1963	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:09 [INFO ]  Epoch:    5	Loss: 2.1780	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:11 [INFO ]  Epoch:    6	Loss: 2.1277	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:32:13 [INFO ]  Epoch:    7	Loss: 2.1352	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:32:15 [INFO ]  Epoch:    8	Loss: 2.0640	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:32:17 [INFO ]  Epoch:    9	Loss: 1.9776	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:32:18 [INFO ]  Epoch:   10	Loss: 1.8864	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:32:20 [INFO ]  Epoch:   11	Loss: 1.7731	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:32:22 [INFO ]  Epoch:   12	Loss: 1.6169	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:32:24 [INFO ]  Epoch:   13	Loss: 1.5408	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:32:26 [INFO ]  Epoch:   14	Loss: 1.4140	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:32:27 [INFO ]  Epoch:   15	Loss: 1.4303	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:32:29 [INFO ]  Epoch:   16	Loss: 1.2213	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:32:31 [INFO ]  Epoch:   17	Loss: 1.2299	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:32:33 [INFO ]  Epoch:   18	Loss: 1.2238	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:32:35 [INFO ]  Epoch:   19	Loss: 1.1434	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:37 [INFO ]  Epoch:   20	Loss: 1.0751	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:32:39 [INFO ]  Epoch:   21	Loss: 1.0546	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:32:41 [INFO ]  Epoch:   22	Loss: 1.0046	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:32:42 [INFO ]  Epoch:   23	Loss: 0.9522	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:32:44 [INFO ]  Epoch:   24	Loss: 1.0172	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:32:46 [INFO ]  Epoch:   25	Loss: 0.9323	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:32:48 [INFO ]  Epoch:   26	Loss: 0.9453	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:32:49 [INFO ]  Epoch:   27	Loss: 0.9562	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:32:51 [INFO ]  Epoch:   28	Loss: 1.0526	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:53 [INFO ]  Epoch:   29	Loss: 1.0480	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:55 [INFO ]  Epoch:   30	Loss: 0.8419	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:32:57 [INFO ]  Epoch:   31	Loss: 0.8462	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:32:58 [INFO ]  Epoch:   32	Loss: 0.8530	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:00 [INFO ]  Epoch:   33	Loss: 0.9723	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:02 [INFO ]  Epoch:   34	Loss: 0.8131	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:33:04 [INFO ]  Epoch:   35	Loss: 0.8226	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:05 [INFO ]  Epoch:   36	Loss: 0.8977	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:08 [INFO ]  Epoch:   37	Loss: 0.8227	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:09 [INFO ]  Epoch:   38	Loss: 0.8260	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:33:11 [INFO ]  Epoch:   39	Loss: 0.7177	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:13 [INFO ]  Epoch:   40	Loss: 0.6856	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:33:15 [INFO ]  Epoch:   41	Loss: 0.8524	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:17 [INFO ]  Epoch:   42	Loss: 0.7925	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:19 [INFO ]  Epoch:   43	Loss: 0.8067	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:33:20 [INFO ]  Epoch:   44	Loss: 0.7030	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:33:22 [INFO ]  Epoch:   45	Loss: 0.8655	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:24 [INFO ]  Epoch:   46	Loss: 0.7292	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:26 [INFO ]  Epoch:   47	Loss: 0.7297	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:28 [INFO ]  Epoch:   48	Loss: 0.6689	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:33:30 [INFO ]  Epoch:   49	Loss: 0.7977	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:32 [INFO ]  Epoch:   50	Loss: 0.6107	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:33 [INFO ]  Epoch:   51	Loss: 0.7163	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:35 [INFO ]  Epoch:   52	Loss: 0.6815	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:37 [INFO ]  Epoch:   53	Loss: 0.7321	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:39 [INFO ]  Epoch:   54	Loss: 0.7224	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:33:41 [INFO ]  Epoch:   55	Loss: 0.7553	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:33:42 [INFO ]  Epoch:   56	Loss: 0.6700	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:33:44 [INFO ]  Epoch:   57	Loss: 0.6404	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:46 [INFO ]  Epoch:   58	Loss: 0.6980	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:48 [INFO ]  Epoch:   59	Loss: 0.6710	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:33:50 [INFO ]  Epoch:   60	Loss: 0.7327	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:33:51 [INFO ]  Epoch:   61	Loss: 0.6629	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:33:53 [INFO ]  Epoch:   62	Loss: 0.6555	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:55 [INFO ]  Epoch:   63	Loss: 0.6921	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:33:57 [INFO ]  Epoch:   64	Loss: 0.6751	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:33:59 [INFO ]  Epoch:   65	Loss: 0.6845	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:01 [INFO ]  Epoch:   66	Loss: 0.7203	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:02 [INFO ]  Epoch:   67	Loss: 0.5724	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:04 [INFO ]  Epoch:   68	Loss: 0.6974	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:06 [INFO ]  Epoch:   69	Loss: 0.6285	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:08 [INFO ]  Epoch:   70	Loss: 0.6809	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:10 [INFO ]  Epoch:   71	Loss: 0.6315	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:34:12 [INFO ]  Epoch:   72	Loss: 0.6649	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:34:14 [INFO ]  Epoch:   73	Loss: 0.6426	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:15 [INFO ]  Epoch:   74	Loss: 0.6529	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:34:17 [INFO ]  Epoch:   75	Loss: 0.6752	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:19 [INFO ]  Epoch:   76	Loss: 0.6542	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:21 [INFO ]  Epoch:   77	Loss: 0.7423	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:23 [INFO ]  Epoch:   78	Loss: 0.6758	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:34:25 [INFO ]  Epoch:   79	Loss: 0.7122	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:27 [INFO ]  Epoch:   80	Loss: 0.6872	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:29 [INFO ]  Epoch:   81	Loss: 0.6631	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:34:30 [INFO ]  Epoch:   82	Loss: 0.6861	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:34:32 [INFO ]  Epoch:   83	Loss: 0.6610	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:34:34 [INFO ]  Epoch:   84	Loss: 0.6317	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:36 [INFO ]  Epoch:   85	Loss: 0.6434	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:38 [INFO ]  Epoch:   86	Loss: 0.6144	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:39 [INFO ]  Epoch:   87	Loss: 0.5772	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:34:41 [INFO ]  Epoch:   88	Loss: 0.6256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:43 [INFO ]  Epoch:   89	Loss: 0.6382	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:34:45 [INFO ]  Epoch:   90	Loss: 0.6981	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:47 [INFO ]  Epoch:   91	Loss: 0.6858	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:34:49 [INFO ]  Epoch:   92	Loss: 0.7135	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:34:50 [INFO ]  Epoch:   93	Loss: 0.6124	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:34:52 [INFO ]  Epoch:   94	Loss: 0.7139	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:34:54 [INFO ]  Epoch:   95	Loss: 0.5815	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:34:56 [INFO ]  Epoch:   96	Loss: 0.6029	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:34:58 [INFO ]  Epoch:   97	Loss: 0.6970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:00 [INFO ]  Epoch:   98	Loss: 0.6860	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:35:01 [INFO ]  Epoch:   99	Loss: 0.6824	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:03 [INFO ]  Epoch:  100	Loss: 0.6260	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:05 [INFO ]  Epoch:  101	Loss: 0.5925	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:35:07 [INFO ]  Epoch:  102	Loss: 0.6298	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:35:09 [INFO ]  Epoch:  103	Loss: 0.6876	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:35:11 [INFO ]  Epoch:  104	Loss: 0.6081	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:13 [INFO ]  Epoch:  105	Loss: 0.5588	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:35:15 [INFO ]  Epoch:  106	Loss: 0.6087	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:35:17 [INFO ]  Epoch:  107	Loss: 0.6249	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:19 [INFO ]  Epoch:  108	Loss: 0.6345	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:21 [INFO ]  Epoch:  109	Loss: 0.6358	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:22 [INFO ]  Epoch:  110	Loss: 0.6536	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:24 [INFO ]  Epoch:  111	Loss: 0.7016	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:35:26 [INFO ]  Epoch:  112	Loss: 0.5874	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:35:28 [INFO ]  Epoch:  113	Loss: 0.6288	Data Time: 0.25s	Train Time: 0.00s
2022-10-04 18:35:30 [INFO ]  Epoch:  114	Loss: 0.7138	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:32 [INFO ]  Epoch:  115	Loss: 0.6019	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:34 [INFO ]  Epoch:  116	Loss: 0.6668	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:35:35 [INFO ]  Epoch:  117	Loss: 0.5859	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:35:37 [INFO ]  Epoch:  118	Loss: 0.6478	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:35:39 [INFO ]  Epoch:  119	Loss: 0.6705	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:35:41 [INFO ]  Epoch:  120	Loss: 0.6943	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:35:43 [INFO ]  Epoch:  121	Loss: 0.6668	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:35:45 [INFO ]  Epoch:  122	Loss: 0.6551	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:47 [INFO ]  Epoch:  123	Loss: 0.6047	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:35:49 [INFO ]  Epoch:  124	Loss: 0.6526	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:35:51 [INFO ]  Epoch:  125	Loss: 0.6534	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:53 [INFO ]  Epoch:  126	Loss: 0.6446	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:35:54 [INFO ]  Epoch:  127	Loss: 0.6289	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:35:56 [INFO ]  Epoch:  128	Loss: 0.6653	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:35:58 [INFO ]  Epoch:  129	Loss: 0.5765	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:36:00 [INFO ]  Epoch:  130	Loss: 0.6596	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:36:02 [INFO ]  Epoch:  131	Loss: 0.7036	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:04 [INFO ]  Epoch:  132	Loss: 0.6647	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:36:05 [INFO ]  Epoch:  133	Loss: 0.6180	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:07 [INFO ]  Epoch:  134	Loss: 0.6710	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:09 [INFO ]  Epoch:  135	Loss: 0.7086	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:36:11 [INFO ]  Epoch:  136	Loss: 0.6174	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:36:13 [INFO ]  Epoch:  137	Loss: 0.6008	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:14 [INFO ]  Epoch:  138	Loss: 0.6766	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:36:16 [INFO ]  Epoch:  139	Loss: 0.6198	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:36:18 [INFO ]  Epoch:  140	Loss: 0.6259	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:36:20 [INFO ]  Epoch:  141	Loss: 0.6601	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:22 [INFO ]  Epoch:  142	Loss: 0.6717	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:24 [INFO ]  Epoch:  143	Loss: 0.6328	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:26 [INFO ]  Epoch:  144	Loss: 0.6141	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:36:28 [INFO ]  Epoch:  145	Loss: 0.6045	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:36:29 [INFO ]  Epoch:  146	Loss: 0.7524	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:31 [INFO ]  Epoch:  147	Loss: 0.6340	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:33 [INFO ]  Epoch:  148	Loss: 0.6797	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:36:35 [INFO ]  Epoch:  149	Loss: 0.6256	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:37 [INFO ]  Epoch:  150	Loss: 0.6434	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:38 [INFO ]  Epoch:  151	Loss: 0.6228	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:36:40 [INFO ]  Epoch:  152	Loss: 0.6500	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:36:42 [INFO ]  Epoch:  153	Loss: 0.7152	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:44 [INFO ]  Epoch:  154	Loss: 0.6363	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:36:46 [INFO ]  Epoch:  155	Loss: 0.7611	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:36:48 [INFO ]  Epoch:  156	Loss: 0.7279	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:36:49 [INFO ]  Epoch:  157	Loss: 0.6140	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:36:52 [INFO ]  Epoch:  158	Loss: 0.5616	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:36:53 [INFO ]  Epoch:  159	Loss: 0.7260	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:36:55 [INFO ]  Epoch:  160	Loss: 0.6006	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:36:57 [INFO ]  Epoch:  161	Loss: 0.6448	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:36:59 [INFO ]  Epoch:  162	Loss: 0.6315	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:01 [INFO ]  Epoch:  163	Loss: 0.6490	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:37:03 [INFO ]  Epoch:  164	Loss: 0.6490	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:05 [INFO ]  Epoch:  165	Loss: 0.5982	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:07 [INFO ]  Epoch:  166	Loss: 0.6360	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:37:09 [INFO ]  Epoch:  167	Loss: 0.6261	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:37:11 [INFO ]  Epoch:  168	Loss: 0.6358	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:13 [INFO ]  Epoch:  169	Loss: 0.6569	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:37:14 [INFO ]  Epoch:  170	Loss: 0.6815	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:16 [INFO ]  Epoch:  171	Loss: 0.6561	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:18 [INFO ]  Epoch:  172	Loss: 0.6098	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:20 [INFO ]  Epoch:  173	Loss: 0.6941	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:37:22 [INFO ]  Epoch:  174	Loss: 0.7106	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:23 [INFO ]  Epoch:  175	Loss: 0.6217	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:26 [INFO ]  Epoch:  176	Loss: 0.7097	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:27 [INFO ]  Epoch:  177	Loss: 0.5936	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:37:29 [INFO ]  Epoch:  178	Loss: 0.5890	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:31 [INFO ]  Epoch:  179	Loss: 0.6495	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:37:32 [INFO ]  Epoch:  180	Loss: 0.6661	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:34 [INFO ]  Epoch:  181	Loss: 0.5811	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:36 [INFO ]  Epoch:  182	Loss: 0.6019	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:38 [INFO ]  Epoch:  183	Loss: 0.6087	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:37:40 [INFO ]  Epoch:  184	Loss: 0.7160	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:37:42 [INFO ]  Epoch:  185	Loss: 0.6652	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:37:44 [INFO ]  Epoch:  186	Loss: 0.7237	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:37:46 [INFO ]  Epoch:  187	Loss: 0.6304	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:37:47 [INFO ]  Epoch:  188	Loss: 0.6662	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:37:49 [INFO ]  Epoch:  189	Loss: 0.6698	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:37:51 [INFO ]  Epoch:  190	Loss: 0.6052	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:53 [INFO ]  Epoch:  191	Loss: 0.6116	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:37:55 [INFO ]  Epoch:  192	Loss: 0.6827	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:37:56 [INFO ]  Epoch:  193	Loss: 0.6472	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:37:58 [INFO ]  Epoch:  194	Loss: 0.6738	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:38:00 [INFO ]  Epoch:  195	Loss: 0.6213	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:38:02 [INFO ]  Epoch:  196	Loss: 0.5929	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:38:03 [INFO ]  Epoch:  197	Loss: 0.6144	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:38:05 [INFO ]  Epoch:  198	Loss: 0.6485	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:38:07 [INFO ]  Epoch:  199	Loss: 0.6065	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:38:09 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:38:09 [INFO ]  
2022-10-04 18:38:09 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:38:12 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:38:12 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:38:12 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:38:12 [INFO ]  	   step  1 (lr=0.347174)                   80.70%                   0.7040
2022-10-04 18:38:12 [INFO ]  
2022-10-04 18:38:12 [INFO ]  
2022-10-04 18:38:12 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:38:15 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:38:15 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:38:15 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:38:15 [INFO ]  	   step  1 (lr=0.347174)                   15.74%                   5.1898
2022-10-04 18:38:15 [INFO ]  
2022-10-04 18:38:15 [INFO ]  CPU Time: 3.40 minutes
2022-10-04 18:38:30 [INFO ]  ======================================== 2022-10-04 18:38:30 ========================================
2022-10-04 18:38:30 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:38:30 [INFO ]  Options: 
2022-10-04 18:38:30 [INFO ]  	base_dir: null
2022-10-04 18:38:30 [INFO ]  	batch_size: 1024
2022-10-04 18:38:30 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:38:30 [INFO ]  	dataset: SVHN
2022-10-04 18:38:30 [INFO ]  	dataset_labels:
2022-10-04 18:38:30 [INFO ]  	- 0
2022-10-04 18:38:30 [INFO ]  	- 1
2022-10-04 18:38:30 [INFO ]  	- 2
2022-10-04 18:38:30 [INFO ]  	- 3
2022-10-04 18:38:30 [INFO ]  	- 4
2022-10-04 18:38:30 [INFO ]  	- 5
2022-10-04 18:38:30 [INFO ]  	- 6
2022-10-04 18:38:30 [INFO ]  	- 7
2022-10-04 18:38:30 [INFO ]  	- 8
2022-10-04 18:38:30 [INFO ]  	- 9
2022-10-04 18:38:30 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:38:30 [INFO ]  	- !!python/tuple
2022-10-04 18:38:30 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:38:30 [INFO ]  	    - 0.44398033618927
2022-10-04 18:38:30 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:38:30 [INFO ]  	- !!python/tuple
2022-10-04 18:38:30 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:38:30 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:38:30 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:38:30 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:38:30 [INFO ]  	decay_epochs: 50
2022-10-04 18:38:30 [INFO ]  	decay_factor: 0.1
2022-10-04 18:38:30 [INFO ]  	device_id: 0
2022-10-04 18:38:30 [INFO ]  	distill_epochs: 1
2022-10-04 18:38:30 [INFO ]  	distill_lr: 0.02
2022-10-04 18:38:30 [INFO ]  	distill_steps: 1
2022-10-04 18:38:30 [INFO ]  	epochs: 200
2022-10-04 18:38:30 [INFO ]  	expand_cls: false
2022-10-04 18:38:30 [INFO ]  	forgetting_dataset: null
2022-10-04 18:38:30 [INFO ]  	init: xavier
2022-10-04 18:38:30 [INFO ]  	init_param: 1.0
2022-10-04 18:38:30 [INFO ]  	input_size: 32
2022-10-04 18:38:30 [INFO ]  	ipc: 10
2022-10-04 18:38:30 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:38:30 [INFO ]  	log_interval: 100
2022-10-04 18:38:30 [INFO ]  	log_level: INFO
2022-10-04 18:38:30 [INFO ]  	lr: 0.01
2022-10-04 18:38:30 [INFO ]  	mode: distill_adapt
2022-10-04 18:38:30 [INFO ]  	nc: 3
2022-10-04 18:38:30 [INFO ]  	num_classes: 10
2022-10-04 18:38:30 [INFO ]  	num_workers: 8
2022-10-04 18:38:30 [INFO ]  	phase: train
2022-10-04 18:38:30 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:38:30 [INFO ]  	start_time: '2022-10-04 18:38:30'
2022-10-04 18:38:30 [INFO ]  	test_batch_size: 1024
2022-10-04 18:38:30 [INFO ]  	
2022-10-04 18:38:32 [INFO ]  train dataset size:	73257
2022-10-04 18:38:32 [INFO ]  test dataset size: 	26032
2022-10-04 18:38:32 [INFO ]  datasets built!
2022-10-04 18:38:32 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:38:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:38:34 [INFO ]  
2022-10-04 18:38:34 [INFO ]  Begin of epoch 0 :
2022-10-04 18:38:37 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:38:37 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:38:37 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:38:37 [INFO ]  	   step  1 (lr=0.020000)                    6.83%                   9.5251
2022-10-04 18:38:37 [INFO ]  
2022-10-04 18:38:37 [INFO ]  Epoch:    0	Loss: 9.4128	Data Time: 0.42s	Train Time: 0.04s
2022-10-04 18:38:39 [INFO ]  Epoch:    1	Loss: 3.1256	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:38:41 [INFO ]  Epoch:    2	Loss: 2.5615	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:38:43 [INFO ]  Epoch:    3	Loss: 2.3745	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:38:44 [INFO ]  Epoch:    4	Loss: 2.2192	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:38:46 [INFO ]  Epoch:    5	Loss: 2.1796	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:38:48 [INFO ]  Epoch:    6	Loss: 2.1811	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:38:50 [INFO ]  Epoch:    7	Loss: 2.1447	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:38:52 [INFO ]  Epoch:    8	Loss: 2.1388	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:38:54 [INFO ]  Epoch:    9	Loss: 2.0276	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:38:55 [INFO ]  Epoch:   10	Loss: 1.9298	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:38:57 [INFO ]  Epoch:   11	Loss: 1.8791	Data Time: 0.16s	Train Time: 0.02s
2022-10-04 18:38:59 [INFO ]  Epoch:   12	Loss: 1.6814	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:39:01 [INFO ]  Epoch:   13	Loss: 1.6031	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:39:03 [INFO ]  Epoch:   14	Loss: 1.3337	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:39:05 [INFO ]  Epoch:   15	Loss: 1.3850	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:39:06 [INFO ]  Epoch:   16	Loss: 1.2368	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:08 [INFO ]  Epoch:   17	Loss: 1.1846	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:39:10 [INFO ]  Epoch:   18	Loss: 1.1095	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:12 [INFO ]  Epoch:   19	Loss: 1.0430	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:14 [INFO ]  Epoch:   20	Loss: 1.1612	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:39:16 [INFO ]  Epoch:   21	Loss: 1.1900	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:39:18 [INFO ]  Epoch:   22	Loss: 1.0207	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:20 [INFO ]  Epoch:   23	Loss: 1.0330	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:39:22 [INFO ]  Epoch:   24	Loss: 0.9818	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:39:23 [INFO ]  Epoch:   25	Loss: 0.9152	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:39:25 [INFO ]  Epoch:   26	Loss: 0.9381	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:39:27 [INFO ]  Epoch:   27	Loss: 0.9819	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:29 [INFO ]  Epoch:   28	Loss: 0.8544	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:39:31 [INFO ]  Epoch:   29	Loss: 0.9523	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:33 [INFO ]  Epoch:   30	Loss: 0.8256	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:39:35 [INFO ]  Epoch:   31	Loss: 0.8347	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:39:36 [INFO ]  Epoch:   32	Loss: 0.8340	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:38 [INFO ]  Epoch:   33	Loss: 0.8464	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:40 [INFO ]  Epoch:   34	Loss: 0.7503	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:42 [INFO ]  Epoch:   35	Loss: 0.9368	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:39:44 [INFO ]  Epoch:   36	Loss: 0.8170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:46 [INFO ]  Epoch:   37	Loss: 0.7350	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:47 [INFO ]  Epoch:   38	Loss: 0.8192	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:39:49 [INFO ]  Epoch:   39	Loss: 0.8000	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:51 [INFO ]  Epoch:   40	Loss: 0.8222	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:53 [INFO ]  Epoch:   41	Loss: 0.7948	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:39:55 [INFO ]  Epoch:   42	Loss: 0.9209	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:39:57 [INFO ]  Epoch:   43	Loss: 0.8485	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:39:58 [INFO ]  Epoch:   44	Loss: 0.7732	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:00 [INFO ]  Epoch:   45	Loss: 0.7502	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:02 [INFO ]  Epoch:   46	Loss: 0.7037	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:40:04 [INFO ]  Epoch:   47	Loss: 0.7313	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:40:06 [INFO ]  Epoch:   48	Loss: 0.7337	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:08 [INFO ]  Epoch:   49	Loss: 0.8216	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:40:10 [INFO ]  Epoch:   50	Loss: 0.7052	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:40:11 [INFO ]  Epoch:   51	Loss: 0.6354	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:13 [INFO ]  Epoch:   52	Loss: 0.7655	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:40:15 [INFO ]  Epoch:   53	Loss: 0.6364	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:17 [INFO ]  Epoch:   54	Loss: 0.6854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:19 [INFO ]  Epoch:   55	Loss: 0.7662	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:40:21 [INFO ]  Epoch:   56	Loss: 0.7282	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:40:23 [INFO ]  Epoch:   57	Loss: 0.6804	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:25 [INFO ]  Epoch:   58	Loss: 0.6874	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:40:26 [INFO ]  Epoch:   59	Loss: 0.6898	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:40:28 [INFO ]  Epoch:   60	Loss: 0.7594	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:30 [INFO ]  Epoch:   61	Loss: 0.7119	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:32 [INFO ]  Epoch:   62	Loss: 0.6307	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:34 [INFO ]  Epoch:   63	Loss: 0.6906	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:40:35 [INFO ]  Epoch:   64	Loss: 0.6712	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:40:37 [INFO ]  Epoch:   65	Loss: 0.6705	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:39 [INFO ]  Epoch:   66	Loss: 0.6332	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:40:41 [INFO ]  Epoch:   67	Loss: 0.7032	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:40:43 [INFO ]  Epoch:   68	Loss: 0.6021	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:40:45 [INFO ]  Epoch:   69	Loss: 0.7126	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:40:47 [INFO ]  Epoch:   70	Loss: 0.6832	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:40:48 [INFO ]  Epoch:   71	Loss: 0.6171	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:40:50 [INFO ]  Epoch:   72	Loss: 0.6225	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:40:52 [INFO ]  Epoch:   73	Loss: 0.6718	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:54 [INFO ]  Epoch:   74	Loss: 0.7123	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:56 [INFO ]  Epoch:   75	Loss: 0.7753	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:58 [INFO ]  Epoch:   76	Loss: 0.7354	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:40:59 [INFO ]  Epoch:   77	Loss: 0.7154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:01 [INFO ]  Epoch:   78	Loss: 0.6558	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:03 [INFO ]  Epoch:   79	Loss: 0.6814	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:05 [INFO ]  Epoch:   80	Loss: 0.7216	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:41:07 [INFO ]  Epoch:   81	Loss: 0.6629	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:41:08 [INFO ]  Epoch:   82	Loss: 0.6241	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:10 [INFO ]  Epoch:   83	Loss: 0.6302	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:41:12 [INFO ]  Epoch:   84	Loss: 0.6895	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:14 [INFO ]  Epoch:   85	Loss: 0.7035	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:41:16 [INFO ]  Epoch:   86	Loss: 0.6097	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:18 [INFO ]  Epoch:   87	Loss: 0.6349	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:41:19 [INFO ]  Epoch:   88	Loss: 0.6805	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:21 [INFO ]  Epoch:   89	Loss: 0.7261	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:41:23 [INFO ]  Epoch:   90	Loss: 0.7995	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:41:25 [INFO ]  Epoch:   91	Loss: 0.6948	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:27 [INFO ]  Epoch:   92	Loss: 0.6566	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:41:28 [INFO ]  Epoch:   93	Loss: 0.6747	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:41:30 [INFO ]  Epoch:   94	Loss: 0.6606	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:41:32 [INFO ]  Epoch:   95	Loss: 0.6104	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:41:34 [INFO ]  Epoch:   96	Loss: 0.6400	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:41:36 [INFO ]  Epoch:   97	Loss: 0.6997	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:38 [INFO ]  Epoch:   98	Loss: 0.6995	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:39 [INFO ]  Epoch:   99	Loss: 0.6269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:41 [INFO ]  Epoch:  100	Loss: 0.5921	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:41:43 [INFO ]  Epoch:  101	Loss: 0.6547	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:41:45 [INFO ]  Epoch:  102	Loss: 0.7192	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:47 [INFO ]  Epoch:  103	Loss: 0.7485	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:49 [INFO ]  Epoch:  104	Loss: 0.7234	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:51 [INFO ]  Epoch:  105	Loss: 0.6946	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:52 [INFO ]  Epoch:  106	Loss: 0.6806	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:41:54 [INFO ]  Epoch:  107	Loss: 0.6246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:41:56 [INFO ]  Epoch:  108	Loss: 0.6878	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:41:58 [INFO ]  Epoch:  109	Loss: 0.6578	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:42:00 [INFO ]  Epoch:  110	Loss: 0.6189	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:02 [INFO ]  Epoch:  111	Loss: 0.6769	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:04 [INFO ]  Epoch:  112	Loss: 0.6763	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:06 [INFO ]  Epoch:  113	Loss: 0.6893	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:42:07 [INFO ]  Epoch:  114	Loss: 0.5857	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:09 [INFO ]  Epoch:  115	Loss: 0.7034	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:42:11 [INFO ]  Epoch:  116	Loss: 0.6429	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:42:13 [INFO ]  Epoch:  117	Loss: 0.5992	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:15 [INFO ]  Epoch:  118	Loss: 0.6330	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:42:17 [INFO ]  Epoch:  119	Loss: 0.6688	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:42:18 [INFO ]  Epoch:  120	Loss: 0.6878	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:42:20 [INFO ]  Epoch:  121	Loss: 0.5626	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:22 [INFO ]  Epoch:  122	Loss: 0.6012	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:24 [INFO ]  Epoch:  123	Loss: 0.5993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:26 [INFO ]  Epoch:  124	Loss: 0.6406	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:42:28 [INFO ]  Epoch:  125	Loss: 0.5856	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:30 [INFO ]  Epoch:  126	Loss: 0.5851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:32 [INFO ]  Epoch:  127	Loss: 0.6006	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:42:34 [INFO ]  Epoch:  128	Loss: 0.6488	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:36 [INFO ]  Epoch:  129	Loss: 0.5985	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:42:38 [INFO ]  Epoch:  130	Loss: 0.6440	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:40 [INFO ]  Epoch:  131	Loss: 0.6556	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:42:41 [INFO ]  Epoch:  132	Loss: 0.6317	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:42:43 [INFO ]  Epoch:  133	Loss: 0.6466	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:42:45 [INFO ]  Epoch:  134	Loss: 0.6409	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:42:47 [INFO ]  Epoch:  135	Loss: 0.6451	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:49 [INFO ]  Epoch:  136	Loss: 0.5667	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:51 [INFO ]  Epoch:  137	Loss: 0.7250	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:53 [INFO ]  Epoch:  138	Loss: 0.6496	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:42:55 [INFO ]  Epoch:  139	Loss: 0.6427	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:42:57 [INFO ]  Epoch:  140	Loss: 0.6725	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:42:59 [INFO ]  Epoch:  141	Loss: 0.6542	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:43:00 [INFO ]  Epoch:  142	Loss: 0.6260	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:43:02 [INFO ]  Epoch:  143	Loss: 0.6634	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:04 [INFO ]  Epoch:  144	Loss: 0.6221	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:43:06 [INFO ]  Epoch:  145	Loss: 0.5780	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:43:08 [INFO ]  Epoch:  146	Loss: 0.7022	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:43:10 [INFO ]  Epoch:  147	Loss: 0.6123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:12 [INFO ]  Epoch:  148	Loss: 0.6633	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:43:13 [INFO ]  Epoch:  149	Loss: 0.5705	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:15 [INFO ]  Epoch:  150	Loss: 0.5985	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:43:17 [INFO ]  Epoch:  151	Loss: 0.6572	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:43:19 [INFO ]  Epoch:  152	Loss: 0.6516	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:43:21 [INFO ]  Epoch:  153	Loss: 0.6295	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:43:23 [INFO ]  Epoch:  154	Loss: 0.6723	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:25 [INFO ]  Epoch:  155	Loss: 0.5705	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:43:27 [INFO ]  Epoch:  156	Loss: 0.6751	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:43:29 [INFO ]  Epoch:  157	Loss: 0.6372	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:31 [INFO ]  Epoch:  158	Loss: 0.7180	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:43:33 [INFO ]  Epoch:  159	Loss: 0.6577	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:43:34 [INFO ]  Epoch:  160	Loss: 0.6483	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:43:36 [INFO ]  Epoch:  161	Loss: 0.5824	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:43:38 [INFO ]  Epoch:  162	Loss: 0.6850	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:40 [INFO ]  Epoch:  163	Loss: 0.6717	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:43:42 [INFO ]  Epoch:  164	Loss: 0.5418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:44 [INFO ]  Epoch:  165	Loss: 0.6271	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:43:46 [INFO ]  Epoch:  166	Loss: 0.6124	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:43:47 [INFO ]  Epoch:  167	Loss: 0.6003	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:43:49 [INFO ]  Epoch:  168	Loss: 0.6610	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:43:51 [INFO ]  Epoch:  169	Loss: 0.6611	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:43:53 [INFO ]  Epoch:  170	Loss: 0.6265	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:43:54 [INFO ]  Epoch:  171	Loss: 0.5854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:43:56 [INFO ]  Epoch:  172	Loss: 0.6200	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:43:58 [INFO ]  Epoch:  173	Loss: 0.5737	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:44:00 [INFO ]  Epoch:  174	Loss: 0.7016	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:02 [INFO ]  Epoch:  175	Loss: 0.6583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:04 [INFO ]  Epoch:  176	Loss: 0.6850	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:44:06 [INFO ]  Epoch:  177	Loss: 0.6959	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:44:08 [INFO ]  Epoch:  178	Loss: 0.6109	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:10 [INFO ]  Epoch:  179	Loss: 0.5557	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:12 [INFO ]  Epoch:  180	Loss: 0.6381	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:14 [INFO ]  Epoch:  181	Loss: 0.6152	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:44:15 [INFO ]  Epoch:  182	Loss: 0.6109	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:44:17 [INFO ]  Epoch:  183	Loss: 0.6664	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:19 [INFO ]  Epoch:  184	Loss: 0.6763	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:44:21 [INFO ]  Epoch:  185	Loss: 0.5543	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:44:23 [INFO ]  Epoch:  186	Loss: 0.6395	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 18:44:25 [INFO ]  Epoch:  187	Loss: 0.6246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:27 [INFO ]  Epoch:  188	Loss: 0.6039	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:29 [INFO ]  Epoch:  189	Loss: 0.6514	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:44:31 [INFO ]  Epoch:  190	Loss: 0.6433	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:44:32 [INFO ]  Epoch:  191	Loss: 0.5950	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:34 [INFO ]  Epoch:  192	Loss: 0.6183	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:44:36 [INFO ]  Epoch:  193	Loss: 0.6924	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:44:38 [INFO ]  Epoch:  194	Loss: 0.5920	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:44:40 [INFO ]  Epoch:  195	Loss: 0.6342	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:44:42 [INFO ]  Epoch:  196	Loss: 0.5733	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:44:44 [INFO ]  Epoch:  197	Loss: 0.6903	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:45 [INFO ]  Epoch:  198	Loss: 0.6777	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:44:47 [INFO ]  Epoch:  199	Loss: 0.6814	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:44:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:44:49 [INFO ]  
2022-10-04 18:44:49 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:44:52 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:44:52 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:44:52 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:44:52 [INFO ]  	   step  1 (lr=0.353336)                   80.05%                   0.7328
2022-10-04 18:44:52 [INFO ]  
2022-10-04 18:44:52 [INFO ]  
2022-10-04 18:44:52 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:44:55 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:44:55 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:44:55 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:44:55 [INFO ]  	   step  1 (lr=0.353336)                   18.14%                   5.3372
2022-10-04 18:44:55 [INFO ]  
2022-10-04 18:44:55 [INFO ]  CPU Time: 3.42 minutes
2022-10-04 18:45:13 [INFO ]  ======================================== 2022-10-04 18:45:13 ========================================
2022-10-04 18:45:13 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:45:13 [INFO ]  Options: 
2022-10-04 18:45:13 [INFO ]  	base_dir: null
2022-10-04 18:45:13 [INFO ]  	batch_size: 1024
2022-10-04 18:45:13 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:45:13 [INFO ]  	dataset: SVHN
2022-10-04 18:45:13 [INFO ]  	dataset_labels:
2022-10-04 18:45:13 [INFO ]  	- 0
2022-10-04 18:45:13 [INFO ]  	- 1
2022-10-04 18:45:13 [INFO ]  	- 2
2022-10-04 18:45:13 [INFO ]  	- 3
2022-10-04 18:45:13 [INFO ]  	- 4
2022-10-04 18:45:13 [INFO ]  	- 5
2022-10-04 18:45:13 [INFO ]  	- 6
2022-10-04 18:45:13 [INFO ]  	- 7
2022-10-04 18:45:13 [INFO ]  	- 8
2022-10-04 18:45:13 [INFO ]  	- 9
2022-10-04 18:45:13 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:45:13 [INFO ]  	- !!python/tuple
2022-10-04 18:45:13 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:45:13 [INFO ]  	    - 0.44398033618927
2022-10-04 18:45:13 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:45:13 [INFO ]  	- !!python/tuple
2022-10-04 18:45:13 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:45:13 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:45:13 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:45:13 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:45:13 [INFO ]  	decay_epochs: 50
2022-10-04 18:45:13 [INFO ]  	decay_factor: 0.1
2022-10-04 18:45:13 [INFO ]  	device_id: 0
2022-10-04 18:45:13 [INFO ]  	distill_epochs: 1
2022-10-04 18:45:13 [INFO ]  	distill_lr: 0.02
2022-10-04 18:45:13 [INFO ]  	distill_steps: 1
2022-10-04 18:45:13 [INFO ]  	epochs: 200
2022-10-04 18:45:13 [INFO ]  	expand_cls: false
2022-10-04 18:45:13 [INFO ]  	forgetting_dataset: null
2022-10-04 18:45:13 [INFO ]  	init: xavier
2022-10-04 18:45:13 [INFO ]  	init_param: 1.0
2022-10-04 18:45:13 [INFO ]  	input_size: 32
2022-10-04 18:45:13 [INFO ]  	ipc: 10
2022-10-04 18:45:13 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:45:13 [INFO ]  	log_interval: 100
2022-10-04 18:45:13 [INFO ]  	log_level: INFO
2022-10-04 18:45:13 [INFO ]  	lr: 0.01
2022-10-04 18:45:13 [INFO ]  	mode: distill_adapt
2022-10-04 18:45:13 [INFO ]  	nc: 3
2022-10-04 18:45:13 [INFO ]  	num_classes: 10
2022-10-04 18:45:13 [INFO ]  	num_workers: 8
2022-10-04 18:45:13 [INFO ]  	phase: train
2022-10-04 18:45:13 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:45:13 [INFO ]  	start_time: '2022-10-04 18:45:13'
2022-10-04 18:45:13 [INFO ]  	test_batch_size: 1024
2022-10-04 18:45:13 [INFO ]  	
2022-10-04 18:45:15 [INFO ]  train dataset size:	73257
2022-10-04 18:45:15 [INFO ]  test dataset size: 	26032
2022-10-04 18:45:15 [INFO ]  datasets built!
2022-10-04 18:45:15 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:45:17 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:45:17 [INFO ]  
2022-10-04 18:45:17 [INFO ]  Begin of epoch 0 :
2022-10-04 18:45:20 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:45:20 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:45:20 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:45:20 [INFO ]  	   step  1 (lr=0.020000)                    7.21%                   8.5598
2022-10-04 18:45:20 [INFO ]  
2022-10-04 18:45:20 [INFO ]  Epoch:    0	Loss: 8.4288	Data Time: 0.38s	Train Time: 0.03s
2022-10-04 18:45:22 [INFO ]  Epoch:    1	Loss: 3.0894	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 18:45:24 [INFO ]  Epoch:    2	Loss: 2.5105	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:45:25 [INFO ]  Epoch:    3	Loss: 2.2660	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:45:27 [INFO ]  Epoch:    4	Loss: 2.2039	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:45:29 [INFO ]  Epoch:    5	Loss: 2.2053	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:45:31 [INFO ]  Epoch:    6	Loss: 2.1881	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:45:32 [INFO ]  Epoch:    7	Loss: 2.1201	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:45:34 [INFO ]  Epoch:    8	Loss: 2.1017	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:45:36 [INFO ]  Epoch:    9	Loss: 2.0172	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:45:38 [INFO ]  Epoch:   10	Loss: 1.9089	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:45:40 [INFO ]  Epoch:   11	Loss: 1.8570	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:45:42 [INFO ]  Epoch:   12	Loss: 1.6133	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:45:44 [INFO ]  Epoch:   13	Loss: 1.5578	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:45:46 [INFO ]  Epoch:   14	Loss: 1.4668	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:45:48 [INFO ]  Epoch:   15	Loss: 1.3747	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:45:50 [INFO ]  Epoch:   16	Loss: 1.3766	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:45:51 [INFO ]  Epoch:   17	Loss: 1.2400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:45:53 [INFO ]  Epoch:   18	Loss: 1.2474	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:45:55 [INFO ]  Epoch:   19	Loss: 1.1876	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:45:57 [INFO ]  Epoch:   20	Loss: 1.1421	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:45:59 [INFO ]  Epoch:   21	Loss: 1.0562	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:46:01 [INFO ]  Epoch:   22	Loss: 1.1164	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:46:02 [INFO ]  Epoch:   23	Loss: 0.9795	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:46:04 [INFO ]  Epoch:   24	Loss: 0.9870	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:06 [INFO ]  Epoch:   25	Loss: 1.1500	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:08 [INFO ]  Epoch:   26	Loss: 0.9804	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:46:10 [INFO ]  Epoch:   27	Loss: 0.9162	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:46:12 [INFO ]  Epoch:   28	Loss: 1.1205	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:13 [INFO ]  Epoch:   29	Loss: 0.9856	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:46:15 [INFO ]  Epoch:   30	Loss: 0.8409	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:46:17 [INFO ]  Epoch:   31	Loss: 0.8366	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:19 [INFO ]  Epoch:   32	Loss: 0.9555	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:46:21 [INFO ]  Epoch:   33	Loss: 0.8018	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:46:22 [INFO ]  Epoch:   34	Loss: 0.7778	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:46:24 [INFO ]  Epoch:   35	Loss: 0.8058	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:46:26 [INFO ]  Epoch:   36	Loss: 0.7994	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:46:28 [INFO ]  Epoch:   37	Loss: 0.7740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:46:30 [INFO ]  Epoch:   38	Loss: 0.7726	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:46:32 [INFO ]  Epoch:   39	Loss: 0.7592	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:33 [INFO ]  Epoch:   40	Loss: 0.8359	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:46:35 [INFO ]  Epoch:   41	Loss: 0.7743	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:46:37 [INFO ]  Epoch:   42	Loss: 0.7125	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:39 [INFO ]  Epoch:   43	Loss: 0.8627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:46:40 [INFO ]  Epoch:   44	Loss: 1.0487	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:46:42 [INFO ]  Epoch:   45	Loss: 0.7920	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:44 [INFO ]  Epoch:   46	Loss: 0.7123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:46 [INFO ]  Epoch:   47	Loss: 0.6861	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:46:48 [INFO ]  Epoch:   48	Loss: 0.6891	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:46:50 [INFO ]  Epoch:   49	Loss: 0.8157	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:46:51 [INFO ]  Epoch:   50	Loss: 0.6369	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:46:53 [INFO ]  Epoch:   51	Loss: 0.6203	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:55 [INFO ]  Epoch:   52	Loss: 0.6587	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:46:57 [INFO ]  Epoch:   53	Loss: 0.7215	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:46:59 [INFO ]  Epoch:   54	Loss: 0.6284	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:01 [INFO ]  Epoch:   55	Loss: 0.6490	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:47:03 [INFO ]  Epoch:   56	Loss: 0.6408	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:04 [INFO ]  Epoch:   57	Loss: 0.6393	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:06 [INFO ]  Epoch:   58	Loss: 0.6137	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:47:08 [INFO ]  Epoch:   59	Loss: 0.7400	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:47:10 [INFO ]  Epoch:   60	Loss: 0.7555	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:12 [INFO ]  Epoch:   61	Loss: 0.6173	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:14 [INFO ]  Epoch:   62	Loss: 0.6400	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:47:16 [INFO ]  Epoch:   63	Loss: 0.5910	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:18 [INFO ]  Epoch:   64	Loss: 0.6162	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:20 [INFO ]  Epoch:   65	Loss: 0.6582	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:47:21 [INFO ]  Epoch:   66	Loss: 0.5926	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:23 [INFO ]  Epoch:   67	Loss: 0.6867	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:25 [INFO ]  Epoch:   68	Loss: 0.6979	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:47:27 [INFO ]  Epoch:   69	Loss: 0.7053	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:47:29 [INFO ]  Epoch:   70	Loss: 0.6960	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:31 [INFO ]  Epoch:   71	Loss: 0.5989	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:47:32 [INFO ]  Epoch:   72	Loss: 0.6270	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:34 [INFO ]  Epoch:   73	Loss: 0.6480	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:36 [INFO ]  Epoch:   74	Loss: 0.6125	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:47:38 [INFO ]  Epoch:   75	Loss: 0.6702	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:47:40 [INFO ]  Epoch:   76	Loss: 0.6822	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:47:42 [INFO ]  Epoch:   77	Loss: 0.6725	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:47:43 [INFO ]  Epoch:   78	Loss: 0.6273	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:47:45 [INFO ]  Epoch:   79	Loss: 0.6296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:47 [INFO ]  Epoch:   80	Loss: 0.6224	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:47:49 [INFO ]  Epoch:   81	Loss: 0.5755	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:47:51 [INFO ]  Epoch:   82	Loss: 0.7301	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:47:53 [INFO ]  Epoch:   83	Loss: 0.6452	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:47:54 [INFO ]  Epoch:   84	Loss: 0.7070	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:47:56 [INFO ]  Epoch:   85	Loss: 0.5649	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:47:58 [INFO ]  Epoch:   86	Loss: 0.6512	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:00 [INFO ]  Epoch:   87	Loss: 0.6054	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:48:01 [INFO ]  Epoch:   88	Loss: 0.6657	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:03 [INFO ]  Epoch:   89	Loss: 0.6327	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:48:05 [INFO ]  Epoch:   90	Loss: 0.6270	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:07 [INFO ]  Epoch:   91	Loss: 0.6117	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:48:09 [INFO ]  Epoch:   92	Loss: 0.6315	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:48:11 [INFO ]  Epoch:   93	Loss: 0.5523	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:48:13 [INFO ]  Epoch:   94	Loss: 0.6969	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:14 [INFO ]  Epoch:   95	Loss: 0.7266	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:16 [INFO ]  Epoch:   96	Loss: 0.5827	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:48:18 [INFO ]  Epoch:   97	Loss: 0.6513	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:20 [INFO ]  Epoch:   98	Loss: 0.6755	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:21 [INFO ]  Epoch:   99	Loss: 0.5595	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:48:23 [INFO ]  Epoch:  100	Loss: 0.5995	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:48:25 [INFO ]  Epoch:  101	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:27 [INFO ]  Epoch:  102	Loss: 0.6415	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:48:29 [INFO ]  Epoch:  103	Loss: 0.6737	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:31 [INFO ]  Epoch:  104	Loss: 0.6422	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:48:32 [INFO ]  Epoch:  105	Loss: 0.5898	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:35 [INFO ]  Epoch:  106	Loss: 0.6486	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:36 [INFO ]  Epoch:  107	Loss: 0.6630	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:38 [INFO ]  Epoch:  108	Loss: 0.6522	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:48:40 [INFO ]  Epoch:  109	Loss: 0.5760	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:42 [INFO ]  Epoch:  110	Loss: 0.5388	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:48:44 [INFO ]  Epoch:  111	Loss: 0.6238	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:48:46 [INFO ]  Epoch:  112	Loss: 0.6764	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:48:47 [INFO ]  Epoch:  113	Loss: 0.5952	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:48:49 [INFO ]  Epoch:  114	Loss: 0.5928	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:48:51 [INFO ]  Epoch:  115	Loss: 0.6036	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:48:53 [INFO ]  Epoch:  116	Loss: 0.6585	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:48:55 [INFO ]  Epoch:  117	Loss: 0.5931	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:48:56 [INFO ]  Epoch:  118	Loss: 0.6345	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:48:58 [INFO ]  Epoch:  119	Loss: 0.6098	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:00 [INFO ]  Epoch:  120	Loss: 0.6343	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:49:02 [INFO ]  Epoch:  121	Loss: 0.6296	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:03 [INFO ]  Epoch:  122	Loss: 0.5856	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:49:05 [INFO ]  Epoch:  123	Loss: 0.6390	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:49:07 [INFO ]  Epoch:  124	Loss: 0.6535	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:49:09 [INFO ]  Epoch:  125	Loss: 0.6308	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:49:11 [INFO ]  Epoch:  126	Loss: 0.7154	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:49:13 [INFO ]  Epoch:  127	Loss: 0.6210	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:14 [INFO ]  Epoch:  128	Loss: 0.6410	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:16 [INFO ]  Epoch:  129	Loss: 0.6543	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:49:18 [INFO ]  Epoch:  130	Loss: 0.6454	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:20 [INFO ]  Epoch:  131	Loss: 0.6367	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:49:22 [INFO ]  Epoch:  132	Loss: 0.6608	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:23 [INFO ]  Epoch:  133	Loss: 0.6570	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:49:25 [INFO ]  Epoch:  134	Loss: 0.6434	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:49:27 [INFO ]  Epoch:  135	Loss: 0.6229	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:49:29 [INFO ]  Epoch:  136	Loss: 0.6269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:31 [INFO ]  Epoch:  137	Loss: 0.6010	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:32 [INFO ]  Epoch:  138	Loss: 0.6063	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:34 [INFO ]  Epoch:  139	Loss: 0.6362	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:36 [INFO ]  Epoch:  140	Loss: 0.7730	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:49:38 [INFO ]  Epoch:  141	Loss: 0.6194	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:49:40 [INFO ]  Epoch:  142	Loss: 0.6492	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:49:42 [INFO ]  Epoch:  143	Loss: 0.6862	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:43 [INFO ]  Epoch:  144	Loss: 0.6551	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:45 [INFO ]  Epoch:  145	Loss: 0.6332	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:49:47 [INFO ]  Epoch:  146	Loss: 0.6354	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:49 [INFO ]  Epoch:  147	Loss: 0.6315	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:49:51 [INFO ]  Epoch:  148	Loss: 0.6112	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:53 [INFO ]  Epoch:  149	Loss: 0.6397	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:55 [INFO ]  Epoch:  150	Loss: 0.6042	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:49:57 [INFO ]  Epoch:  151	Loss: 0.5982	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:49:58 [INFO ]  Epoch:  152	Loss: 0.6994	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:50:00 [INFO ]  Epoch:  153	Loss: 0.6965	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:50:02 [INFO ]  Epoch:  154	Loss: 0.6789	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:50:04 [INFO ]  Epoch:  155	Loss: 0.6584	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:50:06 [INFO ]  Epoch:  156	Loss: 0.6288	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:07 [INFO ]  Epoch:  157	Loss: 0.6040	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:09 [INFO ]  Epoch:  158	Loss: 0.6585	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:50:11 [INFO ]  Epoch:  159	Loss: 0.6320	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:50:13 [INFO ]  Epoch:  160	Loss: 0.6368	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:50:15 [INFO ]  Epoch:  161	Loss: 0.6573	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:17 [INFO ]  Epoch:  162	Loss: 0.6967	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:50:18 [INFO ]  Epoch:  163	Loss: 0.5955	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:21 [INFO ]  Epoch:  164	Loss: 0.6295	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:22 [INFO ]  Epoch:  165	Loss: 0.6385	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:24 [INFO ]  Epoch:  166	Loss: 0.6666	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:50:26 [INFO ]  Epoch:  167	Loss: 0.6603	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:28 [INFO ]  Epoch:  168	Loss: 0.6372	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:30 [INFO ]  Epoch:  169	Loss: 0.6272	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:31 [INFO ]  Epoch:  170	Loss: 0.6038	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:33 [INFO ]  Epoch:  171	Loss: 0.6147	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:35 [INFO ]  Epoch:  172	Loss: 0.6543	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:37 [INFO ]  Epoch:  173	Loss: 0.6595	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:50:38 [INFO ]  Epoch:  174	Loss: 0.6081	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:40 [INFO ]  Epoch:  175	Loss: 0.6538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:42 [INFO ]  Epoch:  176	Loss: 0.5897	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:44 [INFO ]  Epoch:  177	Loss: 0.6334	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:46 [INFO ]  Epoch:  178	Loss: 0.6410	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:48 [INFO ]  Epoch:  179	Loss: 0.6432	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:50:50 [INFO ]  Epoch:  180	Loss: 0.6431	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:50:51 [INFO ]  Epoch:  181	Loss: 0.5920	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:53 [INFO ]  Epoch:  182	Loss: 0.7035	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:50:55 [INFO ]  Epoch:  183	Loss: 0.5485	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:50:57 [INFO ]  Epoch:  184	Loss: 0.6538	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:50:59 [INFO ]  Epoch:  185	Loss: 0.5967	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:51:00 [INFO ]  Epoch:  186	Loss: 0.5335	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:51:02 [INFO ]  Epoch:  187	Loss: 0.6445	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:51:04 [INFO ]  Epoch:  188	Loss: 0.6157	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:51:06 [INFO ]  Epoch:  189	Loss: 0.6494	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:51:08 [INFO ]  Epoch:  190	Loss: 0.7497	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:51:09 [INFO ]  Epoch:  191	Loss: 0.6853	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:51:11 [INFO ]  Epoch:  192	Loss: 0.6709	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:51:13 [INFO ]  Epoch:  193	Loss: 0.6771	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:51:15 [INFO ]  Epoch:  194	Loss: 0.6286	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:51:17 [INFO ]  Epoch:  195	Loss: 0.5961	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:51:19 [INFO ]  Epoch:  196	Loss: 0.5968	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:51:21 [INFO ]  Epoch:  197	Loss: 0.7199	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:51:23 [INFO ]  Epoch:  198	Loss: 0.6692	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:51:24 [INFO ]  Epoch:  199	Loss: 0.6337	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:51:26 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:51:26 [INFO ]  
2022-10-04 18:51:26 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:51:29 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:51:29 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:51:29 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:51:29 [INFO ]  	   step  1 (lr=0.398055)                   80.82%                   0.6917
2022-10-04 18:51:29 [INFO ]  
2022-10-04 18:51:29 [INFO ]  
2022-10-04 18:51:29 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:51:32 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:51:32 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:51:32 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:51:32 [INFO ]  	   step  1 (lr=0.398055)                   14.83%                   6.0451
2022-10-04 18:51:32 [INFO ]  
2022-10-04 18:51:32 [INFO ]  CPU Time: 3.42 minutes
2022-10-04 18:52:38 [INFO ]  ======================================== 2022-10-04 18:52:38 ========================================
2022-10-04 18:52:38 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 18:52:38 [INFO ]  Options: 
2022-10-04 18:52:38 [INFO ]  	base_dir: null
2022-10-04 18:52:38 [INFO ]  	batch_size: 1024
2022-10-04 18:52:38 [INFO ]  	checkpoint_interval: 300
2022-10-04 18:52:38 [INFO ]  	dataset: SVHN
2022-10-04 18:52:38 [INFO ]  	dataset_labels:
2022-10-04 18:52:38 [INFO ]  	- 0
2022-10-04 18:52:38 [INFO ]  	- 1
2022-10-04 18:52:38 [INFO ]  	- 2
2022-10-04 18:52:38 [INFO ]  	- 3
2022-10-04 18:52:38 [INFO ]  	- 4
2022-10-04 18:52:38 [INFO ]  	- 5
2022-10-04 18:52:38 [INFO ]  	- 6
2022-10-04 18:52:38 [INFO ]  	- 7
2022-10-04 18:52:38 [INFO ]  	- 8
2022-10-04 18:52:38 [INFO ]  	- 9
2022-10-04 18:52:38 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 18:52:38 [INFO ]  	- !!python/tuple
2022-10-04 18:52:38 [INFO ]  	    - 0.4379104971885681
2022-10-04 18:52:38 [INFO ]  	    - 0.44398033618927
2022-10-04 18:52:38 [INFO ]  	    - 0.4729299545288086
2022-10-04 18:52:38 [INFO ]  	- !!python/tuple
2022-10-04 18:52:38 [INFO ]  	    - 0.19803012907505035
2022-10-04 18:52:38 [INFO ]  	    - 0.2010156363248825
2022-10-04 18:52:38 [INFO ]  	    - 0.19703614711761475
2022-10-04 18:52:38 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 18:52:38 [INFO ]  	decay_epochs: 50
2022-10-04 18:52:38 [INFO ]  	decay_factor: 0.1
2022-10-04 18:52:38 [INFO ]  	device_id: 0
2022-10-04 18:52:38 [INFO ]  	distill_epochs: 1
2022-10-04 18:52:38 [INFO ]  	distill_lr: 0.02
2022-10-04 18:52:38 [INFO ]  	distill_steps: 1
2022-10-04 18:52:38 [INFO ]  	epochs: 200
2022-10-04 18:52:38 [INFO ]  	expand_cls: false
2022-10-04 18:52:38 [INFO ]  	forgetting_dataset: null
2022-10-04 18:52:38 [INFO ]  	init: xavier
2022-10-04 18:52:38 [INFO ]  	init_param: 1.0
2022-10-04 18:52:38 [INFO ]  	input_size: 32
2022-10-04 18:52:38 [INFO ]  	ipc: 15
2022-10-04 18:52:38 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 18:52:38 [INFO ]  	log_interval: 100
2022-10-04 18:52:38 [INFO ]  	log_level: INFO
2022-10-04 18:52:38 [INFO ]  	lr: 0.01
2022-10-04 18:52:38 [INFO ]  	mode: distill_adapt
2022-10-04 18:52:38 [INFO ]  	nc: 3
2022-10-04 18:52:38 [INFO ]  	num_classes: 10
2022-10-04 18:52:38 [INFO ]  	num_workers: 8
2022-10-04 18:52:38 [INFO ]  	phase: train
2022-10-04 18:52:38 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 18:52:38 [INFO ]  	start_time: '2022-10-04 18:52:38'
2022-10-04 18:52:38 [INFO ]  	test_batch_size: 1024
2022-10-04 18:52:38 [INFO ]  	
2022-10-04 18:52:40 [INFO ]  train dataset size:	73257
2022-10-04 18:52:40 [INFO ]  test dataset size: 	26032
2022-10-04 18:52:40 [INFO ]  datasets built!
2022-10-04 18:52:40 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 18:52:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 18:52:42 [INFO ]  
2022-10-04 18:52:42 [INFO ]  Begin of epoch 0 :
2022-10-04 18:52:45 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:52:45 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:52:45 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:52:45 [INFO ]  	   step  1 (lr=0.020000)                    6.86%                   8.8651
2022-10-04 18:52:45 [INFO ]  
2022-10-04 18:52:45 [INFO ]  Epoch:    0	Loss: 9.5483	Data Time: 0.38s	Train Time: 0.04s
2022-10-04 18:52:47 [INFO ]  Epoch:    1	Loss: 3.0164	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 18:52:49 [INFO ]  Epoch:    2	Loss: 2.4810	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:52:51 [INFO ]  Epoch:    3	Loss: 2.3053	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:52:52 [INFO ]  Epoch:    4	Loss: 2.2676	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:52:54 [INFO ]  Epoch:    5	Loss: 2.2174	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:52:56 [INFO ]  Epoch:    6	Loss: 2.1487	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:52:58 [INFO ]  Epoch:    7	Loss: 2.1349	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:00 [INFO ]  Epoch:    8	Loss: 2.0608	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:53:01 [INFO ]  Epoch:    9	Loss: 2.0179	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:53:03 [INFO ]  Epoch:   10	Loss: 1.8620	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:53:05 [INFO ]  Epoch:   11	Loss: 1.7110	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:07 [INFO ]  Epoch:   12	Loss: 1.5863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:09 [INFO ]  Epoch:   13	Loss: 1.5183	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:53:11 [INFO ]  Epoch:   14	Loss: 1.3292	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:12 [INFO ]  Epoch:   15	Loss: 1.2878	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:14 [INFO ]  Epoch:   16	Loss: 1.1918	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:16 [INFO ]  Epoch:   17	Loss: 1.0959	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:53:18 [INFO ]  Epoch:   18	Loss: 1.1154	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:53:20 [INFO ]  Epoch:   19	Loss: 1.0537	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:53:22 [INFO ]  Epoch:   20	Loss: 1.0060	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:24 [INFO ]  Epoch:   21	Loss: 1.0799	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:26 [INFO ]  Epoch:   22	Loss: 1.0702	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:27 [INFO ]  Epoch:   23	Loss: 1.0556	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:53:29 [INFO ]  Epoch:   24	Loss: 1.0761	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:53:31 [INFO ]  Epoch:   25	Loss: 1.0337	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:33 [INFO ]  Epoch:   26	Loss: 0.9636	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:53:34 [INFO ]  Epoch:   27	Loss: 0.9205	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:36 [INFO ]  Epoch:   28	Loss: 0.8584	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:53:38 [INFO ]  Epoch:   29	Loss: 0.9425	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:40 [INFO ]  Epoch:   30	Loss: 0.9427	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:42 [INFO ]  Epoch:   31	Loss: 0.8219	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:53:44 [INFO ]  Epoch:   32	Loss: 0.8149	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:53:45 [INFO ]  Epoch:   33	Loss: 0.8726	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:53:47 [INFO ]  Epoch:   34	Loss: 0.8546	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:53:49 [INFO ]  Epoch:   35	Loss: 0.8444	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:53:51 [INFO ]  Epoch:   36	Loss: 0.7675	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:53 [INFO ]  Epoch:   37	Loss: 0.7421	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:54 [INFO ]  Epoch:   38	Loss: 0.7616	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:53:56 [INFO ]  Epoch:   39	Loss: 0.7723	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:53:58 [INFO ]  Epoch:   40	Loss: 0.8289	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:00 [INFO ]  Epoch:   41	Loss: 0.8445	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:02 [INFO ]  Epoch:   42	Loss: 0.9611	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:04 [INFO ]  Epoch:   43	Loss: 0.7048	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:06 [INFO ]  Epoch:   44	Loss: 0.7354	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:08 [INFO ]  Epoch:   45	Loss: 0.7521	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:09 [INFO ]  Epoch:   46	Loss: 0.7062	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:11 [INFO ]  Epoch:   47	Loss: 0.7287	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:54:13 [INFO ]  Epoch:   48	Loss: 0.7077	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:15 [INFO ]  Epoch:   49	Loss: 0.8223	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:17 [INFO ]  Epoch:   50	Loss: 0.7166	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:19 [INFO ]  Epoch:   51	Loss: 0.7422	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:21 [INFO ]  Epoch:   52	Loss: 0.6093	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:22 [INFO ]  Epoch:   53	Loss: 0.6292	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:24 [INFO ]  Epoch:   54	Loss: 0.6510	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:26 [INFO ]  Epoch:   55	Loss: 0.6868	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:54:28 [INFO ]  Epoch:   56	Loss: 0.6840	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:30 [INFO ]  Epoch:   57	Loss: 0.7075	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:31 [INFO ]  Epoch:   58	Loss: 0.7193	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:33 [INFO ]  Epoch:   59	Loss: 0.7743	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:35 [INFO ]  Epoch:   60	Loss: 0.7010	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:37 [INFO ]  Epoch:   61	Loss: 0.6193	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:39 [INFO ]  Epoch:   62	Loss: 0.6778	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:41 [INFO ]  Epoch:   63	Loss: 0.6376	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:42 [INFO ]  Epoch:   64	Loss: 0.6949	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:54:44 [INFO ]  Epoch:   65	Loss: 0.6192	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:54:46 [INFO ]  Epoch:   66	Loss: 0.6349	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:48 [INFO ]  Epoch:   67	Loss: 0.6418	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:49 [INFO ]  Epoch:   68	Loss: 0.7114	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:51 [INFO ]  Epoch:   69	Loss: 0.5989	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:53 [INFO ]  Epoch:   70	Loss: 0.6400	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:54:55 [INFO ]  Epoch:   71	Loss: 0.6368	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:54:57 [INFO ]  Epoch:   72	Loss: 0.6326	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:54:59 [INFO ]  Epoch:   73	Loss: 0.6421	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:55:00 [INFO ]  Epoch:   74	Loss: 0.6511	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:02 [INFO ]  Epoch:   75	Loss: 0.6146	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:04 [INFO ]  Epoch:   76	Loss: 0.6467	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:55:06 [INFO ]  Epoch:   77	Loss: 0.6457	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:08 [INFO ]  Epoch:   78	Loss: 0.6374	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:55:09 [INFO ]  Epoch:   79	Loss: 0.5782	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:11 [INFO ]  Epoch:   80	Loss: 0.6762	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:55:13 [INFO ]  Epoch:   81	Loss: 0.6879	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:15 [INFO ]  Epoch:   82	Loss: 0.6552	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:55:17 [INFO ]  Epoch:   83	Loss: 0.6867	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:19 [INFO ]  Epoch:   84	Loss: 0.7139	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:21 [INFO ]  Epoch:   85	Loss: 0.7117	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:55:22 [INFO ]  Epoch:   86	Loss: 0.6517	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:55:24 [INFO ]  Epoch:   87	Loss: 0.6448	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:55:26 [INFO ]  Epoch:   88	Loss: 0.6195	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:55:28 [INFO ]  Epoch:   89	Loss: 0.6368	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:55:30 [INFO ]  Epoch:   90	Loss: 0.6079	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:55:31 [INFO ]  Epoch:   91	Loss: 0.6362	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:33 [INFO ]  Epoch:   92	Loss: 0.6612	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:55:35 [INFO ]  Epoch:   93	Loss: 0.6818	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:37 [INFO ]  Epoch:   94	Loss: 0.5560	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:39 [INFO ]  Epoch:   95	Loss: 0.6225	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:41 [INFO ]  Epoch:   96	Loss: 0.6679	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:55:42 [INFO ]  Epoch:   97	Loss: 0.6200	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:55:44 [INFO ]  Epoch:   98	Loss: 0.5714	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:55:46 [INFO ]  Epoch:   99	Loss: 0.6118	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:48 [INFO ]  Epoch:  100	Loss: 0.5806	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:55:50 [INFO ]  Epoch:  101	Loss: 0.5909	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:52 [INFO ]  Epoch:  102	Loss: 0.6851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:53 [INFO ]  Epoch:  103	Loss: 0.6254	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:55:55 [INFO ]  Epoch:  104	Loss: 0.6049	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:57 [INFO ]  Epoch:  105	Loss: 0.6954	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:55:59 [INFO ]  Epoch:  106	Loss: 0.6113	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:56:01 [INFO ]  Epoch:  107	Loss: 0.6386	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:02 [INFO ]  Epoch:  108	Loss: 0.6729	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:56:04 [INFO ]  Epoch:  109	Loss: 0.6160	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:56:06 [INFO ]  Epoch:  110	Loss: 0.5763	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:08 [INFO ]  Epoch:  111	Loss: 0.6667	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:10 [INFO ]  Epoch:  112	Loss: 0.5719	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:56:12 [INFO ]  Epoch:  113	Loss: 0.6477	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:56:13 [INFO ]  Epoch:  114	Loss: 0.6443	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:56:15 [INFO ]  Epoch:  115	Loss: 0.5529	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:56:17 [INFO ]  Epoch:  116	Loss: 0.6411	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:56:19 [INFO ]  Epoch:  117	Loss: 0.6601	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:21 [INFO ]  Epoch:  118	Loss: 0.6160	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:56:23 [INFO ]  Epoch:  119	Loss: 0.5776	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:56:25 [INFO ]  Epoch:  120	Loss: 0.5826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:27 [INFO ]  Epoch:  121	Loss: 0.5879	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:56:28 [INFO ]  Epoch:  122	Loss: 0.6690	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:56:30 [INFO ]  Epoch:  123	Loss: 0.6775	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:56:32 [INFO ]  Epoch:  124	Loss: 0.6164	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:56:34 [INFO ]  Epoch:  125	Loss: 0.5835	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:56:36 [INFO ]  Epoch:  126	Loss: 0.6525	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:56:38 [INFO ]  Epoch:  127	Loss: 0.6510	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:56:40 [INFO ]  Epoch:  128	Loss: 0.6608	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:56:42 [INFO ]  Epoch:  129	Loss: 0.6186	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:56:43 [INFO ]  Epoch:  130	Loss: 0.5789	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:45 [INFO ]  Epoch:  131	Loss: 0.5865	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:56:47 [INFO ]  Epoch:  132	Loss: 0.5970	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:49 [INFO ]  Epoch:  133	Loss: 0.6469	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:51 [INFO ]  Epoch:  134	Loss: 0.6454	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:53 [INFO ]  Epoch:  135	Loss: 0.5493	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:55 [INFO ]  Epoch:  136	Loss: 0.5791	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:56 [INFO ]  Epoch:  137	Loss: 0.5824	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:56:58 [INFO ]  Epoch:  138	Loss: 0.5945	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:57:00 [INFO ]  Epoch:  139	Loss: 0.5993	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:02 [INFO ]  Epoch:  140	Loss: 0.7001	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:57:04 [INFO ]  Epoch:  141	Loss: 0.6155	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:05 [INFO ]  Epoch:  142	Loss: 0.6774	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:07 [INFO ]  Epoch:  143	Loss: 0.7094	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:09 [INFO ]  Epoch:  144	Loss: 0.6248	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:57:11 [INFO ]  Epoch:  145	Loss: 0.5547	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:57:13 [INFO ]  Epoch:  146	Loss: 0.6087	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 18:57:15 [INFO ]  Epoch:  147	Loss: 0.5999	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:17 [INFO ]  Epoch:  148	Loss: 0.6287	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:57:19 [INFO ]  Epoch:  149	Loss: 0.6405	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:57:20 [INFO ]  Epoch:  150	Loss: 0.5932	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:57:22 [INFO ]  Epoch:  151	Loss: 0.5905	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:24 [INFO ]  Epoch:  152	Loss: 0.6553	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:57:26 [INFO ]  Epoch:  153	Loss: 0.5146	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 18:57:27 [INFO ]  Epoch:  154	Loss: 0.6034	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:29 [INFO ]  Epoch:  155	Loss: 0.6550	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:31 [INFO ]  Epoch:  156	Loss: 0.6535	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:33 [INFO ]  Epoch:  157	Loss: 0.6747	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:35 [INFO ]  Epoch:  158	Loss: 0.6057	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:36 [INFO ]  Epoch:  159	Loss: 0.6036	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:38 [INFO ]  Epoch:  160	Loss: 0.6271	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:40 [INFO ]  Epoch:  161	Loss: 0.5987	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:57:42 [INFO ]  Epoch:  162	Loss: 0.6276	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:57:44 [INFO ]  Epoch:  163	Loss: 0.6586	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:57:46 [INFO ]  Epoch:  164	Loss: 0.5971	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:47 [INFO ]  Epoch:  165	Loss: 0.6088	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:49 [INFO ]  Epoch:  166	Loss: 0.5995	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:57:51 [INFO ]  Epoch:  167	Loss: 0.6480	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:53 [INFO ]  Epoch:  168	Loss: 0.5785	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:57:55 [INFO ]  Epoch:  169	Loss: 0.6673	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:57:56 [INFO ]  Epoch:  170	Loss: 0.5927	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:57:58 [INFO ]  Epoch:  171	Loss: 0.6771	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:58:00 [INFO ]  Epoch:  172	Loss: 0.5852	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 18:58:02 [INFO ]  Epoch:  173	Loss: 0.6826	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:04 [INFO ]  Epoch:  174	Loss: 0.6322	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:58:06 [INFO ]  Epoch:  175	Loss: 0.5482	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:58:07 [INFO ]  Epoch:  176	Loss: 0.6441	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:09 [INFO ]  Epoch:  177	Loss: 0.5972	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:58:11 [INFO ]  Epoch:  178	Loss: 0.5680	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 18:58:13 [INFO ]  Epoch:  179	Loss: 0.6135	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:15 [INFO ]  Epoch:  180	Loss: 0.6326	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:17 [INFO ]  Epoch:  181	Loss: 0.5559	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:58:19 [INFO ]  Epoch:  182	Loss: 0.5780	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 18:58:21 [INFO ]  Epoch:  183	Loss: 0.5627	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:58:22 [INFO ]  Epoch:  184	Loss: 0.6339	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:58:24 [INFO ]  Epoch:  185	Loss: 0.6688	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:26 [INFO ]  Epoch:  186	Loss: 0.6500	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:58:28 [INFO ]  Epoch:  187	Loss: 0.6686	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:30 [INFO ]  Epoch:  188	Loss: 0.5650	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 18:58:31 [INFO ]  Epoch:  189	Loss: 0.6510	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:33 [INFO ]  Epoch:  190	Loss: 0.5717	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:35 [INFO ]  Epoch:  191	Loss: 0.6729	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 18:58:37 [INFO ]  Epoch:  192	Loss: 0.5791	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:58:39 [INFO ]  Epoch:  193	Loss: 0.5962	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:41 [INFO ]  Epoch:  194	Loss: 0.6021	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 18:58:42 [INFO ]  Epoch:  195	Loss: 0.6136	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 18:58:44 [INFO ]  Epoch:  196	Loss: 0.5640	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:46 [INFO ]  Epoch:  197	Loss: 0.5748	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:48 [INFO ]  Epoch:  198	Loss: 0.5713	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 18:58:50 [INFO ]  Epoch:  199	Loss: 0.6170	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 18:58:51 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 18:58:51 [INFO ]  
2022-10-04 18:58:51 [INFO ]  Final evaluation for SVHN :
2022-10-04 18:58:54 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:58:54 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:58:54 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 18:58:54 [INFO ]  	   step  1 (lr=0.368620)                   81.38%                   0.6847
2022-10-04 18:58:54 [INFO ]  
2022-10-04 18:58:54 [INFO ]  
2022-10-04 18:58:54 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 18:58:57 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 18:58:57 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 18:58:57 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 18:58:57 [INFO ]  	   step  1 (lr=0.368620)                   15.29%                   5.2336
2022-10-04 18:58:57 [INFO ]  
2022-10-04 18:58:57 [INFO ]  CPU Time: 3.43 minutes
2022-10-04 19:01:18 [INFO ]  ======================================== 2022-10-04 19:01:18 ========================================
2022-10-04 19:01:18 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 19:01:18 [INFO ]  Options: 
2022-10-04 19:01:18 [INFO ]  	base_dir: null
2022-10-04 19:01:18 [INFO ]  	batch_size: 1024
2022-10-04 19:01:18 [INFO ]  	checkpoint_interval: 300
2022-10-04 19:01:18 [INFO ]  	dataset: SVHN
2022-10-04 19:01:18 [INFO ]  	dataset_labels:
2022-10-04 19:01:18 [INFO ]  	- 0
2022-10-04 19:01:18 [INFO ]  	- 1
2022-10-04 19:01:18 [INFO ]  	- 2
2022-10-04 19:01:18 [INFO ]  	- 3
2022-10-04 19:01:18 [INFO ]  	- 4
2022-10-04 19:01:18 [INFO ]  	- 5
2022-10-04 19:01:18 [INFO ]  	- 6
2022-10-04 19:01:18 [INFO ]  	- 7
2022-10-04 19:01:18 [INFO ]  	- 8
2022-10-04 19:01:18 [INFO ]  	- 9
2022-10-04 19:01:18 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 19:01:18 [INFO ]  	- !!python/tuple
2022-10-04 19:01:18 [INFO ]  	    - 0.4379104971885681
2022-10-04 19:01:18 [INFO ]  	    - 0.44398033618927
2022-10-04 19:01:18 [INFO ]  	    - 0.4729299545288086
2022-10-04 19:01:18 [INFO ]  	- !!python/tuple
2022-10-04 19:01:18 [INFO ]  	    - 0.19803012907505035
2022-10-04 19:01:18 [INFO ]  	    - 0.2010156363248825
2022-10-04 19:01:18 [INFO ]  	    - 0.19703614711761475
2022-10-04 19:01:18 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 19:01:18 [INFO ]  	decay_epochs: 50
2022-10-04 19:01:18 [INFO ]  	decay_factor: 0.1
2022-10-04 19:01:18 [INFO ]  	device_id: 0
2022-10-04 19:01:18 [INFO ]  	distill_epochs: 1
2022-10-04 19:01:18 [INFO ]  	distill_lr: 0.02
2022-10-04 19:01:18 [INFO ]  	distill_steps: 1
2022-10-04 19:01:18 [INFO ]  	epochs: 200
2022-10-04 19:01:18 [INFO ]  	expand_cls: false
2022-10-04 19:01:18 [INFO ]  	forgetting_dataset: null
2022-10-04 19:01:18 [INFO ]  	init: xavier
2022-10-04 19:01:18 [INFO ]  	init_param: 1.0
2022-10-04 19:01:18 [INFO ]  	input_size: 32
2022-10-04 19:01:18 [INFO ]  	ipc: 15
2022-10-04 19:01:18 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 19:01:18 [INFO ]  	log_interval: 100
2022-10-04 19:01:18 [INFO ]  	log_level: INFO
2022-10-04 19:01:18 [INFO ]  	lr: 0.01
2022-10-04 19:01:18 [INFO ]  	mode: distill_adapt
2022-10-04 19:01:18 [INFO ]  	nc: 3
2022-10-04 19:01:18 [INFO ]  	num_classes: 10
2022-10-04 19:01:18 [INFO ]  	num_workers: 8
2022-10-04 19:01:18 [INFO ]  	phase: train
2022-10-04 19:01:18 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 19:01:18 [INFO ]  	start_time: '2022-10-04 19:01:18'
2022-10-04 19:01:18 [INFO ]  	test_batch_size: 1024
2022-10-04 19:01:18 [INFO ]  	
2022-10-04 19:01:20 [INFO ]  train dataset size:	73257
2022-10-04 19:01:20 [INFO ]  test dataset size: 	26032
2022-10-04 19:01:20 [INFO ]  datasets built!
2022-10-04 19:01:20 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 19:01:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 19:01:22 [INFO ]  
2022-10-04 19:01:22 [INFO ]  Begin of epoch 0 :
2022-10-04 19:01:25 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:01:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:01:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:01:25 [INFO ]  	   step  1 (lr=0.020000)                    7.27%                   8.6308
2022-10-04 19:01:25 [INFO ]  
2022-10-04 19:01:25 [INFO ]  Epoch:    0	Loss: 8.3519	Data Time: 0.40s	Train Time: 0.04s
2022-10-04 19:01:27 [INFO ]  Epoch:    1	Loss: 3.0702	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 19:01:29 [INFO ]  Epoch:    2	Loss: 2.5173	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:01:30 [INFO ]  Epoch:    3	Loss: 2.2855	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:01:32 [INFO ]  Epoch:    4	Loss: 2.2345	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:01:34 [INFO ]  Epoch:    5	Loss: 2.1810	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:01:36 [INFO ]  Epoch:    6	Loss: 2.1405	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:01:38 [INFO ]  Epoch:    7	Loss: 2.1118	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:01:40 [INFO ]  Epoch:    8	Loss: 2.0371	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:01:41 [INFO ]  Epoch:    9	Loss: 1.9519	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:01:44 [INFO ]  Epoch:   10	Loss: 1.8566	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:01:45 [INFO ]  Epoch:   11	Loss: 1.8345	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:01:47 [INFO ]  Epoch:   12	Loss: 1.6331	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:01:49 [INFO ]  Epoch:   13	Loss: 1.3905	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:01:51 [INFO ]  Epoch:   14	Loss: 1.2855	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:01:53 [INFO ]  Epoch:   15	Loss: 1.3275	Data Time: 0.22s	Train Time: 0.00s
2022-10-04 19:01:55 [INFO ]  Epoch:   16	Loss: 1.1856	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:01:57 [INFO ]  Epoch:   17	Loss: 1.1561	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:01:59 [INFO ]  Epoch:   18	Loss: 1.1245	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:02:01 [INFO ]  Epoch:   19	Loss: 1.1468	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:03 [INFO ]  Epoch:   20	Loss: 1.0692	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:04 [INFO ]  Epoch:   21	Loss: 1.1014	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:02:06 [INFO ]  Epoch:   22	Loss: 1.1151	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:08 [INFO ]  Epoch:   23	Loss: 0.9088	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:02:10 [INFO ]  Epoch:   24	Loss: 1.1386	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:12 [INFO ]  Epoch:   25	Loss: 0.8774	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:02:14 [INFO ]  Epoch:   26	Loss: 0.8532	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:16 [INFO ]  Epoch:   27	Loss: 0.9039	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:02:18 [INFO ]  Epoch:   28	Loss: 1.0836	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:02:20 [INFO ]  Epoch:   29	Loss: 0.8181	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:02:21 [INFO ]  Epoch:   30	Loss: 0.8746	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:02:23 [INFO ]  Epoch:   31	Loss: 0.8131	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:02:25 [INFO ]  Epoch:   32	Loss: 0.7786	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:02:27 [INFO ]  Epoch:   33	Loss: 0.8820	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:02:29 [INFO ]  Epoch:   34	Loss: 0.8216	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:02:31 [INFO ]  Epoch:   35	Loss: 0.8571	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:02:33 [INFO ]  Epoch:   36	Loss: 0.7474	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:34 [INFO ]  Epoch:   37	Loss: 0.8948	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:36 [INFO ]  Epoch:   38	Loss: 0.7837	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:38 [INFO ]  Epoch:   39	Loss: 0.7491	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:40 [INFO ]  Epoch:   40	Loss: 0.7095	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:02:42 [INFO ]  Epoch:   41	Loss: 0.7826	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:02:43 [INFO ]  Epoch:   42	Loss: 0.7602	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:02:45 [INFO ]  Epoch:   43	Loss: 0.7041	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:02:47 [INFO ]  Epoch:   44	Loss: 0.7400	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:02:49 [INFO ]  Epoch:   45	Loss: 0.7241	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:51 [INFO ]  Epoch:   46	Loss: 0.6871	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:02:53 [INFO ]  Epoch:   47	Loss: 0.6773	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:02:55 [INFO ]  Epoch:   48	Loss: 0.7654	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:02:56 [INFO ]  Epoch:   49	Loss: 0.7415	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:02:58 [INFO ]  Epoch:   50	Loss: 0.7005	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:00 [INFO ]  Epoch:   51	Loss: 0.6236	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:02 [INFO ]  Epoch:   52	Loss: 0.6477	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:03:04 [INFO ]  Epoch:   53	Loss: 0.6522	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:03:06 [INFO ]  Epoch:   54	Loss: 0.6144	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:03:08 [INFO ]  Epoch:   55	Loss: 0.6942	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:03:10 [INFO ]  Epoch:   56	Loss: 0.6842	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:03:12 [INFO ]  Epoch:   57	Loss: 0.6313	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:03:13 [INFO ]  Epoch:   58	Loss: 0.6044	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:15 [INFO ]  Epoch:   59	Loss: 0.7390	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:03:17 [INFO ]  Epoch:   60	Loss: 0.7174	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:19 [INFO ]  Epoch:   61	Loss: 0.6181	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:20 [INFO ]  Epoch:   62	Loss: 0.7122	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:03:22 [INFO ]  Epoch:   63	Loss: 0.6211	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:03:24 [INFO ]  Epoch:   64	Loss: 0.7559	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:03:26 [INFO ]  Epoch:   65	Loss: 0.6612	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:28 [INFO ]  Epoch:   66	Loss: 0.6382	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:03:30 [INFO ]  Epoch:   67	Loss: 0.6455	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:03:32 [INFO ]  Epoch:   68	Loss: 0.5960	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:03:34 [INFO ]  Epoch:   69	Loss: 0.6292	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:03:36 [INFO ]  Epoch:   70	Loss: 0.6606	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:03:37 [INFO ]  Epoch:   71	Loss: 0.6871	Data Time: 0.20s	Train Time: 0.00s
2022-10-04 19:03:39 [INFO ]  Epoch:   72	Loss: 0.6381	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:03:41 [INFO ]  Epoch:   73	Loss: 0.6782	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:43 [INFO ]  Epoch:   74	Loss: 0.6549	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:45 [INFO ]  Epoch:   75	Loss: 0.6516	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:03:46 [INFO ]  Epoch:   76	Loss: 0.5968	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:48 [INFO ]  Epoch:   77	Loss: 0.5713	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:50 [INFO ]  Epoch:   78	Loss: 0.5879	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:03:52 [INFO ]  Epoch:   79	Loss: 0.5650	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:54 [INFO ]  Epoch:   80	Loss: 0.6452	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:03:56 [INFO ]  Epoch:   81	Loss: 0.6376	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:03:58 [INFO ]  Epoch:   82	Loss: 0.6319	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:00 [INFO ]  Epoch:   83	Loss: 0.6885	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:02 [INFO ]  Epoch:   84	Loss: 0.6095	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:04 [INFO ]  Epoch:   85	Loss: 0.6325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:05 [INFO ]  Epoch:   86	Loss: 0.6194	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:07 [INFO ]  Epoch:   87	Loss: 0.6714	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:04:09 [INFO ]  Epoch:   88	Loss: 0.6077	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:11 [INFO ]  Epoch:   89	Loss: 0.6034	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:04:13 [INFO ]  Epoch:   90	Loss: 0.6826	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:04:14 [INFO ]  Epoch:   91	Loss: 0.5441	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:16 [INFO ]  Epoch:   92	Loss: 0.6296	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:18 [INFO ]  Epoch:   93	Loss: 0.5614	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:20 [INFO ]  Epoch:   94	Loss: 0.6126	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:04:22 [INFO ]  Epoch:   95	Loss: 0.6228	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:23 [INFO ]  Epoch:   96	Loss: 0.6817	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:25 [INFO ]  Epoch:   97	Loss: 0.6994	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:04:27 [INFO ]  Epoch:   98	Loss: 0.6103	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:29 [INFO ]  Epoch:   99	Loss: 0.6639	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:31 [INFO ]  Epoch:  100	Loss: 0.6527	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:04:33 [INFO ]  Epoch:  101	Loss: 0.6437	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:04:34 [INFO ]  Epoch:  102	Loss: 0.5628	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:04:36 [INFO ]  Epoch:  103	Loss: 0.5894	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:04:38 [INFO ]  Epoch:  104	Loss: 0.6219	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:04:40 [INFO ]  Epoch:  105	Loss: 0.6545	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:04:42 [INFO ]  Epoch:  106	Loss: 0.5988	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:43 [INFO ]  Epoch:  107	Loss: 0.6406	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:04:45 [INFO ]  Epoch:  108	Loss: 0.5540	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:47 [INFO ]  Epoch:  109	Loss: 0.5706	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:04:49 [INFO ]  Epoch:  110	Loss: 0.5863	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:50 [INFO ]  Epoch:  111	Loss: 0.6226	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:52 [INFO ]  Epoch:  112	Loss: 0.6059	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:04:54 [INFO ]  Epoch:  113	Loss: 0.6088	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:04:56 [INFO ]  Epoch:  114	Loss: 0.5621	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:04:58 [INFO ]  Epoch:  115	Loss: 0.6180	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:00 [INFO ]  Epoch:  116	Loss: 0.6509	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:01 [INFO ]  Epoch:  117	Loss: 0.6542	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:03 [INFO ]  Epoch:  118	Loss: 0.6785	Data Time: 0.28s	Train Time: 0.01s
2022-10-04 19:05:05 [INFO ]  Epoch:  119	Loss: 0.6027	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:05:07 [INFO ]  Epoch:  120	Loss: 0.5852	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:09 [INFO ]  Epoch:  121	Loss: 0.6269	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:11 [INFO ]  Epoch:  122	Loss: 0.6327	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:13 [INFO ]  Epoch:  123	Loss: 0.6483	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:15 [INFO ]  Epoch:  124	Loss: 0.6459	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:17 [INFO ]  Epoch:  125	Loss: 0.5558	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:18 [INFO ]  Epoch:  126	Loss: 0.5991	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:20 [INFO ]  Epoch:  127	Loss: 0.5557	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:05:22 [INFO ]  Epoch:  128	Loss: 0.6129	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:24 [INFO ]  Epoch:  129	Loss: 0.5552	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:25 [INFO ]  Epoch:  130	Loss: 0.5818	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:05:27 [INFO ]  Epoch:  131	Loss: 0.5716	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:05:29 [INFO ]  Epoch:  132	Loss: 0.6433	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:31 [INFO ]  Epoch:  133	Loss: 0.5542	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:33 [INFO ]  Epoch:  134	Loss: 0.6012	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:34 [INFO ]  Epoch:  135	Loss: 0.5866	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:05:36 [INFO ]  Epoch:  136	Loss: 0.6407	Data Time: 0.19s	Train Time: 0.00s
2022-10-04 19:05:38 [INFO ]  Epoch:  137	Loss: 0.6589	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:05:40 [INFO ]  Epoch:  138	Loss: 0.6245	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:05:42 [INFO ]  Epoch:  139	Loss: 0.5735	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:43 [INFO ]  Epoch:  140	Loss: 0.6229	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:05:45 [INFO ]  Epoch:  141	Loss: 0.6729	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:05:47 [INFO ]  Epoch:  142	Loss: 0.5774	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:49 [INFO ]  Epoch:  143	Loss: 0.5740	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:51 [INFO ]  Epoch:  144	Loss: 0.6699	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:05:53 [INFO ]  Epoch:  145	Loss: 0.6046	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:05:55 [INFO ]  Epoch:  146	Loss: 0.5842	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:05:57 [INFO ]  Epoch:  147	Loss: 0.5898	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:05:58 [INFO ]  Epoch:  148	Loss: 0.5864	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:06:00 [INFO ]  Epoch:  149	Loss: 0.5783	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:06:02 [INFO ]  Epoch:  150	Loss: 0.6294	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:04 [INFO ]  Epoch:  151	Loss: 0.6127	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:06:06 [INFO ]  Epoch:  152	Loss: 0.6568	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:08 [INFO ]  Epoch:  153	Loss: 0.6961	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:06:10 [INFO ]  Epoch:  154	Loss: 0.6311	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:06:11 [INFO ]  Epoch:  155	Loss: 0.6974	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:13 [INFO ]  Epoch:  156	Loss: 0.6140	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:06:15 [INFO ]  Epoch:  157	Loss: 0.5682	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:17 [INFO ]  Epoch:  158	Loss: 0.5992	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:06:19 [INFO ]  Epoch:  159	Loss: 0.6346	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:21 [INFO ]  Epoch:  160	Loss: 0.6073	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:22 [INFO ]  Epoch:  161	Loss: 0.5896	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:24 [INFO ]  Epoch:  162	Loss: 0.6004	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:06:26 [INFO ]  Epoch:  163	Loss: 0.6165	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:06:28 [INFO ]  Epoch:  164	Loss: 0.6434	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:06:30 [INFO ]  Epoch:  165	Loss: 0.5860	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:32 [INFO ]  Epoch:  166	Loss: 0.6482	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:06:34 [INFO ]  Epoch:  167	Loss: 0.6354	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:06:36 [INFO ]  Epoch:  168	Loss: 0.5986	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:37 [INFO ]  Epoch:  169	Loss: 0.6847	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:39 [INFO ]  Epoch:  170	Loss: 0.5849	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:41 [INFO ]  Epoch:  171	Loss: 0.6596	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:43 [INFO ]  Epoch:  172	Loss: 0.6151	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:06:45 [INFO ]  Epoch:  173	Loss: 0.6246	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:47 [INFO ]  Epoch:  174	Loss: 0.5873	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:06:48 [INFO ]  Epoch:  175	Loss: 0.6538	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:50 [INFO ]  Epoch:  176	Loss: 0.5980	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:52 [INFO ]  Epoch:  177	Loss: 0.6079	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:06:54 [INFO ]  Epoch:  178	Loss: 0.7205	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:06:56 [INFO ]  Epoch:  179	Loss: 0.5741	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:06:57 [INFO ]  Epoch:  180	Loss: 0.6185	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:06:59 [INFO ]  Epoch:  181	Loss: 0.6333	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:07:01 [INFO ]  Epoch:  182	Loss: 0.7006	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:07:03 [INFO ]  Epoch:  183	Loss: 0.6061	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:07:05 [INFO ]  Epoch:  184	Loss: 0.6261	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:07:07 [INFO ]  Epoch:  185	Loss: 0.6930	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:07:08 [INFO ]  Epoch:  186	Loss: 0.5728	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:07:10 [INFO ]  Epoch:  187	Loss: 0.6662	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:07:12 [INFO ]  Epoch:  188	Loss: 0.6628	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:07:14 [INFO ]  Epoch:  189	Loss: 0.6027	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:07:16 [INFO ]  Epoch:  190	Loss: 0.6217	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:07:18 [INFO ]  Epoch:  191	Loss: 0.6426	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:07:20 [INFO ]  Epoch:  192	Loss: 0.6991	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:07:22 [INFO ]  Epoch:  193	Loss: 0.6018	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:07:24 [INFO ]  Epoch:  194	Loss: 0.6163	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:07:25 [INFO ]  Epoch:  195	Loss: 0.6424	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:07:27 [INFO ]  Epoch:  196	Loss: 0.6254	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:07:29 [INFO ]  Epoch:  197	Loss: 0.5637	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:07:31 [INFO ]  Epoch:  198	Loss: 0.6216	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:07:33 [INFO ]  Epoch:  199	Loss: 0.6067	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:07:34 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 19:07:34 [INFO ]  
2022-10-04 19:07:34 [INFO ]  Final evaluation for SVHN :
2022-10-04 19:07:38 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:07:38 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:07:38 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:07:38 [INFO ]  	   step  1 (lr=0.418532)                   81.46%                   0.6780
2022-10-04 19:07:38 [INFO ]  
2022-10-04 19:07:38 [INFO ]  
2022-10-04 19:07:38 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 19:07:41 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:07:41 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:07:41 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 19:07:41 [INFO ]  	   step  1 (lr=0.418532)                   13.89%                   5.4077
2022-10-04 19:07:41 [INFO ]  
2022-10-04 19:07:41 [INFO ]  CPU Time: 3.44 minutes
2022-10-04 19:36:18 [INFO ]  ======================================== 2022-10-04 19:36:18 ========================================
2022-10-04 19:36:18 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 19:36:18 [INFO ]  Options: 
2022-10-04 19:36:18 [INFO ]  	base_dir: null
2022-10-04 19:36:18 [INFO ]  	batch_size: 1024
2022-10-04 19:36:18 [INFO ]  	checkpoint_interval: 300
2022-10-04 19:36:18 [INFO ]  	dataset: SVHN
2022-10-04 19:36:18 [INFO ]  	dataset_labels:
2022-10-04 19:36:18 [INFO ]  	- 0
2022-10-04 19:36:18 [INFO ]  	- 1
2022-10-04 19:36:18 [INFO ]  	- 2
2022-10-04 19:36:18 [INFO ]  	- 3
2022-10-04 19:36:18 [INFO ]  	- 4
2022-10-04 19:36:18 [INFO ]  	- 5
2022-10-04 19:36:18 [INFO ]  	- 6
2022-10-04 19:36:18 [INFO ]  	- 7
2022-10-04 19:36:18 [INFO ]  	- 8
2022-10-04 19:36:18 [INFO ]  	- 9
2022-10-04 19:36:18 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 19:36:18 [INFO ]  	- !!python/tuple
2022-10-04 19:36:18 [INFO ]  	    - 0.4379104971885681
2022-10-04 19:36:18 [INFO ]  	    - 0.44398033618927
2022-10-04 19:36:18 [INFO ]  	    - 0.4729299545288086
2022-10-04 19:36:18 [INFO ]  	- !!python/tuple
2022-10-04 19:36:18 [INFO ]  	    - 0.19803012907505035
2022-10-04 19:36:18 [INFO ]  	    - 0.2010156363248825
2022-10-04 19:36:18 [INFO ]  	    - 0.19703614711761475
2022-10-04 19:36:18 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 19:36:18 [INFO ]  	decay_epochs: 50
2022-10-04 19:36:18 [INFO ]  	decay_factor: 0.1
2022-10-04 19:36:18 [INFO ]  	device_id: 0
2022-10-04 19:36:18 [INFO ]  	distill_epochs: 1
2022-10-04 19:36:18 [INFO ]  	distill_lr: 0.02
2022-10-04 19:36:18 [INFO ]  	distill_steps: 1
2022-10-04 19:36:18 [INFO ]  	epochs: 200
2022-10-04 19:36:18 [INFO ]  	expand_cls: false
2022-10-04 19:36:18 [INFO ]  	forgetting_dataset: null
2022-10-04 19:36:18 [INFO ]  	init: xavier
2022-10-04 19:36:18 [INFO ]  	init_param: 1.0
2022-10-04 19:36:18 [INFO ]  	input_size: 32
2022-10-04 19:36:18 [INFO ]  	ipc: 15
2022-10-04 19:36:18 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 19:36:18 [INFO ]  	log_interval: 100
2022-10-04 19:36:18 [INFO ]  	log_level: INFO
2022-10-04 19:36:18 [INFO ]  	lr: 0.01
2022-10-04 19:36:18 [INFO ]  	mode: distill_adapt
2022-10-04 19:36:18 [INFO ]  	nc: 3
2022-10-04 19:36:18 [INFO ]  	num_classes: 10
2022-10-04 19:36:18 [INFO ]  	num_workers: 8
2022-10-04 19:36:18 [INFO ]  	phase: train
2022-10-04 19:36:18 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 19:36:18 [INFO ]  	start_time: '2022-10-04 19:36:18'
2022-10-04 19:36:18 [INFO ]  	test_batch_size: 1024
2022-10-04 19:36:18 [INFO ]  	
2022-10-04 19:36:20 [INFO ]  train dataset size:	73257
2022-10-04 19:36:20 [INFO ]  test dataset size: 	26032
2022-10-04 19:36:20 [INFO ]  datasets built!
2022-10-04 19:36:20 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 19:36:22 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 19:36:22 [INFO ]  
2022-10-04 19:36:22 [INFO ]  Begin of epoch 0 :
2022-10-04 19:36:25 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:36:25 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:36:25 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:36:25 [INFO ]  	   step  1 (lr=0.020000)                    7.11%                   9.0597
2022-10-04 19:36:25 [INFO ]  
2022-10-04 19:36:25 [INFO ]  Epoch:    0	Loss: 8.9475	Data Time: 0.36s	Train Time: 0.04s
2022-10-04 19:36:27 [INFO ]  Epoch:    1	Loss: 3.0562	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:36:29 [INFO ]  Epoch:    2	Loss: 2.5571	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:36:30 [INFO ]  Epoch:    3	Loss: 2.3488	Data Time: 0.20s	Train Time: 0.00s
2022-10-04 19:36:32 [INFO ]  Epoch:    4	Loss: 2.2233	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:36:34 [INFO ]  Epoch:    5	Loss: 2.1696	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:36 [INFO ]  Epoch:    6	Loss: 2.1605	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:36:37 [INFO ]  Epoch:    7	Loss: 2.1169	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:36:39 [INFO ]  Epoch:    8	Loss: 2.0868	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:41 [INFO ]  Epoch:    9	Loss: 2.0299	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:42 [INFO ]  Epoch:   10	Loss: 1.9168	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:36:44 [INFO ]  Epoch:   11	Loss: 1.7889	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:36:46 [INFO ]  Epoch:   12	Loss: 1.6069	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:48 [INFO ]  Epoch:   13	Loss: 1.6063	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 19:36:50 [INFO ]  Epoch:   14	Loss: 1.4900	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:36:52 [INFO ]  Epoch:   15	Loss: 1.3434	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:54 [INFO ]  Epoch:   16	Loss: 1.3062	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:36:55 [INFO ]  Epoch:   17	Loss: 1.3171	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:36:57 [INFO ]  Epoch:   18	Loss: 1.2072	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:36:59 [INFO ]  Epoch:   19	Loss: 1.1853	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:01 [INFO ]  Epoch:   20	Loss: 1.1174	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:37:03 [INFO ]  Epoch:   21	Loss: 1.1374	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:05 [INFO ]  Epoch:   22	Loss: 1.0595	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:06 [INFO ]  Epoch:   23	Loss: 1.0586	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:37:08 [INFO ]  Epoch:   24	Loss: 1.0222	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:10 [INFO ]  Epoch:   25	Loss: 0.9618	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:11 [INFO ]  Epoch:   26	Loss: 0.8979	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:13 [INFO ]  Epoch:   27	Loss: 0.9144	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:15 [INFO ]  Epoch:   28	Loss: 0.9404	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:17 [INFO ]  Epoch:   29	Loss: 0.9052	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:18 [INFO ]  Epoch:   30	Loss: 0.9129	Data Time: 0.18s	Train Time: 0.00s
2022-10-04 19:37:20 [INFO ]  Epoch:   31	Loss: 0.9439	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:23 [INFO ]  Epoch:   32	Loss: 0.8707	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:24 [INFO ]  Epoch:   33	Loss: 0.8333	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:37:26 [INFO ]  Epoch:   34	Loss: 0.8637	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:29 [INFO ]  Epoch:   35	Loss: 0.8472	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:30 [INFO ]  Epoch:   36	Loss: 0.7791	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:32 [INFO ]  Epoch:   37	Loss: 0.8610	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:34 [INFO ]  Epoch:   38	Loss: 0.7592	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:36 [INFO ]  Epoch:   39	Loss: 0.7618	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:38 [INFO ]  Epoch:   40	Loss: 0.8334	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:37:39 [INFO ]  Epoch:   41	Loss: 0.8017	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:41 [INFO ]  Epoch:   42	Loss: 1.0022	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:43 [INFO ]  Epoch:   43	Loss: 0.7994	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:37:45 [INFO ]  Epoch:   44	Loss: 0.7701	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:47 [INFO ]  Epoch:   45	Loss: 0.7657	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:37:48 [INFO ]  Epoch:   46	Loss: 0.8032	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:37:50 [INFO ]  Epoch:   47	Loss: 0.7013	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:37:52 [INFO ]  Epoch:   48	Loss: 0.8025	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:37:54 [INFO ]  Epoch:   49	Loss: 0.7343	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:37:56 [INFO ]  Epoch:   50	Loss: 0.6641	Data Time: 0.14s	Train Time: 0.01s
2022-10-04 19:37:58 [INFO ]  Epoch:   51	Loss: 0.6386	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:37:59 [INFO ]  Epoch:   52	Loss: 0.7409	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 19:38:01 [INFO ]  Epoch:   53	Loss: 0.7175	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:03 [INFO ]  Epoch:   54	Loss: 0.7223	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:05 [INFO ]  Epoch:   55	Loss: 0.6816	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:38:07 [INFO ]  Epoch:   56	Loss: 0.6786	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:38:09 [INFO ]  Epoch:   57	Loss: 0.6572	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:38:10 [INFO ]  Epoch:   58	Loss: 0.6689	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:12 [INFO ]  Epoch:   59	Loss: 0.5903	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:38:14 [INFO ]  Epoch:   60	Loss: 0.6320	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:16 [INFO ]  Epoch:   61	Loss: 0.6719	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:38:17 [INFO ]  Epoch:   62	Loss: 0.7312	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:19 [INFO ]  Epoch:   63	Loss: 0.6907	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:21 [INFO ]  Epoch:   64	Loss: 0.6560	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:38:22 [INFO ]  Epoch:   65	Loss: 0.6590	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:24 [INFO ]  Epoch:   66	Loss: 0.6120	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:26 [INFO ]  Epoch:   67	Loss: 0.7349	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:38:28 [INFO ]  Epoch:   68	Loss: 0.7366	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:30 [INFO ]  Epoch:   69	Loss: 0.6806	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:38:32 [INFO ]  Epoch:   70	Loss: 0.7416	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:33 [INFO ]  Epoch:   71	Loss: 0.7486	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:35 [INFO ]  Epoch:   72	Loss: 0.6611	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:37 [INFO ]  Epoch:   73	Loss: 0.6287	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:38:39 [INFO ]  Epoch:   74	Loss: 0.6557	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:38:40 [INFO ]  Epoch:   75	Loss: 0.6341	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:42 [INFO ]  Epoch:   76	Loss: 0.6716	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:38:44 [INFO ]  Epoch:   77	Loss: 0.6494	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:38:46 [INFO ]  Epoch:   78	Loss: 0.8749	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:38:48 [INFO ]  Epoch:   79	Loss: 0.6334	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:38:49 [INFO ]  Epoch:   80	Loss: 0.6273	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:51 [INFO ]  Epoch:   81	Loss: 0.6451	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:38:53 [INFO ]  Epoch:   82	Loss: 0.6059	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:38:55 [INFO ]  Epoch:   83	Loss: 0.6406	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:38:56 [INFO ]  Epoch:   84	Loss: 0.5899	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:38:58 [INFO ]  Epoch:   85	Loss: 0.6245	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:00 [INFO ]  Epoch:   86	Loss: 0.6107	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:02 [INFO ]  Epoch:   87	Loss: 0.6385	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:03 [INFO ]  Epoch:   88	Loss: 0.6160	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:05 [INFO ]  Epoch:   89	Loss: 0.6561	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:07 [INFO ]  Epoch:   90	Loss: 0.6694	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:39:09 [INFO ]  Epoch:   91	Loss: 0.7159	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:11 [INFO ]  Epoch:   92	Loss: 0.6554	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:12 [INFO ]  Epoch:   93	Loss: 0.6734	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:14 [INFO ]  Epoch:   94	Loss: 0.6472	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:16 [INFO ]  Epoch:   95	Loss: 0.5511	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:39:18 [INFO ]  Epoch:   96	Loss: 0.5871	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:20 [INFO ]  Epoch:   97	Loss: 0.6431	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:22 [INFO ]  Epoch:   98	Loss: 0.6160	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:24 [INFO ]  Epoch:   99	Loss: 0.6075	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:39:25 [INFO ]  Epoch:  100	Loss: 0.6471	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:27 [INFO ]  Epoch:  101	Loss: 0.6319	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:29 [INFO ]  Epoch:  102	Loss: 0.6185	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:31 [INFO ]  Epoch:  103	Loss: 0.6464	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:39:33 [INFO ]  Epoch:  104	Loss: 0.5668	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:39:34 [INFO ]  Epoch:  105	Loss: 0.5848	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:36 [INFO ]  Epoch:  106	Loss: 0.6219	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:38 [INFO ]  Epoch:  107	Loss: 0.5338	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:39:40 [INFO ]  Epoch:  108	Loss: 0.6543	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:42 [INFO ]  Epoch:  109	Loss: 0.5893	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:43 [INFO ]  Epoch:  110	Loss: 0.5883	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:45 [INFO ]  Epoch:  111	Loss: 0.6029	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:39:47 [INFO ]  Epoch:  112	Loss: 0.5798	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:49 [INFO ]  Epoch:  113	Loss: 0.6239	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:51 [INFO ]  Epoch:  114	Loss: 0.6351	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:53 [INFO ]  Epoch:  115	Loss: 0.5954	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:39:54 [INFO ]  Epoch:  116	Loss: 0.5930	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:39:56 [INFO ]  Epoch:  117	Loss: 0.6220	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:39:58 [INFO ]  Epoch:  118	Loss: 0.5567	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:40:00 [INFO ]  Epoch:  119	Loss: 0.6029	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:40:02 [INFO ]  Epoch:  120	Loss: 0.5684	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:40:03 [INFO ]  Epoch:  121	Loss: 0.5957	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:05 [INFO ]  Epoch:  122	Loss: 0.5556	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:40:07 [INFO ]  Epoch:  123	Loss: 0.6339	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:40:08 [INFO ]  Epoch:  124	Loss: 0.5830	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:40:10 [INFO ]  Epoch:  125	Loss: 0.5784	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:40:12 [INFO ]  Epoch:  126	Loss: 0.5974	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:40:14 [INFO ]  Epoch:  127	Loss: 0.5955	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:40:16 [INFO ]  Epoch:  128	Loss: 0.6408	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:17 [INFO ]  Epoch:  129	Loss: 0.6027	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:19 [INFO ]  Epoch:  130	Loss: 0.6406	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:40:21 [INFO ]  Epoch:  131	Loss: 0.6349	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:40:23 [INFO ]  Epoch:  132	Loss: 0.6471	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:40:25 [INFO ]  Epoch:  133	Loss: 0.6450	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:40:27 [INFO ]  Epoch:  134	Loss: 0.5631	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:40:28 [INFO ]  Epoch:  135	Loss: 0.6590	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:40:30 [INFO ]  Epoch:  136	Loss: 0.6322	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:32 [INFO ]  Epoch:  137	Loss: 0.6244	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:40:34 [INFO ]  Epoch:  138	Loss: 0.5760	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:40:35 [INFO ]  Epoch:  139	Loss: 0.5497	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:40:37 [INFO ]  Epoch:  140	Loss: 0.5951	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:40:39 [INFO ]  Epoch:  141	Loss: 0.6564	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:41 [INFO ]  Epoch:  142	Loss: 0.6035	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:40:42 [INFO ]  Epoch:  143	Loss: 0.6258	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:44 [INFO ]  Epoch:  144	Loss: 0.5366	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:40:46 [INFO ]  Epoch:  145	Loss: 0.5797	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:48 [INFO ]  Epoch:  146	Loss: 0.6143	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:40:50 [INFO ]  Epoch:  147	Loss: 0.6007	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:40:51 [INFO ]  Epoch:  148	Loss: 0.6337	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:40:53 [INFO ]  Epoch:  149	Loss: 0.6381	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:40:55 [INFO ]  Epoch:  150	Loss: 0.6110	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:40:57 [INFO ]  Epoch:  151	Loss: 0.6624	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:40:59 [INFO ]  Epoch:  152	Loss: 0.5789	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:01 [INFO ]  Epoch:  153	Loss: 0.6208	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:03 [INFO ]  Epoch:  154	Loss: 0.5771	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:41:04 [INFO ]  Epoch:  155	Loss: 0.6519	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:41:06 [INFO ]  Epoch:  156	Loss: 0.6698	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:08 [INFO ]  Epoch:  157	Loss: 0.6433	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:41:10 [INFO ]  Epoch:  158	Loss: 0.5820	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:12 [INFO ]  Epoch:  159	Loss: 0.5671	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:41:13 [INFO ]  Epoch:  160	Loss: 0.6786	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:41:15 [INFO ]  Epoch:  161	Loss: 0.5538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:41:17 [INFO ]  Epoch:  162	Loss: 0.5610	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:19 [INFO ]  Epoch:  163	Loss: 0.6263	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:41:21 [INFO ]  Epoch:  164	Loss: 0.6117	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:41:23 [INFO ]  Epoch:  165	Loss: 0.6567	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:25 [INFO ]  Epoch:  166	Loss: 0.5879	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:41:26 [INFO ]  Epoch:  167	Loss: 0.5526	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:41:28 [INFO ]  Epoch:  168	Loss: 0.5798	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:30 [INFO ]  Epoch:  169	Loss: 0.6930	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:32 [INFO ]  Epoch:  170	Loss: 0.6417	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:34 [INFO ]  Epoch:  171	Loss: 0.6138	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:41:35 [INFO ]  Epoch:  172	Loss: 0.6547	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:41:37 [INFO ]  Epoch:  173	Loss: 0.6562	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:41:39 [INFO ]  Epoch:  174	Loss: 0.5907	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:41:41 [INFO ]  Epoch:  175	Loss: 0.6212	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:43 [INFO ]  Epoch:  176	Loss: 0.6878	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:41:45 [INFO ]  Epoch:  177	Loss: 0.6018	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:47 [INFO ]  Epoch:  178	Loss: 0.5173	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:49 [INFO ]  Epoch:  179	Loss: 0.5675	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:51 [INFO ]  Epoch:  180	Loss: 0.5859	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:41:52 [INFO ]  Epoch:  181	Loss: 0.5511	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:41:54 [INFO ]  Epoch:  182	Loss: 0.5854	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:41:56 [INFO ]  Epoch:  183	Loss: 0.6769	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:41:58 [INFO ]  Epoch:  184	Loss: 0.6380	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:41:59 [INFO ]  Epoch:  185	Loss: 0.6481	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:42:01 [INFO ]  Epoch:  186	Loss: 0.5484	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:42:03 [INFO ]  Epoch:  187	Loss: 0.5295	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:42:05 [INFO ]  Epoch:  188	Loss: 0.5384	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:42:07 [INFO ]  Epoch:  189	Loss: 0.5607	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:42:09 [INFO ]  Epoch:  190	Loss: 0.5652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:42:11 [INFO ]  Epoch:  191	Loss: 0.5754	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:42:12 [INFO ]  Epoch:  192	Loss: 0.5317	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:42:14 [INFO ]  Epoch:  193	Loss: 0.6644	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:42:16 [INFO ]  Epoch:  194	Loss: 0.5869	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:42:18 [INFO ]  Epoch:  195	Loss: 0.5832	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:42:20 [INFO ]  Epoch:  196	Loss: 0.6281	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:42:22 [INFO ]  Epoch:  197	Loss: 0.5795	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:42:24 [INFO ]  Epoch:  198	Loss: 0.6585	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:42:25 [INFO ]  Epoch:  199	Loss: 0.6348	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:42:27 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 19:42:27 [INFO ]  
2022-10-04 19:42:27 [INFO ]  Final evaluation for SVHN :
2022-10-04 19:42:30 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:42:30 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:42:30 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:42:30 [INFO ]  	   step  1 (lr=0.386771)                   81.55%                   0.6857
2022-10-04 19:42:30 [INFO ]  
2022-10-04 19:42:30 [INFO ]  
2022-10-04 19:42:30 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 19:42:33 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:42:33 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:42:33 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 19:42:33 [INFO ]  	   step  1 (lr=0.386771)                   16.20%                   5.2025
2022-10-04 19:42:33 [INFO ]  
2022-10-04 19:42:33 [INFO ]  CPU Time: 3.36 minutes
2022-10-04 19:46:46 [INFO ]  ======================================== 2022-10-04 19:46:46 ========================================
2022-10-04 19:46:46 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-04 19:46:46 [INFO ]  Options: 
2022-10-04 19:46:46 [INFO ]  	base_dir: null
2022-10-04 19:46:46 [INFO ]  	batch_size: 1024
2022-10-04 19:46:46 [INFO ]  	checkpoint_interval: 300
2022-10-04 19:46:46 [INFO ]  	dataset: SVHN
2022-10-04 19:46:46 [INFO ]  	dataset_labels:
2022-10-04 19:46:46 [INFO ]  	- 0
2022-10-04 19:46:46 [INFO ]  	- 1
2022-10-04 19:46:46 [INFO ]  	- 2
2022-10-04 19:46:46 [INFO ]  	- 3
2022-10-04 19:46:46 [INFO ]  	- 4
2022-10-04 19:46:46 [INFO ]  	- 5
2022-10-04 19:46:46 [INFO ]  	- 6
2022-10-04 19:46:46 [INFO ]  	- 7
2022-10-04 19:46:46 [INFO ]  	- 8
2022-10-04 19:46:46 [INFO ]  	- 9
2022-10-04 19:46:46 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-04 19:46:46 [INFO ]  	- !!python/tuple
2022-10-04 19:46:46 [INFO ]  	    - 0.4379104971885681
2022-10-04 19:46:46 [INFO ]  	    - 0.44398033618927
2022-10-04 19:46:46 [INFO ]  	    - 0.4729299545288086
2022-10-04 19:46:46 [INFO ]  	- !!python/tuple
2022-10-04 19:46:46 [INFO ]  	    - 0.19803012907505035
2022-10-04 19:46:46 [INFO ]  	    - 0.2010156363248825
2022-10-04 19:46:46 [INFO ]  	    - 0.19703614711761475
2022-10-04 19:46:46 [INFO ]  	dataset_root: ./data/svhn
2022-10-04 19:46:46 [INFO ]  	decay_epochs: 50
2022-10-04 19:46:46 [INFO ]  	decay_factor: 0.1
2022-10-04 19:46:46 [INFO ]  	device_id: 0
2022-10-04 19:46:46 [INFO ]  	distill_epochs: 1
2022-10-04 19:46:46 [INFO ]  	distill_lr: 0.02
2022-10-04 19:46:46 [INFO ]  	distill_steps: 1
2022-10-04 19:46:46 [INFO ]  	epochs: 200
2022-10-04 19:46:46 [INFO ]  	expand_cls: false
2022-10-04 19:46:46 [INFO ]  	forgetting_dataset: null
2022-10-04 19:46:46 [INFO ]  	init: xavier
2022-10-04 19:46:46 [INFO ]  	init_param: 1.0
2022-10-04 19:46:46 [INFO ]  	input_size: 32
2022-10-04 19:46:46 [INFO ]  	ipc: 15
2022-10-04 19:46:46 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-04 19:46:46 [INFO ]  	log_interval: 100
2022-10-04 19:46:46 [INFO ]  	log_level: INFO
2022-10-04 19:46:46 [INFO ]  	lr: 0.01
2022-10-04 19:46:46 [INFO ]  	mode: distill_adapt
2022-10-04 19:46:46 [INFO ]  	nc: 3
2022-10-04 19:46:46 [INFO ]  	num_classes: 10
2022-10-04 19:46:46 [INFO ]  	num_workers: 8
2022-10-04 19:46:46 [INFO ]  	phase: train
2022-10-04 19:46:46 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-04 19:46:46 [INFO ]  	start_time: '2022-10-04 19:46:46'
2022-10-04 19:46:46 [INFO ]  	test_batch_size: 1024
2022-10-04 19:46:46 [INFO ]  	
2022-10-04 19:46:48 [INFO ]  train dataset size:	73257
2022-10-04 19:46:48 [INFO ]  test dataset size: 	26032
2022-10-04 19:46:48 [INFO ]  datasets built!
2022-10-04 19:46:48 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-04 19:46:49 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-04 19:46:49 [INFO ]  
2022-10-04 19:46:49 [INFO ]  Begin of epoch 0 :
2022-10-04 19:46:53 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:46:53 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:46:53 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:46:53 [INFO ]  	   step  1 (lr=0.020000)                    7.39%                   8.4684
2022-10-04 19:46:53 [INFO ]  
2022-10-04 19:46:53 [INFO ]  Epoch:    0	Loss: 8.7464	Data Time: 0.45s	Train Time: 0.04s
2022-10-04 19:46:55 [INFO ]  Epoch:    1	Loss: 2.9151	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:46:56 [INFO ]  Epoch:    2	Loss: 2.4301	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:46:58 [INFO ]  Epoch:    3	Loss: 2.2684	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:47:00 [INFO ]  Epoch:    4	Loss: 2.2089	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:47:02 [INFO ]  Epoch:    5	Loss: 2.1865	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:47:04 [INFO ]  Epoch:    6	Loss: 2.1350	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:47:06 [INFO ]  Epoch:    7	Loss: 2.0863	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:47:08 [INFO ]  Epoch:    8	Loss: 2.0382	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:47:09 [INFO ]  Epoch:    9	Loss: 1.9124	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:47:11 [INFO ]  Epoch:   10	Loss: 1.8663	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:47:13 [INFO ]  Epoch:   11	Loss: 1.6484	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:47:15 [INFO ]  Epoch:   12	Loss: 1.4757	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:47:16 [INFO ]  Epoch:   13	Loss: 1.4689	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:47:18 [INFO ]  Epoch:   14	Loss: 1.3326	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:20 [INFO ]  Epoch:   15	Loss: 1.2495	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:47:22 [INFO ]  Epoch:   16	Loss: 1.1963	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:47:24 [INFO ]  Epoch:   17	Loss: 1.2169	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:26 [INFO ]  Epoch:   18	Loss: 1.0375	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:47:28 [INFO ]  Epoch:   19	Loss: 1.0320	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:47:30 [INFO ]  Epoch:   20	Loss: 1.1399	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:47:32 [INFO ]  Epoch:   21	Loss: 1.0603	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:47:34 [INFO ]  Epoch:   22	Loss: 1.0984	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:47:35 [INFO ]  Epoch:   23	Loss: 1.0808	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:47:37 [INFO ]  Epoch:   24	Loss: 0.9100	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:47:39 [INFO ]  Epoch:   25	Loss: 1.0283	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:47:41 [INFO ]  Epoch:   26	Loss: 1.0057	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:47:42 [INFO ]  Epoch:   27	Loss: 0.9149	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:47:44 [INFO ]  Epoch:   28	Loss: 0.8752	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:46 [INFO ]  Epoch:   29	Loss: 0.8677	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:47:48 [INFO ]  Epoch:   30	Loss: 0.9644	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:47:50 [INFO ]  Epoch:   31	Loss: 0.9545	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:47:52 [INFO ]  Epoch:   32	Loss: 0.8462	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:54 [INFO ]  Epoch:   33	Loss: 0.8653	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:47:56 [INFO ]  Epoch:   34	Loss: 0.9345	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:57 [INFO ]  Epoch:   35	Loss: 0.8065	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:47:59 [INFO ]  Epoch:   36	Loss: 0.8713	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:01 [INFO ]  Epoch:   37	Loss: 0.8110	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:03 [INFO ]  Epoch:   38	Loss: 0.8198	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:48:04 [INFO ]  Epoch:   39	Loss: 0.7756	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:06 [INFO ]  Epoch:   40	Loss: 0.7583	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:08 [INFO ]  Epoch:   41	Loss: 0.8793	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:10 [INFO ]  Epoch:   42	Loss: 0.9400	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:48:11 [INFO ]  Epoch:   43	Loss: 0.8444	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:13 [INFO ]  Epoch:   44	Loss: 0.8031	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:15 [INFO ]  Epoch:   45	Loss: 0.8410	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:48:17 [INFO ]  Epoch:   46	Loss: 0.7416	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:19 [INFO ]  Epoch:   47	Loss: 0.7335	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:48:20 [INFO ]  Epoch:   48	Loss: 0.7044	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:22 [INFO ]  Epoch:   49	Loss: 0.7320	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:24 [INFO ]  Epoch:   50	Loss: 0.7459	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:48:26 [INFO ]  Epoch:   51	Loss: 0.6449	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:28 [INFO ]  Epoch:   52	Loss: 0.6715	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:30 [INFO ]  Epoch:   53	Loss: 0.7106	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:32 [INFO ]  Epoch:   54	Loss: 0.6251	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:34 [INFO ]  Epoch:   55	Loss: 0.7042	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:35 [INFO ]  Epoch:   56	Loss: 0.6204	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:38 [INFO ]  Epoch:   57	Loss: 0.6837	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:48:39 [INFO ]  Epoch:   58	Loss: 0.7080	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:41 [INFO ]  Epoch:   59	Loss: 0.6696	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:48:43 [INFO ]  Epoch:   60	Loss: 0.6080	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:48:45 [INFO ]  Epoch:   61	Loss: 0.7934	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:47 [INFO ]  Epoch:   62	Loss: 0.7899	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:48:49 [INFO ]  Epoch:   63	Loss: 0.6120	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:51 [INFO ]  Epoch:   64	Loss: 0.6752	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:48:53 [INFO ]  Epoch:   65	Loss: 0.6104	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:48:55 [INFO ]  Epoch:   66	Loss: 0.7129	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:48:56 [INFO ]  Epoch:   67	Loss: 0.6679	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:48:58 [INFO ]  Epoch:   68	Loss: 0.6996	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:49:00 [INFO ]  Epoch:   69	Loss: 0.6642	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:49:02 [INFO ]  Epoch:   70	Loss: 0.6546	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:04 [INFO ]  Epoch:   71	Loss: 0.6694	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:05 [INFO ]  Epoch:   72	Loss: 0.6831	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:49:07 [INFO ]  Epoch:   73	Loss: 0.7004	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:49:09 [INFO ]  Epoch:   74	Loss: 0.7134	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:11 [INFO ]  Epoch:   75	Loss: 0.7257	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:13 [INFO ]  Epoch:   76	Loss: 0.7325	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:14 [INFO ]  Epoch:   77	Loss: 0.7393	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:49:16 [INFO ]  Epoch:   78	Loss: 0.6403	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:49:18 [INFO ]  Epoch:   79	Loss: 0.6588	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:49:20 [INFO ]  Epoch:   80	Loss: 0.7158	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:49:22 [INFO ]  Epoch:   81	Loss: 0.7311	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:49:23 [INFO ]  Epoch:   82	Loss: 0.7206	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:49:25 [INFO ]  Epoch:   83	Loss: 0.6392	Data Time: 0.21s	Train Time: 0.01s
2022-10-04 19:49:27 [INFO ]  Epoch:   84	Loss: 0.6969	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:49:29 [INFO ]  Epoch:   85	Loss: 0.7192	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:31 [INFO ]  Epoch:   86	Loss: 0.7309	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:49:33 [INFO ]  Epoch:   87	Loss: 0.6418	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:49:35 [INFO ]  Epoch:   88	Loss: 0.6794	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:49:37 [INFO ]  Epoch:   89	Loss: 0.6343	Data Time: 0.27s	Train Time: 0.01s
2022-10-04 19:49:38 [INFO ]  Epoch:   90	Loss: 0.6066	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:49:41 [INFO ]  Epoch:   91	Loss: 0.6608	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:42 [INFO ]  Epoch:   92	Loss: 0.5673	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:49:44 [INFO ]  Epoch:   93	Loss: 0.5830	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:49:46 [INFO ]  Epoch:   94	Loss: 0.6821	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:48 [INFO ]  Epoch:   95	Loss: 0.6552	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:49 [INFO ]  Epoch:   96	Loss: 0.6895	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:49:51 [INFO ]  Epoch:   97	Loss: 0.6248	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:49:53 [INFO ]  Epoch:   98	Loss: 0.6261	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:49:55 [INFO ]  Epoch:   99	Loss: 0.6123	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:49:57 [INFO ]  Epoch:  100	Loss: 0.5601	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:49:59 [INFO ]  Epoch:  101	Loss: 0.6335	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:50:01 [INFO ]  Epoch:  102	Loss: 0.6790	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:50:02 [INFO ]  Epoch:  103	Loss: 0.6918	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:04 [INFO ]  Epoch:  104	Loss: 0.6550	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:06 [INFO ]  Epoch:  105	Loss: 0.6818	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:50:08 [INFO ]  Epoch:  106	Loss: 0.6247	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:50:10 [INFO ]  Epoch:  107	Loss: 0.6690	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:12 [INFO ]  Epoch:  108	Loss: 0.5722	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:14 [INFO ]  Epoch:  109	Loss: 0.6021	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:16 [INFO ]  Epoch:  110	Loss: 0.5771	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:50:18 [INFO ]  Epoch:  111	Loss: 0.6068	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:19 [INFO ]  Epoch:  112	Loss: 0.6056	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:21 [INFO ]  Epoch:  113	Loss: 0.6268	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:50:23 [INFO ]  Epoch:  114	Loss: 0.6198	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:50:25 [INFO ]  Epoch:  115	Loss: 0.6531	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:27 [INFO ]  Epoch:  116	Loss: 0.6165	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:50:29 [INFO ]  Epoch:  117	Loss: 0.6039	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:31 [INFO ]  Epoch:  118	Loss: 0.6042	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:33 [INFO ]  Epoch:  119	Loss: 0.5801	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:50:34 [INFO ]  Epoch:  120	Loss: 0.6535	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:50:36 [INFO ]  Epoch:  121	Loss: 0.6029	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:38 [INFO ]  Epoch:  122	Loss: 0.6217	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:50:40 [INFO ]  Epoch:  123	Loss: 0.7106	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:42 [INFO ]  Epoch:  124	Loss: 0.5881	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:50:44 [INFO ]  Epoch:  125	Loss: 0.5976	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:46 [INFO ]  Epoch:  126	Loss: 0.6599	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:47 [INFO ]  Epoch:  127	Loss: 0.6523	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:50:49 [INFO ]  Epoch:  128	Loss: 0.6099	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:50:51 [INFO ]  Epoch:  129	Loss: 0.6757	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:50:53 [INFO ]  Epoch:  130	Loss: 0.6829	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:50:55 [INFO ]  Epoch:  131	Loss: 0.5813	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:50:56 [INFO ]  Epoch:  132	Loss: 0.5878	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:50:58 [INFO ]  Epoch:  133	Loss: 0.6517	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:51:00 [INFO ]  Epoch:  134	Loss: 0.6297	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:51:02 [INFO ]  Epoch:  135	Loss: 0.6081	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:04 [INFO ]  Epoch:  136	Loss: 0.5952	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:06 [INFO ]  Epoch:  137	Loss: 0.5946	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:51:08 [INFO ]  Epoch:  138	Loss: 0.6351	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:09 [INFO ]  Epoch:  139	Loss: 0.6837	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:51:11 [INFO ]  Epoch:  140	Loss: 0.6538	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:13 [INFO ]  Epoch:  141	Loss: 0.6268	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:51:15 [INFO ]  Epoch:  142	Loss: 0.6652	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:17 [INFO ]  Epoch:  143	Loss: 0.7163	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:51:18 [INFO ]  Epoch:  144	Loss: 0.6059	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:20 [INFO ]  Epoch:  145	Loss: 0.6761	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:22 [INFO ]  Epoch:  146	Loss: 0.6115	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:24 [INFO ]  Epoch:  147	Loss: 0.6643	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:26 [INFO ]  Epoch:  148	Loss: 0.7036	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:27 [INFO ]  Epoch:  149	Loss: 0.6780	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:51:29 [INFO ]  Epoch:  150	Loss: 0.5982	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:51:32 [INFO ]  Epoch:  151	Loss: 0.6459	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:51:33 [INFO ]  Epoch:  152	Loss: 0.5720	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:35 [INFO ]  Epoch:  153	Loss: 0.6390	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:37 [INFO ]  Epoch:  154	Loss: 0.7002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:39 [INFO ]  Epoch:  155	Loss: 0.5813	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:41 [INFO ]  Epoch:  156	Loss: 0.6107	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:51:43 [INFO ]  Epoch:  157	Loss: 0.6541	Data Time: 0.26s	Train Time: 0.01s
2022-10-04 19:51:45 [INFO ]  Epoch:  158	Loss: 0.5963	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:47 [INFO ]  Epoch:  159	Loss: 0.5511	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:51:48 [INFO ]  Epoch:  160	Loss: 0.7312	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:50 [INFO ]  Epoch:  161	Loss: 0.5934	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:52 [INFO ]  Epoch:  162	Loss: 0.6269	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:51:54 [INFO ]  Epoch:  163	Loss: 0.5817	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:51:56 [INFO ]  Epoch:  164	Loss: 0.6772	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:51:58 [INFO ]  Epoch:  165	Loss: 0.6413	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:51:59 [INFO ]  Epoch:  166	Loss: 0.6480	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:52:01 [INFO ]  Epoch:  167	Loss: 0.6157	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:52:03 [INFO ]  Epoch:  168	Loss: 0.5899	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:05 [INFO ]  Epoch:  169	Loss: 0.6051	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:52:07 [INFO ]  Epoch:  170	Loss: 0.5983	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:52:09 [INFO ]  Epoch:  171	Loss: 0.6194	Data Time: 0.22s	Train Time: 0.01s
2022-10-04 19:52:11 [INFO ]  Epoch:  172	Loss: 0.6716	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:52:12 [INFO ]  Epoch:  173	Loss: 0.5965	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:14 [INFO ]  Epoch:  174	Loss: 0.6328	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:16 [INFO ]  Epoch:  175	Loss: 0.5743	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:18 [INFO ]  Epoch:  176	Loss: 0.6516	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:20 [INFO ]  Epoch:  177	Loss: 0.6251	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:21 [INFO ]  Epoch:  178	Loss: 0.6178	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:23 [INFO ]  Epoch:  179	Loss: 0.6552	Data Time: 0.17s	Train Time: 0.01s
2022-10-04 19:52:25 [INFO ]  Epoch:  180	Loss: 0.5943	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:52:27 [INFO ]  Epoch:  181	Loss: 0.5869	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:29 [INFO ]  Epoch:  182	Loss: 0.6478	Data Time: 0.24s	Train Time: 0.01s
2022-10-04 19:52:31 [INFO ]  Epoch:  183	Loss: 0.5851	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:32 [INFO ]  Epoch:  184	Loss: 0.6728	Data Time: 0.20s	Train Time: 0.01s
2022-10-04 19:52:34 [INFO ]  Epoch:  185	Loss: 0.5839	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:52:36 [INFO ]  Epoch:  186	Loss: 0.6002	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:38 [INFO ]  Epoch:  187	Loss: 0.5972	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:40 [INFO ]  Epoch:  188	Loss: 0.6195	Data Time: 0.15s	Train Time: 0.01s
2022-10-04 19:52:42 [INFO ]  Epoch:  189	Loss: 0.6173	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:44 [INFO ]  Epoch:  190	Loss: 0.5831	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:52:46 [INFO ]  Epoch:  191	Loss: 0.6644	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:52:47 [INFO ]  Epoch:  192	Loss: 0.6146	Data Time: 0.19s	Train Time: 0.01s
2022-10-04 19:52:49 [INFO ]  Epoch:  193	Loss: 0.6593	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:51 [INFO ]  Epoch:  194	Loss: 0.5850	Data Time: 0.25s	Train Time: 0.01s
2022-10-04 19:52:53 [INFO ]  Epoch:  195	Loss: 0.6085	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:54 [INFO ]  Epoch:  196	Loss: 0.7069	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:52:56 [INFO ]  Epoch:  197	Loss: 0.6121	Data Time: 0.18s	Train Time: 0.01s
2022-10-04 19:52:58 [INFO ]  Epoch:  198	Loss: 0.5479	Data Time: 0.16s	Train Time: 0.01s
2022-10-04 19:53:00 [INFO ]  Epoch:  199	Loss: 0.6632	Data Time: 0.23s	Train Time: 0.01s
2022-10-04 19:53:01 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-04 19:53:01 [INFO ]  
2022-10-04 19:53:01 [INFO ]  Final evaluation for SVHN :
2022-10-04 19:53:05 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:53:05 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:53:05 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-04 19:53:05 [INFO ]  	   step  1 (lr=0.391622)                   81.00%                   0.7004
2022-10-04 19:53:05 [INFO ]  
2022-10-04 19:53:05 [INFO ]  
2022-10-04 19:53:05 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-04 19:53:08 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-04 19:53:08 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-04 19:53:08 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-04 19:53:08 [INFO ]  	   step  1 (lr=0.391622)                   16.57%                   5.3131
2022-10-04 19:53:08 [INFO ]  
2022-10-04 19:53:08 [INFO ]  CPU Time: 3.49 minutes
2022-10-11 08:23:56 [INFO ]  ======================================== 2022-10-11 08:23:56 ========================================
2022-10-11 08:23:56 [INFO ]  Base directory is ./results/distill_adapt/SVHN/Source_FASHION_MNIST
2022-10-11 08:23:56 [INFO ]  Options: 
2022-10-11 08:23:56 [INFO ]  	base_dir: null
2022-10-11 08:23:56 [INFO ]  	batch_size: 1024
2022-10-11 08:23:56 [INFO ]  	checkpoint_interval: 300
2022-10-11 08:23:56 [INFO ]  	dataset: SVHN
2022-10-11 08:23:56 [INFO ]  	dataset_labels:
2022-10-11 08:23:56 [INFO ]  	- 0
2022-10-11 08:23:56 [INFO ]  	- 1
2022-10-11 08:23:56 [INFO ]  	- 2
2022-10-11 08:23:56 [INFO ]  	- 3
2022-10-11 08:23:56 [INFO ]  	- 4
2022-10-11 08:23:56 [INFO ]  	- 5
2022-10-11 08:23:56 [INFO ]  	- 6
2022-10-11 08:23:56 [INFO ]  	- 7
2022-10-11 08:23:56 [INFO ]  	- 8
2022-10-11 08:23:56 [INFO ]  	- 9
2022-10-11 08:23:56 [INFO ]  	dataset_normalization: !!python/tuple
2022-10-11 08:23:56 [INFO ]  	- !!python/tuple
2022-10-11 08:23:56 [INFO ]  	    - 0.4379104971885681
2022-10-11 08:23:56 [INFO ]  	    - 0.44398033618927
2022-10-11 08:23:56 [INFO ]  	    - 0.4729299545288086
2022-10-11 08:23:56 [INFO ]  	- !!python/tuple
2022-10-11 08:23:56 [INFO ]  	    - 0.19803012907505035
2022-10-11 08:23:56 [INFO ]  	    - 0.2010156363248825
2022-10-11 08:23:56 [INFO ]  	    - 0.19703614711761475
2022-10-11 08:23:56 [INFO ]  	dataset_root: ./data/svhn
2022-10-11 08:23:56 [INFO ]  	decay_epochs: 50
2022-10-11 08:23:56 [INFO ]  	decay_factor: 0.1
2022-10-11 08:23:56 [INFO ]  	device_id: 0
2022-10-11 08:23:56 [INFO ]  	distill_epochs: 1
2022-10-11 08:23:56 [INFO ]  	distill_lr: 0.02
2022-10-11 08:23:56 [INFO ]  	distill_steps: 1
2022-10-11 08:23:56 [INFO ]  	epochs: 200
2022-10-11 08:23:56 [INFO ]  	expand_cls: false
2022-10-11 08:23:56 [INFO ]  	forgetting_dataset: null
2022-10-11 08:23:56 [INFO ]  	init: xavier
2022-10-11 08:23:56 [INFO ]  	init_param: 1.0
2022-10-11 08:23:56 [INFO ]  	input_size: 32
2022-10-11 08:23:56 [INFO ]  	ipc: 1
2022-10-11 08:23:56 [INFO ]  	log_file: ./results/distill_adapt/SVHN/Source_FASHION_MNIST/log.txt
2022-10-11 08:23:56 [INFO ]  	log_interval: 100
2022-10-11 08:23:56 [INFO ]  	log_level: INFO
2022-10-11 08:23:56 [INFO ]  	lr: 0.01
2022-10-11 08:23:56 [INFO ]  	mode: distill_adapt
2022-10-11 08:23:56 [INFO ]  	nc: 3
2022-10-11 08:23:56 [INFO ]  	num_classes: 10
2022-10-11 08:23:56 [INFO ]  	num_workers: 8
2022-10-11 08:23:56 [INFO ]  	phase: train
2022-10-11 08:23:56 [INFO ]  	source_dataset: FASHION_MNIST
2022-10-11 08:23:56 [INFO ]  	start_time: '2022-10-11 08:23:56'
2022-10-11 08:23:56 [INFO ]  	test_batch_size: 1024
2022-10-11 08:23:56 [INFO ]  	
2022-10-11 08:23:58 [INFO ]  train dataset size:	73257
2022-10-11 08:23:58 [INFO ]  test dataset size: 	26032
2022-10-11 08:23:58 [INFO ]  datasets built!
2022-10-11 08:23:58 [INFO ]  Build one LeNet network with [xavier(1.0)] init
2022-10-11 08:24:00 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/checkpoints/epoch0000/results.pth
2022-10-11 08:24:00 [INFO ]  
2022-10-11 08:24:00 [INFO ]  Begin of epoch 0 :
2022-10-11 08:24:04 [INFO ]  Begin of epoch 0 evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-11 08:24:04 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-11 08:24:04 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-11 08:24:04 [INFO ]  	   step  1 (lr=0.020000)                    6.93%                   9.0801
2022-10-11 08:24:04 [INFO ]  
2022-10-11 08:24:04 [INFO ]  Epoch:    0	Loss: 9.6896	Data Time: 0.59s	Train Time: 0.03s
2022-10-11 08:24:06 [INFO ]  Epoch:    1	Loss: 3.4181	Data Time: 0.12s	Train Time: 0.01s
2022-10-11 08:24:08 [INFO ]  Epoch:    2	Loss: 2.8977	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:10 [INFO ]  Epoch:    3	Loss: 2.4750	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:24:11 [INFO ]  Epoch:    4	Loss: 2.3148	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:13 [INFO ]  Epoch:    5	Loss: 2.2513	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:24:15 [INFO ]  Epoch:    6	Loss: 2.2041	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:24:17 [INFO ]  Epoch:    7	Loss: 2.2118	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:24:19 [INFO ]  Epoch:    8	Loss: 2.1963	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:24:21 [INFO ]  Epoch:    9	Loss: 2.1441	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:23 [INFO ]  Epoch:   10	Loss: 2.1637	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:25 [INFO ]  Epoch:   11	Loss: 2.0814	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:24:27 [INFO ]  Epoch:   12	Loss: 2.0804	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:29 [INFO ]  Epoch:   13	Loss: 2.0773	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:31 [INFO ]  Epoch:   14	Loss: 2.0160	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:33 [INFO ]  Epoch:   15	Loss: 1.9089	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:35 [INFO ]  Epoch:   16	Loss: 1.8122	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:37 [INFO ]  Epoch:   17	Loss: 1.8128	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:24:39 [INFO ]  Epoch:   18	Loss: 1.7496	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:41 [INFO ]  Epoch:   19	Loss: 2.0540	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:24:43 [INFO ]  Epoch:   20	Loss: 1.8651	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:24:45 [INFO ]  Epoch:   21	Loss: 1.7012	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:24:46 [INFO ]  Epoch:   22	Loss: 1.7630	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:24:48 [INFO ]  Epoch:   23	Loss: 1.6773	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:50 [INFO ]  Epoch:   24	Loss: 1.6123	Data Time: 0.26s	Train Time: 0.01s
2022-10-11 08:24:52 [INFO ]  Epoch:   25	Loss: 1.7413	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:54 [INFO ]  Epoch:   26	Loss: 1.5619	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:24:56 [INFO ]  Epoch:   27	Loss: 1.9907	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:24:58 [INFO ]  Epoch:   28	Loss: 1.5786	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:00 [INFO ]  Epoch:   29	Loss: 1.5819	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:02 [INFO ]  Epoch:   30	Loss: 1.8373	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:04 [INFO ]  Epoch:   31	Loss: 1.5957	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:25:06 [INFO ]  Epoch:   32	Loss: 1.7359	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:25:08 [INFO ]  Epoch:   33	Loss: 1.7011	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:10 [INFO ]  Epoch:   34	Loss: 1.6116	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:12 [INFO ]  Epoch:   35	Loss: 1.5900	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:14 [INFO ]  Epoch:   36	Loss: 1.6275	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:16 [INFO ]  Epoch:   37	Loss: 1.4985	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:25:18 [INFO ]  Epoch:   38	Loss: 1.5583	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:25:20 [INFO ]  Epoch:   39	Loss: 1.6745	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:22 [INFO ]  Epoch:   40	Loss: 1.4379	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:24 [INFO ]  Epoch:   41	Loss: 1.3993	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:25:25 [INFO ]  Epoch:   42	Loss: 1.4457	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:27 [INFO ]  Epoch:   43	Loss: 1.7825	Data Time: 0.20s	Train Time: 0.01s
2022-10-11 08:25:29 [INFO ]  Epoch:   44	Loss: 1.6713	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:31 [INFO ]  Epoch:   45	Loss: 1.5038	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:33 [INFO ]  Epoch:   46	Loss: 1.5857	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:35 [INFO ]  Epoch:   47	Loss: 1.6092	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:37 [INFO ]  Epoch:   48	Loss: 1.7652	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:40 [INFO ]  Epoch:   49	Loss: 1.4727	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:42 [INFO ]  Epoch:   50	Loss: 1.3808	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:44 [INFO ]  Epoch:   51	Loss: 1.4713	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:46 [INFO ]  Epoch:   52	Loss: 1.4085	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:25:48 [INFO ]  Epoch:   53	Loss: 1.3676	Data Time: 0.20s	Train Time: 0.01s
2022-10-11 08:25:50 [INFO ]  Epoch:   54	Loss: 1.3886	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:52 [INFO ]  Epoch:   55	Loss: 1.3166	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:25:54 [INFO ]  Epoch:   56	Loss: 1.4323	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:25:56 [INFO ]  Epoch:   57	Loss: 1.3590	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:25:58 [INFO ]  Epoch:   58	Loss: 1.3870	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:00 [INFO ]  Epoch:   59	Loss: 1.3857	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:26:02 [INFO ]  Epoch:   60	Loss: 1.3355	Data Time: 0.20s	Train Time: 0.01s
2022-10-11 08:26:04 [INFO ]  Epoch:   61	Loss: 1.3304	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:06 [INFO ]  Epoch:   62	Loss: 1.3874	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:26:08 [INFO ]  Epoch:   63	Loss: 1.3810	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:26:10 [INFO ]  Epoch:   64	Loss: 1.6151	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:12 [INFO ]  Epoch:   65	Loss: 1.3385	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:26:14 [INFO ]  Epoch:   66	Loss: 1.3049	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:26:16 [INFO ]  Epoch:   67	Loss: 1.3008	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:26:18 [INFO ]  Epoch:   68	Loss: 1.2482	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:20 [INFO ]  Epoch:   69	Loss: 1.2913	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:26:22 [INFO ]  Epoch:   70	Loss: 1.3216	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:26:25 [INFO ]  Epoch:   71	Loss: 1.3767	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:26:26 [INFO ]  Epoch:   72	Loss: 1.1961	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:28 [INFO ]  Epoch:   73	Loss: 1.3516	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:26:31 [INFO ]  Epoch:   74	Loss: 1.2426	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:33 [INFO ]  Epoch:   75	Loss: 1.2506	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:35 [INFO ]  Epoch:   76	Loss: 1.3058	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:37 [INFO ]  Epoch:   77	Loss: 1.2598	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:39 [INFO ]  Epoch:   78	Loss: 1.2961	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:26:41 [INFO ]  Epoch:   79	Loss: 1.2648	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:43 [INFO ]  Epoch:   80	Loss: 1.2612	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:26:45 [INFO ]  Epoch:   81	Loss: 1.3687	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:47 [INFO ]  Epoch:   82	Loss: 1.3345	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:26:49 [INFO ]  Epoch:   83	Loss: 1.1732	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:26:51 [INFO ]  Epoch:   84	Loss: 1.2973	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:52 [INFO ]  Epoch:   85	Loss: 1.2117	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:55 [INFO ]  Epoch:   86	Loss: 1.1798	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:26:56 [INFO ]  Epoch:   87	Loss: 1.2931	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:26:58 [INFO ]  Epoch:   88	Loss: 1.2720	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:27:00 [INFO ]  Epoch:   89	Loss: 1.3072	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:02 [INFO ]  Epoch:   90	Loss: 1.2779	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:04 [INFO ]  Epoch:   91	Loss: 1.2341	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:27:06 [INFO ]  Epoch:   92	Loss: 1.3052	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:27:08 [INFO ]  Epoch:   93	Loss: 1.2076	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:27:10 [INFO ]  Epoch:   94	Loss: 1.2079	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:12 [INFO ]  Epoch:   95	Loss: 1.1739	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:14 [INFO ]  Epoch:   96	Loss: 1.7674	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:16 [INFO ]  Epoch:   97	Loss: 1.1524	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:18 [INFO ]  Epoch:   98	Loss: 1.4267	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:27:20 [INFO ]  Epoch:   99	Loss: 1.4080	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:22 [INFO ]  Epoch:  100	Loss: 1.3269	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:27:24 [INFO ]  Epoch:  101	Loss: 1.2261	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:27:26 [INFO ]  Epoch:  102	Loss: 1.3191	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:27:28 [INFO ]  Epoch:  103	Loss: 1.3638	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:30 [INFO ]  Epoch:  104	Loss: 1.2858	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:27:32 [INFO ]  Epoch:  105	Loss: 1.2713	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:27:34 [INFO ]  Epoch:  106	Loss: 1.2261	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:36 [INFO ]  Epoch:  107	Loss: 1.3898	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:38 [INFO ]  Epoch:  108	Loss: 1.2664	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:27:40 [INFO ]  Epoch:  109	Loss: 1.2880	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:27:42 [INFO ]  Epoch:  110	Loss: 1.3012	Data Time: 0.27s	Train Time: 0.01s
2022-10-11 08:27:44 [INFO ]  Epoch:  111	Loss: 1.2914	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:27:46 [INFO ]  Epoch:  112	Loss: 1.2791	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:48 [INFO ]  Epoch:  113	Loss: 1.3276	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:27:50 [INFO ]  Epoch:  114	Loss: 1.2941	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:27:52 [INFO ]  Epoch:  115	Loss: 1.2609	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:54 [INFO ]  Epoch:  116	Loss: 1.2328	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:27:56 [INFO ]  Epoch:  117	Loss: 1.2448	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:27:58 [INFO ]  Epoch:  118	Loss: 1.2460	Data Time: 0.26s	Train Time: 0.01s
2022-10-11 08:28:00 [INFO ]  Epoch:  119	Loss: 1.1584	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:02 [INFO ]  Epoch:  120	Loss: 1.2982	Data Time: 0.19s	Train Time: 0.00s
2022-10-11 08:28:04 [INFO ]  Epoch:  121	Loss: 1.2493	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:28:06 [INFO ]  Epoch:  122	Loss: 1.1982	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:28:08 [INFO ]  Epoch:  123	Loss: 1.2524	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:28:10 [INFO ]  Epoch:  124	Loss: 1.3212	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:12 [INFO ]  Epoch:  125	Loss: 1.3130	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:14 [INFO ]  Epoch:  126	Loss: 1.4161	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:16 [INFO ]  Epoch:  127	Loss: 1.2253	Data Time: 0.20s	Train Time: 0.01s
2022-10-11 08:28:18 [INFO ]  Epoch:  128	Loss: 1.3318	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:28:20 [INFO ]  Epoch:  129	Loss: 1.3228	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:28:22 [INFO ]  Epoch:  130	Loss: 1.5122	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:28:24 [INFO ]  Epoch:  131	Loss: 1.2305	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:28:26 [INFO ]  Epoch:  132	Loss: 1.2334	Data Time: 0.15s	Train Time: 0.01s
2022-10-11 08:28:28 [INFO ]  Epoch:  133	Loss: 1.2762	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:28:30 [INFO ]  Epoch:  134	Loss: 1.3422	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:28:32 [INFO ]  Epoch:  135	Loss: 1.2669	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:34 [INFO ]  Epoch:  136	Loss: 1.8893	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:28:36 [INFO ]  Epoch:  137	Loss: 1.2554	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:28:38 [INFO ]  Epoch:  138	Loss: 1.4206	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:28:40 [INFO ]  Epoch:  139	Loss: 1.3101	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:28:42 [INFO ]  Epoch:  140	Loss: 1.3620	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:28:44 [INFO ]  Epoch:  141	Loss: 1.2721	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:28:46 [INFO ]  Epoch:  142	Loss: 1.2490	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:28:48 [INFO ]  Epoch:  143	Loss: 1.3205	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:28:50 [INFO ]  Epoch:  144	Loss: 1.6433	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:28:52 [INFO ]  Epoch:  145	Loss: 1.2676	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:28:54 [INFO ]  Epoch:  146	Loss: 1.2844	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:28:56 [INFO ]  Epoch:  147	Loss: 1.2679	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:28:59 [INFO ]  Epoch:  148	Loss: 1.1721	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:29:00 [INFO ]  Epoch:  149	Loss: 1.2549	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:03 [INFO ]  Epoch:  150	Loss: 1.2047	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:29:05 [INFO ]  Epoch:  151	Loss: 1.1803	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:29:07 [INFO ]  Epoch:  152	Loss: 1.2605	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:29:09 [INFO ]  Epoch:  153	Loss: 1.1944	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:11 [INFO ]  Epoch:  154	Loss: 1.2335	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:29:13 [INFO ]  Epoch:  155	Loss: 1.1983	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:29:14 [INFO ]  Epoch:  156	Loss: 1.3012	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:29:16 [INFO ]  Epoch:  157	Loss: 1.1084	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:29:18 [INFO ]  Epoch:  158	Loss: 1.2116	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:29:20 [INFO ]  Epoch:  159	Loss: 1.4685	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:22 [INFO ]  Epoch:  160	Loss: 1.2033	Data Time: 0.24s	Train Time: 0.00s
2022-10-11 08:29:24 [INFO ]  Epoch:  161	Loss: 1.2866	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:26 [INFO ]  Epoch:  162	Loss: 1.2292	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:29:28 [INFO ]  Epoch:  163	Loss: 1.2544	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:29:30 [INFO ]  Epoch:  164	Loss: 1.5972	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:29:32 [INFO ]  Epoch:  165	Loss: 1.1473	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:29:34 [INFO ]  Epoch:  166	Loss: 1.4522	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:29:36 [INFO ]  Epoch:  167	Loss: 1.2010	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:29:38 [INFO ]  Epoch:  168	Loss: 1.2478	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:29:40 [INFO ]  Epoch:  169	Loss: 1.2459	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:29:42 [INFO ]  Epoch:  170	Loss: 1.4790	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:44 [INFO ]  Epoch:  171	Loss: 1.2495	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:29:46 [INFO ]  Epoch:  172	Loss: 1.2302	Data Time: 0.22s	Train Time: 0.01s
2022-10-11 08:29:48 [INFO ]  Epoch:  173	Loss: 1.2527	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:29:50 [INFO ]  Epoch:  174	Loss: 1.2455	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:29:52 [INFO ]  Epoch:  175	Loss: 1.2684	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:54 [INFO ]  Epoch:  176	Loss: 1.2956	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:29:56 [INFO ]  Epoch:  177	Loss: 1.2067	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:29:58 [INFO ]  Epoch:  178	Loss: 1.2172	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:30:00 [INFO ]  Epoch:  179	Loss: 1.1514	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:02 [INFO ]  Epoch:  180	Loss: 1.1491	Data Time: 0.18s	Train Time: 0.01s
2022-10-11 08:30:04 [INFO ]  Epoch:  181	Loss: 1.2623	Data Time: 0.24s	Train Time: 0.01s
2022-10-11 08:30:07 [INFO ]  Epoch:  182	Loss: 1.3110	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:30:09 [INFO ]  Epoch:  183	Loss: 1.2402	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:30:11 [INFO ]  Epoch:  184	Loss: 1.1923	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:30:13 [INFO ]  Epoch:  185	Loss: 1.1680	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:30:15 [INFO ]  Epoch:  186	Loss: 1.2270	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:30:17 [INFO ]  Epoch:  187	Loss: 1.2031	Data Time: 0.23s	Train Time: 0.01s
2022-10-11 08:30:19 [INFO ]  Epoch:  188	Loss: 1.3553	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:30:21 [INFO ]  Epoch:  189	Loss: 1.2155	Data Time: 0.19s	Train Time: 0.01s
2022-10-11 08:30:23 [INFO ]  Epoch:  190	Loss: 1.1880	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:30:24 [INFO ]  Epoch:  191	Loss: 1.2337	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:26 [INFO ]  Epoch:  192	Loss: 1.1563	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:28 [INFO ]  Epoch:  193	Loss: 1.2389	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:30 [INFO ]  Epoch:  194	Loss: 1.2286	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:32 [INFO ]  Epoch:  195	Loss: 1.2251	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:30:35 [INFO ]  Epoch:  196	Loss: 1.2259	Data Time: 0.21s	Train Time: 0.01s
2022-10-11 08:30:37 [INFO ]  Epoch:  197	Loss: 1.2019	Data Time: 0.17s	Train Time: 0.01s
2022-10-11 08:30:38 [INFO ]  Epoch:  198	Loss: 1.2056	Data Time: 0.16s	Train Time: 0.01s
2022-10-11 08:30:40 [INFO ]  Epoch:  199	Loss: 1.3815	Data Time: 0.25s	Train Time: 0.01s
2022-10-11 08:30:42 [INFO ]  Results saved to ./results/distill_adapt/SVHN/Source_FASHION_MNIST/results.pth
2022-10-11 08:30:42 [INFO ]  
2022-10-11 08:30:42 [INFO ]  Final evaluation for SVHN :
2022-10-11 08:30:46 [INFO ]  Final evaluation for SVHN evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-11 08:30:46 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-11 08:30:46 [INFO ]  	            before steps                   10.20%                   4.3045
2022-10-11 08:30:46 [INFO ]  	   step  1 (lr=0.204800)                   51.03%                   1.5997
2022-10-11 08:30:46 [INFO ]  
2022-10-11 08:30:46 [INFO ]  
2022-10-11 08:30:46 [INFO ]  Final evaluation for FASHION_MNIST :
2022-10-11 08:30:50 [INFO ]  Final evaluation for FASHION_MNIST evaluation for SVHN (evaluate 3 steps: [0, 0, 1]) test results: 
2022-10-11 08:30:50 [INFO ]  	          STEP                   ACCURACY                   LOSS          
2022-10-11 08:30:50 [INFO ]  	            before steps                   87.27%                   0.3620
2022-10-11 08:30:50 [INFO ]  	   step  1 (lr=0.204800)                   22.22%                   4.3215
2022-10-11 08:30:50 [INFO ]  
2022-10-11 08:30:50 [INFO ]  CPU Time: 3.96 minutes
